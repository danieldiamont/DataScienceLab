On Approximation Guarantees for Greedy Low Rank Optimization

A. Supplement
In this section, we provide the missing proofs.
A.1. Proof of Theorem 2
Proof. An important aspect of the assumptions is that the space of atoms spanned by S is orthogonal to the span of L.
Furthermore, span(L [ S) span(S). Let k̄ = k + r. We will first upper bound the denominator in the submodularity ratio.
From strong concavity,
mk̄
kB(L[S)
2

B(L) k2F  `(B(L) )

`(B(L[S) ) + hr`(B(L) ), B(L[S)

B(L) i

Rearranging
0  `(B(L[S) )

`(B(L) )  hr`(B(L) ), B(L[S)


arg max
X:
X=UL[S HVL[S
|L[S|⇥|L[S|
H2R

=

arg max
X:
X=UL[S HVL[S
H2R|L[S|⇥|L[S|

mk̄
kB(L[S) B(L) k2F
2
mk̄
B(L) i
kX B(L) k2F
2

B(L) i

hr`(B(L) ), X

hPUS (r`(B(L) ))PVS , X

where the last equality holds because h(r`(B(L) )), PUL XPVL
X = B(L) + m1 PUS (r`(B(L) ))PVS . Plugging in, we get,

mk̄
kX
2

B(L) i

B(L) k2F ,

B(L) i = 0. Solving the argmax problem, we get

k̄

`(B(L[S) )

`(B(L) ) 

1
kPUS (r`(B(L) ))PVS k2F
2mk̄

We next bound the numerator. Recall that the atoms in S are orthogonal to each other i.e. US and VS are both orthonormal.
(L[S)

For clarity, we define the shorthand, Bij

= hui vj> , B(L[S) i ui vj> , for i, j 2 [|L [ S|].

With an arbitrary i 2 S, and arbitrary scalars ↵ii , ↵ij , ↵ji for j 2 L,

`(B(L[{i}) )

`(B(L) )

(L[S)

`(B(L) + ↵ii Bii

+

X

(L[S)

↵ij Bij

+

j2L

hr`(B

(L)

(L[S)
), ↵ii Bii

+

X

X

(L[S)

↵ji Bji

`(B(L) )

)

j2L

(L[S)
↵ij Bij

+

j2L

X

(L[S)

↵ji Bji

j2L

i

2
3
X
X
M̃1 4 2
(L[S) 2
(L[S)
(L[S)
2
2
↵ii kBii kF +
↵ij
kBij k2F +
↵ji
kBji k2F 5 .
2
j2L

(L[S)
hr`(B(L) ), Bii i2
(L[S)
2M̃1 kBii k2F

where the last inequality follows by setting ↵ij =
Summing up for all i 2 S, we get

+

X
j2L

j2L

(L[S)
hr`(B ), Bij i2
(L[S)
2M̃1 kBij k2F

(L[S)

hr`(B(L) ),Bij

(L[S) 2
M̃1 kBij
kF

(L)

i

+

(L[S) 2

hr`(B(L) ), Bji

for j 2 L, and for j = i.

(L[S) 2
kF

2M̃1 kBji

i

!

,

On Approximation Guarantees for Greedy Low Rank Optimization

X

`(B(L[{i}) )

`(B(L) )

i2S

=

2
X hr`(B(L) ), B(L[S) i2 X
ii
4
+
(L[S) 2
2
M̃
kB
kF
1
i2S
j2L
ii

(L[S) 2

hr`(B(L) ), Bij

(L[S) 2
kF

i

2M̃1 kBij

1
kPUS r`(B(L) )PVS k2F
2M̃1

(L[S) 2

+

hr`(B(L) ), Bji

(L[S) 2
kF

2M̃1 kBji

i

!3
5

A.2. Proofs for greedy improvement
G
Let SG
f (SG
i be the support set formed by Algorithm 1 at iteration i. Define A(i) := f (Si )
i 1 ) with A(0) = 0 as the
⇤
G
greedy improvement. We also define B(i) := f (S ) f (Si ) to be the remaining amount to improve, where S? is the
optimum k-sized solution. We provide an auxiliary Lemma that uses the submodularity ratio to lower bound the greedy
improvement in terms of best possible improvement from step i.

Lemma 1. At iteration i, the incremental gain of the greedy method (Algorithm 1) is
⌧

A(i + 1)

SG
i ,r

r

B(i).

R
⇤
Proof. Let S = SG
i . Let S be the sequential orthogonalization of the atoms in S relative to S. Thus,

rA(i + 1)

|SR |A(i + 1)

⌧ |SR | max f (S [ {a}) f (S)
a2SR
X
⌧
[f (S [ {a}) f (S)]
a2SR

⌧
⌧

S,|SR | [f (S

S,|SR | B(i)

[ SR )

f (S)]

Note that the last inequality follows because f (S [ SR ) f (S⇤ ). The penultimate inequality follows by the definition of
weak submodularity, which applies in this case because the atoms in SR are orthogonal to eachother and are also orthogonal
to S.
Using Lemma 1, one can prove an approximation guarantee for Algorithm 1.
A.2.1. P ROOF OF T HEOREM 3
Proof. From the notation used for Lemma 1, A(i + 1) = B(i)

B(i + 1)  (1
From its definition, B(0) = f (S? )

[f (S? )
=)

⇥

from which the result follows.

f (;)

C)B(i)  (1

⌧

SG ,r
i

r

. From Lemma 1, we have,

C)i+1 B(0).

f (;). So we get,

f (;)]

f (SG
i )

B(i + 1). Let C =

⇤

⇥

f (SG
i )
(1

(1

⇤
f (;)  (1
i

?

C) ) [f (S )

C)i [f (S? )
f (;)]

f (;)]
1

1
e

⌧

k
SG ,r r
i

!

[f (S? )

f (;)]

On Approximation Guarantees for Greedy Low Rank Optimization

A.3. Proof for GECO bounds
Let SO
i be the support set selected by the GECO procedure (Algorithm 2) at iteration i. Similar to the section on greedy
improvement, we define some notation. Let D(i) := f (SO
f (SO
i )
i 1 ) be the improvement made at step i, and as before
we have B(i) = f (S? ) f (SO
)
be
the
remaining
amount
to
improve.
i
We prove the following auxiliary lemma which lower bounds the gain after adding the atom selected by the subroutine
OMPSelin terms of operator norm of the gradient of the current iterate and smoothness of the function.
˜ := {(X, Y) : rank(X
Lemma 2. Assume that `(·) is mi -strongly concave and Mi -smooth over matrices of in the set ⌦
Y)  1}. Then,
⌧ mr+k
D(i + 1)
B(i).
rM̃1
(L)
Proof. For simplicity, say L = SO
) i.e. we denote by B(L) the argmax
i . Recall that for a given support set L, f (L) = `(B
(L[{i})
for `(·) for a given support set L. Hence, by the optimality of B
,

D(i + 1) = `(B(L[{i}) )

`(B(L) )

`(B(L) + ↵uv> )

`(B(L) )

for an arbitrary ↵ 2 R, and the vectors u, v selected by OMPSel. Using the smoothness of the `(·), we get,

D(i + 1)
Putting in ↵ =

⌧
kr`(B(L) )k2 ,
M̃1

↵hr`(B(L) ), uv> i

↵2

M̃1
2

and by ⌧ -optimality of OMPSel, we get,
D(i + 1)

⌧2
kr`(B(L) )k22
2M̃1

Let SR be obtained from after sequentially orthogonalizing S? w.r.t. Si . By definition of the operator norm, we further get,

D(i + 1)

⌧2
kr`(B(L) )k22
2M̃1
⌧2 X
hui vi> , r`(B(L) )i2
2rM̃1 i2SR

= kPUSR r`(B(L) )PVSR k2F
⌘
R
⌧ 2 mr+k ⇣
`(BL[S ) `(B(L) )
rM̃1
⌘
?
⌧ 2 mr+k ⇣
`(BS ) `(B(L) )
rM̃1
⌧ 2 mr+k
=
B(i)
rM̃1

The proof for Theorem 4 from Lemma 2 now follows using the same steps as for Theorem 3 from Lemma 2.

On Approximation Guarantees for Greedy Low Rank Optimization

A.4. Proof for recovery bounds
A.4.1. P ROOF OF T HEOREM 5
For clarity of representation, let C = Cr,k , and for an arbitrary H 2 Rr⇥r , let Br = U>
S HVS , and
Note that has rank at most (k + r). Recall that by the mk+r RSC (Definition 3),

`(B(Sk ) )

`(Br )

hr`(Br ),

i

:= B(Sr )

Bs .

mk+r
k k2F .
2

From the approximation guarantee, we have,

`(B(Sk ) )

`(Br )

(1

C)[`(0)

`(Br )]

(Sk )

=) `(B
) `(Br ) hr`(Br ), i (1 C)[`(0) `(Br )] hr`(Br ),
mk+r
=)
k k2F (1 C)[`(0) `(Br )] hr`(Br ), i
2
1
(1 C)[`(0) `(Br )] (k + r) /2 kr`(Br )k2 k kF ,
where the last inequality is due to generalized Holder’s inequality. Using 2ab  ca2 +
we get

mk+r
kr`(Br )k22
mk+r k k2F
k k2F  (k + r)
+
+ (1
2
mk+r
4
which completes the proof.

b2
c

i

for any positive numbers a, b, c,

C)[`(Br )

`(0)],

