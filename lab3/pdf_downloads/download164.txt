Stochastic Generative Hashing

Supplementary Material
A. Distributional Derivative of Stochastic Neuron
Before we prove the lemma 3, we first introduce the chain rule of distributional derivative.
Lemma 6 (Grubb, 2008) Let u ∈ D0 (Ω), we have
1. (Chain Rule I) The distribution derivative of v = u ◦ f for any f (x) ∈ C 1 : Ω0 → Ω is given by Dv = Du ∂f
∂x .
2. (Chain Rule II) The distribution derivative of v = f ◦ u for any f (x) ∈ C 1 (R) with f 0 bounded is given by
Dv = f 0 (u)Du.
Proof of Lemma 3. Without loss of generality, we first consider 1-dimension case. Given `(h̃) : R → R, ξ ∼ U(0, 1),
h̃ : Ω → {0, 1}. For ∀φ ∈ C0∞ (Ω), we have
Z
Z


φ(x) D`(h̃(x)) dx = − φ0 (x)`(x)dx
Z 0

Z ∞
= −
φ0 (x)`(0)dx +
φ0 (x)`(1)dx
−∞
0
!
∞
0


= − φ(x) `(0) + φ(x) `(1)
−∞

=

0

(`(1) − `(0)) φ(0)

where the last equation comes from φ ∈ C0∞ (Ω). We obtain
D`(h̃) = (`(1) − `(0))δ(h) := ∆`(h).
l

We generalize the conclusion to l-dimension case with expectation over ξ, i.e., h̃(·, ξ) : Ω → {0, 1} , we have the partial
distributional derivative for hk-th coordinate
as
i
h
i
h
i
Dk E{ξi }l
`(h̃(z, ξ)) = E{ξi }l
Dk `(h̃(z, ξ)) = E{ξi }l
(`(h̃1k ) − `(h̃0k )) .
i=1

i=1

i=1,i6=k

Therefore, we have the distributional derivative w.r.t. W as
h
i
h
i
DE{ξi }l
`(h̃(σ(W > x), ξ)) = E{ξi }l
Dk `(h̃(σ(W > x), ξ))
i=1
i=1
h
i
chain rule I = E{ξi }l
Dh̃k `(h̃(σ(W > x), ξ))∇W σ(W > x)
h i=1
 i
= Eξ ∆h̃ `(h̃(σ(W > x), ξ))σ(W > x) • 1 − σ(W > x) x> .

To derive the approximation of the distributional derivative, we exploit the mean value theorem and Taylor expansion.
Specifically, for a continuous and differential loss function `(·), there exists  ∈ (0, 1)
h
i
∂h̃k `(h̃)|h̃k = = ∆h̃ `(h̃) .
k

Moreover, for general smooth functions, we rewrite the ∂h̃i `(h̃)|h̃i = by Taylor expansion, i.e.,
∂h̃k `(h̃)|h̃i = = ∂h̃k `(h̃)|h̃i =1 + O()
∂h̃k `(h̃)|h̃i = = ∂h̃k `(h̃)|h̃i =0 + O().
we have an approximator as
h
i
∂h̃k `(h̃)|h̃k = ≈ σ(wk> x)∂h̃k `(h̃)|h̃k =1 + (1 − σ(wk> x))∂h̃k `(h̃)|h̃k =0 = Eξ ∇h̃ `(h̃, ξ) .

(13)

Plugging into the distributional derivative estimator (7), we obtain a simple biased gradient estimator,
h
i
DW H̃(Θ; x) ≈ D̃W H̃(Θ; x) := Eξ ∇h̃ `(h̃(σ(W > x), ξ))σ(W > x) • (1 − σ(W > x))x> .

(14)

Stochastic Generative Hashing

B. Convergence of Distributional SGD
Lemma 7 (Ghadimi and Lan, 2013) Under the assumption that H is L-Lipschitz smooth and the variance of the stochastic
t
distributional gradient (8) is bounded by σ 2 , the proposed distributional SGD outputs {Θi }i=1 ,
 
t 
t
2 
X
Lσ 2 X 2
L


γi − γi2 E ∇Θ H̃(Θi ) 6 H̃(Θ0 ) − H̃(Θ∗ ) +
γi ,
2
2 i=1
i=1

where Θt = {Wt , Ut , βt , ρt }.
Proof of Theorem 5. Lemma 7 implies that by randomly sampling a search point ΘR with probability P (R = i) =
√
2γ −Lγi2
t
Pt i
t from trajectory {Θi }i=1 , we have
2 where γi ∼ O 1/
i=1 2γi −Lγi
 

2 
1


E ∇Θ H̃(ΘR ) ∼ O √ .
t

Lemma 8 Under the assumption that the variance of the approximate stochastic distributional gradient (10) is bounded
t
by σ 2 , the proposed distributional SGD outputs {Θi }i=1 such that
!
t
t
h
i 1
h
i X
X
∗ > ˜
2 2
∗ 2
γi E (Θi − Θ ) ∇Θ H̃(Θi ) 6
γi σ ,
E kΘ0 − Θ k +
2
i=1
i=1
where Θ∗ denotes the optimal solution.
Proof Denote the optimal solution as Θ∗ , we have



2
b̃ H̃(Θ , x ) − Θ∗ )2
kΘi+1 − Θ∗ k = Θi − γi ∇

Θ
i
i

2
 b̃

2
∗ > b̃
= kΘi − Θ∗ k + γi2 ∇
H̃(Θ
,
x
)
Θ
i
i  − 2γi (Θi − Θ ) ∇Θ H̃(Θi , xi ).
2

Taking expectation on both sides and denoting aj = kΘj − Θ∗ k , we have
i
h
> ˜
2 2
E [ai+1 ] 6 E [ai ] − 2γi E (Θi − Θ∗ ) ∇
Θ H̃(Θi ) + γi σ .
Therefore,
t
X

i 1
h
> ˜
γi E (Θi − Θ∗ ) ∇
Θ H̃(Θi ) 6
2
i=1

E [a0 ] +

t
X

!
γi2 σ 2

.

i=1

Theorem 9 Under the assumption that the variance of the approximate stochastic distributional gradient (10) is bounded
t
by σ 2 , for the solution ΘR sampled from the trajectory {Θi }i=1 with probability P (R = i) = Ptγi γi where γi ∼
i=1
√
O 1/ t , we have
 
h
i
> ˜
E (ΘR − Θ∗ ) ∇
Θ H̃(ΘR ) ∼ O

1
√
t

,

where Θ∗ denotes the optimal solution.
Proof The lemma 8 implies by randomly sampling a search point ΘR with probability P (R = i) =
√
t
γi ∼ O 1/ t from trajectory {Θi }i=1 , we have
i P
h
 
h
i E kΘ0 − Θ∗ k2 + ti=1 γi2 σ 2
1
> ˜
√ .
E (ΘR − Θ∗ ) ∇
H̃(Θ
)
6
∼
O
Pt
Θ
R
t
2 i=1 γi

Ptγi

i=1

γi

where

Stochastic Generative Hashing

C. More Experiments
C.1. Convergence of Distributional SGD and Reconstruction Error Comparison
1.2
8 bits ITQ
16 bits ITQ
32 bits ITQ
64 bits ITQ
8 bits SGH
16 bits SGH
32 bits SGH
64 bits SGH

20

8 bits ITQ
16 bits ITQ
32 bits ITQ
64 bits ITQ
8 bits SGH
16 bits SGH
32 bits SGH
64 bits SGH

1.1

L2 reconstruction error

25

L2 reconstruction error

GIST L2 reconstruction error

MNIST L2 reconstruction error

30

15

10

1
0.9
0.8
0.7
0.6
0.5
0.4

5
0

0.5

1

1.5

2

number of samples visited

0

2.5

0.5

1

1.5

number of samples visited

# 10 6

(a) MNIST

2

2.5
# 10 6

(b) GIST-1M

Figure 4: L2 reconstruction error convergence on MNIST and GIST-1M of ITQ and SGH over the course of training with
varying of the length of the bits (8, 16, 32, 64, respectively). The x-axis represents the number of examples seen by the
training algorithm. For ITQ, it sees the training dataset once in one iteration.
We shows the reconstruction error comparison between ITQ and SGH on MNIST and GIST-1M in Figure 4. The results
are similar to the performance on SIFT-1M. Because SGH optimizes a more expressive objective than ITQ (without
orthogonality) and do not use alternating optimization, it find better solution with lower reconstruction error.
C.2. Training Time Comparison
MNIST Training Time

1200

2

GIST Training Time

# 10 4

BA
SGH

800
600
400
200
0

Training Time (sec)

Training Time (sec)

1000
1.5

0.5

0

8

16

32

bits of hashing codes

(a) MNIST

64

BA
SGH

1

8

16

32

64

bits of hashing codes

(b) GIST-1M

Figure 5: Training time comparison between BA and SGH on MNIST and GIST-1M.
We shows the training time comparison between BA and SGH on MNIST and GIST-1M in Figure 5. The results are
similar to the performance on SIFT-1M. The proposed distributional SGD learns the model much faster.
C.3. More Evaluation on L2NNS Retrieval Tasks
We also use different RecallK@N to evaluate the performances of our algorithm and the competitors. We first evaluated
the performance of the algorithms with Recall 1@N in Figure 6. This is an easier task comparing to K = 10. Under such
measure, the proposed SGH still achieve the state-of-the-art performance.
In Figure 7, we set K, N = 100 and plot the recall by varying the length of the bits on MNIST, SIFT-1M, and GIST-1M.
This is to show the effects of length of bits in different baselines. Similar to the Recall10@N, the proposed algorithm still
consistently achieves the state-of-the-art performance under such evaluation measure.

Stochastic Generative Hashing

D. Stochastic Generative Hashing For Maximum Inner Product Search
In Maximum Inner Product Search (MIPS) problem, we evaluate the similarity in terms of inner product which can avoid
the scaling issue, i.e., the length of the samples in reference dataset and the queries may vary. The proposed model can also
be applied to the MIPS problem. In fact, the Gaussian reconstruction model also preserve the inner product neighborhoods.
Denote the asymmetric inner product as x> U hy , we claim
Proposition 10 The Gaussian reconstruction error is a surrogate for asymmetric inner product preservation.
Proof We evaluate the difference between inner product and the asymmetric inner product,

kx> y − x> U > hy k2 = kx> y − U > hy k2 6 kxk2 ky − U > hy k2 ,
which means minimizing the Gaussian reconstruction, i.e., − log p(x|h), error will also lead to asymmetric inner product
preservation.
We emphasize that our method is designed for hashing problems primarily. Although it can be used for MIPS problem, it is
different from the product quantization and its variants whose distance are calculated based on lookup table. The proposed
distributional SGD can be extended to quantization. This is out of the scope of this paper, and we will leave it as the future
work.
D.1. MIPS Retrieval Comparison
To evaluate the performance of the proposed SGH on MIPS problem, we tested the algorithm on WORD2VEC dataset for
MIPS task. Besides the hashing baselines, since KMH is the Hamming distance generalization of PQ, we replace the KMH
with product quantization (Jegou et al., 2011). We trained the SGH with 71,291 samples and evaluated the performance
with 10,000 query. Similarly, we vary the length of binary codes from 16, 32 to 64, and evaluate the performance by Recall
10@N. We calculated the ground-truth via retrieval through the original inner product. The performances are illustrated
in Figure 8. The proposed algorithm outperforms the competitors significantly, demonstrating the proposed SGH is also
applicable to MIPS task.

E. Generalization
We generalize the basic model to translation and scale invariant extension, semi-supervised extension, as well as coding
with h ∈ {−1, 1}l .
E.1. Translation and Scale Invariant Reduced-MRFs
As we known, the data may not zero-mean, and the scale of each sample in dataset can be totally different. To eliminate
the translation and scale effects, we extend the basic model to translation and scale invariant reduced-MRFs by introducing
parameter α to separate the translation effect and the latent variable z to model the scale effect in each sample x, therefore,
the potential function becomes
1
E(x, h, z) = −β > h + 2 (x − α − U > (z · h))> (x − α − U > (z · h)),
(15)
2ρ
where · denotes element-wise product, α ∈ Rd and z ∈ Rl . Comparing to (2), we replace U > h with U > (z · h) + α so that
the translation and scale effects in both dimension and sample are modeled explicitly.
We treat the α as parameters and z as latent variable. Assume the independence in posterior for computational efficiency,
we approximate the posterior p(z, h|x) with q(h|x; Wh )q(z|x; Wz ), where Wh , Wz denotes the parameters in the posterior
approximation. With similar derivation, we obtain the learning objective as
N
1 X
max
Eq(h|xi )q(z|xi ) [−E(x, h, z) − log q(h|xi ) − log q(z|xi )] .
(16)
U,α,β,ρ;Wh ,Wz N
i=1
Obviously, the proposed distributional SGD is still applicable to this optimization.
E.2. Semi-supervised Extension
Although we only focus on learning the hash function in unsupervised setting, the proposed model can be easily extended to
exploit the supervision information by introducing pairwise model, e.g., (Zhang et al., 2014a; Zhu et al., 2016). Specifically,

Stochastic Generative Hashing

we are provided the (partial) supervision information for some pairs of data, i.e., S = {xi , xi , yij }M
i,j , where
(
1
if xi ∈ N N (xj ) or xj ∈ N N (xi )
yij =
,
0
o.w.
and N N (x) stands for the set of nearest neighbors of x. Besides the original Gaussian reconstruction model in the basic
model in (2), we introduce the pairwise model p(yij |hi , hj ) = B(σ(h>
i hj )) into the framework, which results the joint
distribution over x, y, h as
p(xi , xj , hi , hj , yij ) = p(xi |hi )p(xj |hj )p(hi )p(hj )p(yij |hi , hj )1S (ij) ,
where 1S (ij) is an indicator that outputs 1 when (xi , xj ) ∈ S, otherwise 0. Plug the extended model into the Helmholtz
free energy, we have the learning objective as,
N2

1 X
max
Eq(hi |xi )q(hj |xj ) [log p(xi , xj , hi , hj )] + Eq(hi |xi )q(hj |xj ) [1S (ij) log p(yij |hi , hj )]
U,β,ρ;W N 2
i,j=1

−Eq(hi |xi )q(hj |xi ) [log q(hj |xj )q(hj |xi )] ,
Obviously, the proposed distributional SGD is still applicable to the semi-supervised extension.
E.3. {±1}-Binary Coding
In the main text, we mainly focus on coding with {0, 1}. In fact, the proposed model is applicable to coding with {−1, 1}
with minor modification. Moreover, the proposed distributional SGD is still applicable. We only discuss the basic model
here, the model can also be extended to scale-invariant and semi-supervised variants.
If we set h ∈ {−1, 1}l , the potential function of basic reduced-MRFs (2) does not have any change, i.e.,

1
E(x, h) = −β > h + 2 x> x + h> U > U h − 2x> U h .
2ρ
We need to modify the parametrization of q(h|x) as
q(h|x) =

l
Y

σ(wi> x)

1+hi
2

 1−hi
1 − σ(wi> x) 2 .

(17)

(18)

i=1

Therefore, the stochastic neuron becomes
(
f (z, ξ) :=

1
−1

if σ(z) > ξ
.
if σ(z) < ξ

With similar derivation, we have the distributional derivative of the objective w.r.t. W as


∇W Lsn = Eξ ∆f `(f (z, ξ))∇z σ(z)x> ,
where [∆f `(f (z, ξ))]k =

`(fk1 )

−

(19)

`(fk−1 ).

Furthermore, we have a similar biased gradient estimator as


˜ W Lsn = Eξ ∇f `(f (z, ξ))∇z σ(z)x> .
∇

Plug these modification into the model and algorithm, we can learn a {−1, 1}-encoding function.

(20)

Stochastic Generative Hashing

MNIST 16 bit Recall 1@M

0.8

0.9

0.7

0.8

Recall

0.5

SGH
BA
SpH
SH
ITQ
KMH
GH

0.4
0.3
0.2
0.1

0.9
0.8

SGH
BA
SpH
SH
ITQ
KMH
GH

0.6
0.5
0.4
0.3

400

600

800

1000

0

SIFT1M 16 bit Recall 1@M

0.15

0

400

600

800

1000

SIFT1M 64 bit Recall 1@M

0.9

400

600

800

0.6

SGH
BA
SpH
SH
ITQ
KMH
GH

0.3

0.5

0.2
0.1
0

0

200

400

600

800

0

1000

SIFT1B 16 bit Recall 1@M

SIFT1B 32 bit Recall 1@M

0.12

200

400

600

800

1000

M - number of retrieved items

M - number of retrieved items

SGH
ITQ

SGH
BA
SpH
SH
ITQ
KMH
GH

0.4
0.3

0

1000

M - number of retrieved items

7

200

M - number of retrieved items

0.4

0.1

# 10 -3

0

0.7

0.05

8

1000

0.5

0.2

200

800

0.8

0.1

0

600

0.6

Recall

0.2

400

SIFT1M 32 bit Recall 1@M

0.7

0.25

Recall

200

M - number of retrieved items

SGH
BA
SpH
SH
ITQ
KMH
GH

0.3

0.4

0.1

0

M - number of retrieved items

0.35

0.5

0.2

0.1

Recall

200

0.6

0.3

0
0

SGH
BA
SpH
SH
ITQ
KMH
GH

0.7

0.2

0

MNIST 64 bit Recall 1@M

1

0.7

0.6

Recall

MNIST 32 bit Recall 1@M

1

Recall

0.9

SIFT1B 64 bit Recall 1@M

0.4
0.35

0.1
0.3

6
0.08

4
3

Recall

0.25

Recall

Recall

5
0.06

SGH
ITQ

0.04
2

0.2
0.15

SGH
ITQ

0.1

0.02
1

0.05

0

0
200

400

600

800

1000

M - number of retrieved items

600

800

1000

0

0.3
0.25

0.1

0.2

200

400

600

800

1000

M - number of retrieved items
GIST 64 bit Recall 1@M

0.6

SGH
BA
SpH
SH
ITQ
KMH
GH

0.35

Recall

0.15

400

GIST 32 bit Recall 1@M

0.4

SGH
BA
SpH
SH
ITQ
KMH
GH

0.2

200

M - number of retrieved items

GIST 16 bit Recall 1@M

0.25

Recall

0
0

SGH
BA
SpH
SH
ITQ
KMH
GH

0.5

0.4

Recall

0

0.15

0.3

0.2
0.1

0.05

0.1
0.05
0
0

200

400

600

800

M - number of retrieved items

1000

0

0
0

200

400

600

800

M - number of retrieved items

1000

0

200

400

600

800

1000

M - number of retrieved items

Figure 6: L2NNS comparison on MNIST, SIFT-1M, SIFT-1B, and GIST-1M with the length of binary bits from 16 to
64. We evaluate the performance with Recall 1@M , where M increasing to 1000.

0.25

0.4

0.2

SGH
BA
SpH
SH
ITQ
KMH
GH

0.3
0.2
0.1
0

8

16

32

0.08

SGH
BA
SpH
SH
ITQ
KMH
GH

0.15
0.1
0.05
0

64

8

16

bits of hashing code

(a) L2NNS on MNIST

Recall 100@100

0.5

Recall 100@100

Recall 100@100

Stochastic Generative Hashing

32

SGH
BA
SpH
SH
ITQ
KMH
GH

0.06

0.04

0.02

0

64

8

16

32

64

bits of hashing code

bits of hashing code

(b) L2NNS on SIFT-1M

(c) L2NNS on GIST-1M

Figure 7: L2NNS comparison on MNIST, SIFT-1M, and GIST-1M with Recall 100@100 for the length of bits from 8 to
64.

Recall

0.3
0.25

0.5

0.2

WORD2VEC 64 bit Recall 10@M

0.8

SGH
BA
SpH
SH
ITQ
PQ

0.6

Recall

0.35

WORD2VEC 32 bit Recall 10@M

0.7

SGH
BA
SpH
SH
ITQ
PQ

0.4

0.4

0.7
0.6
0.5

Recall

WORD2VEC 16 bit Recall 10@M

0.45

0.3

0.4

SGH
BA
SpH
SH
ITQ
PQ

0.3

0.15
0.2

0.2

0.1
0.1

0.05
0

0.1
0

0
0

200

400

600

800

M - number of retrieved items

1000

0

200

400

600

800

M - number of retrieved items

1000

0

200

400

600

800

1000

M - number of retrieved items

Figure 8: MIPS comparison on WORD2VEC with the length of binary bits from 16 to 64. We evaluate the performance with
Recall 10@M , where M increasing to 1000.

