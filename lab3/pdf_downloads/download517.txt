Supplementary Material for “Semi-Supervised Classification
Based on Classification from Positive and Unlabeled Data”
Tomoya Sakai 1 2

Marthinus Christoffel du Plessis

Gang Niu 1

Masashi Sugiyama 2 1

A. Proofs of Theorems
In this section, we give the proofs of Theorems in Section 4.
A.1. Proof of Theorem 1
Recall that
γ
RN-PUNU
(g) = (1 − γ)RN-PU (g) + γRN-NU (g)
γ
RN-PNPU
(g)
γ
RN-PNNU
(g)

= (2 − 2γ)θP RP (g) + 2γθN RN (g) + (1 − γ)RU,N (g) + γRU,P (g) + Const,
= (1 − γ)RPN (g) + γRN-PU (g)

= (1 + γ)θP RP (g) + (1 − γ)θN RN (g) + γRU,N (g) + Const,
= (1 − γ)RPN (g) + γRN-NU (g)
= (1 − γ)θP RP (g) + (1 + γ)θN RN (g) + γRU,P (g) + Const.

bP (g), R
bN (g), R
bU,P (g) and R
bU,N (g) be the empirical risks. In order to prove Theorem 1, the following concentration
Let R
lemma is needed:
Lemma 1 For any δ > 0, we have these uniform deviation bounds with probability at least 1 − δ/3:
bP (g)) ≤ C√w Cφ +
supg∈G (RP (g) − R
nP

bN (g)) ≤ C√w Cφ +
supg∈G (RN (g) − R
nN

bU,P (g)) ≤ C√w Cφ +
supg∈G (RU,P (g) − R
nU

bU,N (g)) ≤ C√w Cφ +
supg∈G (RU,N (g) − R
nU

s

s
s
s

ln(3/δ)
,
2nP
ln(3/δ)
,
2nN
ln(3/δ)
,
2nU
ln(3/δ)
.
2nU

All inequalities in Lemma 1 are from the basic uniform deviation bound using the Rademacher complexity (Mohri et al.,
2012), Talagrand’s contraction lemma (Ledoux & Talagrand, 1991), as well as the fact that the Lipschitz constant of ℓR is
1/2. For these reasons, the detailed proof of Lemma 1 is omitted.
1

The University of Tokyo, Japan 2 RIKEN, Japan. Correspondence to: Tomoya Sakai <sakai@ms.k.u-tokyo.ac.jp>.

Proceedings of the 34 th International Conference on Machine Learning, Sydney, Australia, PMLR 70, 2017. Copyright 2017 by the
author(s).

Supplementary Material for “Semi-Supervised Classification Based on Classification from Positive and Unlabeled Data”
γ
Consider RN-PNPU
(g). It is clear that
γ
bγ
supg∈G (RN-PNPU
(g) − R
N-PNPU (g))

bP (g)) + (1 − γ)θN supg∈G (RN (g) − R
bN (g)) + γ supg∈G (RU,N (g) − R
bU,N (g)).
≤ (1 + γ)θP supg∈G (RP (g) − R

Therefore, by applying Lemma 1, for any δ > 0, it holds with probability at least 1 − δ that
γ
bγ
supg∈G (RN-PNPU
(g) − R
N-PNPU (g)) ≤

1
Cw,φ,δ · χ(1 + γ, 1 − γ, γ).
2

γ
Since I(g) ≤ 2RN-PNPU
, with the same probability,

bγ
supg∈G (I(g)−2R
N-PNPU (g)) ≤ Cw,φ,δ ·χ(1 + γ, 1 − γ, γ).

bγ
Similarly, supg∈G (I(g) − 2R
N-PNNU (g)) ≤ Cw,φ,δ · χ(1 − γ, 1 + γ, γ) with probability at least 1 − δ.

γ
Finally, RN-PUNU
(g) is slightly more involved, for that there are both RU,P (g) and RU,N (g). From ℓR (m) + ℓR (−m) = 1,
we can know RU,P (g) + RU,N (g) = 1 and then
(
(2γ − 1)RU,P (g) + Const γ ≥ 1/2,
(1 − γ)RU,N (g) + γRU,P (g) =
(1 − 2γ)RU,N (g) + Const γ < 1/2.

bγ
As a result, supg∈G (I(g) − 2R
N-PUNU (g)) ≤ Cw,φ,δ · χ(2 − 2γ, 2γ, |2γ − 1|) with probability at least 1 − δ.

A.2. Proof of Theorem 2
In fact,



1/4
ℓTS (m) = (m − 1)2 /4


0

m ≤ 0,
0 < m ≤ 1,
m > 1,

and after plugging this ℓTS (m) into ℓeTS (m),

ℓeTS (m) = ℓTS (m) − ℓTS (−m)

1/4



1/4 − (m + 1)2 /4
=

(m − 1)2 /4 − 1/4



−1/4

m ≤ −1,
−1 < m ≤ 0,
0 < m ≤ 1,
m > 1.

It is easy to see that ℓTS (m) and ℓeTS (m) are Lipschitz continuous with the same Lipschitz constant 1/2.

Next, recall that

γ
RC-PUNU
(g) = (1 − γ)RC-PU (g) + γRC-NU (g)
′
′
= (1 − γ)θP RP
(g) + γθN RN
(g) + (1 − γ)RU,N (g) + γRU,P (g),

γ
RC-PNPU
(g) = (1 − γ)RPN (g) + γRC-PU (g)
′
= (1 − γ)θP RP (g) + (1 − γ)θN RN (g) + γθP RP
(g) + γRU,N (g),

γ
RC-PNNU
(g) = (1 − γ)RPN (g) + γRC-NU (g)
′
= (1 − γ)θP RP (g) + (1 − γ)θN RN (g) + γθN RN
(g) + γRU,P (g).

bP (g), R
bN (g), R
bU,P (g), R
bU,N (g), R
b′ (g) and R
b′ (g) be the empirical risks. Again, the following concentration
Let R
P
N
lemma is needed:

Supplementary Material for “Semi-Supervised Classification Based on Classification from Positive and Unlabeled Data”

Lemma 2 For any δ > 0, we have these uniform deviation bounds with probability at least 1 − δ/4:
s
C
C
bP (g)) ≤ √w φ + ln(4/δ) ,
supg∈G (RP (g) − R
nP
32nP
s
bN (g)) ≤ C√w Cφ + ln(4/δ) ,
supg∈G (RN (g) − R
nN
32nN
s
bU,P (g)) ≤ C√w Cφ + ln(4/δ) ,
supg∈G (RU,P (g) − R
nU
32nU
s
bU,N (g)) ≤ C√w Cφ + ln(4/δ) ,
supg∈G (RU,N (g) − R
nU
32nU
s
′
b′ (g)) ≤ C√w Cφ + ln(4/δ) ,
supg∈G (RP
(g) − R
P
nP
8nP
s
′
b′ (g)) ≤ C√w Cφ + ln(4/δ) .
supg∈G (RN
(g) − R
N
nN
8nN
The detailed proof of Lemma 2 is omitted for the same reason as Lemma 1. The difference is due to that 0 ≤ ℓTS (m) ≤ 1/4
and −1/4 ≤ ℓeTS (m) ≤ 1/4 whereas 0 ≤ ℓR (m) ≤ 1 just like 0 ≤ ℓ0-1 (m) ≤ 1. For convenience, we will relax 1/32 to
1/8 in the square root for RP (g), RN (g), RU,P (g), RU,N (g).
γ
Consider RC-PUNU
(g). By applying Lemma 2, for any δ > 0, it holds with probability at least 1 − δ that
γ
bγ
supg∈G (RC-PUNU
(g) − R
C-PUNU (g)) ≤

1 ′
C
· χ(1 − γ, γ, 1).
4 w,φ,δ

γ
Since I(g) ≤ 4RC-PUNU
, with the same probability,

′
bγ
supg∈G (I(g) − 4R
C-PUNU (g)) ≤ Cw,φ,δ · χ(1 − γ, γ, 1).

The other two generalization error bounds can be proven similarly.
A.3. Proofs of Theorems 3 and 4

bγ
b
Note that g is independent of the data for evaluating R
N-PUNU (g), since it is fixed in the evaluation. Thus, VarP [RP (g)] =
2
2
bN (g)] = σ (g)/nN . When nU → ∞,
σP (g)/nP and VarN [R
N
2 2
2 2
bγ
b
b
Var[R
N-PUNU (g)] = 4(1 − γ) θP VarP [RP (g)] + 4γ θN VarN [RN (g)]

= 4(1 − γ)2 ψP + 4γ 2 ψN

= 4(ψP + ψN )γ 2 − 8ψP γ + 4ψP ,

bγ
and it is obvious that γN-PUNU ∈ [0, 1]. All other claims in Theorem 3 follow from that Var[R
N-PUNU (g)] is quadratic
γ
b
b
in γ, that Var[RN-PUNU (g)] = Var[RPN (g)] at γ = 1/2, and that γN-PUNU < 1/2 if ψP < ψN or γN-PUNU > 1/2 if
ψP > ψN .

Likewise, when nU → ∞,

2
2
bγ
Var[R
N-PNPU (g)] = (1 + γ) ψP + (1 − γ) ψN ,
bγ
Var[R
(g)] = (1 − γ)2 ψP + (1 + γ)2 ψN ,
N-PNNU

and γN-PNPU ≥ 0 if ψP ≤ ψN or γN-PNNU ≥ 0 if ψP ≥ ψN . The rest of proof of Theorem 4 is analogous to that of
Theorem 3.

Supplementary Material for “Semi-Supervised Classification Based on Classification from Positive and Unlabeled Data”

B. Experimental Setting
Here, we summarized the experimental settings.
B.1. Implementation in Our Experiments
We implemented the ER by ourselves, and for the other methods, we used the codes available at the authors’ websites:
• LapSVM: http://www.dii.unisi.it/~melacci/lapsvmp/
• SMIR: http://www.ms.k.u-tokyo.ac.jp/software/SMIR.zip
• WellSVM: http://lamda.nju.edu.cn/code_WellSVM.ashx
• S4VM: http://lamda.nju.edu.cn/files/s4vm.rar.
Note that we modified the original code of the S4VM for transductive learning to inductive learning according to Li &
Zhou (2015).
B.2. Parameter Candidates in Our Experiments
The regularization parameters for all the methods were chosen from {10−5 , 10−4 , . . . , 102 }, except the regularization
parameter of the SMIR for the squared loss mutual information (SMI) and that of the S4VM for labeled data. The number
of nearest-neighbors to construct Laplacian matrix for the LapSVM was chosen from the candidates {5, 6, . . . , 10}. The
combination parameter η of PNU classification was chosen from {−1, −0.9, . . . , 1}, and γ of PUNU classification was
chosen from {0, 0.05, . . . , 1}. We chose these hyper-parameters by five-fold cross-validation. The parameter for the ℓ2 regularizer of the SMIR is set at γS /(n · mink∈{±1} p(y = k)) + 0.001, where γS is the regularization parameter for the
SMI. The regularization parameter of the S4VM for the labeled data is set at 1. The other parameters were set at the default
values.
B.3. Data Set Description of Image Classification Data Set
Table 1 is the description of the data sets used in the image classification experiment.
Table 1. The description of the data set used in the image classification experiment.
Data set
Data sources
#Samples
Arts

Art Gallery
vs.
Art Studio

(mP = 15000)
(mN = 15000)

Deserts

Desert Sand
(mP = 15000)
vs.
Desert Vegetation (mN = 5556)

Fields

Field Wild
vs.
Field Cultivated

(mP = 15000)
(mN = 8117)

Stadiums

Stadium Baseball (mP = 15000)
vs.
Stadium Football (mN = 15000)

Platforms

Subway Station
vs.
Train Station

Temples

Temple East Asia (mP = 8691)
vs.
Temple South Asia (mN = 7178)

(mP = 5597)
(mN = 15000)

Supplementary Material for “Semi-Supervised Classification Based on Classification from Positive and Unlabeled Data”

C. Supplementary Results for Experimental Analyses
Figure 1 and Figure 2 respectively show the results of variance reduction and comparison of validation scores. The details
of experimental setting and the interpretation of results can be found in Section 5.1.
4

1.5

1

1.6

Ratio of Variance

θP = 0.3
θP = 0.5
θP = 0.7

Ratio of Variance

Ratio of Variance

2

3
2
1
0

0.5
0

50

100

150

200

250

1.2
1
0.8
0.6

0

300

1.4

50

100

150

200

250

300

0

50

nvU

nvU

(a) Banana (d = 2)

100

150

200

250

300

nvU

(b) Waveform (d = 21)

(c) Splice (d = 60)

θP = 0.3
θP = 0.5
θP = 0.7

1

0.95
0

50

100 150 200 250 300

nvU

(a) Banana (d = 2)

1.1
1.05
1
0.95
0.9
0

50

100 150 200 250 300

nvU

(b) Waveform (d = 21)

Ratio of Misclassification Rate

1.05

Ratio of Misclassification Rate

Ratio of Misclassification Rate

Figure 1. Average and standard error of the ratio between the variance of the empirical PNU risk and that of the PN risk,
b
bη (b
gPN )], as a function of the number of unlabeled samples over 100 trials. Although the variance reduction
Var[R
PNU gPN )]/ Var[RPN (b
is proved for an infinite number of samples, it can be observed with a finite number of samples.

1.04
1.02
1
0.98
0.96
0

50

100 150 200 250 300

nvU

(c) Splice (d = 60)

PNU
PN
Figure 2. Average and standard error of the ratio between the misclassification rate of gbPN
and that of gbPN
as a function of unlabeled
samples over 1000 trials. In many cases, the ratio becomes less than 1 or at worst almost 1, implying that the PNU risk is a promising
alternative to the standard PN risk in validation if unlabeled data is available.

Supplementary Material for “Semi-Supervised Classification Based on Classification from Positive and Unlabeled Data”

D. Magnified Versions of Experimental Results
Here, we show magnified versions of the experimental results in Section 5.
Table 2. Magnified version of Table 1: Average and standard error of the misclassification rates of each method over 50 trials for
benchmark data sets. Boldface numbers denote the best and comparable methods in terms of average misclassifications rate according
to a t-test at a significance level of 5%. The bottom row gives the number of best/comparable cases of each method.
Data set nL
PNU
PUNU
ER
LapSVM
SMIR
WellSVM
S4VM
Banana 10 30.1 (1.0) 32.1 (1.1) 35.8 (1.0) 36.9 (1.0) 37.7 (1.1) 41.8 (0.6) 45.3 (1.0)
d=2
50 19.0 (0.6) 26.4 (1.2) 20.6 (0.7) 21.3 (0.7) 21.1 (1.0) 42.6 (0.5) 38.7 (0.9)
Phoneme
d=5

10 32.5 (0.8) 33.5 (1.0) 33.4 (1.2) 36.5 (1.5) 36.4 (1.2) 28.4 (0.6) 33.7 (1.4)
50 28.1 (0.5) 32.8 (0.9) 27.8 (0.6) 27.0 (0.8) 28.6 (1.0) 26.8 (0.4) 25.1 (0.2)

Magic
d = 10

10 31.7 (0.8) 34.1 (0.9) 34.2 (1.1) 37.9 (1.3) 36.0 (1.2) 30.1 (0.8) 33.3 (0.9)
50 29.9 (0.8) 33.4 (0.9) 30.9 (0.5) 31.0 (0.9) 30.8 (0.9) 28.8 (0.8) 29.2 (0.4)

Image
d = 18

10 29.8 (0.9) 31.7 (0.8) 33.7 (1.1) 36.6 (1.2) 36.7 (1.2) 34.7 (1.1) 35.9 (1.0)
50 20.7 (0.8) 26.6 (1.1) 20.8 (0.8) 20.3 (1.0) 20.9 (0.9) 27.2 (1.0) 23.2 (0.7)

Susy
d = 18

10 44.6 (0.6) 45.0 (0.6) 47.7 (0.4) 48.2 (0.4) 45.1 (0.7) 48.0 (0.3) 46.8 (0.3)
50 38.9 (0.6) 41.5 (0.6) 37.9 (0.7) 43.1 (0.6) 43.9 (0.8) 43.8 (0.7) 42.1 (0.4)

German
d = 20

10 40.8 (0.9) 42.4 (0.7) 43.6 (0.9) 45.9 (0.7) 46.2 (0.8) 42.4 (0.8) 42.0 (0.7)
50 36.2 (0.8) 39.0 (0.8) 38.9 (0.6) 40.6 (0.6) 38.4 (1.1) 38.5 (1.0) 34.9 (0.5)

Waveform 10 17.4 (0.6) 18.0 (0.9) 18.5 (0.6) 24.9 (1.4) 18.0 (1.0) 16.7 (0.6) 20.8 (0.8)
d = 21 50 16.3 (0.6) 23.7 (1.2) 14.2 (0.4) 18.1 (0.8) 15.4 (0.6) 15.5 (0.5) 15.3 (0.3)
ijcnn1
d = 22

10 43.6 (0.6) 40.3 (1.0) 49.7 (0.1) 49.2 (0.3) 44.0 (1.0) 45.9 (0.7) 49.3 (0.8)
50 34.5 (0.8) 37.1 (0.9) 35.5 (0.8) 33.4 (1.1) 49.4 (0.3) 46.2 (0.8) 48.6 (0.4)

g50c
d = 50

10 11.4 (0.6) 12.5 (0.6) 23.3 (2.3) 39.8 (1.6) 21.9 (1.3)
50 12.5 (1.1) 10.1 (0.6) 8.7 (0.4) 22.5 (1.5) 10.6 (0.6)

covtype
d = 54

10 46.2 (0.4) 46.0 (0.4) 46.0 (0.5) 47.1 (0.5) 47.9 (0.5) 46.9 (0.6) 46.4 (0.4)
50 41.3 (0.5) 42.3 (0.5) 41.0 (0.4) 41.5 (0.5) 46.2 (0.8) 43.6 (0.6) 40.8 (0.4)

6.6 (0.4) 27.0 (1.4)
7.4 (0.4) 12.1 (0.5)

Spambase 10 27.2 (0.9) 28.1 (1.1) 31.8 (1.4) 39.7 (1.4) 30.9 (1.3) 23.8 (0.8) 36.1 (1.5)
d = 57 50 23.4 (1.0) 26.6 (1.0) 22.1 (0.7) 28.5 (1.3) 20.9 (0.5) 19.1 (0.4) 24.5 (0.9)
Splice
d = 60

10 38.3 (0.8) 39.3 (0.8) 43.9 (0.8) 47.9 (0.5) 41.6 (0.7) 42.0 (1.0) 42.4 (0.6)
50 30.6 (0.8) 34.7 (0.9) 30.9 (0.8) 38.8 (1.0) 30.6 (0.9) 40.9 (0.8) 35.9 (0.7)

phishing
d = 68

10 24.2 (1.2) 25.8 (1.0) 27.3 (1.6) 37.2 (1.6) 27.6 (1.6) 27.5 (1.4) 31.7 (1.3)
50 15.8 (0.6) 18.3 (0.8) 15.4 (0.5) 21.1 (1.3) 14.7 (0.8) 17.2 (0.7) 16.7 (0.8)

a9a
d = 83

10 31.4 (0.9) 31.3 (1.0) 34.3 (1.2) 41.0 (1.1) 37.3 (1.3) 33.1 (1.2) 34.3 (1.2)
50 27.9 (0.6) 29.9 (0.8) 28.6 (0.7) 33.3 (1.0) 26.9 (0.7) 28.9 (0.8) 26.2 (0.4)

Coil2
d = 241

10 38.7 (0.8) 40.1 (0.8) 42.8 (0.7) 43.9 (0.8) 43.2 (0.8) 39.1 (0.9) 44.0 (0.8)
50 23.2 (0.6) 30.5 (0.9) 23.6 (0.9) 22.8 (0.9) 25.1 (0.9) 22.6 (0.8) 25.4 (0.8)

w8a
d = 300

10 35.9 (0.9) 33.6 (1.0) 41.6 (1.0) 46.6 (0.8) 39.4 (0.9) 42.1 (0.8) 43.0 (0.8)
50 28.1 (0.7) 27.6 (0.6) 27.0 (0.9) 38.7 (0.8) 28.0 (0.9) 33.7 (0.8) 35.2 (1.0)

#Best/Comp.

23

13

11

4

9

13

7

Supplementary Material for “Semi-Supervised Classification Based on Classification from Positive and Unlabeled Data”

PUNU

ER

LapSVM

SMIR

WellSVM

S4VM

103
102
101
100

w8
a

Co
il2

a9
a

10−1

Ba
na
na
Ph
on
em
e
Ma
gic
Im
ag
e
Su
sy
Ge
rm
an
Wa
vef
orm
i jc
nn
1
g5
0c
cov
typ
e
Sp
am
ba
se
Sp
lic
e
ph
i sh
ing

Computation Time [sec.]

PNU

Figure 3. Magnified version of Figure 3: Average computation time over 50 trials for benchmark data sets when nL = 50.

Table 3. Magnified version of Table 2: Average and standard error of misclassification rates over 30 trials for the Places 205 data set.
Boldface numbers denote the best and comparable methods in terms of the average misclassification rate according to a t-test at a
significance level of 5%.
θbP
PNU
ER
LapSVM
SMIR
WellSVM
Data set
nU
θP
Arts

1000 0.50 0.49 (0.01) 27.4 (1.3) 26.6 (0.5) 26.1 (0.7) 40.1 (3.9) 27.5 (0.5)
5000 0.50 0.50 (0.01) 24.8 (0.6) 26.1 (0.5) 26.1 (0.4) 30.1 (1.6)
N/A
10000 0.50 0.52 (0.01) 25.6 (0.7) 25.4 (0.5) 25.5 (0.6)
N/A
N/A

Deserts

1000 0.73 0.67 (0.01) 13.0 (0.5) 15.3 (0.6) 16.7 (0.8) 17.2 (0.8) 18.2 (0.7)
5000 0.73 0.67 (0.01) 13.4 (0.4) 13.3 (0.5) 16.6 (0.6) 24.4 (0.6)
N/A
10000 0.73 0.68 (0.01) 13.3 (0.5) 13.7 (0.6) 16.8 (0.8)
N/A
N/A

Fields

1000 0.65 0.57 (0.01) 22.4 (1.0) 26.2 (1.0) 26.6 (1.3) 28.2 (1.1) 26.6 (0.8)
5000 0.65 0.57 (0.01) 20.6 (0.5) 22.6 (0.6) 24.7 (0.8) 29.6 (1.2)
N/A
10000 0.65 0.57 (0.01) 21.6 (0.6) 22.5 (0.6) 25.0 (0.9)
N/A
N/A

Stadiums

1000 0.50 0.50 (0.01) 11.4 (0.4) 11.5 (0.5) 12.5 (0.5) 17.4 (3.6) 11.7 (0.4)
5000 0.50 0.50 (0.01) 11.0 (0.5) 10.9 (0.3) 11.1 (0.3) 13.4 (0.7)
N/A
10000 0.50 0.51 (0.00) 10.7 (0.3) 10.9 (0.3) 11.2 (0.2)
N/A
N/A

1000 0.27 0.33 (0.01) 21.8 (0.5) 23.9 (0.6) 24.1 (0.5) 30.1 (2.3) 26.2 (0.8)
Platforms 5000 0.27 0.34 (0.01) 23.3 (0.8) 24.4 (0.7) 24.9 (0.7) 26.6 (0.3)
N/A
10000 0.27 0.34 (0.01) 21.4 (0.5) 24.3 (0.6) 24.8 (0.5)
N/A
N/A
Temples

1000 0.55 0.51 (0.01) 43.9 (0.7) 43.9 (0.6) 43.4 (0.6) 50.7 (1.6) 44.3 (0.5)
5000 0.55 0.54 (0.01) 43.4 (0.9) 43.0 (0.6) 43.1 (1.0) 43.6 (0.7)
N/A
10000 0.55 0.50 (0.01) 45.2 (0.8) 44.4 (0.8) 44.2 (0.7)
N/A
N/A

Supplementary Material for “Semi-Supervised Classification Based on Classification from Positive and Unlabeled Data”

References
Ledoux, M. and Talagrand, M. Probability in Banach Spaces: Isoperimetry and Processes. Springer, 1991.
Li, Y.-F. and Zhou, Z.-H. Towards making unlabeled data never hurt. IEEE Transactions on Pattern Analysis and Machine
Intelligence, 37(1):175–188, 2015.
Mohri, M., Rostamizadeh, A., and Talwalkar, A. Foundations of Machine Learning. MIT Press, 2012.

