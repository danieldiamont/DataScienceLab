Generalized Linear Contextual Bandits

Supplementary for

Provably Optimal Algorithms for Generalized Linear Contextual Bandits

A. Proof of Theorem 1
In the following, for simplicity, we will drop the subscript n when there is no ambiguity. Therefore, Vn is denoted V and
so on.
ˆ typically we first show the n 1/2 -consistency of
To prove normality-type results of the maximum likelihood estimator ✓,
⇤
ˆ More
✓ˆ to ✓ . Then, by using a second-order Taylor expansion or Newton-step, we can prove the desired normality of ✓.
details can be found in standard textbooks such as Van der Vaart (2000).
Since m is twice differentiable with m̈
following equation

Define G(✓) :=

Pn

i=1

0, the maximum-likelihood estimation can be written as the solution to the
n
X

(Yi

µ(Xi0 ✓)) Xi = 0 .

(15)

i=1

(µ(Xi0 ✓)

µ(Xi0 ✓⇤ )) Xi , and we have
ˆ =
G(✓⇤ ) = 0 and G(✓)

n
X

(16)

✏ i Xi ,

i=1

ˆ = Pn ✏ i Xi .
where the noise ✏i is defined in (1). For convenience, define Z := G(✓)
i=1

ˆ We first prove the consistency of ✓.
ˆ For any ✓1 , ✓2 2 Rd , mean value theorem implies that
Step 1: Consistency of ✓.
there exists some ✓¯ = v✓1 + (1 v)✓2 with 0 < v < 1, such that
" n
#
X
0¯
0
¯ 1 ✓2 )
G(✓1 ) G(✓2 ) =
µ̇(Xi ✓)Xi Xi (✓1 ✓2 ) := F (✓)(✓
(17)
i=1

Since µ̇ > 0 and

min (V

) > 0, we have
(✓1

✓2 )0 (G(✓1 )

G(✓2 ))

(✓1

✓2 )0 (V )(✓1

for any ✓1 6= ✓2 . Hence, G(✓) is an injection from Rd to Rd , and so G
has a unique solution ✓ˆ = G 1 (Z).

1

✓2 ) > 0

is a well-defined function. Consequently, (15)

Let us consider an ⌘-neighborhood of ✓⇤ , B⌘ := {✓ : k✓ ✓⇤ k  ⌘}, where ⌘ > 0 is a constant that will be specified
later. Note that B⌘ is a convex set, thus ✓¯ 2 B⌘ as long as ✓1 , ✓2 2 B⌘ . Define ⌘ := inf ✓2B⌘ µ̇(x0 ✓) > 0. From (17), for
any ✓ 2 B⌘ ,
2

kG(✓)kV

1

=
=

2

G(✓⇤ )kV 1
1
¯
¯
✓⇤ )0 F (✓)V
F (✓)(✓

kG(✓)
(✓

2⌘

min (V

) k✓

✓⇤ )

⇤ 2

✓ k ,

¯ ⌫ ⌘ V .
where the last inequality is due to the fact that F (✓)

On the other hand, Lemma A of Chen et al. (1999) implies that
n
p
✓ : kG(✓)kV 1  ⌘ ⌘
ˆ
Now it remains to upper bound kZkV 1 = G(✓)
lemma, whose proof is deferred to Section C.

V

1

min (V

o
) ⇢ B⌘ .

to ensure ✓ˆ 2 B⌘ . To do so, we need the following technical

Generalized Linear Contextual Bandits

Lemma 7. Recall

which is the constant in (2). For any > 0, define the following event:
n
o
p
EG := kZkV 1  4
d + log(1/ ) .

Then, EG holds with probability at least 1

.

Suppose EG holds for the rest of the proof. Then, ⌘
⌘  as long as ⌘  1. Thus, we have
✓ˆ
when

min (V

)

16

2

4
⌘

q

s

4
✓ 


d+log(1/ )
min (V )

implies ✓ˆt

✓  ⌘. Since  = 1 , we have

d + log(1/ )
 1,
min (V )

(18)

[d + log(1/ )] /2 .

ˆ Now, we are ready to precede to prove the normality result. The following assumes EG holds
Step 2: Normality of ✓.
(which is high-probability event, according to Lemma 7).
Define

:= ✓ˆ

✓⇤ . It follows from (17) that there exists a v 2 [0, 1] such that
ˆ
Z = G(✓)

G(✓⇤ ) = (H + E)

,

ˆ H := F (✓⇤ ) = Pn µ̇(X 0 ✓⇤ )Xi X 0 and E := F (✓)
˜
where ✓˜ := v✓⇤ + (1 v)✓,
i
i
i=1
close, elements in E are small. By the mean value theorem,
E=

n ⇣
X

F (✓⇤ ). Intuitively, when ✓ˆ and ✓⇤ are

n
⌘
X
µ̇(Xi0 ✓⇤ ) Xi Xi0 =
µ̈(ri )Xi0 Xi Xi0

˜
µ̇(Xi0 ✓)

i=1

i=1

for some ri 2 R. Since µ̈  Mµ and v 2 [0, 1], for any x 2 Rd \ {0}, we have
x0 H

1/2

EH

1/2

x

=

(1

v)



n
X

n
X

µ̈(ri )Xi0

x0 H

1/2

Xi

2

i=1

i=1

Mµ kXi k k k x0 H
0

1/2



Mµ k k x H



Mµ
2
k k kxk ,


n
X

1/2

Xi

Xi Xi0

i=1

2

!

H

1/2

x

!

where we have used the assumption that kXi k  1 for the second inequality. Therefore,
s
M
4M
d + log(1/ )
µ
µ
H 1/2 EH 1/2 
k k
.

2
min (V )
When

min (V

)

64Mµ2

2

(19)

(d + log(1/ ))/4 , we have
H

1/2

EH

1/2

(20)

 1/2 .

Now we are ready to prove the theorem. For any x 2 Rd ,
x0 (✓ˆ

✓⇤ ) = x0 (H + E)

1

Z = x0 H

1

Z

Note that the matrix (H + E) is nonsingular, so its inversion exists.

x0 H

1

E(H + E)

1

Z.

(21)

Generalized Linear Contextual Bandits

For the first term, {✏i } are sub-Gaussian random variables with sub-Gaussian parameter . Define
0

D := [X1 , X2 , . . . , Xn ] 2 Rn⇥d
to be the design matrix. Hoeffding inequality gives
0

1

P{|x H

t}  2 exp

Z|

(

2

x

1 0
xV
2

t2
1 D 0 k2

kx0 H

2

)

(22)

.

Since H ⌫ V = D0 D, we have
x0 H

1

2

D0

= x0 H

1

D0 DH

1

so (22) implies
0

1

P{|x H

t}  2 exp

Z|

(

1

1
2
kxkV
2

x=

)

t2  2
2

2

2

kxkV

1

2 p
log(1/ ) kxkV


,

.

Let the right-hand side be 2 and solve for t, we obtain that with probability at least 1
p

1

2 ,

0

|x H

1

1

Z|



kxkH

1

H

1/2

E(H + E)

1

Z



kxkH

1

H

1/2

E(H + E)

1

H 1/2 kZkH

Z| 

1

(23)

.

For the second term,
|x0 H

1

E(H + E)



1
kxkV


1

H

1/2

where the last inequality is due to the fact that H ⌫ V . Since (H + E)
H

1/2

E(H + E)

1

H 1/2

=

H

1/2

E H

1

H

=

H

1/2

EH

1/2

+H



H

1/2

EH

1/2

1

1

+ H

EH

1/2

1

EH

H 1/2 kZkV

1

=H

E(H + E)

1/2

1

E(H + E)

1

1

H

1

(24)

,

1

E(H + E)

1

H 1/2

1

, we have

H 1/2

E(H + E)
1/2

H

1/2

E(H + E)

1

H 1/2 .

By solving this inequality, we get
H

1/2

E(H + E)

1

H 1/2 

H
1

1/2

EH 1/2
H 1/2 EH 1/2

2 H

1/2

EH

1/2

8Mµ

2

s

d + log(1/ )
,
min (V )

where we have used (20) and (19) in the second and third inequalities, respectively. Combining it with (24) and the bound
in EG , we have
32Mµ 2 d + log(1/ )
p
|x0 H 1 E(H + E) 1 Z| 
kxkV 1 .
(25)
3
min (V )

From (21), (23) and (25), one can see that (5) holds as long as the lower bound (4) for min (V ) holds. Finally, an
application of a union bound on two small-probability events (given in Lemma 7 and (23), respectively) asserts that (5)
holds with probability at least 1 3 .

Generalized Linear Contextual Bandits

B. Proof of Proposition 1
In the following, for simplicity, we will drop the subscript n when there is no ambiguity. Therefore, Vn is denoted V and
so on.
Let X be a randomP
vector drawn from the distribution ⌫. Define Z := ⌃ 1/2 X. Then Z is isotropic, namely, E[ZZ 0 ] =
n
0
1/2
Id . Define U =
V ⌃ 1/2 . From Lemma 1, we have that, for any t, with probability at least
t=1 Zt Zt = ⌃
2
1 2 exp( C2 t ),
p
p
2
n C1 2 nd
t n.
min (U )
1/2
min (⌃)

where is the sub-Gaussian parameter of Z, which is upper-bounded by ⌃ 1/2 =
(2012)). We thus can rewrite the above inequality (which holds with probability 1
as
⇣
⌘
p
p
1
2
n
nd + t n .
min (U )
min (⌃) C1

(see, e.g., Vershynin

We now bound the minimum eigenvalue of V , as follows:
min (V

)

min x0 V x

=

x2Bd

min x0 ⌃1/2 U ⌃1/2 x

=

x2Bd

min (U )

=

min x0 ⌃x

x2Bd

min (U ) min (⌃)
min (⌃)

=

⇣

n

1
2
min (⌃)(C1

p
C1 nd

min (⌃)n

C2

p

p

p ⌘
nd + t n)

n log(1/ ) .

Finally, it can be verified (Lemma 9) that the last expression above is no less than B as long as
!2
p
p
C1 d + C2 log(1/ )
+
min (⌃)

n

2B
,
min (⌃)

finishing the proof.

C. Technical Lemmas and Proofs
C.1. Proof of Lemma 7
Noting that
kZkV

1

1/2

= kV

Zk2 = sup ha, V

1/2

Zi,

kak2 1

let B̂ be a 1/2-net of the unit ball Bd . Then |B̂|  6d (Pollard, 1990, Lemma 4.1), and for any x 2 Bd , there is a x̂ 2 B̂
such that kx x̂k  1/2. Consequently,
hx, V

1/2

Zi

=

hx̂, V

1/2

Zi + hx

=

hx̂, V

1/2

Zi + kx



hx̂, V

1/2

Zi +

x̂, V

1/2

Zi
x x̂
x̂k h
,V
kx x̂k

1
sup hz, V
2 z2Bd

1/2

Zi.

Taking supremum on both sides, we get
sup hx, V

x2Bd

1/2

Zi  2 maxhx̂, V
x̂2B̂

1/2

Zi .

1/2

Zi

Generalized Linear Contextual Bandits

Then a union bound argument implies
P {kZkV

1



> t}





⇢

P maxhx̂, V
x̂2B̂
X n
P hx̂, V
x̂2B̂

X

exp

x̂2B̂

(

Zi > t/2
o
1/2
Zi > t/2
t2
2

1/2 X 0 2

x̂0 V

2

8

t2 /(8

exp

1/2

)

) + d log 6 ,

where p
we have used Hoeffding’s inequality for the third inequality and |B̂|  6d for the last inequality. A choice of
t=4
d + log(1/ ) completes the proof.
C.2. Proof of Lemma 2

By Abbasi-Yadkori et al. (2011, Lemma 11), we have
m+n
X

t=m+1

2
kXt kV
t

1

det Vm+n+1
 2 log
 2d log
det Vm+1

✓

tr (Vm+1 ) + n
d

◆

2 log det Vm+1 .

Pm
Pm
Qd
Note that tr (Vm+1 ) = t=1 tr (Xt Xt0 ) = t=1 kXt k2  m and that det Vm+1 = i=1 i
{ i } are the eigenvalues of Vm+1 . Applying Cauchy-Schwartz inequality yields
v
s
u m+n
✓
◆
m+n
X
u X
n+m
2
t
kXt kV 1  n
kXt kV 1  2nd log
.
t
t
d
t=m+1
t=m+1

d
min (Vm+1 )

1, where

C.3. Proof of Lemma 3
Pt 1
Pt 1
Define Gt (✓) = i=1 (µ(Xi0 ✓) µ(Xi0 ✓⇤ ))Xi and Zt = i=1 ✏i Xi . Following the same argument as in the proof of
Theorem 1, we have Gt (✓ˆt ) = Zt and
kGt (✓)k2V 1 2 k✓ ✓⇤ k2Vt
(26)
t

for any ✓ 2 {✓ : k✓ ✓⇤ k  1}. Combining (26) with the following lemma and the equality Zt = Gt (✓ˆt ) completes the
proof.
Lemma 8. Suppose there is an integer m such that min (Vm ) 1, then for any 2 (0, 1), with probability at least 1
,
for all t > m,
✓
◆
d
2
kZt kV 1  4 2
log(1 + 2t/d) + log(1/ ) .
t
2
Proof. For convenience, fix t such that t > m, and denote Vt and Zt by V and Z, respectively. Furthermore, define
V̄ := V + I and let 1 be the vector of all 1s. It is easy to observe that
2

2

kZkV

1

= kZkV̄

1

+ Z 0 (V

1

1

V̄

We start with bounding the second term. The ShermanMorrison formula gives
1

V̄
Since 10 V

1

1

=V

V 2
1 + 10 V

1

11

0, the above implies that
0




=

Z 0 (V
0

ZV
V

1

V̄

2

1

)Z

Z
2

1

kZkV

1

2

min (V

)

kZkV

1

.

.

)Z .

(27)

Generalized Linear Contextual Bandits

Since

min (V

)

min (Vm )

1, we now have
0  Z 0 (V

1

1

V̄

2

)Z 

kZkV

1

.

The above inequality together with (27) implies that
2

kZkV

 (1

1

)

1

2

kZkV̄

.

1

2

The proof can be finished by applying Theorem 1 and Lemma 10 from Abbasi-Yadkori et al. (2011) to bound kZkV̄
using = 1/2.

1

,

C.4. Proof of Lemma 6
We will prove the first part of the lemma by induction. It is easy to check the lemma holds for s = 1. Suppose we have
a⇤t 2 As and we want to prove a⇤t 2 As+1 . Since the algorithm proceeds to stage s + 1, we know from step 2b that
(s)

(s)

x0t,a ✓⇤ |  wt,a  2

|mt,a

s

for all a 2 As . Specially, it holds for a = a⇤t because a⇤t 2 As by our induction step. Then the optimality of a⇤t implies
(s)

x0t,a⇤t ✓⇤

mt,a⇤t

x0t,a ✓⇤

s

2

2

(s)

s

mt,a

2·2

s

for all a 2 As . Thus we have a⇤t 2 As+1 according to step 2d.

Suppose at is selected at stage st in step 2b. If st = 1, obviously the lemma holds because 0  µ(x)  1 for all x. If
st > 1, since we have proved a⇤t 2 Ast , again step 2b at stage st 1 implies
(s

|mt,at
for a = at and a = a⇤t . Step 2d at stage st

1)

x0t,a ✓⇤ |  2

st +1

1 implies
(s

mt,at⇤t

1)

(s

1)

mt,att

2·2

st +1

.

Combining above two inequalities, we get
x0t,at ✓⇤

(s

mt,att

1)

2

(s )

When at is selected in step 2c, since mt,att
x0t,at ✓⇤
Using the fact that µ(x1 )

(s )

mt,att

µ(x2 )  Lµ (x1

(s

st +1

mt,at⇤t

1)

3·2

x0t,a⇤t ✓⇤

st +1

4·2

st +1

.

(s )

mt,at⇤t , we have
p
1/ T

(s )

mt,at⇤t

x2 ) for x1

p
1/ T

x0t,a⇤t ✓⇤

p
2/ T .

x2 , we will get the desired result.

C.5. Proof of Lemma 9
Lemma 9. Let a and b be two positive constants. If m
Proof. The function t 7! t2

at

a2 + 2b, then m

p
a m

b

b is monotonically increasing for t a/2. Since m
p
p
m a m b
a2 + 2b a a2 + 2b b
p
a2 + b a a2 + 2b + b2 /a2
p
= a2 + b a (a + b/a)2
=

a2 + b

=

0.

a(a + b/a)

0.
a2 + 2b, we have

p

m

a/2, so

