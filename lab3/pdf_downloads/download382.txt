Dual Iterative Hard Thresholding: From Non-convex Sparse Minimization to
Non-smooth Concave Maximization
Supplementary File

A. Technical Proofs
A.1. Proof of Theorem 1
Proof. â€œâ‡â€: If the pair (wÌ„, Î±Ì„) is a sparse saddle point for L, then from the definition of conjugate convexity and inequality (3) we have
P (wÌ„) = max L(wÌ„, Î±) â‰¤ L(wÌ„, Î±Ì„) â‰¤ min L(w, Î±Ì„).
Î±âˆˆF N

kwk0 â‰¤k

On the other hand, we know that for any kwk0 â‰¤ k and Î± âˆˆ F

N

L(w, Î±) â‰¤ max L(w, Î±0 ) = P (w).
Î±0 âˆˆF N

By combining the preceding two inequalities we obtain
P (wÌ„) â‰¤ min L(w, Î±Ì„) â‰¤ min P (w) â‰¤ P (wÌ„).
kwk0 â‰¤k

kwk0 â‰¤k

Therefore P (wÌ„) = minkwk0 â‰¤k P (w), i.e., wÌ„ solves the problem in (1), which proves the necessary condition (a). Moreover,
the above arguments lead to
P (wÌ„) = max L(wÌ„, Î±) = L(wÌ„, Î±Ì„).
Î±âˆˆF N

Then from the maximizing argument property of convex conjugate we know that Î±Ì„i âˆˆ âˆ‚li (wÌ„> xi ). Thus the necessary
condition (b) holds. Note that

2
N
N

1 X
1 X âˆ—
Î»


Î±Ì„i xi  âˆ’
li (Î±Ì„i ) + C,
(11)
L(w, Î±Ì„) = w +

2
NÎ»
N
i=1

where C is a quantity not dependent on w.
minkwk0 â‰¤k L(w, Î±Ì„), it must hold that

Let FÌ„ = supp(wÌ„).
N

wÌ„ = HFÌ„

i=1

1 X
âˆ’
Î±Ì„i xi
N Î» i=1

!

Since the above analysis implies L(wÌ„, Î±Ì„) =
N

= Hk

1 X
âˆ’
Î±Ì„i xi
N Î» i=1

!
.

This validates the necessary condition (c).
â€œâ‡’â€: Conversely, let us assume that wÌ„ is a k-sparse solution to the problem (1) (i.e., conditio(a)) and let Î±Ì„i âˆˆ âˆ‚li (wÌ„> xi )
(i.e., condition (b)). Again from the maximizing argument property of convex conjugate we know that li (wÌ„> xi ) =
Î±Ì„i wÌ„> xi âˆ’ liâˆ— (Î±Ì„i ). This leads to
L(wÌ„, Î±) â‰¤ P (wÌ„) = max L(wÌ„, Î±) = L(wÌ„, Î±Ì„).

(12)

Î±âˆˆF N

The sufficient condition (c) guarantees that FÌ„ contains the top k (in absolute value) entries of âˆ’ N1Î»
on the expression in (11) we can see that the following holds for any k-sparse vector w
L(wÌ„, Î±Ì„) â‰¤ L(w, Î±Ì„).
By combining the inequalities (12) and (13) we get that for any kwk0 â‰¤ k and Î± âˆˆ F N ,
L(wÌ„, Î±) â‰¤ L(wÌ„, Î±Ì„) â‰¤ L(w, Î±Ì„).
This shows that (wÌ„, Î±Ì„) is a sparse saddle point of the Lagrangian L.

PN

i=1

Î±Ì„i xi . Then based
(13)

Dual Iterative Hard Thresholding

A.2. Proof of Theorem 2
Proof. â€œâ‡’â€: Let (wÌ„, Î±Ì„) be a saddle point for L. On one hand, note that the following holds for any k-sparse w0 and
Î±0 âˆˆ F N
min L(w, Î±0 ) â‰¤ L(w0 , Î±0 ) â‰¤ max L(w0 , Î±),
Î±âˆˆF N

kwk0 â‰¤k

which implies
min L(w, Î±) â‰¤ min

max

Î±âˆˆF N kwk0 â‰¤k

max L(w, Î±).

kwk0 â‰¤k Î±âˆˆF N

(14)

On the other hand, since (wÌ„, Î±Ì„) is a saddle point for L, the following is true:
max L(w, Î±) â‰¤ max L(wÌ„, Î±)

min

kwk0 â‰¤k Î±âˆˆF N

Î±âˆˆF N

â‰¤ L(wÌ„, Î±Ì„) â‰¤ min L(w, Î±Ì„)
kwk0 â‰¤k

â‰¤ max

(15)

min L(w, Î±).

Î±âˆˆF N kwk0 â‰¤k

By combining (14) and (15) we prove the equality in (4).
â€œâ‡â€: Assume that the equality in (4) holds. Let us define wÌ„ and Î±Ì„ such that
max L(wÌ„, Î±) = min

max L(w, Î±)

min L(w, Î±Ì„) = max

min L(w, Î±)

Î±âˆˆF N

kwk0 â‰¤k

kwk0 â‰¤k Î±âˆˆF N

.

Î±âˆˆF N kwk0 â‰¤k

Then we can see that for any Î± âˆˆ F N ,
L(wÌ„, Î±Ì„) â‰¥ min L(w, Î±Ì„) = max L(wÌ„, Î±0 ) â‰¥ L(wÌ„, Î±),
kwk0 â‰¤k

Î±0 âˆˆF N

where the â€œ=â€ is due to (4). In the meantime, for any kwk0 â‰¤ k,
L(wÌ„, Î±Ì„) â‰¤ max L(wÌ„, Î±) =
Î±âˆˆF N

min L(w0 , Î±Ì„) â‰¤ L(w, Î±Ì„).

kw0 k0 â‰¤k

This shows that (wÌ„, Î±Ì„) is a sparse saddle point for L.
A.3. Proof of Lemma 1
Proof. For any fixed Î± âˆˆ F N , then it is easy to verify that the k-sparse minimum of L(w, Î±) with respect to w is attained
at the following point:
!
N
1 X
Î±i xi .
w(Î±) = arg min L(w, Î±) = Hk âˆ’
N Î» i=1
kwk0 â‰¤k
Thus we have
D(Î±) = min L(w, Î±) = L(w(Î±), Î±)
kwk0 â‰¤k

=
Î¶1

=

N
 Î»
1 X
Î±i w(Î±)> xi âˆ’ liâˆ— (Î±i ) + kw(Î±)k2
N i=1
2
N
1 X âˆ—
Î»
âˆ’li (Î±i ) âˆ’ kw(Î±)k2 ,
N i=1
2

where â€œÎ¶1 â€ follows from the above definition of w(Î±).
Now let us consider two arbitrary dual variables Î±0 , Î±00 âˆˆ F N and any g(Î±00 ) âˆˆ N1 [w(Î±00 )> x1 âˆ’âˆ‚l1âˆ— (Î±100 ), ..., w(Î±00 )> xN âˆ’
âˆ—
00
âˆ‚lN
(Î±N
)]. From the definition of D(Î±) and the fact that L(w, Î±) is concave with respect to Î± at any fixed w we can derive
that
D(Î±0 ) = L(w(Î±0 ), Î±0 )
â‰¤ L(w(Î±00 ), Î±0 )
â‰¤ L(w(Î±00 ), Î±00 ) + hg(Î±00 ), Î±0 âˆ’ Î±00 i .

Dual Iterative Hard Thresholding

This shows that D(Î±) is a concave function and its super-differential is as given in the theorem.
If we further assume that w(Î±) is unique and {liâˆ— }i=1,...,N are differentiable at any Î±, then âˆ‚D(Î±) = N1 [w(Î±)> x1 âˆ’
âˆ—
âˆ‚l1âˆ— (Î±1 ), ..., w(Î±)> xN âˆ’ âˆ‚lN
(Î±N )] becomes unique, which implies that âˆ‚D(Î±) is the unique super-gradient of D(Î±).
A.4. Proof of Theorem 3
Proof. â€œâ‡’â€: Given the conditions in the theorem, it can be known from Theorem 1 that the pair (wÌ„, Î±Ì„) forms a sparse
saddle point of L. Thus based on the definitions of sparse saddle point and dual function D(Î±) we can show that
D(Î±Ì„) = min L(w, Î±Ì„) â‰¥ L(wÌ„, Î±Ì„) â‰¥ L(wÌ„, Î±) â‰¥ D(Î±).
kwk0 â‰¤k

This implies that Î±Ì„ solves the dual problem in (5). Furthermore, Theorem 2 guarantees the following
D(Î±Ì„) = max

min L(w, Î±) = min

Î±âˆˆF N kwk0 â‰¤k

max L(w, Î±) = P (wÌ„).

kwk0 â‰¤k Î±âˆˆF N

This indicates that the primal and dual optimal values are equal to each other.
â€œâ‡â€: Assume that Î±Ì„ solves the dual problem in (5) and D(Î±Ì„) = P (wÌ„). Since D(Î±Ì„) â‰¤ P (w) holds for any kwk0 â‰¤ k, wÌ„
must be the sparse minimizer of P (w). It follows that
max

min L(w, Î±) = D(Î±Ì„) = P (wÌ„) = min

Î±âˆˆF N kwk0 â‰¤k

max L(w, Î±).

kwk0 â‰¤k Î±âˆˆF N

From the â€œâ‡â€ argument in the proof of Theorem 2 and Corollary 1 we get that the conditions (a)âˆ¼(c) in Theorem 1 should
be satisfied for (wÌ„, Î±Ì„).
A.5. Proof of Theorem 4
We need a series of technical lemmas to prove this theorem. The following lemmas shows that under proper conditions,
w(Î±) is locally smooth around wÌ„ = w(Î±Ì„).
Lemma 2. Let X = [x1 , ..., xN ] âˆˆ RdÃ—N be the data matrix. Assume that {li }i=1,...,N are differentiable and
Â¯ := wÌ„min âˆ’
If kÎ± âˆ’ Î±Ì„k â‰¤

Î»N Â¯
2Ïƒmax (X) ,

1 0
kP (wÌ„)kâˆž > 0.
Î»

then supp(w(Î±)) = supp(wÌ„) and
kw(Î±) âˆ’ wÌ„k â‰¤

Ïƒmax (X, k)
kÎ± âˆ’ Î±Ì„k.
NÎ»

Proof. For any Î± âˆˆ F N , let us define
N

wÌƒ(Î±) = âˆ’

1 X
Î±i xi .
N Î» i=1
0

Consider FÌ„ = supp(wÌ„). Given Â¯ > 0, it is known from Theorem 3 that wÌ„ = HFÌ„ (wÌƒ(Î±Ì„)) and P Î»(wÌ„) = HFÌ„ c (âˆ’wÌƒ(Î±Ì„)). Then
Î»N Â¯
Â¯ > 0 implies FÌ„ is unique, i.e., the top k entries of wÌƒ(Î±Ì„) is unique. Given that kÎ± âˆ’ Î±Ì„k â‰¤ 2Ïƒmax
(X) , it can be shown that
1
Ïƒmax (X)
Â¯
kX(Î± âˆ’ Î±Ì„)k â‰¤
kÎ± âˆ’ Î±Ì„k â‰¤ .
NÎ»
NÎ»
2
This indicates that FÌ„ still contains the (unique) top k entries of wÌƒ(Î±). Therefore,
kwÌƒ(Î±) âˆ’ wÌƒ(Î±Ì„)k =

supp(w(Î±)) = FÌ„ = supp(wÌ„).
Then it must hold that

This proves the desired bound.

kw(Î±) âˆ’ w(Î±Ì„)k = kHFÌ„ (wÌƒ(Î±)) âˆ’ HFÌ„ (wÌƒ(Î±Ì„)) k
1
=
kX (Î± âˆ’ Î±Ì„)k
N Î» FÌ„
Ïƒmax (X, k)
â‰¤
kÎ± âˆ’ Î±Ì„k.
NÎ»

Dual Iterative Hard Thresholding

p
The following lemma bounds the estimation error kÎ± âˆ’ Î±Ì„k = O( hD0 (Î±), Î±Ì„ âˆ’ Î±i) when the primal loss {li }N
i=1 are
smooth.
Lemma 3. Assume that the primal loss functions {li (Â·)}N
i=1 are 1/Âµ-smooth. Then the following inequality holds for any
Î±, Î±00 âˆˆ F and g(Î±00 ) âˆˆ âˆ‚D(Î±00 ):
D(Î±0 ) â‰¤ D(Î±00 ) + hg(Î±00 ), Î±0 âˆ’ Î±00 i âˆ’

2
Î»N Âµ + Ïƒmin
(X, k) 0
kÎ± âˆ’ Î±00 k2 .
2
2Î»N

Moreover, âˆ€Î± âˆˆ F and g(Î±) âˆˆ âˆ‚D(Î±),
s
kÎ± âˆ’ Î±Ì„k â‰¤

2Î»N 2 hg(Î±), Î±Ì„ âˆ’ Î±i
2 (X, k) .
Î»N Âµ + Ïƒmin

Proof. Recall that
D(Î±) =

N
Î»
1 X âˆ—
âˆ’l (Î±i ) âˆ’ kw(Î±)k2 ,
N i=1 i
2

Now let us consider two arbitrary dual variables Î±0 , Î±00 âˆˆ F. The assumption of li being 1/Âµ-smooth implies that its
convex conjugate function liâˆ— is Âµ-strongly-convex. Let F 00 = supp(w(Î±00 )). Then
N
Î»
1 X âˆ— 0
âˆ’li (Î±i ) âˆ’ kw(Î±0 )k2
N i=1
2

!2
N
N

Î»
1 X âˆ— 0
1 X 0


âˆ’li (Î±i ) âˆ’ Hk âˆ’
Î±i xi 
=

N i=1
2
N Î» i=1

D(Î±0 ) =


N
 Î»
0
1 X  âˆ— 00
Âµ

â‰¤
âˆ’li (Î±i ) âˆ’ liâˆ— (Î±i00 )(Î±i0 âˆ’ Î±i00 ) âˆ’ (Î±i0 âˆ’ Î±i00 )2 âˆ’ HF 00
N i=1
2
2
â‰¤

N

1 X 0
âˆ’
Î± xi
N Î» i=1 i

!2





N
N
 Î»
0
1 X  âˆ— 00
Âµ
1 X >
âˆ’li (Î±i ) âˆ’ liâˆ— (Î±i00 )(Î±i0 âˆ’ Î±i00 ) âˆ’ (Î±i0 âˆ’ Î±i00 )2 âˆ’ kw(Î±00 )k2 +
x w(Î±00 )(Î±i0 âˆ’ Î±i00 )
N i=1
2
2
N i=1 i

1
(Î±0 âˆ’ Î±00 )> XF>00 XF 00 (Î±0 âˆ’ Î±00 )
2Î»N 2
2
Î»N Âµ + Ïƒmin
(X, k) 0
â‰¤D(Î±00 ) + hg(Î±00 ), Î±0 âˆ’ Î±00 i âˆ’
kÎ± âˆ’ Î±00 k2 .
2Î»N 2
âˆ’

This proves the first desirable inequality in the lemma. By invoking the above inequality and using the fact D(Î±) â‰¤ D(Î±Ì„)
we get that
2
Î»N Âµ + Ïƒmin
(X, k)
D(Î±Ì„) â‰¤D(Î±) + hg(Î±), Î±Ì„ âˆ’ Î±i âˆ’
kÎ± âˆ’ Î±Ì„k2
2Î»N 2
2
Î»N Âµ + Ïƒmin
(X, k)
â‰¤D(Î±Ì„) + hg(Î±), Î±Ì„ âˆ’ Î±i âˆ’
kÎ± âˆ’ Î±Ì„k2 ,
2Î»N 2
which leads to the second desired bound.
The following lemma gives a simple expression of the gap for properly related primal-dual pairs.
Lemma 4. Given a dual variable Î± âˆˆ F N and the related primal variable
!
N
1 X
w = Hk âˆ’
Î±i xi .
N Î» i=1
The primal-dual gap P D (w, Î±) can be expressed as:
P D (w, Î±) =

N

1 X
li (w> xi ) + liâˆ— (Î±i ) âˆ’ Î±i w> xi .
N i=1

Dual Iterative Hard Thresholding

Proof. It is directly to know from the definitions of P (w) and D(Î±) that
P (w) âˆ’ D(Î±)
N
1 X
Î»
=
li (w> xi ) + kwk2 âˆ’
N i=1
2

=

N
 Î»
1 X
Î±i w> xi âˆ’ liâˆ— (Î±i ) + kwk2
N i=1
2

!

N

1 X
li (w> xi ) + liâˆ— (Î±i ) âˆ’ Î±i w> xi .
N i=1

This shows the desired expression.
Based on Lemma 4, we can derive the following lemma which establishes a bound on the primal-dual gap.
Lemma 5. Consider a primal-dual pair (w, Î±) satisfying
N

1 X
âˆ’
Î±i xi
N Î» i=1

w = Hk

!
.

Then the following inequality holds for any g(Î±) âˆˆ âˆ‚D(Î±) and Î² âˆˆ [âˆ‚l1 (w> x1 ), ..., âˆ‚lN (w> xN )]:
P (w) âˆ’ D(Î±) â‰¤ hg(Î±), Î² âˆ’ Î±i.
Proof. For any i âˆˆ [1, ..., N ], from the maximizing argument property of convex conjugate we have
li (w> xi ) = w> xi li0 (w> xi ) âˆ’ liâˆ— (li0 (w> xi )),
and

0

0

liâˆ— (Î±i ) = Î±i liâˆ— (Î±i ) âˆ’ li (liâˆ— (Î±i )).
By summing both sides of above two equalities we get
li (w> xi ) + liâˆ— (Î±i )
0

0

=w> xi li0 (w> xi ) + Î±i liâˆ— (Î±i ) âˆ’ (li (liâˆ— (Î±i )) + liâˆ— (li0 (w> xi )))
Î¶1

0

0

â‰¤w> xi li0 (w> xi ) + Î±i liâˆ— (Î±i ) âˆ’ liâˆ— (Î±i )li0 (w> xi ),
where â€œÎ¶1 â€ follows from Fenchel-Young inequality. Therefore
hg(Î±), Î² âˆ’ Î±i
N
0
1 X >
=
(w xi âˆ’ liâˆ— (Î±i ))(li0 (w> xi ) âˆ’ Î±i )
N i=1

=
Î¶2

â‰¥

N

0
0
1 X > 0 >
w xi li (w xi ) âˆ’ liâˆ— (Î±i )li0 (w> xi ) âˆ’ Î±i w> xi + Î±i liâˆ— (Î±i )
N i=1
N
1 X
(li (w> xi ) + Î±i liâˆ— (Î±i ) âˆ’ w> xi )
N i=1

Î¶3

=P (w) âˆ’ D(Î±),
where â€œÎ¶2 â€ follows from (16) and â€œÎ¶3 â€ follows from Lemma 4. This proves the desired bound.
The following simple result is also needed in our iteration complexity analysis.
Lemma 6. For any  > 0,
1 ln t
+
â‰¤
t
t
holds when t â‰¥ max

3


	
ln 3 , 1 .

(16)

Dual Iterative Hard Thresholding

Proof. Obviously, the inequality 1t +
t implies that 1t â‰¤ 3 . Also, we have

ln t
t

â‰¤  holds for  â‰¥ 1. When  < 1, it holds that ln( 3 ) â‰¥ 1. Then the condition on
ln( 3 ln 3 )
ln( 3 )2
ln t
2
â‰¤ 3 3 â‰¤ 3  3 = ,
t
3
 ln 
 ln 

where the first â€œâ‰¤â€ follows the fact that ln t/t is decreasing when t â‰¥ 1 while the second â€œâ‰¤â€ follows ln x < x for all
x > 0. Therefore we have 1t + lnt t â‰¤ .
We are now in the position to prove the main theorem.
(t)

of Theorem 4. Part(a): Let us consider g (t) âˆˆ âˆ‚D(Î±(t) ) with gi
we can verify that kw(t) k â‰¤ r/Î». Therefore we have
kg (t) k â‰¤ c0 =

=

1
> (t)
N (xi w

0

(t)

âˆ’ liâˆ— (Î±i )). From the expression of w(t)

r + Î»Ï
âˆš .
Î» N

Let h(t)p= kÎ±(t) âˆ’ Î±Ì„k and v (t) = hg (t) , Î±Ì„ âˆ’ Î±(t) i. The concavity of D implies v (t) â‰¥ 0. From Lemma 3 we know that
h(t) â‰¤ 2Î»N 2 v (t) /(Î»N Âµ + Ïƒmin (X, k)). Then


(h(t) )2 =kPF N Î±(tâˆ’1) + Î· (tâˆ’1) g (tâˆ’1) âˆ’ Î±Ì„k2
â‰¤kÎ±(tâˆ’1) + Î· (tâˆ’1) g (tâˆ’1) âˆ’ Î±Ì„k2
=(h(tâˆ’1) )2 âˆ’ 2Î· (tâˆ’1) v (tâˆ’1) + (Î· (tâˆ’1) )2 kg (tâˆ’1) k2
â‰¤(h(tâˆ’1) )2 âˆ’
Let Î· (t) =

Î»N 2
(Î»N Âµ+Ïƒmin (X,k))(t+1) .

Î· (tâˆ’1) (Î»N Âµ + Ïƒmin (X, k)) (tâˆ’1) 2
(h
) + (Î· (tâˆ’1) )2 c20 .
Î»N 2

Then we obtain


(t) 2

(h ) â‰¤

1
1âˆ’
t



(h(tâˆ’1) )2 +

Î»2 N 4 c20
.
(Î»N Âµ + Ïƒmin (X, k))2 t2

By recursively applying the above inequality we get
(h(t) )2 â‰¤

Î»2 N 4 c20
(Î»N Âµ + Ïƒmin (X, k))2



1 ln t
+
t
t




= c1

1 ln t
+
t
t


.

This proves the desired bound in part(a).
Part(b): Let us consider  =

Î»N Â¯
2Ïƒmax (X) .

From part(a) and Lemma 6 we obtain
kÎ±(t) âˆ’ Î±Ì„k â‰¤ 

after t â‰¥ t0 =

3c1
2

(t)
1
ln 3c
2 . It follows from Lemma 2 that supp(w ) = supp(wÌ„).

0
Let Î² (t) := [l10 ((w(t) )> x1 ), ..., lN
((w(t) )> xN )]. According to Lemma 5 we have
(t)

P D = P (w(t) ) âˆ’ D(Î±(t) )
â‰¤ hg (t) , Î² (t) âˆ’ Î±(t) i
â‰¤ kg (t) k(kÎ² (t) âˆ’ Î±Ì„k + kÎ±Ì„ âˆ’ Î±(t) k).
0
Since Â¯ = wÌ„min âˆ’ Î»1 kP 0 (wÌ„)kâˆž > 0, it follows from Theorem 2 that Î±Ì„ = [l10 (wÌ„> x1 ), ..., lN
(wÌ„> xN )]. Given that t â‰¥ t0 ,
from the smoothness of li and Lemma 2 we get

kÎ² (t) âˆ’ Î±Ì„k â‰¤

1 (t)
Ïƒmax (X, k) (t)
kw âˆ’ wÌ„k â‰¤
kÎ± âˆ’ Î±Ì„k, .
Âµ
ÂµÎ»N

Dual Iterative Hard Thresholding

where in the first â€œâ‰¤â€ we have used kxi k â‰¤ 1. Therefore, the following is valid when t â‰¥ t0 :
(t)

P D â‰¤ kg (t) k(kÎ² (t) âˆ’ Î±Ì„k + kÎ±Ì„ âˆ’ Î±(t) k)


Ïƒmax (X, k)
kÎ±(t) âˆ’ Î±Ì„k.
â‰¤ c0 1 +
ÂµÎ»N


Since t â‰¥ t1 , from part(a) and Lemma 6 we get kÎ±(t) âˆ’ Î±Ì„k â‰¤
implies

(t)
P D

c0 (1+

Ïƒmax (X,k)
ÂµÎ»N

)

, which according to the above inequality

â‰¤ . This proves the desired bound.

A.6. Proof of Theorem 5
0

(t)

(t)

(t)
âˆ’ ljâˆ— (Î±i )). Let h(t) = kÎ±(t) âˆ’ Î±Ì„k and v (t) = hg (t) , Î±Ì„ âˆ’ Î±(t) i.
Proof. Part(a): Let us consider g (t) with gj = N1 (x>
j w
p
(t)
The concavity of D implies v â‰¥ 0. From Lemma 3 we know that h(t) â‰¤ 2Î»N 2 v (t) /(Î»N Âµ + Ïƒmin (X, k)). Let
(t)
(t)
(t)
gBi := HB (t) (g (t) ) and vBi := hgBi , Î±Ì„ âˆ’ Î±(t) i Then
i



(tâˆ’1)
(h(t) )2 =kPF N Î±(tâˆ’1) + Î· (tâˆ’1) gBi
âˆ’ Î±Ì„k2
(tâˆ’1)

â‰¤kÎ±(tâˆ’1) + Î· (tâˆ’1) gBi

âˆ’ Î±Ì„k2

(tâˆ’1)

=(h(tâˆ’1) )2 âˆ’ 2Î· (tâˆ’1) vBi

(tâˆ’1) 2

+ (Î· (tâˆ’1) )2 kgBi

k .

By taking conditional expectation (with respect to uniform random block selection, conditioned on Î±(tâˆ’1) ) on both sides
of the above inequality we get
E[(h(t) )2 | Î±(tâˆ’1) ]
m
m
1 X (tâˆ’1) 2 (tâˆ’1) 2
1 X (tâˆ’1) (tâˆ’1)
2Î·
vBi +
(Î·
) kgBi k
â‰¤(h(tâˆ’1) )2 âˆ’
m i=1
m i=1
2Î· (tâˆ’1) (tâˆ’1) (Î· (tâˆ’1) )2 (tâˆ’1) 2
v
+
kg
k
m
m
Î· (tâˆ’1) (Î»N Âµ + Ïƒmin (X, k)) (tâˆ’1) 2 (Î· (tâˆ’1) )2 2
â‰¤(h(tâˆ’1) )2 âˆ’
(h
) +
c0 ..
Î»mN 2
m
=(h(tâˆ’1) )2 âˆ’

Let Î· (t) =

Î»mN 2
(Î»N Âµ+Ïƒmin (X,k))(t+1) .

Then we obtain

E[(h(t) )2 | Î±(tâˆ’1) ] â‰¤


1âˆ’

1
t



(h(tâˆ’1) )2 +

Î»2 mN 4 c20
.
(Î»N Âµ + Ïƒmin (X, k))2 t2

By taking expectation on both sides of the above over Î±(tâˆ’1) , we further get


1
Î»2 mN 4 c20
E[(h(t) )2 ] â‰¤ 1 âˆ’
E[(h(tâˆ’1) )2 ] +
.
t
(Î»N Âµ + Ïƒmin (X, k))2 t2
This recursive inequality leads to
E[(h(t) )2 ] â‰¤

Î»2 mN 4 c20
(Î»N Âµ + Ïƒmin (X, k))2



1 ln t
+
t
t




= c2

1 ln t
+
t
t


.

This proves the desired bound in part(a).
Part(b): Let us consider  =

Î»N Â¯
2Ïƒmax (X) .

From part(a) and Lemma 6 we obtain
E[kÎ±(t) âˆ’ Î±Ì„k] â‰¤ Î´

3c2
(t)
2
after t â‰¥ t2 = Î´3c
âˆ’ Î±Ì„k â‰¤ E[kÎ±(t) âˆ’ Î±Ì„k]/Î´ â‰¤  holds with
2 2 ln Î´ 2 2 . Then from Markov inequality we know that kÎ±
(t)
(t)
probability at least 1 âˆ’ Î´. Lemma 2 shows that kÎ± âˆ’ Î±Ì„k â‰¤  implies supp(w ) = supp(wÌ„). Therefore when t â‰¥ t2 , the
event supp(w(t) ) = supp(wÌ„) occurs with probability at least 1 âˆ’ Î´.

Dual Iterative Hard Thresholding

Similar to the proof arguments of Theorem 4(b) we can further show that when t â‰¥ 4t2 , with probability at least 1 âˆ’ Î´/2
kÎ±(t) âˆ’ Î±Ì„k â‰¤
which then leads to

Î»N Â¯
,
2Ïƒmax (X)



Ïƒmax (X, k)
(t)
P D â‰¤ c0 1 +
kÎ±(t) âˆ’ Î±Ì„k.
ÂµÎ»N

Since t â‰¥ t3 , from the arguments in part(a) and Lemma 6 we get that kÎ±(t) âˆ’ Î±Ì„k â‰¤


c0 (1+

Ïƒmax (X,k)
ÂµÎ»N

at least 1 âˆ’ Î´/2. Let us consider the following events:
(t)

â€¢ A: the event of P D â‰¤ ;
â€¢ B: the event of kÎ±(t) âˆ’ Î±Ì„k â‰¤
â€¢ C: the event of kÎ±(t) âˆ’ Î±Ì„k â‰¤

Î»N Â¯
2Ïƒmax (X) ;

c0 (1+

Ïƒmax (X,k)
ÂµÎ»N

)

.

When t â‰¥ max{4t2 , t3 }, we have the following holds:
P(A) â‰¥ P(A | B)P(B) â‰¥ P(C | B)P(B) â‰¥ (1 âˆ’ Î´/2)2 â‰¥ 1 âˆ’ Î´.
This proves the desired bound.

)

holds with probability

