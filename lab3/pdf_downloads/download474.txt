Stochastic Bouncy Particle Sampler
Supplementary Material
A. Proof Sketch of Invariance under Noisy Gradients
In this section we start with a simple reformulation of the proof in (Bouchard-Côté et al., 2015) that the BPS Markov
process leaves invariant the distribution p(w, v) = p(w)p(v) where
p(w) ∝
p(v)

=

e−U (w) ,
Unif[S

D−1

w ∈ RD ,

(A.1)

],

(A.2)

where S D−1 is the D-dimensional one-sphere. This will set the stage for the noisy case considered next. For a more formal
and detailed treatment of the BPS algorithm, including ergodicity, see (Bouchard-Côté et al., 2015). For simplicity, we do
not include here the velocity refreshments, which do not change the proof.
The proof sketches below are presented using a discrete-time approach followed by letting ∆t → 0. We have found this
approach more accessible for a machine learning audience. After submitting a preliminary version of this work to the
arXiv, the preprint (Fearnhead et al., 2016) was submitted to the arXiv, which presents similar proofs of invariance by first
deriving a general Fokker-Planck equation and then showing that the equation is satisfied both in noiseless and noisy cases.
A.1. Exact Gradient
To understand why the algorithm is correct, consider first the transition rule

(w + v∆t, v) with probability 1 − ∆t[G]+
(w, v)t+∆t =
(w + v∆t, vr ) with probability ∆t[G]+

(A.3)

where
[x]+ = max(x, 0) ,

(A.4)

G = v · ∇U (w) ,

(A.5)

and
vr = v − 2

(v · ∇U (w))∇U (w)
.
||∇U (w)||2

(A.6)

[pt+∆t (w, v)]d + [pt+∆t (w, v)]r .

(A.7)

This rule acts on the probability density p(w, v) as,
pt+∆t (w, v)

=

The two terms in (A.7) correspond to the two ways to reach (w, v) at time t + ∆t. First, we can start at (w − v∆t, v) at
time t and move a distance v∆t without bouncing. This occurs with probability 1 − ∆t[v · ∇U ]+ , so we have
[pt+∆t (w, v)]d

=

(1 − ∆t[v · ∇U ]+ )pt (v)pt (w − v∆t) ,

=

(1 − ∆t[v · ∇U ]+ )pt (v)(pt (w) − ∆tv · ∇pt (w) + O(∆t2 )) ,

=

(A.8)
2

pt (v)pt (w) [1 + ∆tv · ∇U − ∆t[v · ∇U ]+ ] + O(∆t ) ,

(A.9)
(A.10)

where in (A.9) we did a Taylor expansion and in (A.10) we used (A.1).
The second term in (A.7) corresponds to being at (w − vr ∆t, vr ) at time t, moving vr ∆t and bouncing. This occurs with
probability ∆t[vr · ∇U ]+ = ∆t[−v · ∇U ]+ , so we have
[pt+∆t (w, v)]r

=

∆t[−v · ∇U ]+ pt (w − vr ∆t, vr ) ,

(A.11)

=

∆t[−v · ∇U ]+ pt (w, vr ) + O(∆t2 ) ,

(A.12)

where again we did a Taylor expansion in (A.11). Adding (A.10) and (A.12), and using
[v · ∇U ]+ − [−v · ∇U ]+ = v · ∇U ,

(A.13)

equation (A.7) becomes
= pt (w, v) + O(∆t2 ) ,

pt+∆t (w, v)
which implies that the distribution is stationary,

dpt (w,v)
dt

(A.14)

= 0.

A.2. Noisy Gradient
Consider now a noisy gradient represented as
∇Ũ (w) = ∇U (w) + nw ,

nw ∼ p(nw |w) ,

nw ∈ RD ,

(A.15)

where we assume that p(nw |w) has zero mean.
First note that the requirement that nw and n0w are conditionally independent given w and w0 , with w 6= w0 , is needed to
preserve under the noise the Markov property of the sampler, which requires the bounce point process intensity to depend
only on w, and not the past history of the w trajectory.
Next we decompose the random vector nw into two orthogonal components,
nw = yv + nv ,

(A.16)

with y = v · nw , and nv · v = 0. This induces a corresponding decomposition in the probability density as
dnw p(nw |w) = dydnv p(y|w)p(nv |y, w, v) ,

(A.17)

and note that from the assumption that p(nw |w) has zero mean it follows that p(y|w) has zero mean. The noisy projected
gradient becomes
v · ∇U (w) + y ,

y ∼ p(y|w) .

(A.18)

To study the invariance of p(w, v) under the noisy BPS, let us consider again the decomposition (A.7) into straight and
bounced infinitesimal trajectories. The probability that the particle is at (w − v∆t, v) at time t and moves a distance v∆t
without bouncing is the average of 1 − ∆t[v · ∇U (w) + y]+ over all the possible realizations of y, and is therefore given
by
Z +∞
1 − ∆tPv ≡ 1 − ∆t
[v · ∇U (w) + y]+ p(y|w)dy ,
(A.19)
−∞
+∞

Z
=

1 − ∆t

(v · ∇U (w) + y)p(y|w)dy ,

(A.20)

−v·∇U (w)

where the above expression defines Pv . The first term of (A.7) is therefore
[pt+∆t (w, v)]d

=
=

(1 − ∆tPv )p(w − v∆t, v) ,

(A.21)
2

pt (w, v) − ∆tv · ∇pt (w)pt (v) − ∆tPv pt (w)pt (v) + O(∆t ) ,

= pt (w)pt (v)[1 + ∆tv · ∇U (w) − ∆tPv ] + O(∆t2 ) ,

(A.22)

similarly to (A.8)-(A.10).
The second term in (A.7) now has contributions from all those values (w − ṽr ∆t, ṽr ) at time t, such that a reflection of
ṽr with respect to a noisy ∇Ũ (w) gives v. Such a ṽr exists for every value of the noise vector nw , and is given by
ṽr = v − 2

(v · ∇Ũ (w))∇Ũ (w)
,
||∇Ũ (w)||2

(A.23)

Therefore the second term in (A.7) contains contributions from all the possible realizations of nw and is
Z
[pt+∆t (w, v)]r = ∆t
dnw [ṽr · ∇Ũ (w)]+ p(nw |w)pt (w − ṽr ∆t, ṽr ) ,
(A.24)
RD
Z +∞
Z
= ∆tpt (w, ṽr )
dy p(y|w)[−v · ∇U (w) − y]+ , × dnv p(nv |y, w, v) + O(∆t2 ) ,
−∞

=

∆tPvr pt (w, ṽr ) + O(∆t2 ) ,

(A.25)
R
where we used ṽr · ∇Ũ (w) = −v · ∇U (w) − y, the measure decomposition (A.17), dnv p(nv |y, w, v) = 1 and defined
Z −v·∇U (w)
Pvr =
dy (−v · ∇U (w) − y)p(y|w) .
(A.26)
−∞

Adding now (A.22) and (A.25), using p(ṽr ) = p(v) (since p(v) is uniform) and
Pv − Pvr = v · ∇U (w) ,

(A.27)

which follows from (A.20) and (A.26), and the fact that p(y|w) has zero mean, we get again the stationarity condition
= pt (w, v) + O(∆t2 ) .

pt+∆t (w, v)

(A.28)

B. Biased Approximation
B.1. Biased bouncing rate
In the noiseless case, the velocity bounce is an event in a Poisson process with intensity λ(w) = [v · ∇U (w)]+ while in
the noisy case, the average Poisson intensity is λn (w) = Ey [λn (w, y)] where
λn (w, y) = [v · ∇U (w) + y]+ .

(B.29)

When a thinning upper bound for [v·∇U +y]+ is unknown and the distribution of y is Gaussian with predicted variance ρ2 ,
our algorithm makes a bounce proposal from a Poisson process with intensity
λρ (w) = Ĝ + kρ(w) ,

(B.30)

where Ĝ is our estimate of v · ∇U (w). At the proposed bounce point w, we evaluate λn (w, y), and accept with probability
min(λn (w, y)/λρ (w), 1). The evaluation of λn (w, y) also provides an estimate σ 2 (w) of the variance of y. Assuming y
is Gaussian, the probability of the bound violation event 1 < λn /λρ , is
q(w) = 1 − Φ((λρ (w) − v · ∇U (w))/σ(w)) ,

(B.31)

where Φ is the standard normal CDF. For a given y, the intensity is therefore,
λb (w, y)

=

I[ λn <1] λn (w, y) + I[ λn >1] λρ (w)
λρ

(B.32)

λρ

where I[·] is the indicator function. Averaging over y we get
λb (w)

=

Ey [λb (w, y)]

(B.33)

=

(1 − q(w))Eλn ≤λρ [λn (w, y)] + q(w)λρ (w)

(B.34)

If the probability of bound violation has a universal upper bound q(w) < q, ∀w, we assume
|λb (w) − λn (w)| ≤ Kq = Cq + O(q 2 )

(B.35)

where C is a constant.
B.2. Preliminaries
We are interested bounding the distance between the equilibrium distribution of the biased, noisy BPS process with mean
intensity λb (w), and the exact, noisy process with mean intensity λn (w). We start with some preliminary results.

Wasserstein Distance and Kantorovich Duality
We will consider the Wasserstein distance, defined as
dW (p1 , p2 ) = sup |Ep1 [f ] − Ep2 [f ]| ,

(B.36)

f ∈CL

where CL is the set of 1-Lipshitz continuous functions,
CL = {f : Rd → R : |f (y) − f (x)| ≤ |y − x|} .

(B.37)

Given random variables z1 ∼ p1 , z2 ∼ p2 , a coupling is a joint distribution (z1 , z2 ) ∼ p12 with marginals p1 and p2 . The
Kantorovich duality (Villani, 2008) asserts that
dW (p1 , p2 ) = inf Ep12 [|z1 − z2 |] .
p12

(B.38)

Generators
To simplify the notation, let us define z = (w, v), zr = (w, ṽr ). The infinitesimal generator of a stochastic process is
defined as
Lf (z) = lim

δt→0

E[f (zt+δt )|zt = z] − f (z)
,
δt

(B.39)

and note that it satisfies
R

E[Lf ]

dzt+δt dzp(zt+δt |z)p(z)f (zt+δt ) − E[f (z)]
,
δt
R
dzt+δt p(zt+δt )f (zt+δt ) − E[f (z)]
= lim
,
δt→0
δt
= 0,
=

lim

δt→0

(B.40)
(B.41)
(B.42)

Rwhere the expectation is with respect to the distribution p(z) invariant under the stochastic process, and we used
dzp(zt+δt |z)p(z) = p(zt+δt ). In our case, the generator of a BPS process with intensity λn (w, y) is (Davis, 1984;
Fearnhead et al., 2016)
Lλn f (z) = v · ∇w f (z) + Ey [λn (w, y)(f (zr ) − f (z))]

(B.43)

fλ (z, t) = Eλ [f (zt )|z0 = z] ,

(B.44)

and similarly for λb (w).
Let us define

where the expectation is with respect to the distribution of the stochastic process with intensity λ at time t and with a given
initial condition. This expression satisfies the backward Kolmogorov equation
∂fλ (z, t)
∂t

=

Lλ fλ (z, t) ,

(B.45)

and also (Jacod & Shiryaev, 1987)
lim fλ (z, t) = Eλ [f ] ,

t→∞

(B.46)

where the expectation Eλ [·] is with respect to the distribution invariant under the stochastic process with intensity λ.

Ergodicity
We assume that the random process defined by SBPS is polynomial ergodic (although see the recent (Deligiannidis et al.,
2017)). In particular, we assume that two distributions started at reflected velocities pλn ,t,z = pλn (zt |z0 = z), pλn ,t,zr =
pλn (zt |z0 = zr ) converge as
dW (pλn ,t,z , pλn ,t,zr ) ≤

CA
(α + t)β

(B.47)

where α, β, CA are constants.1
Poisson Equation
Given a function f (z), we will consider below the Poisson equation
Lλ uf (z) = f (z) − Eλ [f ] .

(B.48)

We assume the existence of the solution
Z

∞

ds(Eλ [f ] − fλ (z, s)) ,

uf (z) =

(B.49)

0

where fλ (z, s) was defined in (B.44). The fact that this expression solves (B.48) can be easily verified using (B.45), (B.46)
and fλ (z, 0) = f (z). For f ∈ CL (see (B.37) ), this solution satisfies

Z ∞



(B.50)
ds(fλ (z, s) − fλ (zr , s))
|uf (z) − uf (zr )| = 
Z 0∞
≤
dsEλ [zs − zr,s |] , using the Lipshitz property
(B.51)
Z0 ∞
≤
ds dW (pλ,s,z , pλ,s,zr ) , using (B.38)
(B.52)
0

≤

CA
,
(β + 1)αβ+1

using the ergodicity assumption (B.47) .

(B.53)

B.3. Distance Bound from Stein’s Method
We now prove a bound on the distance between the exact and biased distributions, using Stein’s method (Barbour, 1990;
Ross, 2011; Stein et al., 1972), which was recently used for the related Zig-Zag process (Huggins & Zou, 2017).

dW (pλn , pλb )

=

sup |Eλn [f ] − Eλb [f ]| ,

(B.54)

sup |Eλn [Lλb uf ]| ,

(B.55)

f ∈CL

=

using (B.48)

f ∈CL

=

sup |Eλn [Lλb uf ] − Eλn [Lλn uf ]| ,

using (B.42)

(B.56)

f ∈CL

≤

sup Eλn [|(Lλb − Lλn )uf |] .

(B.57)

f ∈CL

Note that this last expression involves an integral over just one distribution, unlike the first expression (B.54). Inside the
expectation we have, using (B.43),
(Lλn − Lλb )uf (z) ≤

|λn (w) − λb (w)|Ey [|uf (zr ) − uf (z)|] ,

(B.58)

1
This assumed property follows usually from the existence of small sets (Lemma 3 in (Bouchard-Côté et al., 2015)) along with an
appropriate Lyapunov function (Roberts et al., 2004).

where the expectation over y is because zr = (w, vr ) depends on the noise y (see (A.23)). Using (B.35) and (B.53), we
get finally
dW (pλn , pλb ) ≤

Kq CA
.
(β + 1)αβ+1

(B.59)

Interestingly, this bound depends on the mixing speed of the process generated by Lλn (see (B.47)), even though the
distance is between two equilibrium distributions.

C. SBPS algorithm
Algorithm 1 provides a description of the SBPS algorithm with a linear regression based thinning proposal intensity. We
have omitted velocity refreshments for the sake of clarity. ∆t in the code below is the resolution of the piecewise linear
proposal intensity, which should be smaller than the typical time between bounces. In all experiments a value of ∆t = .01
was used.
Algorithm 1 Stochastic Bouncy Particle Sampler
SBPS:
Initialize particle position w ∈ RD , velocity v ∈ S D−1 , t ← 0, regression coefficients β̂0 , β̂1 , ρ(t)
while desired do
t, λ(t) = Sample Proposal Time(β̂0 , β̂1 , ρ(t))
w ←w+v∗t
Store w, t
Observe ∇Ũ (w), Var [v · ∇ log p(xri |w)]
(optional: Update preconditioner and apply it to gradient - see ??)
Calculate G̃(t), c(t)
v = Accept/Reject Proposal(G̃(t), λ(t), v)
β̂0 , β̂1 , ρ(t) = Update Local Regression Coefficients(G̃(t), c(t), t)
end while
Return piecewise linear trajectory of w
Sample Proposal Time(β̂0 , β̂1 , ρ(t)):
tnext proposal ← 0
Initialize set of interpolation points p = {[β̂1 tnext proposal + β̂0 + kρ(tnext proposal )]+ }
Initialize piecewise linear proposal intensity λ(t) = Inter(p)*
Sample u ∼ Unif[0, 1]
Rt
while −log(u) > 0 next proposal λ(t)dt do
Rt
tnext proposal ← tnext proposal + min(∆t, −log(u) − 0 next proposal λ(t)dt)
p ← p ∪ [β̂1 tnext proposal + β̂0 + kρ(tnext proposal )]+
λ = Inter(p)
end while
Return tnext proposal , λ(tnext proposal )
* Inter(p) is a linear interpolation of the points in p and their respective times since the last proposal
Accept/Reject Proposal(G̃(t), λ(t), v):
Draw u ∼ Unif[0, 1]
if u > G̃(w)/λ(t) then
Proposed bounce time accepted:
Initialize {G̃(ti ), c(ti )} and regression coefficients β̂0 , β̂1 , ρ(t) using G̃(t), c(t)
Ũ (w))∇Ũ (w)
Return v − 2 (v·∇||∇
Ũ (w)||2
else
Proposed bounce time rejected, maintain current trajectory:
Return v
end if
Update Local Regression Coefficients(G̃(t), c(t), t):
Add G̃(t), c(t) to {G̃(ti ), c(ti )}
(optional: Perform hyperparameter learning step on regression priors)
Update regression coefficients β̂0 , β̂1 , ρ(t0 ) using standard Bayesian regression formula
(optional: If β̂1 < 0 set β̂1 to non-negative value, update β̂0 accordingly)
Return β̂0 , β̂1 , ρ(t)

−2
−1

0

1

2

3

-1. -2.00
50 e+
e+ 0
03 3
0e
+0
3

-1. -2.00
50 e+
e+ 03
03
0e
+0
3
-1.
0

−2

−3−3

SBPS

-1.
00
e+
-2. -1.50
03
00 e+
e+ 0
03 3

-1.
00
e+
-2. 1.50
03
00 e+
e+ 0
3
03

−1

−2
−2

3
+0
0e
03
e+ 03
50 +
-1. 2.00e
-

−1

0

0
-1.

3
+0
0e
03
e+ 03
50 +
-1. .00e
-2

3
+0
0e
03
e+ 03
50 +
-1. .00e
-2

-1.
00
e+
-2. 1.50
03
00 e+
e+ 0
3
03

-1. -2.00
50 e+
e+ 03
03
0e
+0
3

0

1

03
e+ 03
00 e+
-2.1.50
03
e+
00
-1.

1

0
-1.

0
-1.

−1

2
03
e+ 03
00 +
-2.1.50e
03
e+
00
-1.

0

03
e+ 03
00 +
-2.1.50e
03
e+
00
-1.

1

10000 iterations

3

2

-1.
0

2

−3−3

1000 iterations

3

-1.
0

100 iterations

3

−2

−1

SGLD 0.1

0

1

SGLD 1

2

3

−3 −3

−2

−1

0

1

2

3

mSGNHT 0.2

Figure 1: Sample traces of SBPS, SGLD and mSGNHT sampling a highly non-Gaussian posterior. SBPS appears to explore the
posterior more fully and avoids regions of low density as opposed to the large step size SGLD, leading to less bias.

D. A Highly non-Gaussian Example
We explored a case of sampling from a Bayesian posterior where the Laplace approximations is not accurate. Figure 1
shows results for a highly non-log-concave 2D hyperboloid posterior, with data generated according to yi ∼ N (w0∗ w1∗ , σ).
After introducing a weak Gaussian prior, the resulting log posterior takes the form
L(w0 , w1 |{yi }, σ) =

N
X
i=1

−

(yi − w0 w1 )2
c
− ||w||22 .
2σ 2
2

(D.60)

This posterior was approximated by observing mini-batches of data as in the previous examples. The scaling symmetry
that is manifest in the invariance of the likelihood with respect to w0 , w1 → λw0 , wλ1 leads to the highly non-Gaussian
hyperboloid form. Similar symmetries are encountered in posteriors of deep neural networks with ReLU activation (Dinh
et al., 2017). The parameters used were N = 1000, n = 100, k = 3, c = .0001, w0∗ = w1∗ = 0, σ = 1. σ was not learned.
Figure 1 shows comparisons with SGLD and mSGNHT, while Local BPS and SS-ZZ cannot be applied since there seems
to be no simple exact upper bound for thinning in this case. Note that for the step sizes shown, both SGLD and mSGNHT
deviate into low density regions while not mixing as well as SBPS. The smaller SGLD step size used does not deviate as
much but exhibits even slower mixing.

E. Sampling from Multimodal Targets
Our simple linear model for G(t) (the projected gradient of the log posterior), appears to be sufficiently accurate even when
the Laplace approximation is violated (as shown in the previous examples), but in some highly multimodal cases we have
found this approximation to be insufficient.
In this section we present a slight modification of SBPS to sample from such targets as well. The potential troubles arise
because in a multimodal target one may encounter situations where the measured G(t) drop quickly between successive observations, leading to strong negative regression slopes. In our regression model, we get an interpolation (cf. equation (13))
leading to an upper bound of the form
β̂1 t + β̂0 + kρ(t)

(E.61)

with β̂1 < 0. Since the leading order t dependence in ρ(t) is linear, if k is too small the linear term in (E.61) may be
negative. This will lead the sampler to propose long times between samples and thus enter low target density regions of the
space.

Ground Truth

3

SBPS samples
3

2

2

1

1

0

0
−1

−1

−2
−2
−3
−3
−3

−2

−1

0

1

2

3

−3

−2

−1

0

1

2

3

Figure 2: SBPS sampling from a highly multimodal target. As can be seen from the sample histogram on the right, SBPS manages to
accurately capture the multimodal target. The results are from 1000 epochs of sampling from a dataset of size N = 1000

In such cases, we propose to make additional auxiliary observations at times {taux } along the current linear trajectory
of the particle and update the linear bound accordingly before making the next proposal. On a large enough scale this
procedure will make auxiliary observations G̃ > 0 leading to a positive slope in (E.61). This in turn will prevent the
particle from entering low target density regions.
Note that these auxiliary observations can be performed with the same minibatch of data from the last bounce proposal. In
principle, such strong negative slopes can occur even for a unimodal target if the subsampling noise is highly non-Gaussian,
and this mechanism can also be used in those situations.
We illustrate this mechanism in a simple distribution defined as

L(w) =

D
N X
X

Li (wk ) + const.

(E.62)

i=1 k=1

where w ∈ RD and
"
Li (wk ) = log e

−

2
(wk −1−µi
k)
2σ 2
L

+e

−

2
(wk +1−µi
D+k )
2σ 2
L

#
(E.63)

and each µik is drawn from N (0, σµ ). This is a highly multimodal toy distribution. Although it does not come from
a posterior distribution, it allows us to illustrate the proposed mechanism in a clean setting. Figure 2 shows results for
D = 2, N = 1000, σL = .25, σµ = .01 and mini-batch size n = 10. We used {taux } = {10pt, p ∈ N} where t is the
mean proposal time of all past proposals during the sampling process. While one can add multiple auxiliary points in this
way, in practice we have found that one auxiliary point (p = 1) is sufficient. Figure 2 shows that SBPS is able to correctly
sample from the target while avoiding the issues posed by the multimodality of the distribution. We note that this modified
mechanism does not affect the rest of the examples presented in this paper.

F. SGLD Step Size Scan
In the logistic regression example of Section 6.1, we compare SBPS with Stochastic Gradient Langevin Dynamics
(SGLD) (Welling & Teh, 2011) with fixed step size. A natural question is how to choose an appropriate step size that
ensures the fastest possible mixing without introducing an unacceptable amount of bias. Our criterion was to pick the
biggest possible (i.e., fastest-mixing) step size such that the resulting variance of the per-data-point Negative Log Likelihood (NLL) coincides with that of the Laplace approximation. The latter gives a per-data-point NLL distribution of
1
2
2N χ (d) + N LLŵ /N where ŵ is the MAP estimator (Bickel & Doksum, 2015). The results of this parameter scan are
shown in Figure 3 and suggest a step size of 0.1.

NLL per data point variance

10 -1

SGLD samples
1
χ 2 (d) variance
2N

10 -2
10 -3
10 -4
10 -5
10 -6 -5
10

10 -4

10 -3

10 -1
10 -2
SGLD step size

10 0

10 1

10 2

Figure 3: Per-data-point variance of the NLL in the logistic regression example of Section 7.1, using SGLD samples with step sizes of
10−i/2 , i = 0...9. The samplers were initialized at the MAP. We select the biggest step size whose empirical variance is below that from
the Laplace approximation, 2Nd 2 .

G. The effect of the SBPS hyperparameters
In this section we explore, in the logistic regression example of Section 6.1, the effect of two hyperparameters that control
the behavior of SBPS: the mini-batch size n, and the width k of the upper confidence band. A third hyperparameter is the
rate of velocity refreshments, shown in (Bouchard-Côté et al., 2015) to be necessary in general to prove ergodicity. But, as
mentioned in Section 3, in the examples we considered the mini-batch noise was enough to sufficiently randomize possible
non-mixing trajectories, so we could safely set this parameter to a very low value.
G.1. Mini-batch size n
Figure 4 shows an exploration of different values of the mini-batch size n. Low values for n lead to high noise for G̃.
This in turn yields higher values for the proposal intensity γ(t), which leads to shorter linear trajectories between bounce
proposals. This is consistent with the results of Figure 4 that show a linear relation between n (i.e. computational cost
per bounce proposal) and the average travel time between bounces. The autocorrelation functions (ACFs) were computed
from discrete samples obtained by running SBPS with different n’s such that the total data cost was the same for all cases,
and then discretizing the continuous paths into equal numbers of uniformly spaced samples. As shown, these cost adjusted
ACFs are quite similar. On the other hand, the upper-left panel, shows that lower values of n have faster convergence
to equilibrium, suggesting that low n should be preferred. But this should be contrasted with the fact that shorter linear
trajectories increase the variance of expectations over rapidly changing functions, as discussed in Section 6.3.
G.2. Upper-band width k
Figure 5 shows an exploration of different values of k, the height of the proposal intensity above the estimator mean, in
units of predictive standard deviation (see in Eq.(12) in main text). It therefore controls the trade-off between a regime, at
low k, of faster mixing and high bias from violations of the thinning upper bound ([G̃(t)]+ /λ(t) > 1), and another regime,
high k, of low bias and high variance from slower mixing. As expected, the probability of bound violation decreases
monotonically with k, as seen in the bottom left panel of Figure 5.

1.0 direction f largest c variance

NLL per data p int (l g scale)
NLL ŵ /N
Laplace appr (̂

0.8

0.8

0.6

0.6
0.2

0.2

0.0

0.0
10

104
0.8
0.7
0.6
0.5
0.4
0.3
0.2
0.1
0.0
−0.1
0

105
106
data p ints bserved

−0.4

105

104

lag

−10

106

103

rdinate trace

−12

400
600
800
mini-batch size n

1000

105
lag

106

0.4

−14

0.2

−16
0.0

−18

−0.2

−20
200

104

0.6

c

average time between b unces

−0.2

−0.2

-1

directi n f smallest c variance

0.4

0.4

ACF

100

1.0

−22
0

1
2
3
data p ints bserved

4
1e6

−0.4
0.0

0.5
1.0
1.5
data p ints bserved

2.0
1e5

Figure 4: Effect of mini-batch sizes n in the logistic regression example of Section 6.1. Mini-batch sizes were 50, 100, 200, 500, 900.
Top Left: Average per-data-point NLL over 5 runs. Note that smaller n lead to faster convergence to a region of low NLL. Lower Left:
Estimated average time between particle bounces. Center/Right: ACF and trajectories from a single run, in the directions of smallest
and biggest covariance. The x axis was chosen differently for the trajectory plots for clarity.

NLL per data point (log scale)
NLL ŵ
0.30
Laplace approx.

10-1
0.09
0.08

10

5

10
10
10
data points observed

6

10

0.2
0.0
2

10

30

0.15
0.10
0.05
0.00
0

0.4

0.2
−0.2

4

1
2
3
4
5
confidence interval multiple k

6

direction of smallest covariance

0.6

0.0
3

1.0
0.8

0.4

coordinate trace

bound violation probability

0.20

0.8
0.6
ACF

0.20

direction of largest covariance

1.0

0.40

3

10

4

lag

10

5

10

25
20
15
10
5
0

1

2
3
4
data points observed

6

102
1.0
0.8
0.6
0.4
0.2
0.0
−0.2
−0.4
−0.6
5
0
1e5

103

1

105
104
lag

106

2
3
4
data points observed

5
1e4

Figure 5: Effect of upper band size k in the logistic regression example of Section 6.1, run with mini-batch size n = 100. Bottom Left:
Rate of upper bound violations as a function of k; the same colors are used in the other plots. Top Left: NLL per data point for samples of
SBPS with different k values. Center/Right: ACF and trajectories in the directions of smallest and biggest covariance. Note that smaller
k leads to faster convergence and mixing but increased bias, as visible in the coordinate trace in the direction of biggest covariance. The
x axis was chosen differently for the trajectory plots for clarity.

H. Upper Bounds for Logistic Regression
In the case of logistic regression with data (yi , xi ) the estimator of ∇w U (w) from a mini-batch of size n is
∇w Ũ (w) =

n
NX
xi (σ(w · xi ) − yi ) .
n i=1

(H.64)

A simple bound on G̃(t) is therefore given by
n
N X
|
(v · xi )(σ(w · xi ) − yi )| ,
n i=1

(H.65)

n
NX
≤
||v||2 ||(σ(w · xi ) − yi )xi ||2 ,
n i=1

(H.66)

G̃(t) ≤

n

NX
||xi ||2 ,
n i=1
√
≤ dN max |xij | .
≤

i,j

(H.67)
(H.68)

This is a particular case of a bound derived in (Bierkens et al., 2017). Compared to the bound proposed in (Bouchard-Côté
et al., 2015), this bound is more conservative but cheaper to compute and does not require non-negative covariates. It
similarly scales like N and when the data used in the experiments was modified so that the covariates were non-negative
the bounds differed by a factor lower than 2.

References
Barbour, Andrew D. Stein’s method for diffusion approximations. Probability theory and related fields, 84(3):297–322,
1990.
Bickel, Peter J and Doksum, Kjell A. Mathematical Statistics: Basic Ideas and Selected Topics, volume I, volume 117.
CRC Press, 2015.
Bierkens, Joris, Bouchard-Côté, Alexandre, Doucet, Arnaud, Duncan, Andrew B, Fearnhead, Paul, Roberts, Gareth, and
Vollmer, Sebastian J. Piecewise Deterministic Markov Processes for Scalable Monte Carlo on Restricted Domains.
arXiv preprint arXiv:1701.04244, 2017.
Bouchard-Côté, Alexandre, Vollmer, Sebastian J, and Doucet, Arnaud. The Bouncy Particle Sampler: A Non-Reversible
Rejection-Free Markov Chain Monte Carlo Method. arXiv:1510.02451, 2015.
Davis, Mark HA. Piecewise-deterministic Markov processes: A general class of non-diffusion stochastic models. J. Royal
Stat. Soc., Series B (Methodological), pp. 353–388, 1984.
Deligiannidis, George, Bouchard-Côté, Alexandre, and Doucet, Arnaud. Exponential Ergodicity of the Bouncy Particle
Sampler. arXiv preprint arXiv:1705.04579, 2017.
Dinh, Laurent, Pascanu, Razvan, Bengio, Samy, and Bengio, Yoshua. Sharp minima can generalize for deep nets. arXiv
preprint arXiv:1703.04933, 2017.
Fearnhead, Paul, Bierkens, Joris, Pollock, Murray, and Roberts, Gareth O. Piecewise Deterministic Markov Processes for
Continuous-Time Monte Carlo. arXiv preprint arXiv:1611.07873, 2016.
Huggins, Jonathan H and Zou, James. Quantifying the accuracy of approximate diffusions and Markov chains. In AISTATS,
2017.
Jacod, J. and Shiryaev, A.N. Limit Theorems for Stochastic Processes. Grundlehren der mathematischen Wissenschaften
in Einzeldarstellungen. Springer-Verlag, 1987. ISBN 9783540178828.
Roberts, Gareth O, Rosenthal, Jeffrey S, et al. General state space markov chains and mcmc algorithms. Probability
Surveys, 1:20–71, 2004.
Ross, Nathan. Fundamentals of Stein’s method. Probab. Surv, 8:210–293, 2011.
Stein, Charles et al. A bound for the error in the normal approximation to the distribution of a sum of dependent random
variables. In Proceedings of the Sixth Berkeley Symposium on Mathematical Statistics and Probability, Volume 2:
Probability Theory. The Regents of the University of California, 1972.

Villani, Cédric. Optimal transport: old and new, volume 338. Springer Science & Business Media, 2008.
Welling, Max and Teh, Yee W. Bayesian learning via stochastic gradient Langevin dynamics. In ICML, pp. 681–688, 2011.

