Supplementary Material for
Learning Continuous Semantic Representations of Symbolic Expressions

Miltiadis Allamanis 1 Pankajan Chanthirasegaran 2 Pushmeet Kohli 3 Charles Sutton 2 4

1. Synthetic Expression Datasets
Table 1 and Table 2 are sample expressions within an equivalence class for the two types of datasets we consider.

2. Detailed Evaluation
Figure 1 presents the detailed evaluation for our k-NN metric for each dataset. Figure 2 shows the detailed evaluation
when using models trained on simpler datasets but tested
on more complex ones, essentially evaluating the learned
compositionality of the models. Figure 4 show how the
performance varies across the datasets based on their characteristics. As expected as the number of variables increase,
the performance worsens (Figure 4a) and expressions with
more complex operators tend to have worse performance
(Figure 4b). The results for U NSEEN E Q C LASS look very
similar and are not plotted here.

3. Model Hyperparameters
The optimized hyperparameters are detailed in Table 3.
All hyperparameters were optimized using the Spearmint
(Snoek et al., 2012) Bayesian optimization package. The
same range of values was used for all common model hyperparameters.

References
Snoek, Jasper, Larochelle, Hugo, and Adams, Ryan P. Practical Bayesian optimization of machine learning algorithms.
In NIPS, 2012.
Socher, Richard, Huval, Brody, Manning, Christopher D,
and Ng, Andrew Y. Semantic compositionality through
recursive matrix-vector spaces. In EMNLP, 2012.
Work started when M. Allamanis was at Edinburgh. This work
was done while P. Kohli was at Microsoft. 1 Microsoft Research,
Cambridge, UK 2 University of Edinburgh, UK 3 DeepMind, London, UK 4 The Alan Turing Institute, London, UK. Correspondence
to: Miltiadis Allamanis <t-mialla@microsoft.com>.
Proceedings of the 34 th International Conference on Machine
Learning, Sydney, Australia, PMLR 70, 2017. Copyright 2017 by
the author(s).

Learning Continuous Semantic Representations of Symbolic Expressions

B OOL 8
(¬a) ∧ (¬b)

(¬a ∧ ¬c) ∨ (¬b ∧ a ∧ c) ∨ (¬c ∧ b)

(¬a) ∧ b ∧ c

a¬((¬a) ⇒ ((¬a) ∧ b))
¬((b ∨ (¬(¬a))) ∨ b)
(¬a) ⊕ ((a ∨ b) ⊕ a)
(b ⇒ (b ⇒ a)) ∧ (¬a)
((¬a) ⇒ b) ⇒ (a ⊕ a)

c ⊕ (((¬a) ⇒ a) ⇒ b)
¬((b ⊕ (b ∨ a)) ⊕ c)
¬((¬(b ∨ (¬a))) ⊕ c)
((b ∨ a) ⊕ (¬b)) ⊕ c)
(¬((b ⊕ a) ∧ a)) ⊕ c

¬((¬b) ∨ ((¬c) ∨ a))
((a ∨ b) ∧ c) ∧ (¬a)
(¬((¬(¬b)) ⇒ a)) ∧ c
(c ∧ (c ⇒ (¬a))) ∧ b
b ∧ (¬(b ∧ (c ⇒ a)))

False

(¬a) ∧ (¬b) ∨ (∧c)

¬a ∨ b

(a ⊕ a) ∧ (c ⇒ c)
(¬b) ∧ (¬(b ⇒ a))
b ∧ ((a ∨ a) ⊕ a)
((¬b) ∧ b) ⊕ (a ⊕ a)
c ∧ ((¬(a ⇒ a)) ∧ c)

(a ⇒ (¬c)) ⊕ (a ∨ b)
(a ⇒ (c ⊕ b)) ⊕ b
b ⊕ (a ⇒ (b ⊕ c))
(b ∨ a) ⊕ (x ⇒ (¬a))
b ⊕ ((¬a) ∨ (c ⊕ b))

a ⇒ ((b ∧ (¬c)) ∨ b)
¬(¬((b ∨ a) ⇒ b))
(¬a) ⊕ (¬(b ⇒ (¬a)))
b ∨ (¬((¬b) ∧ a))
¬((a ⇒ (a ⊕ b)) ∧ a)

Table 1. Sample of B OOL 8 data.

P OLY 8
−a − c

c2

b2 c 2

(b − a) − (c + b)
b − (c + (b + a))
a − ((a + a) + c)
(a − (a + a)) − c
(b − b) − (a + c)

(c · c) + (b − b)
((c · c) − c) + c
((b + c) − b) · c
c · (c − (a − a))
c·c

(b · b) · (c · c)
c · (c · (b · b))
(c · b) · (b · c)
((c · b) · c) · b
((c · c) · b) · b

c

b·c

b−c

c − ((c − c) · a)
c − ((a − a) · c)
((a − a) · b) + c
(c + a) − a
(a · (c − c)) + c

(c − (b − b)) · b
(b − (c − c)) · c
(b − b) + (b · c)
c · ((b − c) + c)
(b · c) + (c − c)

(a − (a + c)) + b
(a − c) − (a − b)
(b − (c + c)) + c
(b − (c − a)) − a
b − ((a − a) + c)

Table 2. Sample of P OLY 8 data.

Learning Continuous Semantic Representations of Symbolic Expressions

1.0

0.6

P OLY 8

P OLY 5

ONE V-P OLY 13

ONE V-P OLY 10

S IMP P OLY 10

S IMP P OLY 8

B OOL L5

S IMP B OOL L5

B OOL 10

B OOL 8

B OOL 5

S IMP B OOL 10

0.8

0.4
0.2

5 10

5 10

5 10

5 10

5 10

5 10

5 10

5 10

5 10

5 10

5 10

5 10

0.0

(a) S EEN E Q C LASS evaluation using model trained on the respective training set.
1.0

0.6

P OLY 8

P OLY 5

ONE V-P OLY 13

ONE V-P OLY 10

S IMP P OLY 10

S IMP P OLY 8

B OOL L5

S IMP B OOL L5

B OOL 10

B OOL 8

B OOL 5

S IMP B OOL 10

0.8

0.4
0.2

5 10

5 10

5 10

5 10

5 10

5 10

5 10

5 10

5 10

5 10

5 10

5 10

0.0

(b) U NSEEN E Q C LASS evaluation using model trained on the respective training set.
Figure 1. Evaluation of scorex (y axis) for x = 1, . . . , 15. on the respective S EEN E Q C LASS and U NSEEN E Q C LASS where each model
has been trained on. The markers are shown every five ticks of the x-axis to make the graph more clear. T REE NN refers to the model of
Socher et al. (2012).

Table 3. Hyperparameters used in this work.

Model

Hyperparameters

E Q N ET

learning rate 10−2.1 , rmsprop ρ = 0.88, momentum 0.88, minibatch size 900, representation size D = 64, autoencoder size M = 8, autoencoder noise κ = 0.61, gradient
clipping 1.82, initial parameter standard deviation 10−2.05 , dropout rate .11, hidden
layer size 8, ν = 4, curriculum initial tree size 6.96, curriculum step per epoch 2.72,
objective margin m = 0.5
learning rate 10−3.5 , rmsprop ρ = 0.6, momentum 0.01, minibatch size 650, representation size D = 64, gradient clipping 3.6, initial parameter standard deviation 10−1.28 ,
dropout 0.0, curriculum initial tree size 2.8, curriculum step per epoch 2.4, objective
margin m = 2.41
learning rate 10−3.5 , rmsprop ρ = 0.9, momentum 0.95, minibatch size 1000, representation size D = 64, gradient clipping 5, initial parameter standard deviation 10−4 ,
dropout 0.0, hidden layer size 16, curriculum initial tree size 6.5, curriculum step per
epoch 2.25, objective margin m = 0.62
learning rate 10−2.31 , rmsprop ρ = 0.90, momentum 0.66, minibatch size 100, representation size D = 64, gradient clipping 0.87, token embedding size 128, initial
parameter standard deviation 10−1 , dropout rate 0.26
learning rate 10−2.9 , rmsprop ρ = 0.99, momentum 0.85, minibatch size 500, representation size D = 64, gradient clipping 0.70, token embedding size 64, RNN parameter
weights initialization standard deviation 10−4 , embedding weight initialization standard
deviation 10−3 , dropout 0.0, stack count 40

1-layer-T REE NN

2-layer-T REE NN

GRU

StackRNN

5 10

5 10

5 10

5 10

5 10

5 10

5 10

1.0

5 10

P OLY 8→ONE V-P OLY 13

ONE V-P OLY 10→ ONE V-P OLY 13

5 10

0.8
P OLY 5→P OLY 8

P OLY 8→S IMP P OLY 10

P OLY 5→S IMP P OLY 10

S IMP P OLY 8→S IMP P OLY 10

S IMP P OLY 5→S IMP P OLY 10

P OLY 8→S IMP P OLY 8

B OOL 5→B OOL 10

B OOL 5→B OOL 8

B OOL L5→B OOL 8

Learning Continuous Semantic Representations of Symbolic Expressions

0.6
0.4
0.2

5 10

5 10

0.0

5 10

5 10

5 10

5 10

5 10

5 10

5 10

1.0

5 10

P OLY 8→ONE V-P OLY 13

ONE V-P OLY 10→ ONE V-P OLY 13

5 10

0.8
P OLY 5→P OLY 8

P OLY 8→S IMP P OLY 10

P OLY 5→S IMP P OLY 10

S IMP P OLY 8→S IMP P OLY 10

S IMP P OLY 5→S IMP P OLY 10

P OLY 8→S IMP P OLY 8

B OOL 5→B OOL 10

B OOL 5→B OOL 8

B OOL L5→B OOL 8

(a) S EEN E Q C LASS evaluation using model trained on simpler datasets. Caption is “model trained on”→“Test dataset”.

0.6
0.4
0.2

5 10

5 10

0.0

(b) Evaluation of compositionality. U NSEEN E Q C LASS evaluation using model trained on simpler datasets. Caption is “model trained
on”→“Test dataset”.
tf-idf

GRU

StackRNN

TreeNN-1Layer

TreeNN-2Layer

EqNet

1.0

1.0

0.8

0.8
True Positive Rate

True Positive Rate

Figure 2. Evaluation of compositionality. Evaluation of scorex (y axis) for x = 1, . . . , 15. The markers are shown every five ticks of the
x-axis to make the graph more clear. T REE NN refers to the model of Socher et al. (2012).

0.6

0.4

tf-idf
GRU
StackRNN

0.2

0.0
0.0

0.2

0.4
0.6
False Positive Rate

(a) S EEN E Q C LASS

TreeNN-1Layer
TreeNN-2Layer
EqNet
0.8

0.6

0.4

tf-idf
GRU
StackRNN

0.2

1.0

0.0
0.0

0.2

0.4
0.6
False Positive Rate

(b) U NSEEN E Q C LASS

Figure 3. Receiver operating characteristic (ROC) curves averaged across datasets.

TreeNN-1Layer
TreeNN-2Layer
EqNet
0.8

1.0

1.0

1.0

0.8

0.8

0.6

0.6

scorek

scorek

Learning Continuous Semantic Representations of Symbolic Expressions

1 Var
3 Vars
10 Vars

0.4
0.2
5

k

10

(a) Performance vs. Number of Variables

0.4

Simple
All

0.2
5

k

10

(b) Performance vs. Operator Complexity

Figure 4. E Q N ET performance on S EEN E Q C LASS for various dataset characteristics

