Max-value Entropy Search for Efficient Bayesian Optimization (Appendix)

Zi Wang 1 Stefanie Jegelka 1

1. Related work
Our work is largely inspired by the entropy search (ES) methods (Hennig & Schuler, 2012; Hernández-Lobato et al.,
2014), which established the information-theoretic view of Bayesian optimization by evaluating the inputs that are most
informative to the arg max of the function we are optimizing.
Our work is also closely related to probability of improvement (PI) (Kushner, 1964), expected improvement (EI) (Moc̆kus,
1974), and the BO algorithms using upper confidence bound to direct the search (Auer, 2002; Kawaguchi et al., 2015;
2016), such as GP-UCB (Srinivas et al., 2010). In (Wang et al., 2016), it was pointed out that GP-UCB and PI are closely
related by exchanging the parameters. Indeed, all these algorithms build in the heuristic that the next evaluation point needs
to be likely to achieve the maximum function value or have high probability of improving the current evaluations, which
in turn, may also give more information on the function optima like how ES methods queries. These connections become
clear as stated in Section 3.1 of our paper.
Finding these points that may have good values in high dimensional space is, however, very challenging. In the past,
high dimensional BO algorithms were developed under various assumptions such as the existence of a lower dimensional
function structure (Djolonga et al., 2013; Wang et al., 2013), or an additive function structure where each component is
only active on a lower manifold of the space (Li et al., 2016; Kandasamy et al., 2015). In this work, we show that our
method also works well in high dimensions with the additive assumption made in (Kandasamy et al., 2015).

2. Using the Gumbel distribution to sample y∗
To sample the function maximum y∗ , our first approach is to approximate the distribution for y ∗ and then sample from that
distribution. We use independent Gaussians to approximate the correlated f (x), ∀x ∈ X̂ where X̂ is a discretization of the
input search space X (unless X is discrete, in which case X̂ = X). A similar approach was adopted in (Wang et al., 2016).
We can show that by assuming {f (x)}x∈X̂ , our approximated distribution gives a distribution for an upperbound on f (x).
Lemma 2.1 (Slepian’s Comparison Lemma (Slepian, 1962; Massart, 2007)). Let u, v ∈ Rn be two multivariate Gaussian
random vectors with the same mean and variance, such that
E[v i v j ] ≤ E[ui uj ], ∀i, j.
Then for every y
Pr[ sup v i ≤ y] ≤ Pr[ sup ui ≤ y].
i∈[1,n]

i∈[1,n]

By the Slepian’s lemma, if the covariance kt (x, x0 ) ≥ 0,Q
∀x, x0 ∈ X̂, using the independent assumption with give us a
distribution on the upperbound ŷ∗ of f (x), Pr[ŷ∗ < y] = x∈X̂ Ψ(γy (x))).
We then use the Gumbel distribution to approximate the distribution for the maximum of the function values for X̂, Pr[ŷ∗ <
Q
y] = x∈X̂ Ψ(γy (x))). If for all x ∈ X̂, f (x) have the same mean and variance, the Gumbel approximation is in fact
asymptotically correct by the Fisher-Tippett-Gnedenko theorem (Fisher, 1930).
1

Computer Science and Artificial Intelligence Laboratory, Massachusetts Institute of Technology, Massachusetts, USA. Correspondence to: Zi Wang <ziw@csail.mit.edu>, Stefanie Jegelka <stefje@csail.mit.edu>.
Proceedings of the 34 th International Conference on Machine Learning, Sydney, Australia, 2017. JMLR: W&CP. Copyright 2017 by
the author(s).

Max-value Entropy Search for Efficient Bayesian Optimization

Theorem 2.2 (The Fisher-Tippett-Gnedenko Theorem (Fisher, 1930)). Let {vi }∞
i=1 be a sequence of independent and
identically-distributed random variables, and Mn = max1≤i≤n vi . If there exist constants an > 0, bn ∈ R and a non
n
degenerate distribution function F such that limn→∞ Pr( Mna−b
≤ x) = F (x), then the limit distribution F belongs to
n
either the Gumbel, the Fréchet or the Weibull family.
In particular, for i.i.d. Gaussians, the limit distribution of the maximum of them belongs to the Gumbel distribution (Von Mises, 1936). Though the Fisher-Tippett-Gnedenko theorem does not hold for independent and differently
distributed Gaussians, in practice we still find it useful in approximating Pr[ŷ∗ < y]. In Figure 1, we show an example of
the result of the approximation for the distribution of the maximum of f (x) ∼ GP (µt , kt )∀x ∈ X̂ given 50 observed data
points randomly selected from a function sample from a GP with 0 mean and Gaussian kernel.
1

Pr[ŷ ∗ < y]

0.8
0.6
0.4
0.2
0

Exact
Approx

8

10
y

12

Figure 1. An example of approximating the cumulative probability of the maximum of independent differently distributed Gaussians
Pr[ŷ∗ < y] (Exact) with a Gumbel distribution G(a, b) (Approx) via percentile matching.

3. Regret bounds
Based on the connection of MES to EST, we show the bound on the learning regret for MES with a point estimate for α(x).
Theorem 3.1. Let F be the cumulative probability distribution for the maximum of any function f sampled from
GP (µ, k) over the compact search space X ⊂ Rd , where k(x, x0 ) ≤ 1, ∀x, x0 ∈ X. Let f∗ = maxx∈X f (x) and
w = F (f∗ ) ∈ (0, 1), and assume the observation noise is iid N (0, σ). If in each iteration t, the query point is chosen
ψ(γyt (x))

y t −µ (x)

t
as xt = arg maxx∈X γy∗t (x) 2Ψ(γ ∗t (x)) − log(Ψ(γy∗t (x))), where γy∗t (x) = ∗σt (x)
and y∗t is drawn from F , then with
y∗
P
T
probability at least 1 − δ, in T 0 = i=1 logw 2πδ i number of iterations, the simple regret satisfies

r

CρT
(νt∗ + ζT )
(1)
T
PT
1
where C = 2/ log(1 + σ −2 ) and ζT = (2 log( πδT )) 2 ; π satisfies i=1 πi−1 ≤ 1 and πt > 0, and t∗ = arg maxt νt with
νt , minx∈X,y∗t >f∗ γy∗t (x), and ρT is the maximum information gain of at most T selected points.
rT 0 ≤

Before we continue to the proof, notice that if the function upper bound ŷ∗ is sampled using the approach described in
Section 3.1 and kt (x, x0 ) ≥ 0, ∀x, x0 ∈ X̂, we may still get the regret guarantee by setting y∗ = ŷ∗ (or y∗ = ŷ∗ + L
if X is continuous) since Pr[maxX̂ ≤ y] ≥ Pr[ŷ∗ < y]. Moreover, Theorem 3.1 assumes y∗ is sampled from a universal
maximum distribution of functions from GP (µ, k), but it is not hard to see that if we have a distribution of maximums
PT
adapted from GP (µt , kt ), we can still get the same regret bound by setting T 0 = i=1 logwi 2πδ i , where wi = Fi (f∗ )
and Fi corresponds to the maximum distribution at an iteration where y∗ > f∗ . Next we introduce a few lemmas and then
prove Theorem 3.1.
PT
1
Lemma 3.2 (Lemma 3.2 in (Wang et al., 2016)). Pick δ ∈ (0, 1) and set ζt = (2 log( π2δt )) 2 , where t=1 πt−1 ≤ 1, πt > 0.
Then, it holds that Pr[µt−1 (xt ) − f (xt ) ≤ ζt σt−1 (xt ), ∀t ∈ [1, T ]] ≥ 1 − δ.
Lemma 3.3 (Lemma 3.3 in (Wang et al., 2016)). If µt−1 (xt ) − f (xt ) ≤ ζt σt−1 (xt ), the regret at time step t is upper
t−1 (x)
bounded as r̃t ≤ (νt + ζt )σt−1 (xt ) , where νt , minx∈X m̂tσ−µ
, and m̂t ≥ maxx∈X f (x), ∀t ∈ [1, T ].
t−1 (x)

Max-value Entropy Search for Efficient Bayesian Optimization

Lemma 3.4 (Lemma 5.3 in (Srinivas et al., 2010)). The information gain for the points selected can be expressed in terms
of the predictive variances. If fT = (f (xt )) ∈ RT :
T

I(y T ; f T ) =

1X
2
log(1 + σ −2 σt−1
(xt )).
2 t=1

Proof. (Theorem 3.1) By lemma 3.1 in our paper, we know that the theoretical results from EST (Wang et al., 2016) can be
adapted to MES if y∗ ≥ f∗ . The key question is when a sampled y∗ that can satisfy this condition. Because the cumulative
density w = F (f∗ ) ∈ (0, 1) and y∗t are independent samples from F , there exists at least one y∗t that satisfies y∗t > f∗ with
probability at least 1 − wki in ki iterations.
PT
Let T 0 = i=1 ki be the total number of iterations. We split these iterations to T parts where each part have ki iterations,
PT
i = 1, · · · , T . By union bound, with probability at least 1 − i=1 wki , in all the T parts of iterations, we have at least one
iteration ti which samples y∗ti satisfying y∗ti > f∗ , ∀i = 1, · · · , T .
PT
PT
2 2
Let i=1 wki = 2δ , we can set ki = logw 2πδ i for any i=1 (πi )−1 = 1. A convenient choice for πi is πi = π 6i . Hence
with probability at least 1 − 2δ , there exist a sampled y∗ti satisfying y∗ti > f∗ , ∀i = 1, · · · , T .
Now let ζti = (2 log

π ti
δ

1

) 2 . By Lemma 3.2 and Lemma 3.3, the immediate regret rti = f∗ − f (xti ) can be bounded as
rti ≤ (νti + ζti )σti −1 (xti ).
log(1+σ −2 σ 2

(xt ))

ti −1
i
. Then by Lemma 3.4, we have
Note that by assumption 0 ≤ σt2i −1 (xti ) ≤ 1, so we have σt2i −1 ≤
log(1+σ −2 )
PT
2
2
T
T
T
T
i=1 σti −1 (xti ) ≤ log(1+σ −2 ) I(y T ; f T ) where f T = (f (xti ))i=1 ∈ R , y T = (yti )i=1 ∈ R . From assumptions, we
q
q
PT
PT
2T ρT
have I(y T ; f T ) ≤ ρT . By Cauchy-Schwarz inequality, i=1 σti −1 (xti ) ≤ T i=1 σt2i −1 (xti ) ≤
log(1+σ −2 ) . It
follows that with probability at least 1 − δ,
s
T
X
2T ρT
rti ≤ (νt∗ + ζT )
.
log(1
+ σ −2 )
i=1

As a result, our learning regret is bounded as
rT 0
where T 0 =

PT

i=1

ki =

PT

i=1

logw

δ
2πi

T
1X
rt ≤ (νt∗ + ζT )
≤
T i=1 i

s

2ρT
,
T log(1 + σ −2 )

is the total number of iterations.

At first sight, it might seem like MES with a point estimate does not have a converging rate as good as EST or GP −U CB.
However, notice that minx∈X γy1 (x) < min x ∈ Xγy2 (x) if y1 < y2 , which decides the rate of convergence in Eq. 1. So
if we use y∗ that is too large, the regret bound could be worse. If we use y∗ that is smaller than f∗ , however, its value
won’t count towards the learning regret in our proof, so it is also bad for the regret upper bound. With no principled way
of setting y∗ since f∗ is unknown. Our regret bound in Theorem 3.1 is a randomized trade-off between sampling large and
small y∗ .
For the regret bound in add-GP-MES, it should follow add-GP-UCB. However, because of some technical problems in
the proofs of the regret bound for add-GP-UCB, we haven’t been able to show a regret bound for add-GP-MES either.
Nevertheless, from the experiments on high dimensional functions, the methods worked well in practice.

4. Experiments
In this section, we provide more details on our experiments.
Optimization test functions In Fig. 2, we show the simple regret comparing BO methods on the three challenging
optimization test functions: the 2-D eggholder function, the 10-D Shekel function, and the 10-D Michalewicz function.

Max-value Entropy Search for Efficient Bayesian Optimization
11

800

rt

600

9
UCB
PI
EI
EST
ES
PES
MES-R
MES-G

10
9

rt

UCB
PI
EI
EST
ES
PES
MES-R
MES-G

8

400

UCB
PI
EI
EST
ES
PES
MES-R
MES-G

8

7

rt

1000

6
7

200

5

6

0

5
50

(a)

100

t

150

4

200

50

(b)

100

t

150

200

50

(c)

100

150

200

t

Figure 2. (a) 2-D eggholder function; (b) 10-D Shekel function; (c) 10-D Michalewicz function. PES achieves lower regret on the 2-d
function while MES-G performed better than other methods on the two 10-d optimization test functions.

Choosing the additive decomposition We follow the approach in (Kandasamy et al., 2015), and sample 10000 random
decompositions (at most 2 dimensions in each group) and pick the one with the best data likelihood based on 500 data
points uniformly randomly sampled from the search space. The decomposition setting was fixed for all the 500 iterations
of BO for a fair comparison.

References
Auer, Peter. Using confidence bounds for exploitation-exploration tradeoffs. Journal of Machine Learning Research, 3:
397–422, 2002.
Djolonga, Josip, Krause, Andreas, and Cevher, Volkan. High-dimensional Gaussian process bandits. In Advances in Neural
Information Processing Systems (NIPS), 2013.
Fisher, Ronald Aylmer. The genetical theory of natural selection: a complete variorum edition. Oxford University Press,
1930.
Hennig, Philipp and Schuler, Christian J. Entropy search for information-efficient global optimization. Journal of Machine
Learning Research, 13:1809–1837, 2012.
Hernández-Lobato, José Miguel, Hoffman, Matthew W, and Ghahramani, Zoubin. Predictive entropy search for efficient
global optimization of black-box functions. In Advances in Neural Information Processing Systems (NIPS), 2014.
Kandasamy, Kirthevasan, Schneider, Jeff, and Poczos, Barnabas. High dimensional Bayesian optimisation and bandits via
additive models. In International Conference on Machine Learning (ICML), 2015.
Kawaguchi, Kenji, Kaelbling, Leslie Pack, and Lozano-Pérez, Tomás. Bayesian optimization with exponential convergence. In Advances in Neural Information Processing Systems (NIPS), 2015.
Kawaguchi, Kenji, Maruyama, Yu, and Zheng, Xiaoyu. Global continuous optimization with error bound and fast convergence. Journal of Artificial Intelligence Research, 56(1):153–195, 2016.
Kushner, Harold J. A new method of locating the maximum point of an arbitrary multipeak curve in the presence of noise.
Journal of Fluids Engineering, 86(1):97–106, 1964.
Li, Chun-Liang, Kandasamy, Kirthevasan, Póczos, Barnabás, and Schneider, Jeff. High dimensional Bayesian optimization
via restricted projection pursuit models. In International Conference on Artificial Intelligence and Statistics (AISTATS),
2016.
Massart, Pascal. Concentration Inequalities and Model Selection, volume 6. Springer, 2007.
Moc̆kus, J. On Bayesian methods for seeking the extremum. In Optimization Techniques IFIP Technical Conference, 1974.
Slepian, David. The one-sided barrier problem for Gaussian noise. Bell System Technical Journal, 41(2):463–501, 1962.
Srinivas, Niranjan, Krause, Andreas, Kakade, Sham M, and Seeger, Matthias. Gaussian process optimization in the bandit
setting: no regret and experimental design. In International Conference on Machine Learning (ICML), 2010.

Max-value Entropy Search for Efficient Bayesian Optimization

Von Mises, Richard. La distribution de la plus grande de n valeurs. Rev. math. Union interbalcanique, 1936.
Wang, Zi, Zhou, Bolei, and Jegelka, Stefanie. Optimization as estimation with Gaussian processes in bandit settings. In
International Conference on Artificial Intelligence and Statistics (AISTATS), 2016.
Wang, Ziyu, Zoghi, Masrour, Hutter, Frank, Matheson, David, and De Freitas, Nando. Bayesian optimization in high
dimensions via random embeddings. In International Conference on Artificial Intelligence (IJCAI), 2013.

