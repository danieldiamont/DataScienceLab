Max-value Entropy Search for Efficient Bayesian Optimization (Appendix)

Zi Wang 1 Stefanie Jegelka 1

1. Related work
Our work is largely inspired by the entropy search (ES) methods (Hennig & Schuler, 2012; HernaÌndez-Lobato et al.,
2014), which established the information-theoretic view of Bayesian optimization by evaluating the inputs that are most
informative to the arg max of the function we are optimizing.
Our work is also closely related to probability of improvement (PI) (Kushner, 1964), expected improvement (EI) (MocÌ†kus,
1974), and the BO algorithms using upper confidence bound to direct the search (Auer, 2002; Kawaguchi et al., 2015;
2016), such as GP-UCB (Srinivas et al., 2010). In (Wang et al., 2016), it was pointed out that GP-UCB and PI are closely
related by exchanging the parameters. Indeed, all these algorithms build in the heuristic that the next evaluation point needs
to be likely to achieve the maximum function value or have high probability of improving the current evaluations, which
in turn, may also give more information on the function optima like how ES methods queries. These connections become
clear as stated in Section 3.1 of our paper.
Finding these points that may have good values in high dimensional space is, however, very challenging. In the past,
high dimensional BO algorithms were developed under various assumptions such as the existence of a lower dimensional
function structure (Djolonga et al., 2013; Wang et al., 2013), or an additive function structure where each component is
only active on a lower manifold of the space (Li et al., 2016; Kandasamy et al., 2015). In this work, we show that our
method also works well in high dimensions with the additive assumption made in (Kandasamy et al., 2015).

2. Using the Gumbel distribution to sample yâˆ—
To sample the function maximum yâˆ— , our first approach is to approximate the distribution for y âˆ— and then sample from that
distribution. We use independent Gaussians to approximate the correlated f (x), âˆ€x âˆˆ XÌ‚ where XÌ‚ is a discretization of the
input search space X (unless X is discrete, in which case XÌ‚ = X). A similar approach was adopted in (Wang et al., 2016).
We can show that by assuming {f (x)}xâˆˆXÌ‚ , our approximated distribution gives a distribution for an upperbound on f (x).
Lemma 2.1 (Slepianâ€™s Comparison Lemma (Slepian, 1962; Massart, 2007)). Let u, v âˆˆ Rn be two multivariate Gaussian
random vectors with the same mean and variance, such that
E[v i v j ] â‰¤ E[ui uj ], âˆ€i, j.
Then for every y
Pr[ sup v i â‰¤ y] â‰¤ Pr[ sup ui â‰¤ y].
iâˆˆ[1,n]

iâˆˆ[1,n]

By the Slepianâ€™s lemma, if the covariance kt (x, x0 ) â‰¥ 0,Q
âˆ€x, x0 âˆˆ XÌ‚, using the independent assumption with give us a
distribution on the upperbound yÌ‚âˆ— of f (x), Pr[yÌ‚âˆ— < y] = xâˆˆXÌ‚ Î¨(Î³y (x))).
We then use the Gumbel distribution to approximate the distribution for the maximum of the function values for XÌ‚, Pr[yÌ‚âˆ— <
Q
y] = xâˆˆXÌ‚ Î¨(Î³y (x))). If for all x âˆˆ XÌ‚, f (x) have the same mean and variance, the Gumbel approximation is in fact
asymptotically correct by the Fisher-Tippett-Gnedenko theorem (Fisher, 1930).
1

Computer Science and Artificial Intelligence Laboratory, Massachusetts Institute of Technology, Massachusetts, USA. Correspondence to: Zi Wang <ziw@csail.mit.edu>, Stefanie Jegelka <stefje@csail.mit.edu>.
Proceedings of the 34 th International Conference on Machine Learning, Sydney, Australia, 2017. JMLR: W&CP. Copyright 2017 by
the author(s).

Max-value Entropy Search for Efficient Bayesian Optimization

Theorem 2.2 (The Fisher-Tippett-Gnedenko Theorem (Fisher, 1930)). Let {vi }âˆ
i=1 be a sequence of independent and
identically-distributed random variables, and Mn = max1â‰¤iâ‰¤n vi . If there exist constants an > 0, bn âˆˆ R and a non
n
degenerate distribution function F such that limnâ†’âˆ Pr( Mnaâˆ’b
â‰¤ x) = F (x), then the limit distribution F belongs to
n
either the Gumbel, the FreÌchet or the Weibull family.
In particular, for i.i.d. Gaussians, the limit distribution of the maximum of them belongs to the Gumbel distribution (Von Mises, 1936). Though the Fisher-Tippett-Gnedenko theorem does not hold for independent and differently
distributed Gaussians, in practice we still find it useful in approximating Pr[yÌ‚âˆ— < y]. In Figure 1, we show an example of
the result of the approximation for the distribution of the maximum of f (x) âˆ¼ GP (Âµt , kt )âˆ€x âˆˆ XÌ‚ given 50 observed data
points randomly selected from a function sample from a GP with 0 mean and Gaussian kernel.
1

Pr[yÌ‚ âˆ— < y]

0.8
0.6
0.4
0.2
0

Exact
Approx

8

10
y

12

Figure 1. An example of approximating the cumulative probability of the maximum of independent differently distributed Gaussians
Pr[yÌ‚âˆ— < y] (Exact) with a Gumbel distribution G(a, b) (Approx) via percentile matching.

3. Regret bounds
Based on the connection of MES to EST, we show the bound on the learning regret for MES with a point estimate for Î±(x).
Theorem 3.1. Let F be the cumulative probability distribution for the maximum of any function f sampled from
GP (Âµ, k) over the compact search space X âŠ‚ Rd , where k(x, x0 ) â‰¤ 1, âˆ€x, x0 âˆˆ X. Let fâˆ— = maxxâˆˆX f (x) and
w = F (fâˆ— ) âˆˆ (0, 1), and assume the observation noise is iid N (0, Ïƒ). If in each iteration t, the query point is chosen
Ïˆ(Î³yt (x))

y t âˆ’Âµ (x)

t
as xt = arg maxxâˆˆX Î³yâˆ—t (x) 2Î¨(Î³ âˆ—t (x)) âˆ’ log(Î¨(Î³yâˆ—t (x))), where Î³yâˆ—t (x) = âˆ—Ïƒt (x)
and yâˆ—t is drawn from F , then with
yâˆ—
P
T
probability at least 1 âˆ’ Î´, in T 0 = i=1 logw 2Ï€Î´ i number of iterations, the simple regret satisfies

r

CÏT
(Î½tâˆ— + Î¶T )
(1)
T
PT
1
where C = 2/ log(1 + Ïƒ âˆ’2 ) and Î¶T = (2 log( Ï€Î´T )) 2 ; Ï€ satisfies i=1 Ï€iâˆ’1 â‰¤ 1 and Ï€t > 0, and tâˆ— = arg maxt Î½t with
Î½t , minxâˆˆX,yâˆ—t >fâˆ— Î³yâˆ—t (x), and ÏT is the maximum information gain of at most T selected points.
rT 0 â‰¤

Before we continue to the proof, notice that if the function upper bound yÌ‚âˆ— is sampled using the approach described in
Section 3.1 and kt (x, x0 ) â‰¥ 0, âˆ€x, x0 âˆˆ XÌ‚, we may still get the regret guarantee by setting yâˆ— = yÌ‚âˆ— (or yâˆ— = yÌ‚âˆ— + L
if X is continuous) since Pr[maxXÌ‚ â‰¤ y] â‰¥ Pr[yÌ‚âˆ— < y]. Moreover, Theorem 3.1 assumes yâˆ— is sampled from a universal
maximum distribution of functions from GP (Âµ, k), but it is not hard to see that if we have a distribution of maximums
PT
adapted from GP (Âµt , kt ), we can still get the same regret bound by setting T 0 = i=1 logwi 2Ï€Î´ i , where wi = Fi (fâˆ— )
and Fi corresponds to the maximum distribution at an iteration where yâˆ— > fâˆ— . Next we introduce a few lemmas and then
prove Theorem 3.1.
PT
1
Lemma 3.2 (Lemma 3.2 in (Wang et al., 2016)). Pick Î´ âˆˆ (0, 1) and set Î¶t = (2 log( Ï€2Î´t )) 2 , where t=1 Ï€tâˆ’1 â‰¤ 1, Ï€t > 0.
Then, it holds that Pr[Âµtâˆ’1 (xt ) âˆ’ f (xt ) â‰¤ Î¶t Ïƒtâˆ’1 (xt ), âˆ€t âˆˆ [1, T ]] â‰¥ 1 âˆ’ Î´.
Lemma 3.3 (Lemma 3.3 in (Wang et al., 2016)). If Âµtâˆ’1 (xt ) âˆ’ f (xt ) â‰¤ Î¶t Ïƒtâˆ’1 (xt ), the regret at time step t is upper
tâˆ’1 (x)
bounded as rÌƒt â‰¤ (Î½t + Î¶t )Ïƒtâˆ’1 (xt ) , where Î½t , minxâˆˆX mÌ‚tÏƒâˆ’Âµ
, and mÌ‚t â‰¥ maxxâˆˆX f (x), âˆ€t âˆˆ [1, T ].
tâˆ’1 (x)

Max-value Entropy Search for Efficient Bayesian Optimization

Lemma 3.4 (Lemma 5.3 in (Srinivas et al., 2010)). The information gain for the points selected can be expressed in terms
of the predictive variances. If fT = (f (xt )) âˆˆ RT :
T

I(y T ; f T ) =

1X
2
log(1 + Ïƒ âˆ’2 Ïƒtâˆ’1
(xt )).
2 t=1

Proof. (Theorem 3.1) By lemma 3.1 in our paper, we know that the theoretical results from EST (Wang et al., 2016) can be
adapted to MES if yâˆ— â‰¥ fâˆ— . The key question is when a sampled yâˆ— that can satisfy this condition. Because the cumulative
density w = F (fâˆ— ) âˆˆ (0, 1) and yâˆ—t are independent samples from F , there exists at least one yâˆ—t that satisfies yâˆ—t > fâˆ— with
probability at least 1 âˆ’ wki in ki iterations.
PT
Let T 0 = i=1 ki be the total number of iterations. We split these iterations to T parts where each part have ki iterations,
PT
i = 1, Â· Â· Â· , T . By union bound, with probability at least 1 âˆ’ i=1 wki , in all the T parts of iterations, we have at least one
iteration ti which samples yâˆ—ti satisfying yâˆ—ti > fâˆ— , âˆ€i = 1, Â· Â· Â· , T .
PT
PT
2 2
Let i=1 wki = 2Î´ , we can set ki = logw 2Ï€Î´ i for any i=1 (Ï€i )âˆ’1 = 1. A convenient choice for Ï€i is Ï€i = Ï€ 6i . Hence
with probability at least 1 âˆ’ 2Î´ , there exist a sampled yâˆ—ti satisfying yâˆ—ti > fâˆ— , âˆ€i = 1, Â· Â· Â· , T .
Now let Î¶ti = (2 log

Ï€ ti
Î´

1

) 2 . By Lemma 3.2 and Lemma 3.3, the immediate regret rti = fâˆ— âˆ’ f (xti ) can be bounded as
rti â‰¤ (Î½ti + Î¶ti )Ïƒti âˆ’1 (xti ).
log(1+Ïƒ âˆ’2 Ïƒ 2

(xt ))

ti âˆ’1
i
. Then by Lemma 3.4, we have
Note that by assumption 0 â‰¤ Ïƒt2i âˆ’1 (xti ) â‰¤ 1, so we have Ïƒt2i âˆ’1 â‰¤
log(1+Ïƒ âˆ’2 )
PT
2
2
T
T
T
T
i=1 Ïƒti âˆ’1 (xti ) â‰¤ log(1+Ïƒ âˆ’2 ) I(y T ; f T ) where f T = (f (xti ))i=1 âˆˆ R , y T = (yti )i=1 âˆˆ R . From assumptions, we
q
q
PT
PT
2T ÏT
have I(y T ; f T ) â‰¤ ÏT . By Cauchy-Schwarz inequality, i=1 Ïƒti âˆ’1 (xti ) â‰¤ T i=1 Ïƒt2i âˆ’1 (xti ) â‰¤
log(1+Ïƒ âˆ’2 ) . It
follows that with probability at least 1 âˆ’ Î´,
s
T
X
2T ÏT
rti â‰¤ (Î½tâˆ— + Î¶T )
.
log(1
+ Ïƒ âˆ’2 )
i=1

As a result, our learning regret is bounded as
rT 0
where T 0 =

PT

i=1

ki =

PT

i=1

logw

Î´
2Ï€i

T
1X
rt â‰¤ (Î½tâˆ— + Î¶T )
â‰¤
T i=1 i

s

2ÏT
,
T log(1 + Ïƒ âˆ’2 )

is the total number of iterations.

At first sight, it might seem like MES with a point estimate does not have a converging rate as good as EST or GP âˆ’U CB.
However, notice that minxâˆˆX Î³y1 (x) < min x âˆˆ XÎ³y2 (x) if y1 < y2 , which decides the rate of convergence in Eq. 1. So
if we use yâˆ— that is too large, the regret bound could be worse. If we use yâˆ— that is smaller than fâˆ— , however, its value
wonâ€™t count towards the learning regret in our proof, so it is also bad for the regret upper bound. With no principled way
of setting yâˆ— since fâˆ— is unknown. Our regret bound in Theorem 3.1 is a randomized trade-off between sampling large and
small yâˆ— .
For the regret bound in add-GP-MES, it should follow add-GP-UCB. However, because of some technical problems in
the proofs of the regret bound for add-GP-UCB, we havenâ€™t been able to show a regret bound for add-GP-MES either.
Nevertheless, from the experiments on high dimensional functions, the methods worked well in practice.

4. Experiments
In this section, we provide more details on our experiments.
Optimization test functions In Fig. 2, we show the simple regret comparing BO methods on the three challenging
optimization test functions: the 2-D eggholder function, the 10-D Shekel function, and the 10-D Michalewicz function.

Max-value Entropy Search for Efficient Bayesian Optimization
11

800

rt

600

9
UCB
PI
EI
EST
ES
PES
MES-R
MES-G

10
9

rt

UCB
PI
EI
EST
ES
PES
MES-R
MES-G

8

400

UCB
PI
EI
EST
ES
PES
MES-R
MES-G

8

7

rt

1000

6
7

200

5

6

0

5
50

(a)

100

t

150

4

200

50

(b)

100

t

150

200

50

(c)

100

150

200

t

Figure 2. (a) 2-D eggholder function; (b) 10-D Shekel function; (c) 10-D Michalewicz function. PES achieves lower regret on the 2-d
function while MES-G performed better than other methods on the two 10-d optimization test functions.

Choosing the additive decomposition We follow the approach in (Kandasamy et al., 2015), and sample 10000 random
decompositions (at most 2 dimensions in each group) and pick the one with the best data likelihood based on 500 data
points uniformly randomly sampled from the search space. The decomposition setting was fixed for all the 500 iterations
of BO for a fair comparison.

References
Auer, Peter. Using confidence bounds for exploitation-exploration tradeoffs. Journal of Machine Learning Research, 3:
397â€“422, 2002.
Djolonga, Josip, Krause, Andreas, and Cevher, Volkan. High-dimensional Gaussian process bandits. In Advances in Neural
Information Processing Systems (NIPS), 2013.
Fisher, Ronald Aylmer. The genetical theory of natural selection: a complete variorum edition. Oxford University Press,
1930.
Hennig, Philipp and Schuler, Christian J. Entropy search for information-efficient global optimization. Journal of Machine
Learning Research, 13:1809â€“1837, 2012.
HernaÌndez-Lobato, JoseÌ Miguel, Hoffman, Matthew W, and Ghahramani, Zoubin. Predictive entropy search for efficient
global optimization of black-box functions. In Advances in Neural Information Processing Systems (NIPS), 2014.
Kandasamy, Kirthevasan, Schneider, Jeff, and Poczos, Barnabas. High dimensional Bayesian optimisation and bandits via
additive models. In International Conference on Machine Learning (ICML), 2015.
Kawaguchi, Kenji, Kaelbling, Leslie Pack, and Lozano-PeÌrez, TomaÌs. Bayesian optimization with exponential convergence. In Advances in Neural Information Processing Systems (NIPS), 2015.
Kawaguchi, Kenji, Maruyama, Yu, and Zheng, Xiaoyu. Global continuous optimization with error bound and fast convergence. Journal of Artificial Intelligence Research, 56(1):153â€“195, 2016.
Kushner, Harold J. A new method of locating the maximum point of an arbitrary multipeak curve in the presence of noise.
Journal of Fluids Engineering, 86(1):97â€“106, 1964.
Li, Chun-Liang, Kandasamy, Kirthevasan, PoÌczos, BarnabaÌs, and Schneider, Jeff. High dimensional Bayesian optimization
via restricted projection pursuit models. In International Conference on Artificial Intelligence and Statistics (AISTATS),
2016.
Massart, Pascal. Concentration Inequalities and Model Selection, volume 6. Springer, 2007.
MocÌ†kus, J. On Bayesian methods for seeking the extremum. In Optimization Techniques IFIP Technical Conference, 1974.
Slepian, David. The one-sided barrier problem for Gaussian noise. Bell System Technical Journal, 41(2):463â€“501, 1962.
Srinivas, Niranjan, Krause, Andreas, Kakade, Sham M, and Seeger, Matthias. Gaussian process optimization in the bandit
setting: no regret and experimental design. In International Conference on Machine Learning (ICML), 2010.

Max-value Entropy Search for Efficient Bayesian Optimization

Von Mises, Richard. La distribution de la plus grande de n valeurs. Rev. math. Union interbalcanique, 1936.
Wang, Zi, Zhou, Bolei, and Jegelka, Stefanie. Optimization as estimation with Gaussian processes in bandit settings. In
International Conference on Artificial Intelligence and Statistics (AISTATS), 2016.
Wang, Ziyu, Zoghi, Masrour, Hutter, Frank, Matheson, David, and De Freitas, Nando. Bayesian optimization in high
dimensions via random embeddings. In International Conference on Artificial Intelligence (IJCAI), 2013.

