Communication-efficient Algorithms for
Distributed Stochastic Principal Component Analysis

Dan Garber 1 Ohad Shamir 2 Nathan Srebro 3

Abstract
We study the fundamental problem of Principal
Component Analysis in a statistical distributed
setting in which each machine out of m stores
a sample of n points sampled i.i.d. from a single unknown distribution. We study algorithms
for estimating the leading principal component
of the population covariance matrix that are both
communication-efficient and achieve estimation
error of the order of the centralized ERM solution that uses all mn samples. On the negative side, we show that in contrast to results obtained for distributed estimation under convexity assumptions, for the PCA objective, simply
averaging the local ERM solutions cannot guarantee error that is consistent with the centralized
ERM. We show that this unfortunate phenomena
can be remedied by performing a simple correction step which correlates between the individual
solutions, and provides an estimator that is consistent with the centralized ERM for sufficientlylarge n. We also introduce an iterative distributed
algorithm that is applicable in any regime of n,
which is based on distributed matrix-vector products. The algorithm gives significant acceleration
in terms of communication rounds over previous
distributed algorithms, in a wide regime of parameters.

1. Introduction
Principal Component Analysis (PCA) (Pearson, 1901;
Hotelling, 1933; Jolliffe, 2002) is one of the most celebrated and popular techniques in data analysis and ma1
Technion - Israel Institute of Technology, Haifa, Israel 2 Weizmann Institute of Science, Rehovot, Israel
3
Toyota Technological Institute, Illinois, USA. Correspondence to:
Dan Garber <dangar@technion.ac.il>, Ohad
Shamir <ohad.Shamir@weizmann.ac.il>, Nathan Srebro
<nati@ttic.edu>.

Proceedings of the 34 th International Conference on Machine
Learning, Sydney, Australia, PMLR 70, 2017. Copyright 2017
by the author(s).

chine learning. For data that consists of N vectors in
RdP
, x1 , ..., xN , with normalized covariance matrix XÌ‚ =
N
1
>
i=1 xi xi , The PCA method finds the k-dimensional
N
subspace (which corresponds to the span of the top k principal components) such that the projection of the data onto
the subspace has largest variance, i.e., it is the solution to
the optimization problem:
max

WâˆˆRdÃ—k ,WT W=I

kXÌ‚Wk2F .

(1)

PCA is often considered in a statistical setting in which the
assumption is that the input vectors are not arbitrary but
sampled i.i.d. from some fixed but unknown distribution
with certain general characteristics D. Then, it is often of
interest to use the observed sample to estimate the top k
principal components of the population covariance matrix,
rather then that of the sample, which leads to the modified
optimization problem:


max
kExâˆ¼D xx> Wk2F .
(2)
WâˆˆRdÃ—k ,WT W=I

Of course the empirical estimation problem (1) and the
population estimation problem (2) are well connected, and
it is well-known that under mild assumptions on the distribution D and given a sufficiently large sample, we can
guarantee small estimation error in (2) by solving optimization problem (1).
In this work we consider the problem of estimating the first
principal component (i.e., k = 1) in a statistical and distributed setting. We assume the availability of m machines,
each of which stores a sample of n vectors sampled i.i.d
from a fixed distribution D over Rd , and we are interested
in algorithms that can be applied efficiently to solve Problem (2) for k = 1, with estimation error that approaches
that of a centralized algorithm, which has access to all mn
samples and does not pay for communication between machines. Indeed, when considering the efficiency of algorithms, we will mainly focus on the amount of communication between machines they require, since this is often
the most expensive resource in distributed computing. We
note that the i.i.d. assumption is standard in many applications of PCA, and can be leveraged to get more efficient
algorithms than when the data partition is arbitrary. Also,
we will make a standard assumption that the population covariance matrix has a non-zero additive gap between the

Communication-efficient Algorithms for Distributed Stochastic Principal Component Analysis

first and second eigenvalues, which makes the problem of
estimating the leading principal component meaningful.
A main challenge that often arises in many computational
settings of principal components is that it leads to inherently non-convex optimization problems. While many
times these problems turn out to admit efficient algorithms,
the rich toolbox of optimization and statistical estimation
procedures developed for convex problems often cannot be
directly applied to problems such as (1) and (2). Instead,
one often needs to consider a specialized and more involved
analysis, to get analogous convergence results for the PCA
problem. This for instance was the case in a recent wave
of results that applied concepts such as stochastic gradient updates (Balsubramani et al., 2013; Shamir, 2016a; Jain
et al., 2016b; Allen Zhu & Li, 2016b) and variance reduction (Shamir, 2015; 2016c; Garber & Hazan, 2015; Garber
et al., 2016; Allen Zhu & Li, 2016a) to the PCA problem.
This is also the case in our distributed setting. For instance,
(Zhang et al., 2013) proposed communication-efficient algorithms for a distributed statistical estimation settings,
similar to ours, but under convexity assumptions. The authors show that under their assumptions, in a wide regime
of parameters (namely when the per-machine sample size
n is large enough), then a simple averaging of the empirical
risk minimizers (ERM), computed locally on each machine,
leads to estimation error of the population parameters of
the order the centralized ERM solution. While averaging
makes perfect sense in a convex setting, it is clear that it
can completely fail in a non-convex setting. Indeed, we
show that already for the PCA problem with k = 1, simply
averaging the local ERM solutions (and normalizing to obtain a unit vector as required), cannot improve significantly
over the estimation error of any single machine. We then
show that a simple fix to the above scheme, namely correlating the directions of individual ERM solutions, remedies this phenomena and results in estimation error similar
to that of the centralized ERM solution. Much like the results of (Zhang et al., 2013), this result only holds in the
regime when the per-machine sample size n is sufficiently
large. As discussed, due to the inherent non-convexity of
the PCA objective, this approach requires a novel analysis
tailored to the PCA problem. In this context, we view this
work as an initiation of a research effort to understand how
to efficiently aggregate statistical estimators in a distributed
non-convex setting.
A second line of results for distributed estimation under
convexity assumptions consider iterative algorithms that
perform multiple communication rounds and are based on
distributed gradient computations (some examples include
(Shamir et al., 2014; Zhang & Lin, 2015; Lee et al., 2015;
Shamir, 2016b; Jaggi et al., 2014; Reddi et al., 2016)). The
benefit of these methods is that (a) they provide meaningful
estimation error guarantees in a much wider regime of pa-

rameters than the â€œone-shotâ€ aggregation methods (namely
in terms of the number of samples per machine), and (b),
due to their iterative nature, they allow to approximate the
centralized ERM solution arbitrary well. Unfortunately,
these methods, all of which rely heavily on convexity assumption, cannot be directly applied to the PCA problem.
Towards designing efficient distributed iterative methods
for our PCA setting, we consider the application of the
recently proposed method of Shift-and-Invert power iterations (S&I) for PCA (Garber & Hazan, 2015; Garber et al.,
2016). The S&I method reduces the problem of computing
the leading eigenvector of a real positive semidefinite matrix to that of approximately solving a small number (i.e.
poly-logarithmic in the problem parameters) of systems of
linear equations. These in turn, could be efficiently solved
by arbitrary distributed convex solvers. We show that coupling the S&I method with the stochastic pre-conditioning
technique for linear systems proposed in (Zhang & Lin,
2015) and well known fast gradient methods such as the
conjugate gradient method, gives state-of-the-art guarantees in terms of communication costs, and provides a significant improvement over distributed variants of classical
fast eigenvector algorithms such as power iterations and the
faster Lanczos algorithm. Much like its convex counterparts, which only rely on distributed gradient computations
and simple vector aggregations, our iterative method only
relies on distributed matrix-vector products, i.e., it requires
each machine to only send products of its local empirical
covariance matrix with some input vector.
Beyond the results described so far, (Liang et al., 2014;
Boutsidis et al., 2016) studied distributed algorithms for
PCA in a deterministic setting in which the partition of
the data across machines is arbitrary and communication
is measured in terms of number of transmitted bits. The
approximation guarantees provided in these works are in
terms of the projection of the data onto the leading principal components (instead of alignment between the estimate
and the optimal solution, studied in this paper). Applying
these results to our setting will give a number of communication rounds that scales like poly(âˆ’1 Î´ âˆ’1 ), where  is the
desired error and Î´ is the population eigengap. In our setting,  will scale with the inverse of the size of the sample,
i.e.,  â‰ˆ (mn)âˆ’1 , which for these algorithms will result in
amount of communication that is polynomial in the size of
the data. In contrast, we will be interested in algorithms
whose communication costs does not scale with n at all. In
this context we note that, by focusing on algorithms that
either perform simple aggregation of local ERM solutions,
or perform only distributed matrix-vector products with the
empirical covariance matrix, we can circumvent the need to
measure communication explicitly in terms of the number
of bits transmitted, which often burdens the analysis of natural algorithms, such as those proposed here.

Communication-efficient Algorithms for Distributed Stochastic Principal Component Analysis

2. Preliminaries
2.1. Notation and problem setting
We write vectors in Rd in boldface lower-case letters (e.g.,
v), matrices in boldface upper-case letters (e.g., X), and
scalars are written as lightface letters (e.g., c). We let k Â·
k denote the standard Euclidean norm for vectors and the
spectral norm for matrices.
We consider the following statistical distributed setting.
Let D be a distribution over vectors in Rd with squared
`2 norm at most b, for some b > 0. We consider a setting
in which m machines, numbered 1...m, are each given a
dataset of n samples drawn i.i.d. from D. We let v1 denote
a leading eigenvector of the population covariance matrix
X = Exâˆ¼D [xx> ]. Our goal is to efficiently (mainly in
terms of communication) find an estimate w for v1 , i.e., a
unit vector that maximizes the product (v1> w)2 with high
probability. Towards this end, we assume that the population covariance matrix X has a non-zero eigengap Î´, i.e.,
Î´ := Î»1 (X) âˆ’ Î»2 (X) > 0, where Î»i (Â·) denotes the ith
largest eigenvalue of a symmetric real matrix. Note that
Î´ > 0 is necessary for v1 to be uniquely defined (up to
sign).
In addition, we let XÌ‚i denote the empirical covariance matrix of the sample stored on machine i for every i âˆˆ [m],
Pn
(i) (i)>
(i)
(i)
i.e., XÌ‚i = n1 j=1 xj xj , where x1 ...xn are the
samples stored on machine i. We let XÌ‚ denote the empirical covariance matrix
Pmof the union of points across all
1
machines i.e., XÌ‚ = m
i=1 XÌ‚i .
Our model of communication assumes that the m machines
work in rounds during which a central machine (w.l.o.g.
machine 1) can send a single vector in Rd to all other machines, or every machine can send either the leading eigenvector of its local empirical covariance matrix, or the product of a single input vector with its local covariance, to machine 1. We will measure communication complexity in
terms of number of such rounds required to achieve a certain estimation error.
2.1.1. T HE CENTRALIZED SOLUTION
Our primary benchmark for measuring performance will be
the centralized empirical risk minimizer which is the leading eigenvector of the aggregated empirical covariance matrix XÌ‚.
The following standard result bounds the error of the centralized ERM.
Lemma 1 (Risk of centralized ERM). Fix p âˆˆ (0, 1). Suppose that Î´ > 0 and let vÌ‚1 denote the leading eigenvector
of XÌ‚, i.e., vÌ‚1 âˆˆ arg maxv:kvk=1 v> XÌ‚v. Then it holds w.p.
at least 1 âˆ’ p that

32b2 ln(d/p)
.
(3)
mnÎ´ 2
Lemma 1 is a direct consequence of the following standard concentration argument for random matrices, and the
Davis-Kahan sin(Î¸) theorem (whose proof is given in the
appendix for completeness):
Theorem 1 (Matrix Hoeffding, see (Tropp, 2012)). Let D
be a distribution over vectors with squared `2 norm
Pn at most
b, and let X = Exâˆ¼D [xx> ]. Let XÌ‚ = n1 i=1 xi x>
i ,
where x1 , ..., xn are
 sampled i.i.d.
 from D. Then,
 2it holds

 n
that âˆ€ > 0 : Pr kXÌ‚ âˆ’ Xk â‰¥  â‰¤ d Â· exp âˆ’ 16b
.
2
1 âˆ’ (v1> vÌ‚1 )2 â‰¤ ERM (p) :=

Theorem 2 (Davis-Kahan sin(Î¸) theorem). Let X, Y be
symmetric real dÃ—d matrices with leading eigenvectors vX
and vY respetively. Also, suppose that Î´(X) := Î»1 (X) âˆ’
2
2
>
Î»2 (X) > 0. Then it holds that 1 âˆ’ vX
vY â‰¤ 2 kXâˆ’Yk
Î´(X)2 .
2.2. Informal statement of main results and previous
algorithms
We now informally describe our main results, followed by a
detailed description of previous approaches that are directly
applicable to our setting. The algorithmic results (both new
and old) are summarized in Table 1.
2.2.1. M AIN RESULTS
Failure of simple averaging of local ERM solutions We
show that a natural approach of simply averaging the individual leading eigenvectors of the empirical covariance
matrices XÌ‚i (and normalizing the obtain a unit vector)
cannot significantly improve (beyond logarithmic factors)
over the performance of any of the individual eigenvectors.
(i)
More concretely, if we let vÌ‚1 denote the leading eigenvector of XÌ‚i for any i âˆˆ [m], and we denote their average
Pm (i)
1
by vÌ„1 = m
i=1 vÌ‚1 , then there exists a distribution D
over vectors with magnitude O(1) and covariance eigengap Î´ = 1, such that
"
 > 2 #
 
vÌ„1 v1
1
âˆ€m, n : ED 1 âˆ’
=â„¦
,
kvÌ„1 k
n
See Theorem 3 in Section 3 for the complete and formal
argument.
A successful single communication round algorithm via
correlation of individual ERM solutions We show that
if prior to averaging the local ERM solutions, as suggested
above, we correlate their directions by aligning them according to any single machine (say machine number 1),
Pm
(i)> (1)
(i)
1
vÌ‚1 )vÌ‚1 , then this
i.e., we let vÌ„1 = m
i=1 sign(vÌ‚1
guarantees that for any p âˆˆ (0, 1), w.p. at least 1 âˆ’ p,
 
 ï£¶
ï£«
dm
 > 2
2
4 2 dm
b
ln
b
ln
p
p
vÌ„1 v1
ï£¸ . (4)
1âˆ’
= Oï£­
+
kvÌ„1 k
Î´ 2 mn
Î´ 4 n2

Communication-efficient Algorithms for Distributed Stochastic Principal Component Analysis
Method
Centralized ERM
Distributed Power Method
Distributed Lanczos
â€œHot-potatoâ€ SGD

1 âˆ’ (w> v1 )2 w.p. 3/4
2
ln d
ERM = Î˜( bÎ´2 mn
)
ERM Â· (1 + o(1))
ERM Â· (1 + o(1))
O(ERM)


# communcation rounds
OÌƒ(Î»1 /Î´)
p
OÌƒ( Î»1 /Î´)
m

ERM Â· (1 + o(1))

OÌƒ(min{(b/Î´)1/2 nâˆ’1/4 , m1/4 })

O(ERM ) + O

Average of ERMs with sign-fixing (Theorem 4)
Distributed Shift&Invert + precond. linear systems (Theorem 6)

b4 ln2 d
Î´ 4 n2

1

Table 1. Comparison of estimation error and number of communication rounds. For simplicity we fix the failure probability to p = 1/4
and assume mn is in the regime in which Lemma 1 is meaningful, i.e, mn = â„¦(b2 Î´ âˆ’2 ln d). The OÌƒ(Â·) suppresses logarithmic factors
in b, d, 1/p, 1/ERM . For the result of Theorem 4 we assume the regime m = O(d). The sub-constant o(1) factors could be made, in
principle, arbitrary small in all relevant results by trading approximation with communication.

See Theorem 4 in Section 3 for the complete and formal
result.
In particular, in the likely scenario when m = O(d/p)
2
we have that w.p. at least 1 âˆ’ p, 1 âˆ’ vÌ„1> v1 /kvÌ„1 k =
ERM (p)) Â· O 1 + m2 Â· ERM (p) , where ERM (p)) is defined in Eq. (3). Another related interpretation of the results is that the bound in Eq. (4) is comparable with ERM

(up to poly-log factors) when n = â„¦ Î´ âˆ’2 b2 m ln(dm/p) .
We also show a matching lower bound that the bound in
Eq. (4) is tight (up to poly-log factors) for this aggregation
method.
A multi communication round algorithm We present a
distributed algorithm based on the Shift-and-Invert framework for leading eigenvector computation (Garber &
Hazan, 2015; Garber et al., 2016) which is applied to explicitly solving the centralized ERM problem. We show
that for any p âˆˆ (0, 1), when mn = â„¦(b2 ln(d/p)/Î´ 2 ) (i.e.,
when Lemma 3 is meaningful), the algorithm produces a
solution w such that w.p. at least 1 âˆ’ p,
1 âˆ’ (v1> w)2 â‰¤ ERM (p)) Â· (1 + o(1)) ,

(5)

where ERM (p)) is
âˆš defined in Eq. (3). The algorithm performs overall OÌƒ( bÎ´ âˆ’1/2 nâˆ’1/4 ) distributed matrix-vector
products with the centralized empirical covariance matrix
XÌ‚ 1 . The OÌƒ(Â·) notation hides poly-logarithmic factors in
1/p, 1/Î´, d, 1/ERM (p). See Theorem 6 in Section 4 for the
complete and formal result.
We note that in particular, under our assumption that mn =
â„¦Ìƒ(b2 /Î´ 2 ), it holds that the number of distributed matrixvector products is upper bounded by OÌƒ(m1/4 ). Moreover,
in the regime n = â„¦(b2 Î´ âˆ’2 ), we can see that the number
of distributed matrix-vector products depends only polylogarithmically on the problem parameters.
In general, the sub-constant o(1) factor in (5) could be
made arbitrarily small by trading the approximation error
1

i.e., on each round, each machine i sends the product of an
input vector in Rd with its local covariance matrix XÌ‚i .

with the number of distributed matrix-vector products.
2.2.2. P REVIOUS ALGORITHMS
Distributed versions of classical iterative algorithms:
Classical fast iterative algorithms for computing the leading eigenvector of a positive semidefinite matrix, such as
the well-known Power Method and the Lanczos Algorithm, require iterative multiplications of the input matrix (XÌ‚ in our case) with the current estimate. It is thus
straightforward to implement these algorithms in our distributed setting, by multiplying the same vector with the
covariance matrices at each machine, and averaging the
result. Thus, by well-known convergence guarantees of
these two methods, we will have that for a fixed  > 0,
these methods produce a unit vector w such that, for any
p âˆˆ (0, 1), 1 âˆ’ (w> vÌ‚1 )2 â‰¤  w.p. at least 1 âˆ’ p, after p
O(Î»Ì‚1 Î´Ì‚ âˆ’1 ln(d/p)) rounds for the Power Method and
O( Î»Ì‚1 Î´Ì‚ âˆ’1 ln(d/p)) for the Lanczos Algorithm, where
Î»Ì‚1 , Î´Ì‚ denote the leading eigenvalue and eigengap of XÌ‚,
respectively. Moreover, in the regime of mn in which
Lemma 1 is meaningful, we can replace Î»Ì‚1 , Î´Ì‚ with Î»1 , Î´
in the above bounds, and the result will still hold with high
probability.
Simple calculations show that in the regime of mn in which
Lemma 1 is meaningful, it holds that our Shift-and-Invertbased algorithm outperforms distributed Lanczos (in terms
of worst-case guarantees) whenever n = â„¦Ìƒ(b2 /Î»21 ).
â€œHot potatoâ€ SGD: Another straightforward approach is
to apply a sequential algorithm for direct risk minimization that can process the data-points one by one, such as
stochastic gradient descent (SGD), by passing its state from
one machine to the next, after completing a full pass over
the machineâ€™s data. Clearly, this process of making a full
pass over the data of a certain machine before sending the
final estimate to the next one, requires overall m communication rounds in order to make a full pass over all mn
points. SGD for PCA was studied in several results in
recent years (Balsubramani et al., 2013; Shamir, 2016a;c;

Communication-efficient Algorithms for Distributed Stochastic Principal Component Analysis

Jain et al., 2016a; Allen Zhu & Li, 2016b). For instance
applying the result of (Jain et al., 2016a) in this way will
result in a final estimate w satisfying

 2
b ln d
>
2
w.p. at least 3/4. (6)
1 âˆ’ (w v1 ) = O
Î´ 2 mn
We note that in the regime in which the bound in (6) is
meaningful it holds that the number of communication
rounds of our Shift-and-Invert-based algorithm is upperbounded by OÌƒ(m1/4 ) which for sufficiently large m dominates the communication complexity of SGD.

3. Single Communication Round Algorithms
via ERM on Each Machine
In this section we consider distributed algorithms that require only a single round of communication. Naturally for
this regime, all algorithms will be based on aggregating the
ERM solutions of the individual machines, i.e., each machine i only sends the leading eigenvector of its empirical covariance matrix XÌ‚i to a centralized machine (without
loss of generality, machine 1) which it turn combines them
to a single unit vector in some manner.
3.1. Simple averaging of eigenvectors fail
Perhaps the simplest method to aggregate the individual
eigenvectors of each machine is to average them, and then
normalize to obtain a unit vector. For instance, in the
distributed statistical setting considered in (Zhang et al.,
2013), in which the objective is strongly convex, it was
shown that simply averaging the individual ERM solutions
leads, in a meaningful regime of parameters, to estimation
error of the order of the centralized ERM solution. However, here we show that for PCA, in which the objective is
certainly not convex, this approach fails practically in any
regime, in the sense that the error of the returned aggregated solution can be no better than that returned by any
single machine.
Theorem 3. There exists a distribution over vectors in R2
with `2 norm bounded by a universal constant for which the
eigengap in the covariance matrix is 1 (i.e., Î´ = 1), such
(i)
that if each machine i returns an estimate vÌ‚1 which is
an unbiased leading eigenvector of XÌ‚i (i.e., both outcomes
(i)
(i)
âˆ’vÌ‚1 , +vÌ‚1 are equally likely), then the aggregated vector
P
(i)
m
1
vÌ„1 = m
i=1 vÌ‚1 satisfies
"

2 #
vÌ„1
âˆ€m, n : E 1 âˆ’
, v1
= â„¦(1/n).
kvÌ„1 k

The proof is given in the appendix.

3.2. Averaging with Sign Fixing
As evident from the statement of Theorem 3, an important
assumption is that each machine produces an unbiased estimate, in the sense that the sign of the outcome is uniform
and independent of the other machines. This hints that correlating the signs of the different estimates can circumvent
the lower bound result in Theorem 3. It turns out that this
is indeed the case, as captured by the following theorem:
Theorem 4. Let wÌƒi be the leading eigenvector of XÌ‚i for
any i âˆˆ [m], and consider
the unit vector
Pm
>
i=1 sign(wÌƒi wÌƒ1 )wÌƒi
.
(7)
w = Pm
k i=1 sign(wÌƒi> wÌƒ1 )wÌƒi k
Then, for any p âˆˆ (0,ï£«
1), it holds
 at least 1 âˆ’ p that
ï£¶
 w.p.
dm
2
b log p
b4 log2 dm
p
ï£¸.
1 âˆ’ (v1> w)2 = O ï£­
+
Î´ 2 mn
Î´ 4 n2
For ease of presentation, throughout the rest of this section
we denote the correlated vector wÌ‚i = sign(wÌƒi> wÌƒ1 )wÌƒi for
any i âˆˆ [m].
The main step towards proving Theorem 4 is to consider
each wÌ‚i as an approximately unbiased perturbation of the
true leading eigenvector v1 and to upper bound the magnitude of this perturbation. This is carried out in the following much more general and self-contained lemma, which
might be of independent interest. The proof is given in the
appendix.
Lemma 2. Let A be a positive semidefinite matrix with
some fixed leading eigenvector v1 , a leading eigenvalue Î»1
and an eigengap Î´ := Î»1 (A) âˆ’ Î»2 (A) > 0. Let AÌ‚ be some
positive semidefinite matrix such that kAÌ‚ âˆ’ Ak â‰¤ Î´/4.
Then there is a unique leading eigenvector vÌ‚1 of AÌ‚ such
that hvÌ‚1 , vi â‰¥ 0, and


ckAÌ‚ âˆ’ Ak2


,
vÌ‚1 âˆ’ v1 âˆ’ (Î»1 I âˆ’ A)â€  (AÌ‚ âˆ’ A)v1  â‰¤
Î´2
where â€  denotes the pseudo-inverse, and c is a positive numerical constant.
Lemma 2 is central to the proof of the following Lemma,
of which the proof of Theorem 4 is an easy consequence.
We defer the proof of both the Lemma and that of Theorem
4 to the appendix.
Lemma 3. The following two conditions hold with probability at least 1âˆ’pâˆ’d exp(âˆ’Î´ 2 n/cb2 ), for some numerical
constants c, c0 > 0:
â€¢ The leading eigenvalue of every XÌ‚i is simple, i.e.,
Î»1 (XÌ‚i ) âˆ’ Î»2 (XÌ‚i ) > 0.
â€¢ Fixing v1 , there exist unique leading eigeni
vectors vÌ‚1i , . . . , vÌ‚m
of XÌ‚1 , . . . , XÌ‚m , such that
 1 Pm i
i
maxi kvÌ‚1 âˆ’ v1 k â‰¤ 41 , and  m
i=1 vÌ‚1 âˆ’
q

 2

2

v1  â‰¤ c0 b log(2dm/p)
+ b log(2dm/p)
.
Î´2 n
Î´ 2 mn

Communication-efficient Algorithms for Distributed Stochastic Principal Component Analysis

3.3. Lower Bound for Sign Fixing

min {FÎ»,w (z) :=

zâˆˆRd

We now show that the result of Theorem 4 is tight up to
poly-logarithmic factors and cannot be improved in general:
Theorem 5. For any Î´ âˆˆ (0, 1) and d > 1, there exist a
distribution over vectors in Rd (of norm at most a universal
constant) with eigengap Î´ in the covariance matrix, such
that for any number of machines m and for per-machine
sample size any n sufficiently larger than 1/Î´ 2 , the aggrePm (i)
1
gated vector vÌ„1 = m
i=1 vÌ‚1 (even after sign fixing with
the population
eigenvector
v ) satisfies
"


2 # 1

vÌ„1
1
1
E 1âˆ’
, e1
= â„¦
+
kvÌ„1 k
Î´ 2 mn Î´ 4 n2
The proof is given in the appendix.

4. A Multi-round Algorithm based on
Shift-and-Invert Iterations
In this section we move on to consider distributed algorithms that perform multiple communication rounds. The
main motivation, beyond improving some poly-logarithmic
factors in the estimation error, is to obtain a result that does
not require the per-machine sample size n to grow with the
number of machines m, as in the result of Theorem 4.
Towards this end we consider the use of the Shift-andInvert meta-algorithm, originally described in (Garber &
Hazan, 2015; Garber et al., 2016), to explicitly solve the
centralized ERM objective, i.e., find a unit vector that is an
approximate solution to maxv:kvk=1 v> XÌ‚v.
Throughout this section we let Î»Ì‚1 , Î´Ì‚ denote the leading
eigenvalue and eigengap of XÌ‚, respectively. Also, we assume without loss of generality that b = 1 (i.e., all data
points lie in the unit Euclidean ball).
Since our approach is to approximate the population risk
by approximating the empirical risk, we state the following simple lemma for completeness (a proof is given in the
appendix).
Lemma 4 (Risk of approximated-ERM for PCA). Let w
be a unit vector such that (w> vÌ‚1 )2 â‰¥ 1 âˆ’ , for some fixed
 > 0, where vÌ‚1 is the leading eigenvector âˆš
of XÌ‚. Then it
holds that 1 âˆ’ (w> v1 )2 â‰¤ 1 âˆ’ (w> vÌ‚1 )2 + 2.
4.1. The Shift-and-Invert meta-algorithm
The Shift-and-Invert algorithm (Garber & Hazan, 2015;
Garber et al., 2016) efficiently reduces the problem of
computing the leading eigenvector of a positive semidefinite matrix XÌ‚ to that of approximately-solving a polylogarithmic number of linear systems, i.e., finding approximate minimizers of convex quadratic optimization problems of the form

1 >
z (Î»I âˆ’ XÌ‚)z âˆ’ z> w},
2

(8)

where Î» > Î»1 (XÌ‚) is a shifting parameter. The algorithm is
essentially based on applying power iterations to a shifted
and inverted matrix (Î»I âˆ’ XÌ‚)âˆ’1 , where the shifting parameter Î» is carefully chosen. The algorithm that implements
this reduction, originally described in (Garber & Hazan,
2015), is given below (see Algorithm 1).
Algorithm 1 S HIFT- AND -I NVERT P OWER M ETHOD
1: Input: estimate Î´Ìƒ for the gap Î´Ì‚, accuracy  âˆˆ (0, 1),

failure probability p
 

2: Set: m1 â† d8 ln 144d/p2 e, m2 â† d 32 ln 18d
p2  e
n  m1 +1  m2 +1 o
1
3: Set: Ëœ â† min 16
Î´Ìƒ/8
, 4 Î´Ìƒ/8
4: Set: Î»(0) â† 1 + Î´Ìƒ , wÌ‚0 â† random unit vector, s â† 0
5: repeat
6:
s â† s + 1 , Ms â† (Î»(sâˆ’1) I âˆ’ XÌ‚)
7:
for t = 1...m1 do
8:
Find approx. minimizer - wÌ‚t of FÎ»(sâˆ’1) ,wÌ‚tâˆ’1 (z)
9:
10:
11:
12:

such that kwÌ‚t âˆ’ Mâˆ’1
Ëœ
s wÌ‚tâˆ’1 k â‰¤ 
end for
ws â† wÌ‚m1 /kwÌ‚m1 k
Find approx. minimizer - vs of FÎ»(sâˆ’1) ,ws (z) such
that kvs âˆ’ Mâˆ’1
Ëœ
s ws k â‰¤ 
âˆ†s â† 12 Â· w> v1s âˆ’Ëœ , Î»(s) â† Î»(sâˆ’1) âˆ’ âˆ†2s
s

13: until âˆ†s â‰¤ Î´Ìƒ
14: Î»(f ) â† Î»(s) , Mf â† (Î»(f ) I âˆ’ XÌ‚)
15: for t = 1...m2 do
16:
Find approx. minimizer - wÌ‚t of FÎ»(f ) ,wÌ‚tâˆ’1 (z) such

Ëœ
that kwÌ‚t âˆ’ Mâˆ’1
f wÌ‚tâˆ’1 k â‰¤ 
17: end for
18: Return: wf â† wÌ‚m2 /kwÌ‚m2 k
Lemma 5 (Efficient reduction of top eigenvector to convex optimization; originally Theorem 4.2 in (Garber &
Hazan, 2015)). Suppose that Î´Ì‚ := Î»1 (XÌ‚) âˆ’ Î»2 (XÌ‚) > 0
and suppose that the estimate Î´Ìƒ in Algorithm 1 satisfies
Î´Ìƒ âˆˆ [Î´Ì‚/2, 3Î´Ì‚/4]. Then, with probability at least 1 âˆ’ p,
Algorithm 1 finds a unit vector wf such that (wf> vÌ‚1 )2 â‰¥
1 âˆ’ , and the total number of optimization problems of
the form (8) solved 
during the run of the algorithm,
  is upd
âˆ’1
per bounded by O ln(d/p) ln(Î´Ì‚ ) + ln p
. Moreover, throughout the run of the algorithm it holds that
1 + Î´Ì‚ â‰¥ Î»(s) âˆ’ Î»Ì‚1 = â„¦(Î´Ì‚).
Remark: the purpose of the repeat-until loop in Algorithm 1 is to efficiently find a shifting parameter Î»(f ) such
that c1 Î´Ì‚ â‰¤ Î»(f ) âˆ’ Î»Ì‚1 â‰¤ c2 Î´Ì‚ for some universal constants
c2 > c1 > 0. When n satisfies n = â„¦(Î´ âˆ’2 ln(d/p)),
we can directly find (w.h.p) such a shifting parameter, by

Communication-efficient Algorithms for Distributed Stochastic Principal Component Analysis

simply estimating Î»Ì‚1 , Î´Ì‚ from the data of a single machine.
Also, we can take wÌ‚0 to be the leading eigenvector of any
single machine, since this will already have a constant correlation with vÌ‚1 . Thus, for such n, the total number of
optimization problems can be reduced to O(ln(pâˆ’1 âˆ’1 )).
Algorithm 1 is a meta-algorithm in the sense that the choice
of solver for the optimization problems min FÎ»,w is unspecified, and any solver will do. A simple calculation
shows that a naive application of either the conjugate gradient method or Nesterovâ€™s accelerated gradient method to
solve these optimization problems in a distributed manner,
i.e., the computation of the gradient vector
q is distributed

across machines, will require overall OÌƒ Î»Ì‚1 /Î´Ì‚ communication rounds, which does not give any improvement over
the distributed Lanczos approach, described in Subsection
2.2.2. However, this can be substantially improved by taking advantage of the fact that the data on all machines is
sampled i.i.d. from the same distribution. In particular,
we present below an approach based on applying a preconditioner to the optimization Problem (8), in the spirit of
the one described in (Zhang & Lin, 2015).
4.2. Faster Distributed Approximation of Linear
Systems via Local Preconditioning
Let M = Î»Iâˆ’ XÌ‚, for some shift parameter Î» > Î»Ì‚1 , and define the pre-conditioning matrix C = (Î»+Âµ)Iâˆ’ XÌ‚1 , where
Âµ is required so C is invertible. Consider now solving the
following modified quadratic problem:
1
FÌƒÎ»,w (y) := y> Câˆ’1/2 MCâˆ’1/2 y âˆ’ y> Câˆ’1/2 w. (9)
2
Note that if yâˆ— is the optimal solution to Problem (9), i.e.,
yâˆ— = C1/2 Mâˆ’1 C1/2 Câˆ’1/2 w = C1/2 Mâˆ’1 w,
then zâˆ— := Câˆ’1/2 yâˆ— is the optimal solution to Problem (8).
The idea behind choosing C this way is very intuitive. Ideally we could have chosen C = M, making the condition number of FÌƒÎ»,w equal to Îº(FÌƒÎ»,w ) = 1, which is the
best we can hope for. The problem of course is that this
requires us to explicitly compute Mâˆ’1/2 , which is more
challenging then just computing the leading eigenvector of
XÌ‚. The next best thing is thus to choose C based only
on the data available on any single machine, which allows
computing Câˆ’1/2 without additional communication overhead, and leads to the choice described above. The following lemma, rephrased from (Zhang & Lin, 2015), quantifies
exactly how such a choice of C helps in improving the condition number of the new optimization problem, Problem
(9). The proof is given in the appendix.
Lemma 6. Suppose
 that Âµ â‰¥
 kXÌ‚ âˆ’ XÌ‚1 k. Then, FÌƒÎ»,w (y)
is 1-smooth and

Î»âˆ’Î»Ì‚1
(Î»âˆ’Î»Ì‚1 )+2Âµ

-strongly convex. In particu-

lar, Îº(FÌƒÎ»,w ) â‰¤ 1 + 2Âµ/(Î» âˆ’ Î»Ì‚1 ). Moreover, fixing yÌƒ âˆˆ Rd ,

if we let zÌƒ := Câˆ’1/2 yÌƒ, then it holds that kzÌƒ âˆ’ Mâˆ’1 wk â‰¤
(Î» âˆ’ Î»Ì‚1 )âˆ’1/2 kyÌƒ âˆ’ C1/2 Mâˆ’1
pwk. In particular, for any
p âˆˆ (0, 1), if we set Âµ = 4 ln(d/p)/n, then the above
holds with probability at least 1 âˆ’ p, where this probability
depends only on the randomness in XÌ‚1 .
4.2.1. S OLVING THE PRE - CONDITIONED LINEAR
SYSTEMS

We now discuss the application of gradient-based algorithms for finding an approximate minimizer of the preconditioned problem, Problem (9), in our distributed setting. Towards this end we require a distributed implementation for the first-order oracle of FÌƒÎ»,w (y) (i.e., computation of the value and gradient vector at a queried point).
A straight-forward implementation of the first-order oracle
in our distributed setting is given in Algorithm 2.
Algorithm 2 Distributed First-Order Oracle for FÌƒÎ»,w (y)
1: Input: shift parameter Î» > 0, regularization parameter
Âµ > 0, vector w âˆˆ Rd , query vector y âˆˆ Rd
2: send yÌƒ := Câˆ’1/2 y to machines {2, . . . , m} for C :=
(Î» + Âµ)I âˆ’ XÌ‚1 {executed on machine 1}
3: for i = 1...m do
Ëœ i := XÌ‚i yÌƒ to machine 1 {executed on each
4:
send âˆ‡
machine i}
5: end for
Ëœ
Ëœ := 1 Pm âˆ‡
6: aggregate âˆ‡
i=1 i {executed on machine 1}
m
1
Ëœ âˆ’
7: compute FÌƒÎ»,w (y) = 2 (Î»y> Câˆ’1 y âˆ’ y> Câˆ’1/2 âˆ‡)
> âˆ’1/2
y C
w {executed on machine 1}
Ëœ âˆ’ Câˆ’1/2 w
8: compute âˆ‡FÌƒÎ»,w (y) = Î»Câˆ’1 y âˆ’ Câˆ’1/2 âˆ‡
{executed on machine 1}
9: return: (FÌƒÎ»,w (y), âˆ‡FÌƒÎ»,w (y))
We have the following lemma, the proof of which is deferred to the appendix.
Lemma 7. Fix some Î» > Î»1 (XÌ‚) and w âˆˆ Rd , and let
1 â‰¥ Âµ > 0 be as in Lemma 6. Fix  > 0. Consider the
following two-step algorithm:
1. Apply either the conjugate gradient method or Nesterovâ€™s accelerated method with the distributed firstorder oracle described in Algorithm 2 to find yÌƒ âˆˆ Rd
such that FÌƒÎ»,w (yÌƒ) âˆ’ minyâˆˆRd FÌƒÎ»,w (y) â‰¤ 0
2. Return zÌƒ = Câˆ’1/2 yÌƒ.

âˆ’1
2Âµ
Then, for 0 = 2 1 + Î»âˆ’
(Î» âˆ’ Î»Ì‚1 ) it holds that
Î»Ì‚
1

kzÌƒ âˆ’ (Î»I âˆ’ XÌ‚1 )âˆ’1 wk â‰¤ , and the total number distributed matrix-vector products with the empirical covariance matrix XÌ‚ required to compute zÌƒ is upper-bounded by
O

q

1 + 2Âµ(Î» âˆ’ Î»Ì‚1 )âˆ’1 ln 1 +

2Âµ
Î» âˆ’ Î»Ì‚1




kwk/[(Î» âˆ’ Î»Ì‚1 )]
.

Communication-efficient Algorithms for Distributed Stochastic Principal Component Analysis

We now state our main result for this section, which is a
simple consequence of the previous lemmas. The full proof
is given in the appendix.
Theorem 6. Fix  âˆˆ (0, 1) and p âˆˆ
p(0, 1). Suppose that
mn = â„¦(Î´ âˆ’2 ln(d/p)). Set Âµ = 4 ln(3d/p)/n. Applying the Shift-and-Invert algorithm, Algorithm 1, with the
parameters , p/3, and applying the algorithm in Lemma
7 with the parameter Âµ, to approximately solve the linear
systems, yields with probability at least 1 âˆ’ p a unit vector
wf such that (wf> vÌ‚1 )2 â‰¥ 1 âˆ’ , after executing at most
ï£«s p
Oï£­

" 

ln(d/p)
d
âˆš
ln
ln
p2
Î´ n

+ ln

2



d
p2



 
1
ln
Î´

!
p
ln(d/p)
âˆš
Î´2 n
s
=

OÌƒ

1
âˆš

!

Î´ n

distributed matrix-vector products with the empirical covariance matrix XÌ‚.

5. Experiments
To validate some of our theoretical findings we conducted experiments with single-round algorithms on synthetic data. We generated synthetic datasets using two distributions. For both distributions we used the covariance
matrix X = UÎ£U> with U being a random d Ã— d orthonormal matrix and Î£ is diagonal satisfying: Î£(1, 1) =
1, Î£(2, 2) = 0.8, âˆ€j â‰¥ 3 : Î£(j, j) = 0.9Â·Î£(j âˆ’1, j âˆ’1),
i.e., Î´ = 0.2. One dataset was generated according to the
normal distributions N (0, X), and for p
the second datasets
we generated samples by taking x = 3/2X1/2 y where
y âˆ¼ U [âˆ’1, 1]. In both cases we set d = 300.
Beyond the single-round algorithms that are based on
aggregating the individual ERM solutions described so
far, we propose an additional natural aggregation approach, based on aggregating the individual projection ma(i)
trices. More concretely, letting {vÌ‚1 }m
i=1 denote the leading eigenvectors of the individual machines, let PÌ„1 :=
Pm (i) (i)>
1
. We then take the final estimate w to
i=1 vÌ‚1 vÌ‚1
m
be the leading eigenvector of the aggregated matrix PÌ„1 .
Note that as with the sign-fixing based aggregation, this
approach also resolves the sign-ambiguity in the estimates
produced by the different machines, which circumvents the
lower bound result of Theorem 3.
For both datasets we fixed the number of machines to
m = 25. We tested the estimation error (i.e., the value
1 âˆ’ (w> v1 )2 where v1 is the leading eigenvector of X and
w is the estimator) of five benchmarks vs. the per-machine
sample size n: the centralized solution vÌ‚1 , the average
of the individual (unbiased) ERM solutions (normalized to
unit norm),the average of ERM solutions with sign-fixing,
and the leading eigenvector of the averaged projection ma-

trix. We also plotted the average loss of the individual ERM
solutions. Results are averaged over 400 independent runs.
The results for the normal distribution appear in Figure 1.
The results for the uniform-based distribution are very similar and are deferred to the appendix. We can see that, as
our lower bound in Theorem 3 suggests, simply averaging
and normalizing the individual ERM solutions has significantly worse performance than the centralized ERM solution. Perhaps surprisingly, the performance of this estimator is even worse than the average error of an estimate
computed using only a single machine. We see that both
aggregation methods that are based on correlating the individual ERM solutions, namely the sign-fixing-based estimator, and the proposed averaging-of-projections heuristic,
are asymptotically consistent with the centralized ERM.
In particular, the averaging-of-projections scheme, at least
empirically, significantly outperforms the sign-fixing approach, which justifies further theoretical investigation of
this heuristic. For the sign fixing approach, we can see that
as suggested by our bounds, the estimator is not consistent
with the centralized ERM solution for small values of n.
0.9

centralized ERM
avg. of ERMs
sign-fix avg. of ERMs.
projection avg.
avg. machine loss

0.8

0.7

0.6

avg. error

4.3. Putting it all together

0.5

0.4

0.3

0.2

0.1

0
0

100

200

300

400

500

600

n

Figure 1. Estimation error vs. the per-machine sample size n for
a normal distribution.

6. Discussion
We presented communication-efficient algorithms for distributed statistical estimation of principal components. Focusing on our results for methods based on a single communication round, we initiated a study of how to correctly aggregate distributed ERM solutions in a non-convex setting.
An important take-home message of our work is that in a
non-convex setting, simply averaging the local solutions is
not a good idea. On the positive side, we show that a very
simple correction (i.e., sign-fixing) is possible by leveraging the specific structure of the problem at hand. It is thus
interesting to develop a richer theory of how to perform
such aggregations in more involved non-convex problems.

Communication-efficient Algorithms for Distributed Stochastic Principal Component Analysis

References
Eigenvalues and eigenvectors of 2x2 matrices.
http://www.math.harvard.edu/archive/
21b_fall_04/exhibits/2dmatrices/.

Jain, Prateek, Jin, Chi, Kakade, Sham M, Netrapalli, Praneeth, and Sidford, Aaron. Matching matrix bernstein with little memory: Near-optimal finite sample guarantees for ojaâ€™s algorithm. arXiv preprint
arXiv:1602.06929, 2016b.

Allen Zhu, Zeyuan and Li, Yuanzhi. Even faster SVD decomposition yet without agonizing pain. In Advances
in Neural Information Processing Systems 29: Annual
Conference on Neural Information Processing Systems
2016, December 5-10, 2016, Barcelona, Spain, pp. 974â€“
982, 2016a.

Jolliffe, IT. Principal component analysis. 2002. Springverlag, New York, 2002.

Allen Zhu, Zeyuan and Li, Yuanzhi. Fast global convergence of online PCA. CoRR, abs/1607.07837, 2016b.

Liang, Yingyu, Balcan, Maria-Florina F, Kanchanapally,
Vandana, and Woodruff, David. Improved distributed
principal component analysis. In NIPS, 2014.

Balsubramani, Akshay, Dasgupta, Sanjoy, and Freund,
Yoav. The fast convergence of incremental PCA. In
Advances in Neural Information Processing Systems 26:
27th Annual Conference on Neural Information Processing Systems 2013, pp. 3174â€“3182, 2013.
Boutsidis, Christos, Woodruff, David P, and Zhong, Peilin.
Optimal principal component analysis in distributed and
streaming models. In Proceedings of the 48th Annual
ACM SIGACT Symposium on Theory of Computing, pp.
236â€“249. ACM, 2016.
Garber, Dan and Hazan, Elad. Fast and simple pca via
convex optimization. arXiv preprint arXiv:1509.05647,
2015.
Garber, Dan, Hazan, Elad, Jin, Chi, Kakade, Sham M.,
Musco, Cameron, Netrapalli, Praneeth, and Sidford,
Aaron. Faster eigenvector computation via shift-andinvert preconditioning. CoRR, abs/1605.08754, 2016.
Golub, Gene H and Pereyra, Victor. The differentiation
of pseudo-inverses and nonlinear least squares problems
whose variables separate. SIAM Journal on numerical
analysis, 10(2):413â€“432, 1973.
Hotelling, H. Analysis of a complex of statistical variables
into principal components. J. Educ. Psych., 24, 1933.
Jaggi, Martin, Smith, Virginia, TakaÌc, Martin, Terhorst,
Jonathan, Krishnan, Sanjay, Hofmann, Thomas, and Jordan, Michael I. Communication-efficient distributed
dual coordinate ascent. In Advances in Neural Information Processing Systems, pp. 3068â€“3076, 2014.
Jain, Prateek, Jin, Chi, Kakade, Sham M, Netrapalli, Praneeth, and Sidford, Aaron. Matching matrix bernstein with little memory: Near-optimal finite sample guarantees for ojaâ€™s algorithm. arXiv preprint
arXiv:1602.06929, 2016a.

Lee, Jason D., Ma, Tengyu, and Lin, Qihang. Distributed
stochastic variance reduced gradient methods. CoRR,
abs/1507.07595, 2015.

Magnus, Jan R. On differentiating eigenvalues and eigenvectors. Econometric Theory, 1(02):179â€“191, 1985.
Pearson, K. On lines and planes of closest fit to systems of
points in space. Philosophical Magazine, 2(6):559â€“572,
1901.
Reddi, Sashank J., KonecnyÌ, Jakub, RichtaÌrik, Peter,
PoÌczos, BarnabaÌs, and Smola, Alexander J. AIDE:
fast and communication efficient distributed optimization. CoRR, abs/1608.06879, 2016.
Shamir, Ohad. A stochastic PCA and SVD algorithm with
an exponential convergence rate. In Proceedings of the
32nd International Conference on Machine Learning,
ICML 2015, Lille, France, 6-11 July 2015, pp. 144â€“152,
2015.
Shamir, Ohad. Convergence of stochastic gradient descent
for PCA:. In Proceedings of the 33nd International Conference on Machine Learning, ICML 2016, New York
City, NY, USA, June 19-24, 2016, pp. 257â€“265, 2016a.
Shamir, Ohad. Without-replacement sampling for stochastic gradient methods. In Advances in Neural Information
Processing Systems 29: Annual Conference on Neural
Information Processing Systems 2016, December 5-10,
2016, Barcelona, Spain, pp. 46â€“54, 2016b.
Shamir, Ohad. Fast stochastic algorithms for svd and pca:
Convergence properties and convexity. In Proceedings of
The 33rd International Conference on Machine Learning, pp. 248â€“256, 2016c.
Shamir, Ohad, Srebro, Nathan, and Zhang, Tong.
Communication-efficient distributed optimization using
an approximate newton-type method. In Proceedings of
the 31th International Conference on Machine Learning,
ICML 2014, Beijing, China, 21-26 June 2014, pp. 1000â€“
1008, 2014.

Communication-efficient Algorithms for Distributed Stochastic Principal Component Analysis

Tropp, Joel A. User-friendly tail bounds for sums of random matrices. Foundations of Computational Mathematics, 12(4):389â€“434, 2012.
Yu, Yi, Wang, Tengyao, and Samworth, Richard J. A useful variant of the davisâ€“kahan theorem for statisticians.
Biometrika, 102(2):315â€“323, 2015.
Zhang, Yuchen and Lin, Xiao. Disco: Distributed optimization for self-concordant empirical loss. In Proceedings of the 32nd International Conference on Machine
Learning (ICML-15), pp. 362â€“370, 2015.
Zhang, Yuchen, Duchi, John C, and Wainwright, Martin J.
Communication-efficient algorithms for statistical optimization. Journal of Machine Learning Research, 14:
3321â€“3363, 2013.

Communication-efficient Algorithms for Distributed Stochastic Principal Component Analysis

A. Proofs Omitted from Section 3
A.1. Proof of Theorem 3
Proof. Consider the following distribution over R2 .


1
x = e1 +
,
2

1 , 2 âˆ¼ U {âˆ’1, +1},

where e1 is the first standard basis vector in R2 .
The population covariance matrix and the empirical covariance matrix of a sample of size n are clearly given by




2 0
2 yn
X=
,
XÌ‚(n) =
,
0 1
yn 1
where yn is a random variable which is the average of n U {âˆ’1, +1} random variables. By elementary calculations we
have that the leading eigenvector of XÌ‚(n) is given by
!
2yn
p
,
vÌ‚1 = Ïƒ Â· C(yn ) Â· 1,
1 + 1 + 4yn2
where
ï£«
C(yn ) := ï£­1 +

2y
p n
1 + 1 + 4yn2

!2 ï£¶âˆ’1/2
ï£¸

âˆš
is the normalization factor that guarantees that vÌ‚1 is a unit vector. In particular, it holds that 1/ 2 â‰¤ C(yn ) â‰¤ 1. The
random variable Ïƒ âˆ¼ U {âˆ’1, +1} is independent of yn and determines the sign of vÌ‚1 , which follows from our assumption
that vÌ‚1 is generated by unbiased ERM.
Pm (i)
(1)
(m)
1
Consider now the average of m such unit vectors vÌ‚1 ..vÌ‚1 given by vÌ„ = m
i=1 vÌ‚1 and the normalized estimate
vÌ„1 /kvÌ„1 k, and recall that the leading eigenvector of the population covariance matrix is e1 . It holds that
h

vÌ„1
vÌ„1 (2)2
vÌ„1 (1)2
=
1
âˆ’
.
, e1 i2 =
vÌ„1 (1)2 + vÌ„1 (2)2
vÌ„1 (1)2 + vÌ„1 (2)2
kvÌ„1 k

(10)

Towards upper-bounding the RHS of (10) in expectation, the main step is to lower bound the random variable |vÌ„1 (2)| using
Chebyshevâ€™s inequality.
It holds that
E[|vÌ„1 (2)|]

=

=
(a)

=

â‰¥
(b)

=
(c)

ï£¹
ï£®

 X


 1 (i) 
 1 m (i) 2C(yn(i) )yn(i) 
ï£»
q
E  vÌ‚1 (2) = E ï£°
Ïƒ

m
(i)2 
 m i=1
1 + 1 + 4yn
ï£¹
ï£®
 X

 1 m (i) 2C(yn(i) )|yn(i) | 

ï£»
ï£°
q
E 
Ïƒ

(i)2 
 m i=1
1 + 1 + 4yn

ï£¹ï£¹
ï£®
ï£®
 X

 1 m (i) 2C(yn(i) )|yn(i) | 
 | {Ïƒ (i) }ï£»ï£»
q
E{Ïƒ(i) } ï£°E{y(i) } ï£°
Ïƒ

n
m
(i)2
 i=1
1 + 1 + 4yn 
ï£®
ï£¹ï£¹
ï£®


m
(i)
(i)
X


2C(y
)|y
|
1
n
n
(i)
(i) ï£»ï£»

ï£°
ï£°
q
E{Ïƒ(i) } E{y(i) }
Ïƒ
| {Ïƒ } 
n
m
(i)2


i=1
1 + 1 + 4yn
#
"
"
#


m
1 X

2C(yn )|yn |
1


p
E{Ïƒ(i) } 
= Î˜ âˆš
,
Ïƒ (i)  Â· Eyn
m

mn
1 + 1 + 4yn2 (d)
i=1

(11)

Communication-efficient Algorithms for Distributed Stochastic Principal Component Analysis
(i)
Ïƒ (i) yn

q

(i)2
(i)
(i)
where (a) follows since
âˆ¼Ïƒ
and C(yn )/(1 + 1 + 4yn ) depends only on |yn |, (b) follows from the
(i)
triangle inequality, and (c) follows since {Ïƒ (i) }iâˆˆ[m] and {yn }iâˆˆ[m] are independent random variables. Finally, it is easy
Pm (i)
to verify that (d) follows since i=1 Ïƒ /m is the average of m U {âˆ’1, +1} random variables andphence its expected
âˆš
âˆš
absolute value is Î˜(1/ m). Similarly the expected absolute value of yn is Î˜(1/ n) and C(yn )/(1 + 1 + 4yn2 ) is lower
(i)

(i)
|yn |

bounded by a positive constant.
Also, observe that
ï£®
!2 ï£¹
2 #
1
1 (i)
1
2C(yn )yn
ï£»
p
= E[vÌ‚1 (2)2 ] = E ï£°
E[vÌ„1 (2)2 ] = E
vÌ‚ (2)
m 1
m
m
1 + 1 + 4yn2


1
1
2
â‰¥
E[yn ] = Î˜
,
2m
mn
âˆš
where the inequality follows since |yn | â‰¤ 1 and 1/ 2 â‰¤ C(yn ) â‰¤ 1.
"

(12)

Combining Eq. (11) and Eq. (12), we have by an application of Chebyshevâ€™s inequality to the random variable |vÌ„1 (2)| that
there exists universal constants c1 > 0 such that


1
1
Pr |vÌ„1 (2)| â‰¤ âˆš
â‰¤ .
(13)
4
c1 mn
Also, it is easy to verify that
E[vÌ„1 (1)2 ] = O(1/m),

E[vÌ„1 (2)2 ] = O(1/m).

Thus, by a simple application of Markovâ€™s inequality we have that there exists a universal constant c2 > 0 such that


1
1
2
2
Pr max{vÌ„1 (1) , vÌ„1 (2) } â‰¥
(14)
â‰¤ .
c3 m
4
Using Eq. (10), (13) and (14) we finally have that




 
vÌ„1 (2)2
vÌ„1
1
2
E h
, e1 i = 1 âˆ’ E
=1âˆ’â„¦
.
kvÌ„1 k
vÌ„1 (1)2 + vÌ„1 (2)2
n

A.2. Proof of Lemma 2
Proof. The proof is based on viewing AÌ‚ as an unbiased perturbation of the matrix A, and computing a Taylor expansion
of vÌ‚1 around v1 . For notational convenience, let E = AÌ‚ âˆ’ A, and define A(t) = A + tE for t âˆˆ [0, 1]. Also, define Î»(t)
to be the leading eigenvalue of A(t).
First, we note that for any t âˆˆ [0, 1], A(t) has an eigengap of at least Î´/2 between its first two eigenvalues (since by
Weylâ€™s inequality, its eigenvalues are at most ktEk â‰¤ kEk â‰¤ Î´/4 different than A, and we know that A has an eigengap
of Î´). Therefore, the leading eigenvalue of A(t) is simple. This means that the function v(t), which equals the leading
eigenvector of A(t), is uniquely defined up to a sign. This sign will be chosen so that hv(t), v1 i â‰¥ 0, which makes v(t)
unique and well-defined2 . By Theorem 1 in (Magnus, 1985), we have that both Î»(t) and v(t) are infinitely differentiable
at any t âˆˆ [0, 1], and satisfy3
Î»0 (t) = v(t)> Ev(t) , v0 (t) = (Î»(t)I âˆ’ A(t))â€  Ev(t) .
2

Note thatp
ties are impossible, since that can only happen if hv(t), v1 i = 0, yet by applying the Davis-Kahan sin(Î¸) theorem
(Theorem 2), 1 âˆ’ hv(t), v1 i2 â‰¤ 2kA(t)âˆ’Ak
â‰¤ 2kEk
â‰¤ 12 .
Î´
Î´
3
Formally speaking, the theorem only ensures v(t), Î»(t) exist and are infinitely differentiable in some open neighborhood of t.
However, since the result holds for any t âˆˆ [0, 1], and the proof implies that these functions are unique in each such neighborhood
(where the uniqueness of v(t) holds once we fixed the sign as above), it follows that the same holds in all of t âˆˆ [0, 1].

Communication-efficient Algorithms for Distributed Stochastic Principal Component Analysis

We will also need to bound the second derivative of v(t). By the product rule and the equations above, this derivative
equals

âˆ‚
âˆ‚
(Î»(t)I âˆ’ A(t))â€  Ev(t) + (Î»(t)I âˆ’ A(t))â€  E v(t)
âˆ‚t
âˆ‚t

âˆ‚
â€ 
â€ 
=
(Î»(t)I âˆ’ A(t)) Ev(t) + (Î»(t)I âˆ’ A(t)) E(Î»(t)I âˆ’ A(t))â€  Ev(t).
âˆ‚t

v00 (t) =

(15)

To compute the derivative above, we apply the chain rule. The derivative of a pseudo-inverse Bâ€  of a matrix-valued
function B = B(t) with respect to t (assuming B and hence its pseudo-inverse is symmetric for all t) is given by (see
Theorem 4.3 in (Golub & Pereyra, 1973))






2 âˆ‚
2
âˆ‚
âˆ‚
B Bâ€  + Bâ€ 
B (I âˆ’ BBâ€  ) + (I âˆ’ Bâ€  B)
B Bâ€  .
âˆ’Bâ€ 
âˆ‚t
âˆ‚t
âˆ‚t
This formula is true assuming the rank of B is constant in some open neighborhood of t. Applying
this for B =
âˆ‚
 (Î»(t)I âˆ’ A(t)) =
Î»(t)I
âˆ’
A(t)
(which
indeed
has
a
fixed
rank
of
d
âˆ’
1
by
the
eigengap
assumption),
noting
that
âˆ‚t


v(t)> Ev(t)I âˆ’ E â‰¤ 2kEk, and using the facts that kv(t)k = 1, kI âˆ’ Bâ€  Bk â‰¤ 1,kI âˆ’ BBâ€  k â‰¤ 1 and
k(Î»(t)I âˆ’ A(t))â€  k â‰¤ 2/Î´ (since the smallest non-zero eigenvalue of Î»(t)I âˆ’ A(t) is at least Î´/2), we have that


âˆ‚

24 Â· kEk
â€  

.
 âˆ‚t (Î»(t)I âˆ’ A(t))  â‰¤
Î´2
Plugging this into (15), and again using the fact that k(Î»(t)I âˆ’ A(t))â€  k â‰¤ 2/Î´, we get that
kv00 (t)k â‰¤

ckEk2
Î´2

for some numerical constant c.
By a first-order Taylor expansion of v(t) with an explicit remainder term4 ,
Z
1 1
v(1) = v(0) + v0 (0) +
(1 âˆ’ t)2 v00 (t)dt ,
2 t=0
which by the equations above and the definition of v(t) implies that
Z
1 1
vÌ‚1 = v1 + (Î»1 I âˆ’ A)â€  Ev1 +
(1 âˆ’ t)2 v00 (t)dt .
2 t=0
This implies


vÌ‚1 âˆ’ v1 âˆ’ (Î»1 I âˆ’ A)â€  Ev1  â‰¤ 1
2
0

2

2

Z

1

(1 âˆ’ t)2 kv00 (t)kdt â‰¤

t=0

ckEk2
2Î»2

Z

1

(1 âˆ’ t)2 dt,

t=0

0

which is at most c kEk /Î» for some appropriate numerical constant c . Plugging back E = AÌ‚âˆ’A, the result follows.
A.3. Proof of Lemma 3
Proof. Using the matrix Hoeffding inequality (Theorem 1) and a union bound, we that


 2 
Î´
Î´ n
Pr âˆƒi, kXÌ‚i âˆ’ Xk >
â‰¤ md exp âˆ’ 0 2
12
cb

(16)

for some constant c0 > 0. Thus, with high probability, maxi kXÌ‚i âˆ’ Xk â‰¤ Î´/12. By Weylâ€™s inequality, it follows that the
eigenvalues of X and XÌ‚i are at most Î´/12 apart, and since X has an eigengap of Î´ between its two leading eigenvalues,
Since v(t), v0 (t), v00 (t) are all vectors, this is a direct consequence of the standard Taylor expansion of the scalar function t 7â†’
v(t)j , mapping t to the j-th coordinate of v(t), using the fact that this mapping is differentiable to any order (see Theorem 1 in (Magnus,
1985), and in particular twice continuously differentiable.
4

Communication-efficient Algorithms for Distributed Stochastic Principal Component Analysis

it follows that XÌ‚i has an eigengap of at least Î´ âˆ’ Î´/12 âˆ’ Î´/12 > 0, which proves the first part of the lemma. To
handle the second part, note that by a variant of the Davis-Kahan sinÎ¸ theorem (see Corollary 1 in (Yu et al., 2015)), if
maxi kXÌ‚i âˆ’ Xk â‰¤ Î´/12, then the leading eigenvectors vÌ‚1i of XÌ‚i (after choosing the sign appropriately, i.e. hvÌ‚1i , v1 i â‰¥ 0)
are all at a distance of at most 1/4 from v1 . Moreover, by Lemma 2,
m
m

c 1 X
1 X
 i

kXÌ‚i âˆ’ Xk2 .
vÌ‚1 âˆ’ v1 âˆ’ (Î»1 I âˆ’ X)â€  (XÌ‚i âˆ’ X)v1  â‰¤ 2 Â·
m i=1
Î´ m i=1
By the triangle inequality, this implies

m
1 X

vÌ‚1i âˆ’ v1 âˆ’ (Î»1 I âˆ’ X)â€ 

m
i=1

! 
m
m

c 1 X
1 X

(XÌ‚i âˆ’ X) v1  â‰¤ 2 Â·
kXÌ‚i âˆ’ Xk2 ,

m i=1
Î´ m i=1

and therefore (as kv1 k = 1),




m
m
m
1 X


  X

c 1 X



i
2
â€   1

vÌ‚1 âˆ’ v1  â‰¤ 2 Â·
kXÌ‚i âˆ’ Xk + (Î»1 I âˆ’ X) Â· 
XÌ‚i âˆ’ X .

m
m


Î´
m
i=1
i=1
i=1

(17)

Since
X has an eigengap of Î´, it follows that the minimal non-zero eigenvalue of Î»1 I âˆ’ X is at least Î´, and therefore

(Î»1 I âˆ’ X)â€   â‰¤ 1/Î´. As to the other terms, recall that XÌ‚i is the average of n i.i.d. matrices with mean X, and 1 Pm XÌ‚i
i=1
m
is the average of mn such i.i.d. matrices. Thus, by a matrix Hoeffding inequality (Theorem 1) and a union bound, it holds
with probability at least 1 âˆ’ p that
r
b2 log(2dm/p)
âˆ€i, kXÌ‚i âˆ’ Xk â‰¤ c1
n
as well as


r
m

1 X
b2 log(2dm/p)


XÌ‚i âˆ’ X â‰¤ c1


m
mn
i=1
for some constant c1 . Combining
 2  this with (16) using a union bound, and plugging into (17), it follows that with probability
at least 1 âˆ’ p âˆ’ d exp âˆ’ cÎ´0 bn2 ,


r
m

1 X
cc21 b2 log(2dm/p)
b2 log(2dm/p)


i
+ c1
.
vÌ‚1 âˆ’ v1  â‰¤

2

m
Î´ n
Î´ 2 mn
i=1
Slightly simplifying, the result follows.
A.4. Proof of Theorem 4
Proof of Thm. 4. The proof is an easy consequence of Lemma 3. Assuming the events in the lemma occur, we have that
the leading eigenvalues of X as well as XÌ‚i for all i are simple, hence the leading eigenvectors are all unique up to a sign.
In particular, let v1 be the eigenvector closest to wÌƒ1 = wÌ‚1 , with ties broken arbitrarily, so that kwÌ‚1 âˆ’ v1 k â‰¤ kwÌ‚1 + v1 k.
This implies that wÌ‚1 = vÌ‚11 (where vÌ‚11 is as defined in Lemma 3), since otherwise, by the inequality above,
p we would get
k âˆ’ vÌ‚11 âˆ’ v1 k â‰¤ k âˆ’ vÌ‚11 + v1 k, which implies in turn hvÌ‚11 , v1 i â‰¤ 0, contradicting the fact that kvÌ‚11 âˆ’ v1 k = 2 âˆ’ 2hvÌ‚1 , v1 i
is at most 1/4 by Lemma 3.
Having established that wÌ‚1 = vÌ‚11 , we note that by Lemma 3 and the triangle inequality, for any i > 1,
kvÌ‚1i âˆ’ vÌ‚11 k â‰¤

1
1
and therefore kvÌ‚1i âˆ’ wÌ‚1 k â‰¤ .
2
2

As vÌ‚1i , wÌ‚1 are unit vectors, this implies that kvÌ‚1i âˆ’ wÌ‚1 k < k âˆ’ vÌ‚1i âˆ’ wÌ‚1 k. Since for any i, we have wÌ‚i âˆˆ {âˆ’vÌ‚1i , vÌ‚1i }, with
i
i
the sign chosen based on which vector is closest to wÌ‚1 , it follows
 that wÌ‚i = vÌ‚1 for all i. Applying Lemma 3 with wÌ‚i = vÌ‚1 ,
2
2
we get that with probability at least 1 âˆ’ p âˆ’ d exp âˆ’Î´ n/cb ,
m
1 X



wÌ‚i âˆ’ v1 

m i=1

â‰¤ c0

 b2 log(2dm/p)

r
+

Î´2 n
b2 log(2dm/p) 
.
Î´ 2 mn

Communication-efficient Algorithms for Distributed Stochastic Principal Component Analysis

Squaring both sides and using the fact that (x + y)2 â‰¤ 2x2 + 2y 2 , we get that
m
1 X
2


wÌ‚i âˆ’ v1 

m i=1

â‰¤

2(c0 )2

 b4 log2 (2dm/p)

Î´ 4 n2
b2 log(2dm/p) 
+
.
(18)
Î´ 2 mn

This holds with probability at least 1 âˆ’ p âˆ’ d exp âˆ’Î´ 2 n/cb2 . To simplify things a bit, note that we can assume
d exp(âˆ’Î´ 2 n/cb2 ) â‰¤ p without loss of generality, since otherwise the bound in the displayed equation above is at least
a constant and therefore trivially true (holds with probability 1) if we make the constant c0 sufficiently large. Therefore, we
can argue that (18) (with an appropriate c0 ) holds with probability at least 1 âˆ’ 2p. Absorbing the 2 factor into the p term,
slightly increasing c0 appropriately, and simplifying a bit, the result finally follows from the simple observation that

1
2 âˆ’ kw âˆ’ v1 k2 â‰¥
2
m
m

1 X
2 
1 X 
1

2


2 âˆ’ 2w âˆ’
wÌ‚i  âˆ’ 2
wÌ‚i âˆ’ v1 
2
m i=1
m i=1
m
1 X
2


wÌ‚i âˆ’ v1  ,
â‰¥ 1 âˆ’ 2
m i=1

(v1> w)2 =

where the first inequality follows from the triangle inequality and the inequality (a + b)2 â‰¤ P
2a2 + 2b2 , and the second
m
1
inequality follows since v1 is a unit vector, and by definition, w is the unit vector closest to m i=1 wÌ‚i .
A.5. Proofs of Theorem 5
The proof is a combination of the following two lemmas, each proves one of the lower bounds. We first state the two
lemmas and then prove them.
Lemma 8. For any Î´ âˆˆ (0, 1) and d > 1, there exist a distribution over vectors in Rd (of norm at most 2) such that the
covariance matrix has eigengap Î´, and for any number of machines m and per-machine sample size n, the aggregated
Pm (i)
1
vector vÌ„1 = m
i=1 vÌ‚1 (even after sign fixing) satisfies





1
1
vÌ„1
2
, e1 i
= â„¦ min
,
.
E 1âˆ’h
kvÌ„1 k
m Î´ 2 mn
Lemma 9. For any Î´ âˆˆ (0, 1) and d > 1, there exist a distribution over vectors in Rd (of norm at most 2) with eigengap
Î´ in the covariance matrix, such that for any number of machines m and for per-machine sample size any n sufficiently
Pm (i)
1
larger than 1/Î´ 2 , the aggregated vector vÌ„1 = m
i=1 vÌ‚1 (even after sign fixing with the population eigenvector v1 )
satisfies




1
vÌ„1
2
E 1âˆ’h
, e1 i
= â„¦
.
kvÌ„1 k
Î´ 4 n2
proof of Lemma 8. We will prove the result for d = 2 (i.e. a distribution in R2 ). This is without loss of generality, since
we can always embed the distribution below in Rd for any d > 2 (say, by having all coordinates other than the first two
identically zero).
âˆš
Consider the distribution defined by the random vector x = 1 + Î´e1 +Ïƒe2 , where Ïƒ is uniformly distributed on {âˆ’1, +1},
and e1 = (1, 0), e2 = (0, 1) are the standard basis vectors. Clearly, the population covariance matrix is


1+Î´ 0
X := E[xx> ] =
,
0
1
with a leading eigenvector (1, 0). Let us now consider the distribution of the output of a machine i. Given n samples, the
empirical covariance matrix is


n
âˆš
1X
1 + Î´ yn
XÌ‚(n) =
, yn := 1 + Î´ Â·
i ,
yn
1
n i=1

Communication-efficient Algorithms for Distributed Stochastic Principal Component Analysis

where i are i.i.d. and uniformly distributed on {âˆ’1, +1}. Using a standard formula for the leading eigenvector of a 2 Ã— 2
matrix (eig), we have that the leading eigenvector (and hence the output of any machine i) is of the form
!
r
1
Î´2
Î´
2
vÌ‚1 =
uÌ‚ where uÌ‚ :=
+
+ yn , yn .
(19)
kuÌ‚k
2
4
Note that with this formula, the leading eigenvector is always closer to (1, 0) than (âˆ’1, 0), and converges to (1, 0) as
n â†’ âˆž. Thus, we can view the random variable vÌ‚(i) as the output of any machine i, given n samples and after fixing the
sign.
Pm (i)
1
Consider now the average of m such vectors given by vÌ„ = m
i=1 vÌ‚1 . Using (19), we have that
ï£®
!2 ï£¹
m
m
X
X
1
1
(i)
(i)
ï£»= 1
vÌ‚2
E[(vÌ‚2 )2 ] = E[(vÌ‚(2))2 ]
E[vÌ„1 (2)2 ] = E ï£°
m i=1
m2 i=1
m
ï£¹
ï£®
yn2
1 ï£°
ï£».
q
(20)
E
=
m
Î´2
Î´2
2
2
+ 2y + Î´
+y
n

2

4

n

By definition of yn and recalling that Î´ âˆˆ [0, 1], we have that there exist universal constants c1 , c2 > 0 such that with
constant probability it holds that c1 /n â‰¥ yn2 â‰¥ c2 /n. Using this fact and considering the two cases 1/n â‰¥ Î´ 2 and
1/n < Î´ 2 in the RHS of Eq. (20) separately, we can see that


1
1
E[vÌ„1 (2)2 ] = â„¦
min{1, 2 } .
(21)
m
Î´ n
Using Eq. (21) we have that


vÌ„1
2
, e1 i
E h
kvÌ„1 k




vÌ„1 (1)2
vÌ„1 (2)2
= E
=1âˆ’E
vÌ„1 (1)2 + vÌ„1 (2)2
vÌ„1 (1)2 + vÌ„1 (2)2





1
1
2
â‰¤ 1 âˆ’ E vÌ„1 (2) = 1 âˆ’ â„¦ min
,
,
m Î´ 2 mn


where the inequality follows since kvÌ„1 k â‰¤ 1.

proof of Lemma 9. As in Lemma 8, we prove the result for d = 2, however, using a different construction. Consider the
defined by the random vector
âˆš
x = 1 + Î´ Â· e1 + Î¾ Â· e2 ,
where Î¾ is an independent random variable defined as:
 âˆš
2 âˆš
Î¾=
âˆ’1/ 2

w.p. 1/3
w.p. 2/3

âˆš
It is easy to verify that E[Î¾] = 0, E[Î¾ 2 ] = 1, E[Î¾ 3 ] = 1/ 2. As we shall see, choosing Î¾ to be asymmetric (as opposed to 
in the proof of Lemma 9) will be key to our construction. Clearly, the population covariance and the empirical covariance
of a sample of size n are given by we have




1+Î´ 0
1 + Î´ yn
X = E[xx> ] =
,
XÌ‚(n) =
,
0
1
yn
zn
where
yn :=

âˆš

n

1+Î´Â·

1X
Î¾i ,
n i=1

n

zn :=

1X 2
Î¾ ,
n i=1 i

Communication-efficient Algorithms for Distributed Stochastic Principal Component Analysis

with Î¾1 , . . . , Î¾n being i.i.d. copies of the random variable Î¾.
(1)

(m)

Clearly the leading eigenvector of X is e1 = (1, 0). Consider now vÌ‚1 , . . . , vÌ‚1 to be the leading eigenvectors of m i.i.d.
(1)
m)
empirical covariance matrices of n samples, XÌ‚(n) , . . . , XÌ‚(n) , and let vÌ„1 denote their average after sign-fixings according
to the leading eigenvector of the population covariance e1 . In the following, we let vÌ‚ji denote the jth coordinate in the
(i)

eigenvector vÌ‚1 .
It holds that


vÌ„1
2
E h
, e1 i
kvÌ„1 k




vÌ„1 (1)2
vÌ„1 (2)2
= E
=1âˆ’E
vÌ„1 (1)2 + vÌ„1 (2)2
vÌ„1 (1)2 + vÌ„1 (2)2
ï£®
!2 ï£¹
m
X


1
â‰¤ 1 âˆ’ E vÌ„1 (2)2 = 1 âˆ’ E ï£°
sign(vÌ‚1i )vÌ‚2i ï£»
m i=1


!2
m

1 X 
i i
â‰¤ 1âˆ’
E sign(vÌ‚1 )vÌ‚2
m i=1
2
= 1 âˆ’ E[sign(vÌ‚11 )vÌ‚21 ] ,

(22)

where the first inequality follows since kvÌ„1 k â‰¤ 1, the second inequality follows from Jensenâ€™s inequality, and the last
(1)
(m)
equality follows from the fact that vÌ‚1 , . . . , vÌ‚1 are i.i.d. random variables. From this chain of inequalities, it follows
2
that it is enough to lower bound E[sign(vÌ‚11 )vÌ‚21 ] , where vÌ‚1 is the leading eigenvector computed by machine 1.
Let us now consider the distribution of the leading eigenvector of the empirical covariance matrix XÌ‚(n) . Using a standard
formula for the leading eigenvector of a 2 Ã— 2 matrix (eig), we have that this leading eigenvector vÌ‚1 is proportional to
ï£«
ï£¶
s
2
Î´
+
1
âˆ’
z
Î´
+
1
âˆ’
z
n
n
ï£­
+
+ yn2 , yn ï£¸
(23)
2
2
Assume for now that zn â‰¤ 1 + cÎ´ for some positive constant c to be fixed later (note this happens with arbitrarily high
probability as n â†’ âˆž, as zn converges to 1 in probability). In that case, the sign of the first coordinate in the formula
above is positive, and has the same sign as the first coordinate of the leading eigenvector v1 = (1, 0). Moreover, we know
(1)
that vÌ‚1 must have unit norm, from which follows that


q

Î´+1âˆ’zn 2
Î´+1âˆ’zn
2 , y
+
+
y
n
n
2
2
(1)
sign(vÌ‚11 ) Â· vÌ‚1 = s
(24)

2 .
q

2
Î´+1âˆ’z
Î´+1âˆ’z
n
n
yn2 +
+
+ yn2
2
2
In particular, letting rn = 1 âˆ’ zn , we have that if rn â‰¥ âˆ’cÎ´, then
sign(vÌ‚11 ) Â· vÌ‚21 = s


yn2

+

= v
u
u
ty 2 +
n

Î´+rn
2

+

yn
q


Î´+rn 2
2

2
+

yn2

yn

Î´+rn 2
2

r
1+

1+



2yn
Î´+rn

2

!2 .

(25)

Towards using Eq. (22) to derive the lower bound, the main step is to bound the expectation of the RHS of Eq.(25) away
from zero. To get an intuition why this is possible, observe that when n â†’ âˆž (in particular, when it is significantly larger
than 1/Î´ 2 ), it holds that
yn
RHS of (25) â‰ˆ p
,
2
yn + Î˜(Î´ 2 )

Communication-efficient Algorithms for Distributed Stochastic Principal Component Analysis

since in this regime, with high probability, rn << Î´ and yn << 1. Now comes to play our choice of Î¾ to be an asymmetric
random variable. If, just for sake of intuition, we set n = 1, it is easy to verify that despite the fact that E[yn ] = 0, it holds
that
"
#
#
"
Î¾
yn
=E p
< 0.
E p
yn2 + Î˜(Î´ 2 )
Î¾ 2 + Î˜(Î´ 2 )
Note in particular that taking Î¾ to be uniformly distributed on {âˆ’1, +1}, as in Lemma 8, will still give zero expectation,
and hence will not work. We now formalize this intuition. We will use a Taylor expansion of the formula above, in order to

2
bound its expectation (over yn , rn ), from which a lower bound on E sign(vÌ‚11 ) Â· vÌ‚21
would follow. To that end, define
the function
tyn
g(t) = v
!2 , t âˆˆ [0, 1],
u
r


u
2

t(ty )2 + Î´+trn 2 1 + 1 + 2tyn
n
2
Î´+trn
and note that g(1) equals sign(vÌ‚11 ) Â· vÌ‚21 as defined above. By a Taylor expansion, we have
1
s3
sign(vÌ‚11 ) Â· vÌ‚21 = g(1) = g(0) + g 0 (0) + g 00 (0) + g 000 (s)
2
6
5
for some s âˆˆ [0, 1]. A tedious calculation of gâ€™s derivatives reveals that this implies


yn
rn yn
|yn |3 + |rn |3
1
1
sign(vÌ‚1 ) Â· vÌ‚2 =
âˆ’ 2 Â±O
,
Î´
Î´
Î´3

(26)

assuming max{|yn |, |rn |} â‰¤ cÎ´ for some constant c (hence fixingc we used 
in our earlier assumptions on rn , zn ). To
3
3
n|
be the expression on the right-hand side
simplify notation, let qn = sign(vÌ‚11 ) Â· vÌ‚21 , let bn = yÎ´n âˆ’ rnÎ´y2 n Â± O |yn | Î´+|r
3
of the equation above, and let A be the event that max{|yn |, |rn |} â‰¤ cÎ´ indeed holds. Also, note that with probability 1,
|qn | â‰¤ 1 and |bn | = O(1/Î´ 3 ). Thus, by Eq. (26), we have that E[qn |A] = E[bn |A], and therefore
E[qn ] = Pr(Â¬A) Â· E[qn |Â¬A] + Pr(A) Â· E[qn |A]
= Pr(Â¬A) Â· E[qn |Â¬A] + Pr(A) Â· E[bn |A]
= Pr(Â¬A) Â· E[qn |Â¬A] + E[bn ] âˆ’ Pr(Â¬A) Â· E[bn |Â¬A]

= E[bn ] Â± O Pr(Â¬A)/Î´ 3 .
Plugging back the definitions of qn , bn , A, we get that







yn
rn yn
|yn |3 + |rn |3
1
E sign(vÌ‚11 ) Â· vÌ‚21 = E
âˆ’ 2 Â±O
Â±
O
Pr(max{|y
|,
|r
|}
>
cÎ´)
.
n
n
Î´
Î´
Î´3
Î´3
âˆš
Pn
Pn
Recalling that yn = 1 + Î´ Â· n1 i=1 Î¾i and rn = 1 âˆ’ zn = 1 âˆ’ n1 i=1 Î¾i2 , where Î¾i are i.i.d. copies of a zero-mean,
âˆš
bounded random variable satisfying E[Î¾ 3 ] = 1/ 2, and using Hoeffdingâ€™s inequality, it is easily verified that the above
equals




âˆš
1
1
1
2
0 + 1 + Î´âˆš
Â±O
Â±O
exp(âˆ’â„¦(nÎ´ )) ,
Î´3
(Î´ 2 n)3/2
2Î´ 2 n


2

which is â„¦ Î´21n assuming n is sufficiently larger than 1/Î´ 2 . As a result, we get that E sign(vÌ‚11 ) Â· vÌ‚21
= â„¦ Î´41n2 as
required.

B. Proofs Omitted from Section 4
B.1. Proof of Lemma 4
Proof. Let â€¢ denote the standard inner product for matrices, i.e., A â€¢ B = Tr(AB> ). It holds that
(w> v1 )2

5

ww> â€¢ v1 v1> â‰¥ vÌ‚1 vÌ‚1> â€¢ v1 v1> âˆ’ kww> âˆ’ vÌ‚1 vÌ‚1> kF Â· kv1 v1> k
q
âˆš
= (w> v1 )2 âˆ’ 2(1 âˆ’ 1(w> vÌ‚1 )2 ) â‰¥ (w> v1 )2 âˆ’ 2.

=

Using MATLABâ€™s symbolic math toolbox together with some straightforward manual calculations

Communication-efficient Algorithms for Distributed Stochastic Principal Component Analysis

B.2. Proof of Lemma 6
Proof. Observe that C = M + (XÌ‚ âˆ’ XÌ‚1 ) + ÂµI. Thus, by our assumption on Âµ it follows that
M + 2ÂµI  C  M.

(27)

Since FÌƒÎ»,w (y) is twice differentiable, in order to bound its smoothness and strong-convexity parameters, it suffices to
upper bound the largest eigenvalue and lower bound the smallest eigenvalue of its Hessian, respectively.
The Hessian of FÌƒÎ»,w (y) is given by âˆ‡2 FÌƒÎ»,w (y) = Câˆ’1/2 MCâˆ’1/2 .
From Eq. (27) it follows that we can write M = C âˆ’ âˆ† where âˆ†  0.
Thus we have that
Î»1 (Câˆ’1/2 MCâˆ’1/2 ) = Î»1 (Câˆ’1/2 (C âˆ’ âˆ†)Câˆ’1/2 ) â‰¤ Î»1 (I) = 1,

(28)

where the inequality follows since Câˆ’1/2 âˆ†Câˆ’1/2 is positive semidefinite.
Since M, C are invertible and positive definite, Eq. (27) implies that
Mâˆ’1  Câˆ’1  (M + 2ÂµI)âˆ’1 .

(29)

Thus we have that
Î»d (Câˆ’1/2 MCâˆ’1/2 )

= Î»d (M1/2 Câˆ’1/2 Câˆ’1/2 MCâˆ’1/2 C1/2 Mâˆ’1/2 ) = Î»d (M1/2 Câˆ’1 M1/2 )
Î»i (M)
}
â‰¥ Î»d (M1/2 (M + 2ÂµI)âˆ’1 M1/2 ) = min{
iâˆˆ[d] Î»i (M) + 2Âµ
=

Î»d (M)
Î» âˆ’ Î»Ì‚1
,
=
Î»d (M) + 2Âµ
(Î» âˆ’ Î»Ì‚1 ) + 2Âµ

(30)

where the first equality follows from matrix similarity and the fact that M, C are invertible, and the first inequality follows
from Eq. (29).
To prove the second part of the lemma we observe that
kzÌƒ âˆ’ Mâˆ’1 wk

= kCâˆ’1/2 yÌƒ âˆ’ Câˆ’1/2 C1/2 Mâˆ’1 wk â‰¤ kCâˆ’1/2 k Â· kyÌƒ âˆ’ C1/2 Mâˆ’1 wk
1
â‰¤ q
kyÌƒ âˆ’ C1/2 Mâˆ’1 wk,
Î» âˆ’ Î»1 (XÌ‚)

where the second inequality follows from Eq. (29).
Finally, the last part of the lemma follows from a direct application of Theorem 1 to upper bound kX âˆ’ XÌ‚1 k.
B.3. Proof of Lemma 7
Proof. Let zâˆ— := (Î»I âˆ’ XÌ‚)âˆ’1 w, yâˆ— := C1/2 (Î»I âˆ’ XÌ‚)âˆ’1 w, and recall that zâˆ— and yâˆ— are the global minimizers of FÎ»,w (z)
and FÌƒÎ»,w (y), respectively. Using the results of Lemma 6 we have that
âˆ—

âˆ’1/2

kzÌƒ âˆ’ z k â‰¤ (Î» âˆ’ Î»Ì‚1 )

âˆ—

kyÌƒ âˆ’ y k â‰¤ (Î» âˆ’ Î»Ì‚1 )

âˆ’1/2

s 
2 1+

2Âµ
Î» âˆ’ Î»Ì‚1



0 ,

where the second inequality follows from the strong-convexity of FÌƒÎ»,w (y). Thus, it suffices to set 0 as stated in the lemma
in order to obtain the approximation guarantee for zÌƒ.

Communication-efficient Algorithms for Distributed Stochastic Principal Component Analysis

To upper-bound the total number of communication rounds required to obtain yÌƒ with the guarantee prescribed in the lemma,
we note that both the conjugate gradient method and Nesterovâ€™s accelerated gradient method require
!
r
Î²
âˆ—
0
O
ln (ky k/ )
(31)
Î±
calls to the first-order oracle of FÌƒÎ»,w (y) to obtain yÌƒ satisfying FÌƒÎ»,w (yÌƒ) âˆ’ minyâˆˆRd FÌƒÎ»,w (y) â‰¤ 0 , where Î± and Î² are
the strong-convexity and smoothness parameters of FÌƒÎ»,w , respectively, and assuming w.l.o.g. that the initial iterate is
y0 = ~0. Thus, by our construction of a distributed first-order oracle given in Algorithm 2, we have that the total number
of communication rounds is upper bounded by (31). The lemma now follows from noticing that by Lemma 6 we have that
2Âµ
and that
Î²/Î± = 1 + Î»âˆ’
Î»Ì‚1


kyâˆ— k = kC1/2 (Î»I âˆ’ XÌ‚1 )wk â‰¤ Î»1 (C1/2 )(Î» âˆ’ Î»Ì‚1 )âˆ’1 kwk = O kwk/(Î» âˆ’ Î»Ì‚1 ) .

B.4. Proof of Theorem 6
Proof. Under our assumption that mn = â„¦(Î´ âˆ’2 ln(d/p)), the following three events all hold with probability at least 1 âˆ’ p
(each of which holds w.p. at least 1 âˆ’ p/3):
1. the output wf satisfies (wf> vÌ‚1 )2 â‰¥ 1 âˆ’  (holds w.p. 1 âˆ’ p/3 by applying Lemma 5 with our choice of parameters)
2. Î´Ì‚ = Î˜(Î´) (by applying Theorem 1)
3. kXÌ‚ âˆ’ XÌ‚1 k â‰¤ Âµ, where Âµ is as prescribed in the Theorem (by applying Theorem 1)
The approximation guarantee of wf follows directly from Lemma 5. It thus remains to upper-bound the number of matrixvector products. Thus, combining Lemmas 5 and 7 we have that when using either the conjugate gradient method or
Nesterovâ€™s accelerated method to approximately solve the linear systems in Algorithm 1, as prescribed in Lemma 7, the
total number of distributed matrix-vector products with XÌ‚ is:
r

 

!!
 
d
(1 + 2Âµ/Î´)
2Âµ
d
âˆ’1
Â·
ln Î´ ln
+ ln
=
1+
O ln
p
Î´
p
Î´Ëœ

r

 
  

 !
2Âµ
d
d
(1 + 2Âµ/Î´)
1
âˆ’1 2
O
1+
ln Î´ ln
+ ln
ln
+ ln
=
Î´
p
p
Î´
Ëœ
r

  

 
   !
2Âµ
d
(1
+
2Âµ/Î´)
1
d
d
O
1+
ln Î´ âˆ’1 ln2
+ ln
ln
+ ln2
ln
,
Î´
p
p
Î´
p
Î´
where the first term in the O(Â·) in the first row accounts for the total number of instances of FÎ»,w (z) needs to be solved,
given by the bound in Lemma 5, and the second term in the first row accounts for the communication-complexity of solving
each such instance according to Lemma 7. Additionally, we have used Lemma 5 to lower bound Î» âˆ’ Î»Ì‚1 = â„¦(Î´Ì‚), and Ëœ()
is as prescribed in Algorithm 1. Finally, we have upper-bounded ln(kwk), in all instances of FÎ»,w (z) solved throughout
the run of the algorithm, by noticing that in all of them it holds that

 
 

d
,
ln(kwk) = O ln Î»(s) âˆ’ Î»Ì‚1 )âˆ’ max{m1 ,m2 }
= O ln Î´ âˆ’1 ln
p
where m1 , m2 are as prescribed in Algorithm 1, and we have used Lemma 5 again to lower bound Î»(s) âˆ’ Î»Ì‚1 = â„¦(Î´).
âˆš
4 ln(3d/p)
âˆš
Finally, using Lemma 6, we can set Âµ =
. Thus, the overall number of communication rounds is upper-bound
n
by
ï£«s p
ï£¶
!
p



  !
ln(d/p)
ln(d/p)
d
d
1
ï£¸.
âˆš
âˆš
Oï£­
ln
ln
+ ln2
ln
p2
p2
Î´
Î´ n
Î´2 n

Communication-efficient Algorithms for Distributed Stochastic Principal Component Analysis

C. Additional Experimental Results
0.9

centralized ERM
avg. of ERMs
sign-fix avg. of ERMs.
projection avg.
avg. machine loss

0.8

0.7

avg. error

0.6

0.5

0.4

0.3

0.2

0.1

0
0

100

200

300

400

500

600

n

Figure 2. Estimation error vs. the per-machine sample size n for uniform sampling-based distribution.

D. Proof of the Davis-Kahan sinÎ¸ Theorem
We prove Theorem 2 in greater generality. In particular, Theorem 2 follows from setting k = 1 in the next theorem.
Theorem 7 (Davis-Kahan sinÎ¸ theorem). Let X, Y be symmetric real d Ã— d matrices and fix k âˆˆ [d]. Let VX and VY
denote dÃ—k matrix whose columns are the top k eigenvectors of X and the matrix whose columns are the top k eigenvectors
of Y, respectively. Also, suppose that Î´k (X) := Î»k (X) âˆ’ Î»k+1 (X) > 0. Then it holds that
>
>
kVX VX
âˆ’ VY VY
kF â‰¤ 2

kX âˆ’ Yk
.
Î´k (X)

Proof. Throughout the proof we denote the projection matrices:
>
>
>
âŠ¥
>
PX := VX VX
, PâŠ¥
X := I âˆ’ VX VX , PY := VY VY , PY := I âˆ’ VY VY ,

i.e., PX is the projection matrix onto the top k eigenvectors of X and PâŠ¥
X is the projection matrix onto the lower d âˆ’ k
eigenvectors, and same goes for PY , PâŠ¥
Y . We also let A â€¢ B denote the standard inner products between matrices A, B.
We can write PY as
PY

âŠ¥
âŠ¥
âŠ¥
= PX PY PX + PâŠ¥
X PY PX + PX PY PX + PX PY PX .

(32)

Observe that


âŠ¥
âŠ¥
PX PY PâŠ¥
X â€¢ X = Tr PX PY PX X = Tr PY PX XPX = 0,

(33)
PâŠ¥
X XPX

where the second equality follows from the cyclic property of the trace, and the last equality follows since
0dÃ—d . Using Eq. (32) and (33) we have that

âŠ¥
âŠ¥
âŠ¥
PY â€¢ X = PX PY PX â€¢ X + PâŠ¥
X PY PX â€¢ X = Tr (PX PY PX X) + Tr PX PY PX X


âŠ¥ âŠ¥
âŠ¥
âŠ¥
âŠ¥
= Tr (PY PX X) + Tr PâŠ¥
X PY PX PX X â‰¤ Tr (PY PX X) + Tr PX PY PX Â· Î»1 (PX X)

= Tr (PY PX X) + Î»k+1 (X) Â· Tr PâŠ¥
X PY ,

=

(34)

Communication-efficient Algorithms for Distributed Stochastic Principal Component Analysis

where the inequality follows since for any two positive semidefinite matrices A, B it holds that Tr(AB) â‰¤ Tr(A) Â· Î»1 (B)
âŠ¥
and the fact that PâŠ¥
X X is positive semidefinite. The last equality follows since Î»1 (PX X) = Î»k+1 (X). It further holds that
PY â€¢ Y

â‰¥ PX â€¢ Y = Tr(PX X) + PX â€¢ (Y âˆ’ X).

(35)

Subtracting Eq. (35) from Eq. (34) we have that

Tr (PY PX X) + Î»k+1 (X) Â· Tr PâŠ¥
X PY âˆ’ Tr(PX X) âˆ’ PX â€¢ (Y âˆ’ X) â‰¥ PY â€¢ X âˆ’ PY â€¢ Y.
Rearranging we have that
Tr ((I âˆ’ PY )PX X) âˆ’ Î»k+1 (X) Â· Tr PâŠ¥
X PY



â‰¤

(Y âˆ’ X) â€¢ (PY âˆ’ PX )

â‰¤

kX âˆ’ Yk Â· kPX âˆ’ PY kF .

(36)

It holds that
Tr ((I âˆ’ PY )PX X)

= Tr (PX (I âˆ’ PY )PX PX X)
â‰¥ Tr (PX (I âˆ’ PY )PX ) Â· Î»k (PX X)
= Tr (PX âˆ’ PY PX )) Â· Î»k (X)
(k âˆ’ PX â€¢ PY ) Â· Î»k (X)
Î»k (X)
kPX âˆ’ PY k2F .
=
2

=

(37)

Furthermore, it holds that

1
2
Tr PâŠ¥
X PY = Tr ((I âˆ’ PX )PY ) = k âˆ’ PX â€¢ PY = kPX âˆ’ PY kF .
2

(38)

Plugging Eq. (37) and (38) into Eq. (36), we have that
1
kPX âˆ’ PY k2F Â· (Î»k (X) âˆ’ Î»k+1 (X)) â‰¤ kX âˆ’ Yk Â· kPX âˆ’ PY kF ,
2
which completes the proof.

(39)

