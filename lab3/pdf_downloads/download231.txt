Supplementary Materials for:
On Calibration of Modern Neural Networks

S1. Further Information on Calibration
Metrics
We can connect the ECE metric with our exact miscalibration definition, which is restated here:
i

h 


E P Ŷ = Y | P̂ = p − p
P̂

Let FP̂ (p) be the cumulative distribution function of P̂ so
that FP̂ (b) − FP̂ (a) = P(P̂ ∈ [a, b]). Using the RiemannStieltjes integral we have
i
h 



E P Ŷ = Y | P̂ = p − p
P̂

=

≈

Z

1

0
M
X

The first two constraint ensure that q is a probability distribution, while the last constraint limits the scope of distributions. Intuitively, the constraint specifies that the average
true class logit is equal to the average weighted logit.
Proof. We solve this constrained optimization problem using the Lagrangian. We first ignore the constraint q(zi )(k)
and later show that the solution satisfies this condition. Let
λ, β1 , . . . , βn ∈ R be the Lagrangian multipliers and define
L=−

 




P Ŷ = Y | P̂ = p − p dFP̂ (p)

m=1





P(Ŷ = Y |P̂ = pm ) − pm  P(P̂ ∈ Im )

where
Im represents the interval of bin Bm .



P(Ŷ = Y |P̂ = pm ) − pm  is closely approximated
by |acc(Bm ) − p̂(Bm )| for n large. Hence ECE using M
binshconverges
to the M-termiRiemann-Stieltjes sum of



EP̂ P Ŷ = Y | P̂ = p − p .

S2. Further Information on Temperature
Scaling

Here we derive the temperature scaling model using the entropy maximization principle with an appropriate balanced
equation.
Claim 1. Given n samples’ logit vectors z1 , . . . , zn and
class labels y1 , . . . , yn , temperature scaling is the unique
solution q to the following entropy maximization problem:
max
q

subject to

−

n X
K
X

i=1 k=1
q(zi )(k) ≥
K
X

q(zi )(k) log q(zi )(k)

q(zi )(k) = 1

k=1
n
X
i=1

∀i, k

0

(yi )

zi

=

∀i

n X
K
X

i=1 k=1

(k)

zi q(zi )(k) .

n X
K
X

i=1 k=1

+λ

"K
n
X
X
i=1

+

q(zi )(k) log q(zi )(k)

n
X

(k)
zi q(zi )(k)

k=1

βi

i=1

K
X

−

(y )
zi i

#

(q(zi )(k) − 1).

k=1

Taking the derivative with respect to q(zi )(k) gives
∂
(k)
L = −nK − log q(zi )(k) + λzi + βi .
(k)
∂q(zi )
Setting the gradient of the Lagrangian L to 0 and rearranging gives
(k)

q(zi )(k) = eλzi
Since

PK

k=1

+βi −nK

.

q(zi )(k) = 1 for all i, we must have
(k)

(k)

q(zi )

eλzi

= PK

j=1

(j)

eλzi

,

which recovers the temperature scaling model by setting
T = λ1 .
Figure S1 visualizes Claim 1. We see that, as training continues, the model begins to overfit with respect to NLL (red
line). This results in a low-entropy softmax distribution
over classes (blue line), which explains the model’s overconfidence. Temperature scaling not only lowers the NLL
but also raises the entropy of the distribution (green line).

S3. Additional Tables
Tables S1, S2, and S3 display the MCE, test error, and NLL
for all the experimental settings outlined in Section 5.

Supplementary Materials: On Calibration of Modern Neural Networks

Entropy vs. NLL on CIFAR−100
3.5

Entropy / NLL / T

3

Entropy & NLL after Calibration
Entropy before Calibration
NLL before Calibration
Optimal T Selected

2.5
2
1.5
1
0.5
0

100

200

300

400

500

Epoch
Figure S1. Entropy and NLL for CIFAR-100 before and after calibration. The optimal T selected by temperature scaling rises throughout
optimization, as the pre-calibration entropy decreases steadily. The post-calibration entropy and NLL on the validation set coincide
(which can be derived from the gradient optimality condition of T ).
Dataset

Model

Uncalibrated

Hist. Binning

Isotonic

BBQ

Temp. Scaling

Vector Scaling

Matrix Scaling

Birds
Cars
CIFAR-10
CIFAR-10
CIFAR-10
CIFAR-10
CIFAR-10
CIFAR-100
CIFAR-100
CIFAR-100
CIFAR-100
CIFAR-100
ImageNet
ImageNet
SVHN

ResNet 50
ResNet 50
ResNet 110
ResNet 110 (SD)
Wide ResNet 32
DenseNet 40
LeNet 5
ResNet 110
ResNet 110 (SD)
Wide ResNet 32
DenseNet 40
LeNet 5
DenseNet 161
ResNet 152
ResNet 152 (SD)

30.06%
41.55%
33.78%
34.52%
27.97%
22.44%
8.02%
35.5%
26.42%
33.11%
21.52%
10.25%
14.07%
12.2%
19.36%

25.35%
5.16%
26.87%
17.0%
12.19%
7.77%
16.49%
7.03%
9.12%
6.22%
9.36%
18.61%
13.14%
14.57%
11.16%

16.59%
15.23%
7.8%
16.45%
6.19%
19.54%
18.34%
10.36%
10.95%
14.87%
10.59%
3.64%
11.57%
8.74%
18.67%

11.72%
9.31%
72.64%
19.26%
9.22%
14.57%
82.35%
10.9%
9.12%
11.88%
8.67%
9.96%
10.96%
8.85%
9.09%

9.08%
20.23%
8.56%
15.45%
9.11%
4.58%
5.14%
4.74%
8.85%
5.33%
19.4%
5.22%
12.29%
12.29%
18.05%

9.81%
8.59%
27.39%
15.55%
4.43%
3.17%
19.39%
2.5%
8.85%
6.31%
8.82%
8.65%
9.61%
9.61%
30.78%

38.67%
29.65%
22.89%
10.74%
9.65%
4.36%
16.89%
45.62%
35.6%
44.73%
38.64%
18.77%
18.76%

20 News
Reuters
SST Binary
SST Fine Grained

DAN 3
DAN 3
TreeLSTM
TreeLSTM

17.03%
14.01%
21.66%
27.85%

10.47%
16.78%
3.22%
28.35%

9.13%
44.95%
13.91%
19.0%

6.28%
36.18%
36.43%
8.67%

8.21%
25.46%
6.03%
44.75%

8.24%
18.88%
6.03%
11.47%

17.43%
19.39%
6.03%
11.78%

Table S1. MCE (%) (with M = 15 bins) on standard vision and NLP datasets before calibration and with various calibration methods.
The number following a model’s name denotes the network depth. MCE seems very sensitive to the binning scheme and is less suited
for small test sets.

S4. Additional Reliability Diagrams
We include reliability diagrams for additional datasets:
CIFAR-10 (Figure S2) and SST (Figure S3 and Figure S4).
Note that, as mentioned in Section 2, the reliability dia-

grams do not represent the proportion of predictions that
belong to a given bin.

Supplementary Materials: On Calibration of Modern Neural Networks

Dataset

Model

Uncalibrated

Hist. Binning

Isotonic

BBQ

Temp. Scaling

Vector Scaling

Matrix Scaling

Birds
Cars
CIFAR-10
CIFAR-10
CIFAR-10
CIFAR-10
CIFAR-10
CIFAR-100
CIFAR-100
CIFAR-100
CIFAR-100
CIFAR-100
ImageNet
ImageNet
SVHN

ResNet 50
ResNet 50
ResNet 110
ResNet 110 (SD)
Wide ResNet 32
DenseNet 40
LeNet 5
ResNet 110
ResNet 110 (SD)
Wide ResNet 32
DenseNet 40
LeNet 5
DenseNet 161
ResNet 152
ResNet 152 (SD)

22.54%
14.28%
6.21%
5.64%
6.96%
5.91%
15.57%
27.83%
24.91%
28.0%
26.45%
44.92%
22.57%
22.31%
1.98%

55.02%
16.24%
6.45%
5.59%
7.3%
6.12%
15.63%
34.78%
33.78%
34.29%
34.78%
54.06%
48.32%
48.1%
2.06%

23.37%
14.9%
6.36%
5.62%
7.01%
5.96%
15.69%
28.41%
25.42%
28.61%
26.73%
45.77%
23.2%
22.94%
2.04%

37.76%
19.25%
6.25%
5.55%
7.35%
6.0%
15.64%
28.56%
25.17%
29.08%
26.4%
46.82%
47.58%
47.6%
2.04%

22.54%
14.28%
6.21%
5.64%
6.96%
5.91%
15.57%
27.83%
24.91%
28.0%
26.45%
44.92%
22.57%
22.31%
1.98%

22.99%
14.15%
6.37%
5.62%
7.1%
5.96%
15.53%
27.82%
24.99%
28.45%
26.25%
45.53%
22.54%
22.56%
2.0%

29.51%
17.98%
6.42%
5.69%
7.27%
6.0%
15.81%
38.77%
35.09%
37.4%
36.14%
52.44%
2.08%

20 News
Reuters
SST Binary
SST Fine Grained

DAN 3
DAN 3
TreeLSTM
TreeLSTM

20.06%
2.97%
11.81%
49.5%

25.12%
7.81%
12.08%
49.91%

20.29%
3.52%
11.75%
48.55%

20.81%
3.93%
11.26%
49.86%

20.06%
2.97%
11.81%
49.5%

19.89%
2.83%
11.81%
49.77%

22.0%
3.52%
11.81%
48.51%

Table S2. Test error (%) on standard vision and NLP datasets before calibration and with various calibration methods. The number
following a model’s name denotes the network depth. Error with temperature scaling is exactly the same as uncalibrated.

Dataset

Model

Uncalibrated

Hist. Binning

Isotonic

BBQ

Temp. Scaling

Vector Scaling

Matrix Scaling

Birds
Cars
CIFAR-10
CIFAR-10
CIFAR-10
CIFAR-10
CIFAR-10
CIFAR-100
CIFAR-100
CIFAR-100
CIFAR-100
CIFAR-100
ImageNet
ImageNet
SVHN

ResNet 50
ResNet 50
ResNet 110
ResNet 110 (SD)
Wide ResNet 32
DenseNet 40
LeNet 5
ResNet 110
ResNet 110 (SD)
Wide ResNet 32
DenseNet 40
LeNet 5
DenseNet 161
ResNet 152
ResNet 152 (SD)

0.9786
0.5488
0.3285
0.2959
0.3293
0.2228
0.4688
1.4978
1.1157
1.3434
1.0134
1.6639
0.9338
0.8961
0.0842

1.6226
0.7977
0.2532
0.2027
0.2778
0.212
0.529
1.4379
1.1985
1.4499
1.2156
2.2574
1.4716
1.4507
0.1137

1.4128
0.8793
0.2237
0.1867
0.2428
0.1969
0.4757
1.207
1.0317
1.2086
1.0615
1.8173
1.1912
1.1859
0.095

1.2539
0.6986
0.263
0.2159
0.2774
0.2087
0.4984
1.5466
1.1982
1.459
1.1572
1.9893
1.4272
1.3987
0.1062

0.8792
0.5311
0.2102
0.1718
0.2283
0.1750
0.459
1.0442
0.8613
1.0565
0.9026
1.6560
0.8885
0.8657
0.0821

0.9021
0.5299
0.2088
0.1709
0.2275
0.1757
0.4568
1.0485
0.8655
1.0648
0.9011
1.6648
0.8879
0.8742
0.0844

2.334
1.0206
0.2048
0.1766
0.2229
0.176
0.4607
2.5637
1.8182
2.5507
1.9639
2.1405
0.0924

20 News
Reuters
SST Binary
SST Fine Grained

DAN 3
DAN 3
TreeLSTM
TreeLSTM

0.7949
0.102
0.3367
1.1475

1.0499
0.2403
0.2842
1.1717

0.8968
0.1475
0.2908
1.1661

0.9519
0.1167
0.2778
1.149

0.7387
0.0994
0.2739
1.1168

0.7296
0.0990
0.2739
1.1085

0.9089
0.1491
0.2739
1.1112

Table S3. NLL (%) on standard vision and NLP datasets before calibration and with various calibration methods. The number following
a model’s name denotes the network depth. To summarize, NLL roughly follows the trends of ECE.

Supplementary Materials: On Calibration of Modern Neural Networks

1.0

Accuracy

0.8

Uncal. - CIFAR-10
ResNet-110 (SD)
Outputs
Gap

Temp. Scale - CIFAR-10
ResNet-110 (SD)
Outputs
Gap

Hist. Bin. - CIFAR-10
ResNet-110 (SD)
Outputs
Gap

Iso. Reg. - CIFAR-10
ResNet-110 (SD)
Outputs
Gap

0.6
0.4
0.2

ECE=4.12

0.0
0.0 0.2 0.4 0.6 0.8 1.0

ECE=0.60

ECE=0.67

0.0 0.2 0.4 0.6 0.8 1.0 0.0 0.2 0.4 0.6 0.8 1.0
Confidence

ECE=1.11
0.0 0.2 0.4 0.6 0.8 1.0

Figure S2. Reliability diagrams for CIFAR-10 before (far left) and after calibration (middle left, middle right, far right).

1.0

Accuracy

0.8

Uncal. - SST-FG
Tree LSTM
Outputs
Gap

Temp. Scale - SST-FG
Tree LSTM
Outputs
Gap

Hist. Bin. - SST-FG
Tree LSTM
Outputs
Gap

Iso. Reg. - SST-FG
Tree LSTM
Outputs
Gap

0.6
0.4
0.2

ECE=6.71

0.0
0.0 0.2 0.4 0.6 0.8 1.0

ECE=2.56

ECE=2.09

0.0 0.2 0.4 0.6 0.8 1.0 0.0 0.2 0.4 0.6 0.8 1.0
Confidence

ECE=1.65
0.0 0.2 0.4 0.6 0.8 1.0

Figure S3. Reliability diagrams for SST Binary and SST Fine Grained before (far left) and after calibration (middle left, middle right,
far right).

1.0

Accuracy

0.8

Uncal. - SST-BIN
Tree LSTM
Outputs
Gap

Temp. Scale - SST-BIN
Tree LSTM
Outputs
Gap

Hist. Bin. - SST-BIN
Tree LSTM
Outputs
Gap

Iso. Reg. - SST-BIN
Tree LSTM
Outputs
Gap

0.6
0.4
0.2

ECE=6.63

0.0
0.0 0.2 0.4 0.6 0.8 1.0

ECE=1.84

ECE=1.93

0.0 0.2 0.4 0.6 0.8 1.0 0.0 0.2 0.4 0.6 0.8 1.0
Confidence

ECE=1.65
0.0 0.2 0.4 0.6 0.8 1.0

Figure S4. Reliability diagrams for SST Binary and SST Fine Grained before (far left) and after calibration (middle left, middle right,
far right).

