Supp Materials: An Analytical Formula of Population Gradient for
two-layered ReLU network and its Applications in Convergence and
Critical Point Analysis
Yuandong Tian
Facebook AI Research
yuandong@fb.com
March 18, 2017

1

Introduction

No theorem is provided.

2

Related Works

No theorem is provided.

3

Problem Definition

No theorem is provided.

4

The Analytical Formula

Here we list all detailed proof for all the theorems.

e

(a)

(b)

w

w

e

✓

✓

O

O

✓

✓<0

0
Figure 1: (a)-(b) Two cases in Thm. 1.

1

4.1

One ReLU Case

Theorem 1 Suppose F (e, w) = X | D(e)D(w)Xw where e is a unit vector and X = [x1 , x2 , · · · , xN ]| is
N -by-d sample matrix. If xi ∼ N (0, I), then:
E [F (e, w)] =

N
((π − θ)w + kwk sin θe)
2π

(1)

where θ ∈ [0, π] is the angle between e and w.
Proof Note that F can be written in the following form:
X
F (e, w) =

xi x|i w

(2)

|
i:x|
i e≥0,xi w≥0

where xi are samples so that X = [x1 , x2 , · · · , xn ]| . We set up the axes related to e and w as in
Fig. 1, while the rest of the axis are prependicular to the plane. In this coordinate system, any vector
cos θ
(and any set
x = [r sin φ, r cos φ, x3 , . . . , xd ]. We have an orthonomal set of bases: e, e⊥ = − w/kwk−e
sin θ
of bases that span the rest of the space). Under the basis, the representation for e and w is [1, 0d−1 ] and
[kwk cos θ, −kwk sin θ, 0d−2 ]. Note that here θ ∈ (−π, π]. The angle θ is positive when e “chases after” w,
and is otherwise negative.
h P
i
Now we consider the quality R(φ0 ) = E N1 i:φi ∈[0,φ0 ] xi x|i . If we take the expectation and use polar
coordinate only in the first two dimensions, we have:


X
1
xi x|i  = E [xi x|i |φi ∈ [0, φ0 ]] P [φi ∈ [0, φ0 ]]
R(φ0 ) = E 
N
i:φi ∈[0,φ0 ]


Z +∞ Z Z +∞ Z φ0 r sin φ
d
Y
r cos φ 


 r sin φ r cos φ . . . xd p(r)p(θ)
=
p(xk )rdrdφdx3 . . . dxd
 ... 
0
−∞
0
k=3
xd
2

where p(r) = e−r /2 and p(θ) = 1/2π. Note that R(φ0 ) is a d-by-d matrix. The first 2-by-2 block can be
R +∞
computed in close form (note that 0 r2 p(r)rdr = 2). Any off-diagonal element except for the first 2-by-2
block is zero due to symmetric property of spherical Gaussian variables. Any diagonal element outside the
first 2-by-2 block will be P [φi ∈ [0, φ0 ]] = φ0 /2π. Finally, we have:




2φ0 − sin 2φ0
1 − cos 2φ0
0
X
1 
1
1 − cos 2φ0
2φ0 + sin 2φ0
0 
xi x|i  =
(3)
R(φ0 ) = E 
N
4π
0
0
2φ0 Id−2
i:φi ∈[0,φ0 ]


− sin 2φ0 1 − cos 2φ0 0
φ0
1 
1 − cos 2φ0
sin 2φ0
0
=
Id +
(4)
2π
4π
0
0
0
With this equation, we could then compute E [F (e, w)]. When θ ≥ 0, the condition {i : x|i e ≥ 0, x|i w ≥ 0}
is equivalent to {i : φi ∈ [θ, π]} (Fig. 1(a)). Using w = [kwk cos θ, −kwk sin θ, 0d−2 ] and we have:

=

=
=
For θ < 0, the condition
we get

E [F (e, w)] = N (R(π) − R(θ)) w
(5)




− sin 2θ 1 − cos 2θ 0
cos θ
N 
sin 2θ
0 − sin θ
2(π − θ)w − kwk 1 − cos 2θ
(6)
4π
0
0
0
0



N
sin θ
(π − θ)w + kwk
(7)
0
2π
N
((π − θ)w + kwk sin θe)
(8)
2π
{i : x|i e ≥ 0, x|i w ≥ 0} is equivalent to {i : φi ∈ [0, π + θ]} (Fig. 1(b)), and similarly

N
((π + θ)w − kwk sin θe)
2π
Notice that by abuse of notation, the θ appears in Eqn. 1 is the absolute value and Eqn. 1 follows.
E [F (e, w)] = N (R(π + θ) − R(0)) w =

2

(9)

5

Critical Point Analysis

Remember that we have: suppose F (e, w) = X | D(e)D(w)Xw where e is a unit vector and X = [x1 , x2 , · · · , xN ]|
is N -by-d sample matrix. If xi ∼ N (0, I), then:
E [F (e, w)] =

N
((π − θ)w + kwk sin θe)
2π

where θ ∈ [0, π] is the angle between e and w. And the expected gradient for g(x) =
respect to wj is the following:
K

 X


− E ∇wj J =
E F (ej , wj∗0 ) − E [F (ej , wj 0 )]

(10)
PK

j=1

σ(wj| x) with

(11)

j 0 =1



where ej = wj /kwj k. By solving Eqn. 64 (E ∇wj J = 0 j = 1, . . . , K), it is possible to identify all critical
points of g(x). In general Eqn. 64 is highly nonlinear and cannot be solved efficiently, however, we show that
in our particular case, it is possible since Eqn. 64 has interesting properties.
First of all, the system of equations


E ∇wj J = 0 , j = 1, . . . , K
(12)
or

K
X

E [F (ej , wj 0 ] =

j 0 =1

K
X



E F (ej , wj∗0

, j = 1, . . . , K

(13)

j 0 =1

is a linear combination of wj and wj∗ but with varying coefficients. We could rewrite the system as follows:
diagaE | + Bdiagw̄E | = diaga∗ E | + B ∗ W ∗ |

(14)

where E, W , W ∗ , a, B, a∗ and B ∗ are all K-by-K matrices:
a = sin Θ| w̄

,

a∗ = sin Θ∗ | w̄∗

(15)

B = π11| − Θ|

,

B ∗ = π11| − Θ∗ |

(16)

E = [e1 , e2 , . . . , eK ]

(17)
∗

W = [w1 , w2 , . . . , wK ] ,
0

W =

∗
[w1∗ , w2∗ , . . . , wK
]

(18)

0

where θj∗j ≡ ∠(wj , wj∗0 ) and θjj0 = θjj ≡ ∠(wj , wj 0 ), Θ = [θji ] (the element at i-th row, j-th column of Θ is
∗
k].
θji ) and Θ∗ = [θj∗i ], w̄ = [kw1 k, kw2 k, . . . , kwK k] and w̄∗ = [kw1∗ k, kw2∗ k, . . . , kwK
Eqn. 14 already has interesting properties. The first thing we consider is whether the critical point will
fall outside the Principle Hyperplane Π∗ , which is the plane spanned by the ground truth weight vectors W ∗ .
The following theorem shows that the critical points outside Π∗ must lie in a manifold:
Lemma 1 If {wj } is a critical point satisfying Eqn. 14, then for any orthogonal mapping R with R|Π∗ = Id,
{Rwj } is also a critical point.
Proof First of all, since R is an orthogonal transformation, it keeps all angles and magnitudes and a, a∗ ,
B, w̄ and w̄∗ are invariant. For simplicity we write Y = diaga + Bdiagw̄ − diaga∗ and Y is also invariant
under R. Since R|Π∗ = Id, we have RW ∗ = W ∗ and
|
∗
YR ER
− BR
W ∗ | = Y E | R| − B ∗ W ∗ | R| = (Y E | − B ∗ W ∗ | ) R| = 0

(19)

Note that for d ≥ K + 2, there always exists R 6= Id and satisfy such a condition, which yield continuous
critical points. Further, such a transformation forms a Lie group. Therefore we have:
Theorem 2 If d ≥ K +2, then any critical point satisfying Eqn. 14 and is outside Π∗ must lie in a manifold.
The intuition is simple. For any out-of-plane critical point, pick a matrix that satisfies the condition of the
theorem, and tranforms it to a different yet infinitely close critical points. Such a matrix always exists, since
for the d − K subspace, if it is odd, then we can always pick a rotation whose fixed axis is not aligned with
all K weights; if it is even, then there is a rotation matrix without a fixed point.
3

5.1

Characteristics within the Principle Plane

We could right-multiple E and turn the normal equation to a linear function with respect to the magnitude
of weights kwk. Note that we have:
E | E = cos Θ,

(W ∗ )| E = diagw̄∗ Θ∗

W | E = diagw̄ cos Θ,

(20)

Therefore, Eqn. 14 becomes:
diaga cos Θ + Bdiagw̄ cos Θ = diaga∗ cos Θ + B ∗ diagw̄∗ cos Θ∗

(21)

which is a homogenous linear equation with respect to the magnitude of the weights (note that a and a∗ is
linear to the magnitudes). In particular, the (i, j) entry of the LHS and RHS of this equality are:
!
K
K
X
X
i
k
LHSij = cos θj
sin θi kwk k +
(π − θik )kwk k cos θjk
(22)
k=1

RHSij

=

K
X

cos θji

k=1

!
sin θi∗k kwk∗ k

+

k=1

K
X

(π − θi∗k )kwk∗ k cos θj∗k

(23)

k=1

Therefore, the following equation holds:
M w̄ = M ∗ w̄∗

(24)

where M and M ∗ are K 2 -by-K matrices. Each entry mij,k that correponds to the coefficient of k-th weight
vector at (i, j) entry of Eqn. 14 is defined as:
mij,k
m∗ij,k

=
=

(π − θik ) cos θjk + sin θik cos θji
(π −

θi∗k ) cos θj∗k

+

sin θi∗k

cos θji

(25)
(26)

Special case on the diagonal. For diagonal element (i, i), cos θii = 1 and mii,k = h(θik ), m∗ii,k = h(θi∗k ),
where
h(θ) = (π − θ) cos θ + sin θ.
(27)
Therefore, with only diagonal element, we arrive at the following subset of the constraints to be satisfied for
any critical points:
Mr w̄ = Mr∗ w̄∗
(28)
where Mr = h(Θ| ) and Mr∗ = h(Θ∗ | ) are both K-by-K matrices. Note that if Mr is full-rank, then we could
solve w̄ from Eqn. 28 and plug it back in Eqn. 24 to check whether it is indeed a critical point.
Lemma 2 If w̄∗ 6= 0 (no trivial ground truth solutions), and for a given (Θ, Θ∗ ), there exists a row (e.g.
l-th row) of M and M ∗ , namely m|l and m∗l | , satisfying
m∗l − Mr∗ | Mr−1 ml > 0

or

m∗l − Mr∗ | Mr−1 ml < 0

(29)

Then (Θ, Θ∗ ) cannot be a critical point.
Proof Suppose given (Θ, Θ∗ ), we get Mr and Mr∗ and compute w̄ using Eqn. 28, then we have
(w̄∗ )| Mr∗ | Mr−1 ml = (Mr∗ w̄∗ )| Mr−1 ml = w̄| Mr| Mr−1 ml = w̄| ml

(30)

Therefore, from the condition m∗l − Mr∗ | Mr−1 ml > 0 and w̄∗ ≥ 0 but w̄∗ 6= 0, we have
(w̄∗ )| (m∗l − Mr∗ | Mr−1 ml ) = (w̄∗ )| m∗l − w̄| ml > 0

(31)

but this contradicts with the necessary condition for (Θ, Θ∗ ) to become a critical point (Eqn. 24). Similarly
we can prove the other side.
Separation property of Eqn. 29. Note that both the k-th element of m∗l and Mr∗ | Mr−1 ml in Eqn. 29
are only dependent on the k-th true weight vector wk∗ (and all {wj }).
4

• For m∗l , this can be seen by Eqn. 26, in which the k-th element is only related to the angles θ·∗k between
wk∗ and {wj }.
• For Mr∗ | Mr−1 ml , notice that the k-th column of Mr∗ (the k-th row of Mr∗ | ) is only related to wk∗ but
not other ground truth weight vectors. This separation property makes analysis much easier, as shown
in the case of K = 2.
Therefore, we could consider the following function regarding to one (rather than K) ground truth unit
weight vector e∗ and all estimated unit vectors {el }:
Lij (e∗ , {el }) = m∗ij − v∗ | Mr−1 mij

(32)

∗
where v∗ | = [h(θ1∗ ), h(θ2∗ ), . . . , h(θK
)], θj∗ = ∠(e∗ , wj ) and m∗ij = (π − θi∗ ) cos θj∗ + sin θi∗ cos θji (like Eqn. 26).

Proposition 1 Lij (e∗ , {el }) = 0 for any e∗ = el , 1 ≤ l ≤ K. In addition, Lii (e∗ , {el }) ≡ 0.
Proof When e∗ = el , then θk∗ = θkl and v∗ | becomes the l-th row of Mr . Since Mr Mr−1 = IK×K , v∗ | Mr−1
becomes a unit vector with only l-th element being 1. Therefore, again with θk∗ = θkl , we have:
Lij (e∗ , {el }) = m∗ij − mij,l = 0

(33)

For Lii , by definition mii is i-th column of Mr , so Mr−1 mii is a unit vector with only i-th element being 1.
Therefore
(v∗ )| Mr−1 mii = h(θi∗ ) = m∗ii
(34)

Then the previous lemma can be written as the following:
Theorem 3 If w̄∗ 6= 0, and for a given parameter w, Ljj 0 ({θl∗k }, Θ) > 0 or < 0 for all 1 ≤ k ≤ K, then w
cannot be a critical point.

5.2

ReLU network with two hidden nodes (K = 2)

For K = 2, we have 4-by-2 matrix (the row order is (1, 1), (1, 2), (2, 1), (2, 2)):


(π − θ11 ) cos θ11 + sin θ11 cos θ11 (π − θ12 ) cos θ12 + sin θ12 cos θ11
(π − θ11 ) cos θ21 + sin θ11 cos θ21 (π − θ12 ) cos θ22 + sin θ12 cos θ21 

M = 
(π − θ21 ) cos θ11 + sin θ21 cos θ12 (π − θ22 ) cos θ12 + sin θ22 cos θ12 
(π − θ21 ) cos θ21 + sin θ21 cos θ22 (π − θ22 ) cos θ22 + sin θ22 cos θ22


π
(π − θ) cos θ + sin θ

π cos θ
(π − θ) + sin θ cos θ

= 
(π − θ) + sin θ cos θ

π cos θ
(π − θ) cos θ + sin θ
π
since θ12 = θ21 = θ, θ11 = θ22 = 0. Similarly we could write

(π − θ1∗1 ) cos θ1∗1 + sin θ1∗1 cos θ11

(π − θ1∗1 ) cos θ2∗1 + sin θ1∗1 cos θ21
M∗ = 
(π − θ2∗1 ) cos θ1∗1 + sin θ2∗1 cos θ12
(π − θ2∗1 ) cos θ2∗1 + sin θ2∗1 cos θ22

(35)

(36)

M ∗:

(π − θ1∗2 ) cos θ1∗2 + sin θ1∗2 cos θ11
(π − θ1∗2 ) cos θ2∗2 + sin θ1∗2 cos θ21 

(π − θ2∗2 ) cos θ1∗2 + sin θ2∗2 cos θ12 
(π − θ2∗2 ) cos θ2∗2 + sin θ2∗2 cos θ22

(37)

In this case,
Mr =

 1

h(θ1 ) h(θ12 )
,
h(θ21 ) h(θ22 )

Mr∗ =

 ∗1

h(θ1 ) h(θ1∗2 )
h(θ2∗1 ) h(θ2∗2 )

(38)

Therefore, if we know θ12 = θ21 , θ1∗1 , θ1∗2 , θ2∗1 and θ2∗2 , then we could compute M and M ∗ and solve a linear
equation to get the magnitude of w1 and w2 , which collectly identify the critical points. Note that M is a
4-by-2 matrix, so critical point only happens if the matrix has singular structure.

5

Global Optimum. One special case is when θ12 = θ21 = θ1∗2 = θ2∗1 = π/2 and θ1∗1 = θ2∗2 = 0, in this case,
we have:


π
1
 0
π/2

M = M∗ = 
(39)
π/2
0 
1
π
and thus kwj k = kwj∗ k is the unique solution.
When K = 2, the following conjecture is empirically correct.
Conjecture 1 If e∗ is in the interior of Cone(e1 , e2 ), then L12 (θ1∗ , θ2∗ , θ21 ) > 0. If e∗ is in the exterior, then
L12 < 0. If e∗ is on the boundary then L12 = 0. Same for L21 .
Remark Note that L1j can be written as the following:
L1j (e∗ , {e1 , e2 })

= m∗1j − [h(θ1∗ ), h(θ2∗ )] Mr−1 m1j
|

[(π − θ1∗ )e∗ + sin θ1∗ e1 ] ej


(π − θ11 )e|1 + sin θ11 e|1
∗ ∗
∗ ∗
− [α(θ1 , θ2 , θ), β(θ1 , θ2 , θ)]
e
(π − θ12 )e|2 + sin θ12 e|1 j
=

(40)
(41)
(42)

Here we have
[α, β] = [α(θ1∗ , θ2∗ , θ), β(θ1∗ , θ2∗ , θ)] ≡ [h(θ1∗ ), h(θ2∗ )]Mr−1

(43)

We know that L11 = 0 by Proposition 1. Therefore
u1j




 α(θ1∗ , θ2∗ , θ21 )
≡ (π − θ1∗ )e∗ + sin θ1∗ e1 − (π − θ11 )e1 + sin θ11 e1 , (π − θ12 )e2 + sin θ12 e1
β(θ1∗ , θ2∗ , θ21 )


α(θ1∗ , θ2∗ , θ)
= (π − θ1∗ )e∗ + sin θ1∗ e1 − [πe1 , (π − θ)e2 + sin θe1 ]
β(θ1∗ , θ2∗ , θ)

(44)

is perpendicular to e1 . So if we compute the inner product between u12 and e⊥
1 (the unit vector that is in
Π∗ and is orthogonal to e1 ), we get
∗
∗
u|12 e⊥
1 = (π − θ1 ) sin θ1 − [(π − θ) sin θ] β

(45)

Since e2 = cos θe1 + sin θe⊥
1 so we have:
L12 (e∗ , {e1 , e2 }) = u|12 e2 = sin θ(u|12 e⊥
1)

(46)

Note that Eqn. 45 is a function with 2-variables θ and θ1∗ (θ2∗ is determined by θ and θ1∗ , depending on whether
e∗ is inside or outside Cone(e1 , e2 )). And we could verify it numerically.
Theorem 4 If Conjecture 1 is correct, then for 2 ReLU network, (w1 , w2 ) (w1 6= w2 ) is not a critical point,
if they both are in Cone(w1∗ , w2∗ ), or both out of it.
Proof If both w1∗ and w2∗ are inside Cone(w1 , w2 ), then from Conjecture 1, we have
L12 (θ1k∗ , θ2k∗ , θ21 ) > 0

(47)

for k = 1, 2. Since K = 2 we could simply apply Thm. ?? to say (w1 , w2 ) is not a critical point. Similary
we prove the case for both w1∗ and w2∗ outside Cone(w1 , w2 ).

6
6.1

Convergence Analysis
Single ReLU case

In this subsection, we mainly deal with the following dynamics:


N
N
kw∗ k
E [∇w J] = (w − w∗ ) +
θw∗ −
sin θw
2
2π
kwk
6

(48)

Theorem 5 In the region kw0 − w∗ k < kw∗ k, following the dynamics (Eqn. 48), the Lyapunov function
V (w) = 12 kw − w∗ k2 has V̇ < 0 and the system is asymptotically stable and thus wt → w∗ when t → +∞.
Proof Denote that Ω = {w : kw0 − w∗ k < kw∗ k}. Note that
V̇ = −(w − w∗ )| ∇w J = −y| M y

(49)

where y = [kw∗ k, kwk]| and M is the following 2-by-2 matrix:


1
sin 2θ + 2π − 2θ
−(2π − θ) cos θ − sin θ
M=
2π
2 −(2π − θ) cos θ − sin θ

(50)

In the following we will show that M is positive definite when θ ∈ (0, π/2]. It suffices to show that M11 > 0,
M22 > 0 and det(M ) > 0. The first two are trivial, while the last one is:
4det(M )

=
=
=
=

2

2π(sin 2θ + 2π − 2θ) − [(2π − θ) cos θ + sin θ]


2π(sin 2θ + 2π − 2θ) − (2π − θ)2 cos2 θ + (2π − θ) sin 2θ + sin2 θ
2

2

2

2

2

(4π − 1) sin θ − 4πθ + 4πθ cos θ − θ cos θ + θ sin 2θ

(52)
(53)

2

2

(51)

(4π − 4πθ − 1) sin θ + θ cos θ(2 sin θ − θ cos θ)

(54)

Note that 4π 2 − 4πθ − 1 = 4π(π − θ) − 1 > 0 for θ ∈ [0, π/2], and g(θ) = sin θ − θ cos θ ≥ 0 for θ ∈ [0, π/2]
since g(0) = 0 and g 0 (θ) ≥ 0 in this region. Therefore, when θ ∈ (0, π/2], M is positive definite.
√
When θ = 0, M (θ) = π[1, −1; −1, 1] and is semi-positive definite, with the null eigenvector being 22 [1, 1],
i.e., kwk = kw∗ k. However, along θ = 0, the only w that satisfies kwk = kw∗ k is w = w∗ . Therefore,
V̇ = −y| M y < 0 in Ω. Note that although this region could be expanded to the entire open half-space
H = {w : w| w∗ > 0}, it is not straightforward to prove the convergence in H, since the trajectory might go
outside H. On the other hand, Ω is the level set V < 21 kw∗ k2 so the trajectory starting within Ω remains
inside.

kw w⇤ k < kw⇤ k

(a)

(b)

Convergent region

O

Sample
region

w

r
O

⇤

✓

w⇤
Vd (1

Successful samples

✏)/2

Figure 2: (a) Sampling strategy to maximize the probability of convergence. (b) Relationship between
sampling range r and desired probability of success (1 − )/2.
Theorem 6 When K = 1, the dynamics in Eqn. 64 converges to w∗ with probability at least (1 − )/2, if
the initial value w0 is sampled uniformly from Br = {w : kwk ≤ r} with:
r
2π
r≤
kw∗ k
(55)
d+1
Proof Given a ball of radius r, we first compute the “gap” δ of sphere cap (Fig. 2(b)). First cos θ =

r
2kw∗ k ,

2

r
so δ = r cos θ = 2kw
∗ k . Then a sufficient condition for the probability argument to hold, is to ensure that
the volume Vshaded of the shaded area is greater than 1−
2 Vd (r), where Vd (r) is the volume of d-dimensional
ball of radius r. Since Vshaded ≥ 21 Vd (r) − δVd−1 , it suffices to have:

1
1−
Vd (r) − δVd−1 ≥
Vd (r)
2
2
7

(56)

which gives
 Vd
2 Vd−1

(57)

Vd (1)
kw∗ k
Vd−1 (1)

(58)

δ≤
Using δ =

r2
2kw∗ k

and Vd (r) = Vd (1)rd , we thus have:
r≤

where Vd (1) is the volume of the unit ball. Since the volume of d-dimensional unit ball is
Vd (1) =
where Γ(x) =

R∞
0

π d/2
Γ(d/2 + 1)

(59)

tx−1 e−t dt. So we have
√ Γ(d/2 + 1/2)
Vd (1)
= π
Vd−1 (1)
Γ(d/2 + 1)

(60)

From Gautschi’s Inequality
x1−s <

Γ(x + 1)
< (x + s)1−s
Γ(x + s)

x > 0, 0 < s < 1

(61)

with s = 1/2 and x = d/2 we have:


d+1
2

−1/2
<

Γ(d/2 + 1/2)
<
Γ(d/2 + 1)

 −1/2
d
2

(62)

Therefore, it suffices to have
r

2π
kw∗ k
(63)
d+1
Note that this upper bound is tight when δ → 0 and d → +∞, since all inequality involved asymptotically
becomes equal.
r≤

6.2

Multiple ReLU case

Explanation of Eqn. 18. We first write down the dynamics to be studied:
K

 X


− E ∇wj J =
E F (ej , wj∗0 ) − E [F (ej , wj 0 )]

(64)

j 0 =1

We first define f (wj , wj 0 , wj∗0 ) = F (wj /kwj k, wj∗0 ) − F (wj /kwj k, wj 0 ). Therefore, the dynamics can be
written as:

 X 

− E ∇wj J =
E f (wj , wj 0 , wj∗0 )
(65)
j0

Suppose we have a finite group P = {Pj } which is a subgroup of orthognoal group O(d). P1 is the identity
element. If w and w∗ have the following symmetry: wj = Pj w and wj∗ = Pj w∗ , then RHS of Eqn. 64 can
be simplified as follows:


−E ∇wj J
=

X 
 X
E [f (Pj w, Pj 0 w, Pj 0 w∗ )]
E f (wj , wj 0 , wj∗0 ) =
j0

j0

=

X

E [f (Pj w, Pj Pj 00 w, Pj Pj 00 w∗ )]

({Pj }K
j=1 is a group)

j 00

=

Pj

X

E [f (w, Pj 00 w, Pj 00 w∗ )]

(kP w1 k = kw1 k, ∠(P w1 , P w2 ) = ∠(w1 , w2 ))

j 00

=

−Pj E [∇w1 J]

(66)
8

which means that if all wj and wj∗ are symmetric under the action of cyclic group, so does their expected
gradient. Therefore, the trajectory {wt } keeps such cyclic structure. Instead of solving a system of K
equations, we only need to solve one:
− E [∇w J] =

K
X

E [f (w, Pj w, Pj w∗ )]

(67)

j=1

Theorem 7 For a bias-free two-layered ReLU network
X
g(x; w) =
σ(wj| x)

(68)

j

that takes spherical Gaussian inputs, if the teacher’s parameters {wj∗ } form a set of orthnomal bases, then:
(1) When the student parameters is initialized to be [x0 , y 0 , . . . , y 0 ] under the basis of w∗ , where (x0 , y 0 ) ∈
Ω = {x ∈ (0, 1], y ∈ [0, 1], x > y}, then the dynamics (Eqn. 64) converges to teacher’s parameters {wj∗ }
(or (x, y) = (1, 0));
√
√
1
( K − 1 − arccos(1/ K) + π).
(2) when x0 = y 0 ∈ (0, 1], then it converges to a saddle point x = y = πK
This theorem is quite complicated. We will start with a few lemmas and gradually come to the conclusion.
t
First, if w0 = [x, y, y, . . . , y] under the bases {wj∗ }K
j=1 , then from simple computation we know that w
also follows this pattern. Therefore, we only need to study the following 2D dynamics related to x and y:



  



2π
∇x J
1
θ
x−1
− E
= − [(π − φ)(x − 1 + (K − 1)y)]
+ ∗
+φ
∇y J
1
φ −φ
y
N
 
x
+ [(K − 1)(α sin φ∗ − sin φ) + α sin θ]
(69)
y
0

0

Here the symmetrical factor (α ≡ kwj∗0 k/kwj k, θ ≡ θj∗j , φ ≡ θjj , φ∗ ≡ θj∗j ) are defined as follows:
α = (x2 + (K − 1)y 2 )−1/2 ,

cos θ = αx,

cos φ∗ = αy,

cos φ = α2 (2xy + (K − 2)y 2 )

(70)

Now we start a sequence of lemmas.
Lemma 3 For φ∗ , θ and φ defined in Eqn. 70:
≡ (x2 + (K − 1)y 2 )−1/2

(71)

cos θ

≡ αx

(72)

∗

≡ αy

(73)

≡ α2 (2xy + (K − 2)y 2 )

(74)

α
cos φ

cos φ

we have the following relations in the triangular region Ω0 = {(x, y) : x ≥ 0, y ≥ 0, x ≥ y + 0 } (Fig. 1(c)):
(1) φ, φ∗ ∈ [0, π/2] and θ ∈ [0, θ0 ) where θ0 = arccos √1K .
p
(2) cos φ = 1 − α2 (x − y)2 and sin φ = α(x − y) 2 − α2 (x − y)2 .
(3) φ∗ ≥ φ (equality holds only when y = 0) and φ∗ > θ.
Proof Propositions
(1) and (2) are computed by direct calculations.
In particular, note that since cos θ =
p
√
αx = 1/ 1 + (K − 1)(y/x)2 and x > y ≥ 0, we have cos θ ∈ (1/ K, 1] and θ ∈ [0, θ0 ). For Preposition (3),
φ∗ = arccos αy > θ = arccos αx because x > y. Finally, for x > y > 0, we have
cos φ
α2 (2xy + (K − 2)y 2 )
=
= α(2x + (K − 2)y) > α(x + (K − 1)y) > 1
cos φ∗
αy

(75)

The final inequality is because K ≥ 2, x, y > 0 and thus (x+(K −1)y)2 > x2 +(K −1)2 y 2 > x2 +(K −1)y 2 =
α−2 . Therefore φ∗ > φ. If y = 0 then φ∗ = φ.
9

y
(0, 1)

x = y+✏

Saddle point

(x⇤ , x⇤ )

⌦✏
O

Teacher’s
parameters

(1, 0)

(✏, 0)

x

Figure 3: The region Ω considered in the analysis of Eqn. 69.
Lemma 4 For the dynamics defined in Eqn. 69, there exists 0 > 0 so that the trianglar region Ω0 =
{(x, y) : x ≥ 0, y ≥ 0, x ≥ y + 0 } (Fig. 3) is a convergent region. That is, the flow goes inwards for all three
edges and any trajectory starting in Ω0 stays.
Proof We discuss the three boundaries as follows:
Case 1: y = 0, 0 ≤ x ≤ 1, horizontal line. In this case, θ = 0, φ = π/2 and φ∗ = π/2. The y
component of the dynamics in this line is:
f1 ≡ −

π
2π
∇y J = − (x − 1) ≥ 0
N
2

(76)

So −∇y J points to the interior of Ω.
Case 2: x = 1, 0 ≤ y ≤ 1, vertical line. In this case, α ≤ 1 and the x component of the dynamics is:
f2 ≡ −

2π
∇x J
N

=
=

−(π − φ)(K − 1)y − θ + (K − 1)(α sin φ∗ − sin φ) + α sin θ
∗

−(K − 1) [(π − φ)y − (α sin φ − sin φ)] + (α sin θ − θ)

(77)
(78)

Note that since α ≤ 1, α sin θ ≤ sin θ ≤ θ, so the second term is non-positive. For the first term, we only
need to check whether (π − φ)y − (α sin φ∗ − sin φ) is nonnegative. Note that
(π − φ)y − (α sin φ∗ − sin φ)
p
p
= (π − φ)y + α(x − y) 2 − α2 (x − y)2 − α 1 − α2 y 2
h
i
h p
i
p
p
= y π − φ − α 2 − α2 (x − y)2 + α x 2 − α2 (x − y)2 − 1 − α2 y 2

(79)
(80)
(81)

p
p
√
In Ω we have (x − y)2 ≤ 1, combined with α ≤ 1, we have 1 ≤ 2 − α2 (x − y)2 ≤ 2 and 1 − α2 y 2 ≤ 1.
Since x = 1, the second term is nonnegative. For the first term, since α ≤ 1,
p
π √
π − φ − α 2 − α2 (x − y)2 ≥ π − − 2 > 0
(82)
2
So (π − φ)y − (α sin φ∗ − sin φ) ≥ 0 and −∇x J ≤ 0, pointing inwards.
Case 3: x = y + , 0 ≤ y ≤ 1, diagonal line. We compute the inner product between (−∇x J, −∇y J)
and (1, −1), the inward normal of Ω at the line. Using φ ≤ π2 sin φ for φ ∈ [0, π/2] and φ∗ − θ = arccos αy −
arccos αx ≥ 0 when x ≥ y, we have:

|  
2π ∇x J
1
f3 (y, ) ≡ −
= φ∗ − θ − φ + [(K − 1)(α sin φ∗ − sin φ) + α sin θ] 
(83)
−1
N ∇y J




π
≥ (K − 1) α sin φ∗ − 1 +
sin φ
2(K − 1)
p

p

π
= α(K − 1)
1 − α2 y 2 −  1 +
2 − α 2 2
2(K − 1)
Note that for y > 0:
αy = p

1
(x/y)2

1
1
=p
≤√
2
K
+ (K − 1)
(1 + /y) + (K − 1)
10

(84)

p
p
p
√
√
For y = 0, αy = 0 < 1/K. So wephave 1 − α2 y 2 ≥ 1 − 1/K. And 2 − α2 2 ≤ 2. Therefore
√
f3 ≥ α(K − 1)(C1 − C2 ) with C1 ≡ 1 − 1/K > 0 and C2 ≡ 2(1 + π/2(K − 1)) > 0. With  = 0 > 0
sufficiently small, f3 > 0.
Lemma 5 (Reparametrization) Denote  = x − y > 0. The terms αx, αy and α involved in the trigometric functions in Eqn. 69 has the following parameterization:


 
β − β2
y
1
β + (K − 1)β2 
(85)
α x =
K
Kβ2

p
p
where β√2 = (K − β 2 )/(K − 1). The reverse transformation is given by β = K − (K − 1)α2 2 . Here
β ∈ [1, K) and β2 ∈ (0, 1]. In particular, the critical point (x, y) = (1, 0) corresponds to (β, ) = (1, 1). As
a result, all trigometric functions in Eqn. 69 only depend on the single variable β. In particular, the following
relationship is useful:
√
(86)
β = cos θ + K − 1 sin θ
Proof This transformation can be checked by simple algebraic manipulation. For example:
!
r

1
1
K
1 p
2−
2− =y
(β − β2 ) =
−
(K
−
1)
=
(Ky
+
)
αK
K
α2
K

(87)

To prove Eqn. 86, first we notice that K cos θ = Kαx = β + (K − 1)β2 . Therefore, we have (K cos θ − β)2 −
(K − 1)2 β22 = 0, which gives β 2 − 2β cos θ + 1 − K sin2 θ = 0. Solving this quadratic equation and notice that
β ≥ 1, θ ∈ [0, π/2] and we get:
p
√
β = cos θ + cos2 θ + K sin2 θ − 1 = cos θ + K − 1 sin θ
(88)

Lemma 6 After reparametrization (Eqn. 85), f3 (β, ) ≥ 0 for  ∈ (0, β2 /β]. Furthermore, the equality is
true only if (β, ) = (1, 1) or (y, ) = (0, 1).
Proof Applying the parametrization (Eqn. 85) to Eqn. 83 and notice that α = β2 = β2 (β), we could write
f3 = h1 (β) − (φ + (K − 1) sin φ)

(89)

When β is fixed, f3 now is a monotonously decreasing function with respect to  > 0. Therefore, f3 (β, ) ≥
f3 (β, 0 ) for 0 <  ≤ 0 ≡ β2 /β. If we could prove f3 (β, 0 ) ≥ 0 and only attain zero at known critical point
(β, ) = (1, 1), the proof is complete.
Denote f3 (β, 0 ) = f31 + f32 where
f31 (β, 0 )
0

f32 (β,  )

= φ∗ − θ − 0 φ + 0 α sin θ
=

(K − 1)(α sin φ∗ − sin φ)0

(90)
(91)

For f32 it suffices to prove that 0 (α sin φ∗ − sin φ) = β2 sin φ∗ − ββ2 sin φ ≥ 0, which is equivalent to sin φ∗ −
sin φ/β ≥ 0. But this is trivially true since φ∗ ≥ φ and β ≥ 1. Therefore, f32 ≥ 0. Note that the equality
only holds when φ∗ = φ and β = 1, which corresponds to the horizontal line x ∈ (0, 1], y = 0.
For f31 , since φ∗ ≥ φ, φ∗ > θ and 0 ∈ (0, 1], we have the following:


θ
f31 = 0 (φ∗ − φ) + (1 − 0 )(φ∗ − θ) − 0 θ + β2 sin θ ≥ −0 θ + β2 sin θ ≥ β2 sin θ −
(92)
β
And it reduces to showing whether β sin θ − θ is nonnegative. Using Eqn. 86, we have:
f33 (θ) = β sin θ − θ =

√
1
sin 2θ + K − 1 sin2 θ − θ
2

(93)

√
√
0
Note that f33
= cos 2θ + K − 1 sin 2θ − 1 = K cos(2θ − θ0 ) − 1, where θ0 = arccos √1K . By Prepositions
0
1 in Lemma 3, θ ∈ [0, θ0 ). Therefore, f33
≥ 0 and since f33 (0) = 0, f33 ≥ 0. Again the equity holds when
θ = 0, φ∗ = φ and 0 = 1, which is the critical point (β, ) = (1, 1) or (y, ) = (0, 1).
11

Lemma 7 For the dynamics defined in Eqn. 69, the only critical point (∇x J = 0 and ∇y J = 0) within Ω
is (y, ) = (0, 1).
Proof We prove by contradiction. Suppose (β, ) is a critical point other than w∗ . A necessary condition
for this to hold is f3 = 0 (Eqn. 83). By Lemma 7,  > 0 = β2 /β > 0 and
 − 1 + Ky =

β−α
β − β2 /
β − β2 /0
1
(β2 − α + β − β2 ) =
=
>
=0
α
α
α
α

(94)

So  − 1 + Ky is strictly greater than zero. On the other hand, the condition f3 = 0 implies that
1
((K − 1)(α sin φ∗ − sin φ) + α sin θ) = − (φ∗ − θ) + φ


(95)

Using φ ∈ [0, π/2], φ∗ ≥ φ and φ∗ > θ, we have:
−

2π
∇y J
N

= −(π − φ)( − 1 + Ky) − (φ∗ − φ) − φy + ((K − 1)(α sin φ∗ − sin φ) + α sin θ) y
1
= −(π − φ)( − 1 + Ky) − (φ∗ − φ) − (φ∗ − θ)y < 0


(96)

So the current point (β, ) cannot be a critical point.
Lemma 8 Any trajectory in Ω0 converges to (y, ) = (1, 0), following the dynamics defined in Eqn. 69.
|

Proof We have Lyaponov function V = E [E] so that V̇ = −E [∇w J | ∇w J] ≤ −E [∇w J] E [∇w J] ≤ 0. By
Lemma 7, other than the optimal solution w∗ , there is no other symmetric critical point, ∇w J 6= 0 and thus
V̇ < 0. On the other hand, by Lemma 4, the triangular region Ω0 is convergent, in which the 2D dynamics
is C ∞ differentiable. Therefore, any 2D solution curve ξ(t) will stay within. By PoincareBendixson theorem,
when there is a unique critical point, the curve either converges to a limit circle or the critical point. However,
limit cycle is not possible since V is strictly monotonous decreasing along the curve. Therefore, ξ(t) will
converge to the unique critical point, which is (y, ) = (1, 0) and so does the symmetric system (Eqn. 64).
Lemma 9 When x = y ∈ (0, 1], the 2D dynamics (Eqn. 69) reduces to the following 1D case:
−
where x∗ =

√

1
πK (

2π
∇x J = −πK(x − x∗ )
N

(97)

√
K − 1 − arccos(1/ K) + π). Furthermore, x∗ is a convergent critical point.

Proof The 1D system can√be computed with simple algebraic manipulations (note that when x = y, φ = 0
and θ = φ∗ = arccos(1/ K)). Note that the 1D system is linear and its close form solution is xt =
x0 + Ce−K/2N t and thus convergent.
Combining Lemma 8 and Lemma 9 yields Thm. 7.

7

Simulations

No theorems is provided.

8

Extension to multilayer ReLU network

Proposition 2 For neural network with ReLU nonlinearity and using l2 loss to match with a teacher network
of the same size, the gradient inflow gj for node j at layer c has the following form:
X
gj = Qj
(Qj 0 uj 0 − Q∗j 0 u∗j 0 )
(98)
j0

P
where Qj and Q∗j are N -by-N diagonal matrices. For any k ∈ [c + 1], Qk = j∈[c] wjk Dj Qj and similarly
for Q∗k . The gradient with respect to wj (the parameters immediately under node j), is computed as:
∇wj J = XcT Dj| gj
12

(99)

Proof We prove by induction on layer. For the first layer, there is only one node with g = u − v, therefore
Qj = Qj 0 = I. Suppose the condition holds for all node j ∈ [c]. Then for node k ∈ [c + 1], we have:


X
X
X
X
Qj 0 uj 0 −
gk =
wjk Dj gj =
wjk Dj Qj 
Q∗j 0 u∗j 0 
j

=

j0

j

=

X

wjk Dj Qj

j0

j0

k0

Qj 0 Dj 0

X
k0

wjk0 uk0 −

X

k0

wjk Dj Qj

X
j0

j

Q∗j 0 Dj∗0

X

∗
∗
wjk
0 uk 0

k0







X
X X
X
X X
∗  ∗


uk0
Qj 0 Dj 0 wjk0  uk0 −
wjk Dj Qj  
Q∗j 0 Dj∗0 wjk
wjk Dj Qj  
0
k0

Setting Qk =

X
j0

j

=

j0

j



X
X
X
X
X
∗ 
∗
wjk Dj Qj 
Qj 0
Dj 0 wjk0 uk0 −
Dj∗0 wjk
Q∗j 0
0 uk 0

P

j0

j

j

wjk Dj Qj and Q∗k =
gk =

X

P

k0

j

j

j0

∗
wjk
Dj∗ Q∗j (both are diagonal matrices), we thus have:

Qk Qk0 uk0 − Qk Q∗k0 u∗k0 = Qk

k0

X
k0

13

Qk0 uk0 − Q∗k0 u∗k0

(100)

