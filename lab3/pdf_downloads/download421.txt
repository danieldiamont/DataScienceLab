Tight Bounds for Approximate Caratheodory and Beyond

Tight Bounds for Approximate Carathéodory and Beyond:
Supplementary Material
A. Overview of Convex Analysis
We give a brief overview on the theory of convex functions. For a detailed exposition we refer readers to (Nesterov, 2004).
Subgradients. A function f : Q ✓ Rd ! R defined on a convex domain Q is said to be convex if every point x 2 Q
has a non-empty subgradient @f (x) = {g 2 Rd ; f (y) f (x) + g > (y x), 8y 2 Q}. Geometrically, this means that a
function is convex iff it is the maximum of all its supporting hyperplanes, i.e. f (x) = maxx0 ,g2@f (x0 ) f (x0 ) + g > (x x0 ).
When there is a unique element in @f (x) we call it the gradient and denote it by rf (x). We will sometimes abuse notation
and refer to rf (x) as an arbitrary element of @f (x) even when it is not unique.
Strong convexity and smoothness. We say that a function f : Q ✓ Rd ! R is µ-strongly convex with respect to norm
k·k if for all x, y 2 Q and all subgradients g 2 @f (x):
f (y)

g > (y

f (x)

x)

1
µ ky
2

2

xk

A function is said to be -smooth with respect to the k·k if for all x, y 2 Q and g 2 @f (x):
f (y)

g > (y

f (x)

x) 

1
ky
2

2

xk

Bregman divergence and the Hessian. Every continuously differentiable f induces a concept of ‘distance’ known as the
Bregman-divergence: given x, y 2 Q, we define Df (ykx) := f (y) f (x) rf (x)> (y x) as the second order error
when computing f (y) using the linear approximation of f around x. The fact that f is convex guarantees Df (ykx) 0.
If the subgradient of f is unique everywhere, we can define µ-strong convexity and -smoothness with respect to the
2
2
Bregman divergence, as Df (ykx) 12 kx yk and Df (ykx)  12 µ kx yk . If f is also twice-differentiable, a simple
way to compute its strong convexity and smoothness parameters is by bounding the k·k-eigenvalues of the Hessian. If
2
2
µ · kwk  w> r2 f (x)w  · kwk for all x 2 Q and w 6= 0, then f is µ-strongly convex and -smooth. This is because:
Df (ykx) =
=

Z

0

1Z

Z

1

[rf (x + (y

0
s

x)t)

x)> r2 f (x + (y

(y
0

rf (x)]> (y
x)s)(y

x)dt

x)dsdt

Lipschitz constant. We say that a convex function is ⇢-Lipschitz with respect to norm k·k if krf (x)k⇤  ⇢. Note that
⇢-Lipschitz continuity requires a bound on the dual norm, since
|f (y)

f (x)| =



Z

Z
Z

1
0
1

0

rf (x + t(y

x))> (y

x)dt

rf (x + t(y

x))> (y

x) dt

1
0

krf (x + t(y

 ⇢ · ky

xk

x))k⇤ · ky

xk dt

Tight Bounds for Approximate Caratheodory and Beyond

Fenchel duality. It is useful to write a convex function as the maximum of its supporting hyperplanes. One way to do that
is using the Fenchel transform. When defining Fenchel transforms, it is convenient to identify a function f : Q ! R to its
extension f˜ : Rd ! R [ {1} such that f˜(x) = f (x) for x 2 Q and f˜(x) = 1 otherwise. Given that identification, we can
define the Fenchel transform of a function f as the function f ⇤ : Rd ! R [ {1} given by f ⇤ (z) = supx2Rd z > x f (x). If
f is convex, the Fenchel transformation is self-invertible, i.e., (f ⇤ )⇤ = f or equivalently: f (x) = maxz z > x f ⇤ (z). Notice
that the previous expression is a way to write any convex function as a maximum over linear functions in x parametrized by
z. The Fenchel inequality f (x) + f ⇤ (z) z > x follows directly from the definition of the Fenchel transform.
Envelope Theorem. When writing a convex function f = maxi fi as a maximum of other convex function (typically linear
functions), the Envelope Theorem gives a way to compute derivatives. Its statement is quite intuitive: since gradients are
local objects, the gradient of f at a certain point is the gradient of the function fi being maximized at that point. Formally, if
f (x) = maxz g(x, z) where g(x, z) is convex in x for every fixed z, then if f (x0 ) = g(x0 , z0 ), then @x g(x0 , z0 ) ✓ @f (x0 ).
A direct application of this theorem is in computing the gradients of the Fenchel dual: rf ⇤ (z) = arg minx {z > x f (x)}
and f ⇤ (z) = z > rf ⇤ (z) f (rf ⇤ (z)).
Smoothness and strong convexity duality. Finally, we will use the following duality theorem:
Theorem A.1. The function f : Q ! R is a (1/ )-strongly convex function with respect to k·k if and only if its Fenchel
dual f ⇤ : Rd ! R is a -smooth with respect to k·k⇤ .
Proof. Here we prove that -strong convexity of a function implies (1/ )-smoothness of its dual, since this is the direction
we will use. We refer to (Kakade et al., 2012; Shalev-Shwartz, 2007) for a proof of the converse.
Fix z1 , z2 2 Rd and let yi 2 @f ⇤ (zi ) = arg maxy2Q zi> y f (y). Since f is strongly convex, there in an unique
maximum, so we can write yi = rf ⇤ (zi ). Also, f ⇤ (zi ) = zi> yi f (yi ). Since the Fenchel transform is self-dual,
f (yi ) = maxz yi> z f ⇤ (z) = zi> yi f ⇤ (zi ). In particular, this means that zi 2 @f (yi ).
Using the strong-convexity of f , we can write:

1
ky1
2

y2 k

2

1
ky1
2
Summing the expressions above and applying Holder’s inequality, we get:

y2 k

2

f (y2 )
f (y1 )

1

f (y1 )
f (y2 )

2

ky1

z1> (y2
z2> (y1

z1 )> (y2

y2 k  (z2

y1 )
y2 )

y1 )  kz1

⇤

z2 k · ky1

y2 k

Therefore:
· kz1

which implies the smoothness bound:

z2 k⇤

ky1

Df ⇤ (z2 kz1 )
Z 1
=
[rf ⇤ (z1 + t(z2
0



1
kz1
2

y2 k = krf ⇤ (z1 )

z1 ))

rf ⇤ (z2 )k

rf ⇤ (z1 )]> (z2

z1 )dt

2

z2 k ⇤

B. A primer on Mirror Descent
For the sake of completeness, we will present here an elementary exposition of the Mirror Descent Framework, which is
used in our proof. For a complete exposition we refer to Nemirovskii (Ben-Tal & Nemirovski, 2001) or Bubeck (Bubeck,
2014).

Tight Bounds for Approximate Caratheodory and Beyond

The goal of Mirror Descent is to minimize a convex function f : Q ✓ Rd ! R with Lipschitz constant ⇢ with respect to
norm k·k. To motivate Mirror Descent, it is useful to think of dot products y > x as a product of vectors in two different
vector spaces, which can be thought as vectors vs linear forms or column vectors vs row vectors. In the spirit of Hölder’s
inequality, we can think of x as living in the Rd space equipped with k·k norm while y lives in Rd equipped with the dual
norm k·k⇤ . When we approximate f (y) f (x) ⇡ rf (x)> (y x), the second term is a dot-product of a vector in the
domain y x, which we call the primal space and measure using k·k norm and a gradient vector, which we call the dual
space and measure with dual norm k·k⇤ .

Keeping the discussion in the previous paragraph in mind, we can revisit the most intuitive method to minimize convex
functions: gradient descent. The gradient descent method consists in following the directions of steepest descent, which is
the direction opposite to the gradient. This leads to an iteration of the type: yt+1 = yt ⌘ · rf (yt ). In the view of primal
space and dual space, this iteration suddenly looks strange, because one is summing a primal vector yt with a dual vector
rf (yt ) which live in different spaces. In some sense, the gradient descent for Lipschitz convex functions only makes sense
in the `2 norm, in which k·k = k·k⇤ (see the subgradient descent method in (Nesterov, 2004)).

This motivated the idea of a map M : Rd ! Q connecting the primal and the dual space. The idea in the mirror descent
algorithm is to keep two vectors (yt , zt ) one in the primal space and one in the dual space. In each iteration we compute
rf (yt ), obtaining a dual vector and update:
zt+1 = zt

⌘rf (yt )

yt+1 = M (zt+1 )

It is convenient in the analysis to think of this map as the gradient of a convex function M = r! ⇤ . In the usual setup, we
define the mirror map, which is a convex function ! : Q ! R, 1 -strongly convex with respect to k·k. Let ! ⇤ : Rd ! R
be the Fenchel-dual ! ⇤ (z) = supy2Q z > y !(y) which is a -smooth convex function with respect to k·k⇤ by Theorem
A.1.
Notice that ! ⇤ is defined as a maximum over linear functions of z indexed by y. The result known as the envelope theorem
states that r! ⇤ (z0 ) is the gradient of the linear function maximized at z0 . Therefore: r! ⇤ (z0 ) = y 2 arg maxy {z0> y
!(y)}. This in particular implies that r! ⇤ (z) 2 Q since !(y) = 1 for y 2
/ Q.
Using the definition of ! and ! ⇤ we can define the Mirror Descent iteration as:
zt+1 = zt

⌘rf (yt )

yt+1 = r! ⇤ (zt+1 )

Now, we are ready to prove Theorem 2.1. We restate it:
Theorem B.1 (Restatement of Theorem 2.1).P
In the setup described above with D = maxz2Q D! (zkz0 ), ⌘ = ✏/ ⇢2 then
in T 2D ⇢2 /✏2 iterations, it holds that T1 t rf (yt )> (yt y)  ✏, 8y 2 Q.
Proof. The idea of the proof is to bound the growth of ! ⇤ (zt ) using smoothness property of ! ⇤ :
! ⇤ (zt )  ! ⇤ (z0 ) +
= ! ⇤ (0)

T
X1
t=0

T
X1
t=0

r! ⇤ (zt )> (zt+1

⌘ryt> rf (yt ) +

zt ) +

2

kzt+1

2

z t k⇤

2

2

⌘ 2 krf (yt )k⇤

P
>
By the Fenchel inequality ! ⇤ (zt ) zt> y !(y) = (z0
!(y ⇤ ) for all y 2 Q. Combining with the
t ⌘rf (yt )) y
previous inequality and re-arranging the terms, we get:
X
⌘
rf (yt )> (yt y)  !(y) + ! ⇤ (z0 ) r!(y0 )> y + ⌘ 2 ⇢2 T
2
t
The gradient of ! ⇤ (z0 ) = supy z0> y !(y) corresponds by the envelope theorem to y maximizing z0> y !(y). Therefore,
since y0 = r! ⇤ (z0 ), ! ⇤ (z0 ) = z0> y0 !(y0 ). Substituting ! ⇤ (z0 ) in the above expression and using the definition of
Bregman divergence, we get:
X
⌘
rf (yt )> (yt y)  D! (yky0 ) + ⌘ 2 ⇢2 T
2
t

Tight Bounds for Approximate Caratheodory and Beyond

Rearranging the terms and using that D! (yky0 )  D, we obtain:
1X
rf (yt )> (yt
T t
So for T

2 D⇢2 1
✏2 , T

P

t

rf (yt )> (yt

D
⌘⇢2
y) 
+
=
⌘T
2

r

s

2D ⇢2
for ⌘ =
T

2D
T ⇢2

y)  ✏.

Corollary B.2. In the conditions of the previous theorem, for ȳt =

1
T

PT

yt , f (ȳt )

t=1

f ⇤  ✏, where f ⇤ = miny2Q f (y)

Proof. Let y ⇤ = arg miny2Q f (y). Applying the previous theorem with y = y ⇤ we get:
f (y ⇤ ) 

f (ȳt )

1X
f (yt )
T t

f (y ⇤ ) 

1X
rf (yt )> (yt
T t

y⇤ )  ✏

where both inequalities follow from convexity of f .

C. Mirror Map
Proposition C.1. For 1 < q  2, the function ! : B q (1) ! R, !(y) =
the `q norm and maxy2B q (1) D! (yk0) = 12 .

1
2

2

kykq is (q

1)-strongly convex with respect to

While a similar statement is shown to hold in (Shalev-Shwartz, 2007), we provide a proof here for completeness.
Proof. We want to bound !(y) !(x) g > (y x) for all g 2 @!(x). For all x in the interior of the ball B q (1) there is a
unique subgradient which we represent by r!(x). In the border of B q (1), however, there are multiple subgradients. First
we claim that we need only to bound !(y) !(x) r!(x)> (y x) where r!(x) denotes the gradient of the function
2
1
2 kykq . In order to see that, notice that if g is a subgradient in a point x and y 2 B q (1) then:
!(x + t(y

x))

!(x)

g > (y

x)

0

by the definition of subgradient. Dividing the expression by t and taking the limit when t ! 0+, we get: r!(x)> (y
g > (y x), so in particular: !(y) !(x) g > (y x) !(y) !(x) r!(x)> (y x).

x)

This observation allows us to bound the strong convexity parameter of ! by looking at the k·kq -eigenvalues of the Hessian
2
of !. In particular, we will show that for all w 2 Rd , w> r2 !(y)w (q 1) kwkq .
p

To make the notation simpler, we define P OW : Rd ⇥ R ! Rd as P OW(y, p) = (|yi | · sgn(yi ))i . This allows us to represent
r kykq in a succinct form: since
@i kykq =
1 q

so we can write r kykq = kykq

1
q 1
(kykq ) q
q

· P OW(y, q

r!(y) = r



1 q
xi q

1 q

· sgn(xi ) = kykq

xqi

1

sgn(yi )

1). Therefore:

1
2
2
kykq = kykq · r kykq = kykq
2

q

· P OW(y, q

1)

Now, to compute the Hessian, we have:
r2 !(y) = (2

2 2q

q) kykq

· P OW(y, q

1)P OW(y, q

1)> + (q

2 q

1) kykq

D IAG(|yi |

q 2

)

Tight Bounds for Approximate Caratheodory and Beyond

where D IAG(|yi |

q 2

) is the diagonal matrix with xqi
2

w> r2 !(y)w = (2

q) · kykq

(q

1)

X
i

2

1) 4

= (q

i

in the diagonal. Using the fact that 1 < q  2, we can write:
X q 2
q
2 q
[P OW(y, q 1)> w]2 + (q 1) · kykq
|y|i wi2
i

q

|y|i

X

2

!2qq

|yi |

X

·

i

q(2 q)
·22q
2

q 2

|y|i

!22q

wi2

!

X

·

i

(|yi |

q(q 2)
2

2

wiq ) q

! q2 3 q2
5

The last equality is a convoluted re-writing of the previous expression, but allows us to apply Hölder’s inequality. Recall that
Hölder’s inequality states that kz1 ka · kz2 kb z1> z2 whenever a1 + 1b = 1. Applying this inequality with a = 2 2 q and
b = 2q , we get:
>

2

w r !(y)w

(q

1) ·

X
i

|yi |

q(2 q)
2

· |yi |

q(q 2)
2

wiq

! q2

= (q

1) ·

X

wiq

i

! q2

= (q

2

1) · kwkq

Finally, we need to show how to compute the Fenchel dual ! ⇤ and the mirror map r! ⇤ efficiently:

Proposition C.2. The Fenchel dual of the function ! defined in Proposition C.1 can be computed explicitly:
(
2
1
kzkp
if kzkp  1
⇤
! (z) = 2
kzkp 12 if kzkp > 1
Also, r! ⇤ (z) = (z) · min(1, kzkp ) where (z) is a vector with `q -norm 1 such that z > (z) = kzkp . This function can be
p 1
p 1
explicitly computed as: (z)i = sgn(zi ) · |zi |
/ kzkp .
Proof. By the definition of Fenchel duality:
⇤

1
2
kykq = max
0 1
2

>

! (z) = max z y
y2B q (1)

"

max

ŷ;kŷkq =1

>

z ŷ

1
2

2

#

= max

0 1

kzkp

1
2

2

where the second equality follows from writting y = ŷ for 0   1 and kŷkp = 1. The optimal value of ŷ is (z). The
expression kzkp 12 2 is maximized at = kzkp . Since is restricted to lie between 0 and 1, the optimal must be
min(1, kzkp ).
If kzkp  1,

= kzkp and ! ⇤ (z) =

1
2

2

kzkp . If kzkp > 1, then

By the envelope theorem, r! ⇤ (z) = ŷ ·

= 1 and ! ⇤ (z) = kzkp

1
2.

= (z) · min(1, kzkp ). Now, it simple to check that
X
X
q
q(p 1)
q(p 1)
p
p
k (z)kq =
|zi |
/ kzkp
=
|zi | / kzkp = 1
i

z > (z) =

has the desired properties:

i

X
i

p 1

zip / kzkp

= kzkp

Combining the previous results, we obtain:
Theorem C.3. Given n points v1 , . . . , vn 2 B p (1) ✓ Rd with p 2 and u 2 conv{v1 , . . . , vn }, there is a deterministic
algorithm of running time O(nd · p/✏2 ) that a outputs a multiset vi(1) , . . . , vi(k) for k = 4(p 1)/✏2 such that u0 =
Pk
1
0
ukp  ✏.
t=1 vi(t) and ku
k

Tight Bounds for Approximate Caratheodory and Beyond

Proof. The number of iterations of Mirror Descent (and consequently the sparsity bound) T = 4p/✏2 can be obtained by
substituting D = 1/2 and 1 = (q 1) 1 = p 1 from Proposition C.1 in Theorem 3.2.
For the running time, notice that the time per iteration is dominated by the computation of the subgradient of f . The most
expensive step is the computation of V > y which takes dn operations, which is the size of matrix V .

D. Missing Proofs from Section 3.1
Proof of Theorem 3.5. Let ApproxCara(u) represent the convex combination x of vertices of P returned by the algorithm
from Theorem C.3, when receiving as input the vertices of P and the point u, and solving for precision r/2. Then let
e0 = u, xi = ApproxCara(ei 1 ), ei = 2(ei 1 V xi ), for i 2 {1, . . . , } where = log(r/✏). Note that kei kp =
P
r
1
2ke
⇣Pi 1 V xi kp⌘  2 · 2  r, hence ei 2 P , so the input to ApproxCara is always well defined. Let x = i=1 2i 1 · xi 2
(i 1)
= 22 1 11 · = 2(1 ✏/r) .
i=1 2
Let us bound the error when approximating u with V x:
kV x

X 1
· xi
2i 1
i=1

ukp = V

X 1
=
V xi
2i 1
i=2
=

1
2

1

X
i=

!

1
e1
2

1
V xi
2i

u

X 1
· V xi
2i 1
i=1

=
p

p

1 X 1
=
V xi
2 i=2 2i 2

e

1

=

1

2

1

kV x

e0

X 1
V xi + V x1
2i 1
i=2

=
p

e1

e0
p

= ...
p

e

1 kp



1
2

1

·

r
2

p

= r/2 = ✏
Each of the = log(r/✏) iterations requires a call to ApproxCara for precision r/2, which produces a solution with sparsity
O(p/r2 ). Hence x will have O rp2 log r✏ nonzero coordinates.
Proof of Corollary 3.6. Let vi0 = vi u for all i. This corresponds to translating P such that u is placed at the origin. By the
triangle inequality, this at most doubles the radius of the origin-centered `p ball circumscribing the polytope. Applying
P
0
Theorem 3.5 we obtain a vector x 2 2(1 r/✏) such that
 ✏. Let x0i = xi /kxk1 2 . This satisfies
i2supp(x) xi vi
p
P
P
P
P
0 0
0 0
0
0
 ✏/kxk1 . Hence
=
u) =
u 
i2supp(x) xi vi
i2supp(x) xi vi
i2supp(x) xi (vi
i2supp(x) xi vi
✏
2(1 ✏/r)

p

 ✏.

p

p

p

E. Analysis via Conditional Gradient Methods
We first show that the Frank Wolfe algorithm described in Section 3.2 provides the same guarantees as the Mirror Descent.
Then we argue that the two algorithms are completely isomorphic. We start by reviewing the Frank-Wolfe algorithm.
Instead P
of the standard choice of parameters ⌘t = 2/(t + 1) we will choose ⌘t = 1/t since it has the nice feature that
t
xt = 1t s=1 yt . In various applications discussed by Barman (Barman, 2015) it is crucial that the convex combination is
uniform over (a multi-set of) vertices. For completeness we provide a proof of convergence of the Frank-Wolfe algorithm.
The proof follows the presentation in (Jaggi, 2013) and (Bubeck, 2014) with the small change that we choose ⌘t so that we
get an uniform convex combination in the end.
Lemma E.1 (Frank-Wolfe). If f is -smooth with respect to norm k·k and R = maxx,y2X kx yk then the Frank Wolfe
algorithm ⇣(described
by the iteration FW in Section 3.2) with parameters ⌘t = 1/t is such that f (xt ) minx2X f (x)  ✏
⌘
for t = ⌦

R2
✏

.

Proof. Let x⇤ be the minimizer of f and define

t

= f (xt )

f (x⇤ ). Since xt+1 = xt + ⌘t (yt

xt ), then by the definition

Tight Bounds for Approximate Caratheodory and Beyond

of -smoothness we have:
f (xt+1 )  f (xt ) + ⌘t rf (xt )> (yt

xt ) +

1 2
⌘ kyt
2 t

2

xt k

By the choice of yt we have that yt> rf (xt )  (x⇤ )> rf (xt ) and therefore:
(yt

xt )> rf (xt )  (x⇤

xt )> rf (xt )  f (x⇤ )

so:
t+1

which can be re-written as:

t+1

t+1



 (1
Y

(1

t

= f (xt+1 )

f (x⇤ ) 

t

⌘t

t

+

f (xt ) =

t

1 2 2
⌘ R
2 t

⌘t2 R2 . Telescoping this expression we get:
✓
◆
X 1 R2
R2
1
⌘t ) 0 +
⌘
=
O
for ⌘t =
t
2
2
t
t
t
t

⌘t )

t

+

1
2

Instantiating the Frank-Wolfe algorithm for our problem gives another optimization solution for the approximate
Caratheodory Theorem:
Pt
2
Theorem E.2. If xt , yt are iterates of the Frank-Wolfe algorithm for f (x) = kx ukp then 1t s=1 yt u  ✏ for
t=⌦

p
✏2

p

.

2

2

Proof. By combining Theorem A.1, Proposition C.1 and the fact that the Fenchel dual of 12 kxkp is 12 kxkq we obtain that
⇤
f (x) is 2(p 1)-smooth. Observe that since u is a convex combination of vertices
⇣ 2of⌘ P , then f (x ) = 0. Also, given how
Pt
2
pR
1
2
⌘t were chosen, xt = t s=1 yt . This implies that kxt ukp  ✏ for t = ⌦ ✏2 .

A remarkable fact, however, is that the algorithm in Theorem E.2 and the one in Theorem 3.2 produce the same iterates.
Next we prove this fact:
Proof of Theorem 3.7. Recall the the Frank-Wolfe iteration is given by:
>
ytFW = arg min rf (xFW
t 1) y
y2P

xFW
t =

✓

1

1
t

◆

xFW
t 1+

1 FW
·y
t t

2

for f (x) = kx ukp . Next we describe the Mirror Descent iteration. To avoid confusion we re-name the varibles and the
function in the (MD) iteration:
MD
xMD
t+1 = xt

⌘rg(ztMD )

MD
zt+1
= r! ⇤ (xMD
t+1 )

for g(z) = maxy2P z > (u y) and ! ⇤ is as in Proposition C.2. The vertices output by the Frank Wolfe algorithm are ytFW
and the vertices output by the Mirror Descent algorithm are ytMD = u rg(ztMD ).
MD
Let y0 be an arbitrary point P
of P and let xFW
0 = y0 and z0 = u
t
1 MD
1
FW
and xt = u + ⌘t xt = t s=1 yt .

y0 . We claim that for all t = 1, 2, . . . we have ytMD = ytFW

The main observation we need to prove this fact is that rf (x) = 1 (x) · (x u) where 1 (x) is a non-negative
real number and (·) is the function defined in Proposition C.2. Observe that by the same proposition, we can write
r! ⇤ (x) = 2 (x) · (x u). The important fact about is that it is invariant by rescaling its arguments by a non-negative
function, i.e., (tx) = (x) for t 0.
Pt
1 MD
1
Now, we can prove the claim by induction, suppose that ysMD = ysFW for all s < t and that xFW
t = u + ⌘t xt = t
s=1 yt .
Pt
MD
MD
MD
MD
MD
⇤ MD >
MD >
Then xt+1 = xt ⌘(u yt ) = ⌘(t+1) s=1 (u yt ) and yt = arg miny2P r! (xt ) y = arg miny2P (xt ) y.
FW
>
FW
For Frank-Wolfe, yt+1
= arg miny2P rf (xFW
u)> y. The lemma follows from the fact that,
t ) y = arg miny2P (xt
FW
MD
by induction hypothesis, xt
u and xt are rescaled versions of the same vector.

Tight Bounds for Approximate Caratheodory and Beyond

F. Lower bound proofs
F.1. Proof of Theorem 5.3
Proof. Let x 2

n

be k-sparse, i.e. |supp (x)| = k, such that H̃x

u

k in terms of ✏ and p.

p

 ✏. We would like to lower bound the sparsity

We will use two main ingredients in the proof: the first is the power mean inequality which states that for any vector
P
1/t
x 2 Rn , n1 i xti
is non-decreasing in t. In particular, this implies that kxkt · n 1/t is non-decreasing3 . The second
2
2
fact we will use is that for every vector kxk1  kxk2 · |supp (x)|. This follows from the Cauchy-Schwarz inequality:
⇣P
⌘2 ⇣ P
⌘ ⇣P
⌘
2
2
2
kxk1 =

i2supp(x) xi · 1
i2supp(x) xi ·
i2supp(x) 1 = kxk2 · |supp (x)|. Combining both results give us a
bound involving the 2-norm of the error:
✏

H̃x

u

=

p

1
· kHx
n1/p

e1 kp

1
· kHx
n1/2

e1 k2

where the last step follows from the power-mean inequality. Squaring both sides, we get:
✏2

1
(Hx
n

e1 )> (Hx

e1 ) =

1⇥ > >
x H Hx
n

⇤
2
2e>
1 Hx + 1 = kxk2

2

kxk1
|supp (x)|

1
n

We used the fact that e>
1 Hx = kxk1 = 1 since the top row of H consists of only 1’s. Hence k
1/ max ✏2 , 1/n = min 1/✏2 , n .

1
1
=
n
k

1
n

✏2 + 1/n

1

F.2. Proof of Theorem 5.1
Bounding probabilities. All the lemmas and theorems from this of this section are in the conditions of the construction
described in Section 5: A and V are the random matrices previously defined, and S is a fixed subset of x-coordinates of size
k.


p
p
Lemma F.1. If the x-player plays the uniform strategy, then E V · ~1/n
 p/n, and P V · ~1/n
✏  n✏p2
p

for n

p

p/✏2 .

Proof. The bound on the expectation follows from Khintchine’s inequality, which states that for any given vectors
u1 , . . . , um 2 Rn and iid uniform { 1, +1}-variables ri
E

X

ri u i

i

p



p

X

p·

i

2
kui kp

!1/2

We refer to (Wolff et al.) or (Barman, 2015) for a proof. Let vi be the columns of V . Since they are iid uniform, vi has the
same distribution of ri vi for some uniform { 1, +1}-variable ri . So:
E V

✓

◆
1~
1
n

=E
p

X
i

vi
ri
n

p



p

✓

1
p· n· 2
n

◆1/2

=

r

p
n

The second part of the lemma is direct from Markov’s inequality.
For the second part, consider an x-player that is restricted to only use coordinates from S. We want to show that the y-player
has a strategy that that would make all columns in S have a high value in y > V . The idea is that since n is large and k is
small (in fact, a constant independent of n) there should be rows that are very skewed (i.e. have a lot more +1’s than 1’s
in the S columns). If y plays a strategy that only uses such rows, then he can force x to have high value.
3

This can be seen by computing the derivative of Mt (x) =

1
n

P

i

xti

1/t

with respect to t and showing it is non-positive.

Tight Bounds for Approximate Caratheodory and Beyond

We call a row of A is good for the y-player if it has more than (1/2 + ✏)k 1’s in the S-coordinates. Next we show that with
high probability there is a large enough number of good rows available for the y-player. For this result, we need to lower
bound the probability in the tail of the binomial distribution, which requires a tight anti-concentration inequality.
Anti-concentration can be derived by carefully plugging the moment generating function into the Paley-Zygmund (Paley &
Zygmund, 1932) inequality, or by sharply estimating a sum of terms involving binomial coefficients. For further information
we refer the reader to Tao’s book (Tao).
Lemma F.2 (Chernoff bound). If 0 < ⇢  1/2, Xi are iid {0, 1}-random variables with P[Xi = 1] = ⇢ and
Pk
is the variance of X = i=1 Xi , then there exist constants C, c > 0 such that for all  c ,
hP
i
k
P
⇢·k 
c exp C 2
i=1 Xi

2

= k⇢(1 ⇢)

Lemma F.3 (Anti-concentration for the binomial distribution). In the same conditions as in the previous lemma, there exist
constants C̃, c̃ > 0 such that for all  c ,
hP
i
⇣
⌘
k
P
⇢·k
c̃ exp
C̃ 2
i=1 Xi
Lemma F.4. There are r = ⌦(n exp( O(k✏2 )) good rows with probability at least 1

exp( ⌦(n exp( O(k✏2 )))).

Proof. Applying Lemma F.3 with ⇢ = 1/2 and = 4✏ we obtain that the probability that a row is at least k 12 + ✏ k
+1’s (or 1’s, due to symmetry) is at least exp( O(k✏2 )). So in expectation, there are n exp( O(k✏2 )) good rows, so the
result follows by applying the Chernoff bounds with ⇢ = exp( O(k✏2 )) and = c .
With high probability there will be at least r = ⌦(n exp( O(k✏2 )) good rows for the y-player to play. We want to argue
that if the y-player can find r good rows, then he can play yi = r 1/q for each good row i, and 0 otherwise, and he will
leave an x-player restricted to choosing only columns from a subset S without any good option to play.
Lemma F.5. Let S be a fixed subset of columns of A, and let AS be the matrix whose columns are the columns of A that
belong to S. Conditioning on AS having r good rows, with probability at least 1 k exp ⌦(r✏2 ) , every column in S
contains at least r(1/2 + ✏/2) +1’s in the r good rows.
Proof. Sample matrix A according to the following procedure: in the first phase, sample each entry of A uniformly and
independently from { 1, +1}. In the second phase, for each row, shuffle the entries in S (i.e. for each row, sample a
random permutation of S and apply to the entries corresponding to those columns). In the first phase we can decide which
rows are good, call those R. Conditioning on the first phase, and fixing a column j 2 S, the entries Aij for i 2 R are
independent and uniform from { 1, +1}; the probability of Aij being 1 is at least 12 + ✏, since this entry is a random
entry from a good row sampled in the first phase. The result follows by applying the Chernoff bound with ⇢ = 12 + ✏ and
= ( ✏)/(⇢ · (1 ⇢)).
Now, we combine all the events discussed so far using the union bound:
· A satisfies V · ~1/n  ✏, and
P p
for every subset S of k rows, there is a subset R of r = ⌦(n exp( O(k✏2 ))) rows such that for all i 2 S, j2R Aij ✏r.
Lemma F.6. Fix ✏ and k. For sufficiently large n, there is a matrix A such that V = n

1/p

Proof. The proof follows from the probabilistic method. For each subset S, with probability at least 1
exp( ⌦(n exp( O(k✏2 )))) there are r good rows (Lemma F.4) and with probability 1
k exp ⌦(r✏2 ) =
1
2
2
1
k exp ⌦(n✏ exp( O(k✏P
))) there are at least ( 2 + ✏)r many +1s in each column corresponding to the
r rows (Lemma F.5), causing
✏r. The probability that both events occur can be bounded by 1
j2R Aij
O k exp ⌦(n✏2 exp( O(k✏2 ))) . Applying the union bound over all nk subsets S, we get:
✓ ◆
n
1
O k exp ⌦(n✏2 exp( O(k✏2 )))
1 exp k log n O(✏2 n exp( O(k✏2 )))
k
which goes to one as n ! 1 for any fixed k and ✏. Also, as n ! 1 the probability that V ( n1 )~1

p

 ✏ also goes to 1.

Tight Bounds for Approximate Caratheodory and Beyond

Theorem F.7 (Carathéodory lower bound). There is a matrix V whose columns have unit `p norm such that V · ~1/n
and for every x 2

, |supp (x)|  k = O(p/✏2 ), kV xkp

p

 ✏,

2✏.

Proof. Let V be the matrix obtained in Lemma F.6. From there, we have that V · ~1/n

p

 ✏. Now, fix any x 2

with

|supp
of x. Let also R be the set of rows for which
P (x)|  k, and let S be the set of columns corresponding to the support
1/q
A
✏r
for
all
i
2
S.
Now,
define
y
2
B
(1)
such
that
y
=
r
uf
i 2 R, and yi = 0 otherwise:
q
i
j2R ij
kV xkp

y> V x = n

We want to choose the parameters such that

1/p

r 1/p
n

If k  C ·

p
✏2

2. Substituting r = ⌦(n exp( O(k✏2 ))):

⇣ r ⌘1/p

= exp

for a suitable constant C, we get kV xkp

2✏.

n

⇣ r ⌘1/p
r✏
=
✏
n
r1/q · n1/p

· (y > A)x

✓

O

✓

k✏2
p

◆◆

G. Applications
The approach presented in the previous sections can be easily generalized or directly applied to a series of applications.
Here we identify three representative applications to illustrate the usefulness of our approach. We note that there are many
other possible applications in combinatorial optimization, game theory and machine learning, where a convex combination
is often maintained as a subroutine of the algorithm.
G.1. Fast rounding in polytopes with linear optimization oracles
The most direct application of our approach is to efficiently round a point in a polytope whenever it admits a fast linear
optimization oracle. An natural such instance is given by the matroid polytope. We denote a n-element matroid by M and
its rank by r.
Proposition G.1. There is an algorithm which, given a fractional point x⇤ contained inside the base
polytope
of a matroid
⇣ 2/p
⌘
p·r
M, and a norm parameter p 2, produces a distribution D over matroid bases supported on O
points, such that
✏2
kEx⇠D [x]

x⇤ kp  ✏. Furthermore the algorithm requires O nr2/p p/✏2 calls to M’s independence oracle.

Proof. The result follows from applying Theorem 3.2 for x⇤ in the convex hull of the characteristic vectors for matroid
bases. Note that each of these vectors has sparsity r so their p norm is precisely r1/p . Hence we have the desired sparsity for
the support of D. Each iteration requires maximizing a linear function over the bases of the polytope, which can be done
using the standard greedy algorithm, and requires O(n) calls to the independence oracle.
Of course, there are other nice polytopes where the existence of an efficient linear optimization oracle offers advantages. To
this aspect, we mention the s-t-flow polytope (i.e. the convex hull of all s-t paths), whose oracle is implemented with a single
shortest path computation. This enables us to speed up the path stripping subroutine in the Raghavan-Thompson randomized
rounding algorithm for approximating minimum congestion integral multicommodity flows (Raghavan & Thompson, 1991).
As described in (Raghavan & Thompson, 1991) the algorithm takes O(m2 ), which can be improved to near linear time
by carefully using link-cut trees (Kang & Payor, 2015). By contrast, approximate Carathéodory provides a lightweight
algorithm for producing an approximate decomposition into integral paths, without the need of complicated data structures.
Proposition G.2. There is an algorithm which, given a fractional s-t-flow f⇣⇤ routing
⌘ one unit of demand in G, and a norm
2/p
parameter p 2, produces a distribution D over s t-paths supported on O p·n✏2
points, such that kEf ⇠D [f ] f ⇤ kp 
⇣ 2/p ⌘
✏. Furthermore the algorithm requires O p·n✏2
shortest path computations.
In the setting of Raghavan-Thompson, fixing p = ⇥(log n) yields an approximate path stripping routine that runs in time
Õ(m/✏2 ).

Tight Bounds for Approximate Caratheodory and Beyond

G.2. SVM training
Support vector machines (SVM) are an extremely popular classification method, and have found ample usage in machine
learning, with applications ranging from finance to neuroscience. In the era of big data it is crucial for any such method to be
able to train on huge datasets. While a number of implementations (L IBLINEAR (Fan et al., 2008), P-packSVM (Zhu et al.,
2009), Pegasos (Shalev-Shwartz et al., 2011)) achieve excellent convergence rates in the case of linear SVM’s, handling
arbitrary kernels raises a significantly harder problem. L IB L INEAR and Pegasos achieve O(log(1/✏)), respectively O(1/✏)
convergence rate, but cannot be extended beyond linear kernels. The ✏ dependence for P-packSVM scales as O(1/✏), but it
requires knowing the Cholesky factorization of the kernel matrix in advance. In our case, a simple extension of the method
described in Section 3 gives O(1/✏2 ) convergence, while only requiring matrix-vector multiplications involving the kernel
matrix. So Cholesky factorization is no longer required, and the matrix does not need to be stored explicitly. In the case of
linear SVM’s, our method runs in nearly linear time.
Our approach is inspired from a reformulation of the training problem of Kitamura, Takeda, and Iwata (Kitamura et al.,
2014), who present a method for SVM training based on Wolfe’s algorithm. Their algorithm relies on a dual formulation
introduced by Schölkopf et al. (Schölkopf et al., 2000) which can be easily reformulated as a convex problem over a
product of two convex sets. More specifically, we are given empirical data (xi, yi ) 2 X ⇥ {±1}, 1  i  n, along with a
function that maps features to a Hilbert space : X ! H, which determines a kernel function k(x, y) = h (x), (y)i. Let
K 2 Rn⇥n , where Kij = k(xi, xj ), E+ = {ei : yi = +1}, E = {ei : yi = 1}.
In (Kitamura et al., 2014), the ⌫-SVM problem is reformulated as:

min

(

subject to

>

) K(

+
+

+

)

2 R CH⌘ (E+ )

2 R CH⌘ (E )

where ⌘ =

2
⌫n

and R CH⌘ (A) :=

P

a2A

a a|0



a

 ⌘,

P

a2A

a

= 1 is the restricted convex hull of set A.

Our approach to solve this problem will be to rephrase it as a saddle point problem (similar to what was done for the
approximate Carathéodory problem) and apply Mirror Descent, with a suitable Mirror Map, to solve the dual. Before doing
that, we introduce a few useful definitions and facts:
p
Definition G.3. Let K be a symmetric positive definite matrix. Then kxkK := x> Kx.
Proposition G.4. The dual norm of kxkK is kxkK

1

. In other words kxkK = maxy:kykK

1 1

hy, xi.

Proof. This can be verified using Lagrange multipliers: over the unit k·kK 1 -ball the term y > x attains its maximum at
p
>
y = Kx/ kKxkK 1 = Kx/ x> Kx. We can verify that for this choice of y, y > x = px >Kx = kxkK .
x Kx

Definition G.5. Let S⌘ = {

+

|

+

2 R CH⌘ (E+ ),

2 R CH⌘ (E )}.

Proposition G.6 (Linear optimization over S⌘ ). Linear optimization over S⌘ can be implemented in Õ(n) time.
Proof. The implementation of the linear optimization routine is done in near-linear time via a simple greedy algorithm. The
first thing to notice is that the objective is separable, so it is sufficient to optimize separately on E+ and E . This can be
done easily, since we need to distribute one unit of mass over the coordinates that span E+ and one unit of mass over the
coordinates that span E , such that no coordinate receives more than ⌘. Therefore adding mass to the coordinates spanning
E+ in increasing order of the weights y, and vice-versa to those spanning E yields the optimal solution.
With these facts on hand, we can now proceed to describing our equivalent formulation as a saddle-point problem, which
will then be solved using a similar method to the one we employed for the previous applications.
Note that instead of directly using the kernel matrix K in the formulation, we replace it with K̃ = K + 2✏ I. This only
changes the value of the objective by at most ✏/2 and it has the advantage of making K̃ positive semidefinite, since it is now
2
guaranteed to be non-degenerate. This allows us to write the objective function ( +
)> K̃( +
) as k +
kK̃ .
This formulation can be easily converted to a saddle point problem:

Tight Bounds for Approximate Caratheodory and Beyond

min k kK̃ = min
2S

for f (y) :=

min

max

2S⌘ y:kykK̃

2S⌘

1 1

y> =

y > defined over the k·kK̃

1

min

y:kykK̃

1 1

✓

min y >
2S⌘

◆

=

min

y:kykK̃

1 1

f (y)

-ball.

The subgradients of f are easy to compute, since they require a simple linear optimization over S:
@f (y) =

arg min y >
2S

which can be done in time Õ(n) using the greedy algorithm described in Proposition G.6. The mirror map of choice for the
domain {y : kykK̃ 1  1}will be ! : {y : kykK̃ 1  1} ! R, !(y) = 12 kyk2K̃ 1 , with
! ⇤ (z) =

(

1
2
2 kzkK̃

kzkK̃

1
2

if kzkK̃  1
.
if kzkK̃ > 1

Also, similarly to Proposition C.2, we have r! ⇤ (z) = K̃z · min(1, 1/kzkK̃ ), hence kr! ⇤ (Z)kK̃

1

 1.

The only thing left to do is to analyze the algorithm’s iteration count by bounding the strong convexity of ! and the Lipschitz
constant of f . We will do this with respect to k · k2 .
⇣
⌘
1
Proposition G.7. ! is min 2✏ , kKk + 2✏
-strongly convex with respect to k · k2 , where kKk is the spectral norm of
K.
1

2
1
Proof.
=
K + 2✏ I
⌫
⇣ Writing down ⌘the Hessian of the mirror map, we obtain r !(y) = K̃
1
✏
✏
min 2 , kKk + 2
I. The reason for using K̃ instead of K in the formulation is now evident: if K is not full

rank, then ! is not strongly convex. Adding a small multiple of the identity forces all the eigenvalues of K̃ to be at least ✏/2,
and avoids the degeneracy where some of them may be zero.
p
Proposition G.8. f is 2 ⌘-Lipschitz with respect to k · k2 .
Proof. We simply need to bound the 2-norm of the subgradient. By the construction presented in Proposition G.6 the
subgradient contains 2·d1/⌘e nonzero coordinates, 2·b1/⌘c of which are precisely ⌘.
pThis enables us to obtain a better upper
bound
than
one
would
usually
expect
on
the
2-norm
of
the
subgradient,
namely
2 · (b1/⌘c · ⌘ 2 + (1 ⌘ · b1/⌘c)2 ) 
p
p
2
2 · (2/⌘) · ⌘ = 2 ⌘.
Proposition G.9. maxy:kykK̃ 1 12 kyk2K̃ 

1
2

Finally we can put everything together:
Theorem G.10. An ✏-approximate solution to ⌫-SVM can be found in O ⌘ · max
O max 1✏ kKk / ⌫n✏2 iterations.
Proof. Follows from plugging in the parameters
descent algorithm.

⇣
= min ✏/2, (kKk + ✏/2)

1

⌘

2
✏ kKk

+

✏
2

/✏2

=

p
, L = 2 ⌘, R = O(1) into the mirror

At this point, it makes sense to analyze the performance of our algorithm for the most common choices of SVM kernels,
which only requires bounding the spectral norm of the kernel matrix; for this purpose we will simply use the trace bound.
The results are summarized in the table below. The last column of the table contains the number of iterations required to find
a solution down to a precision of ✏, given that all the vectors xi belong to the unit `2 ball.

Tight Bounds for Approximate Caratheodory and Beyond

Kernel type
Polynomial (homogeneous):
Kij = hxi , xj id
Polynomial (inhomogeneous):
d

Kij = (1 + hxi , xj i)
RBF:
Kij = exp( kxi xj k2 /2 2 )
Sigmoid:
Kij = tanh(↵ · hxi , xj i + c)

Upper bound on kKk

Iteration count

n · maxi kxi k2d
2

1
1
O max n⌫✏
3 , ⌫✏2
⇣
⇣
⌘⌘
1
2d
O max n⌫✏
3 , ⌫✏2

n · 1 + maxi kxi k22
n
n

d

O max

1
1
n⌫✏3 , ⌫✏2

O max

1
1
n⌫✏3 , ⌫✏2

It is worth mentioning that each iteration requires Õ(n) time for computing the subgradient, and a multiplication of the
kernel matrix with a vector; one advantage is that the kernel matrix does not need to be explicitly stored, as its entries can be
computed on the fly, whenever needed. In the case of linear kernels, this computation is implemented in linear time since
P
>
K̃z = [x1 | . . . |xn ] [x1 | . . . |xn ] z + 2✏ z, which requires computing a linear combination h = i xi · zi of the vectors x,
and n dot products between vectors from the training set and h.

