Optimal Densification for Fast and Accurate Minwise Hashing

A. Proofs
Theorem 5 Give any two finite sets S1 , S2 ∈ Ω, with A =
|S1 ∪ S2 | > a = |S1 ∩ S2 | > 0 and |Ω| = D → ∞. The
limiting variance of the estimators from densification and
improved densification when k = D → ∞ is given by:



a
A−a
lim V ar(h) =
> 0 (15)
k→∞
A A(A + 1)


a
a 3(A − 1) + (2A − 1)(a − 1)
+
−
lim V ar(h ) =
>0
k→∞
A
2(A + 1)(A − 1)
A
(16)

Proof: When k = D, then Nemp = D − A. Substituting
this value in the variance formulas from (Shrivastava & Li,
2014c) and taking the limit as D = k → ∞, we get the
a
<
above expression after manipulation. When 0 < R = A
1, they both are strictly positive.


Nemp =

k−1
X
j=0

1{Ej = 1},



|S1 ∩ S2 |
P r h (S1 ) = h (S2 ) =
=R
|S1 ∩ S2 |
R
R
RR̄
V ar(h∗ ) =
+ A 2 + B 2 − R2
k
k
k
∗
lim V ar(h ) = 0
∗

∗

(17)
(18)
(19)

where Nemp is the number of simultaneous empty bins between S1 and S2 and the quantities A and B are given by


Nemp (Nemp − 1)
A = E 2Nemp +
k − Nemp

B = E (k − Nemp )(k − Nemp − 1) + 2Nemp (k − Nemp − 1)

Nemp (Nemp − 1)(k − Nemp − 1)
+
k − Nemp

Proof:
The collision probability is easy using a simple observation that values coming from different bin numbers can
never match across S1 and S2 , i.e. h∗i (Si ) 6= h∗j (S2 ) if
i 6= j, as they have disjoint different range. So whenever, for a simultaneous empty bin i, i.e. Ei = 1, we get
h∗i (S1 ) = h∗i (S2 ) after reassignment, the value must be
coming from same non-empty bin, say numbers k which is
not not empty. Thus,

(21)

where 1 is the indicator
function. We partition the event

h∗j (S1 ) = h∗j (S2 ) into two cases depending on Ej . Let
MjN (Non-empty Match at j) and MjE (Empty Match at
j) be the events defined as:
MjN = 1{Ej = 0 and h∗j (S1 ) = h∗j (S2 )}
MjE

= 1{Ej = 1 and

h∗j (S1 )

=

h∗j (S2 )}

(22)
(23)

Note that, MjN = 1 =⇒ MjE = 0 and MjE = 1 =⇒
MjN = 0. From the LSH property of estimator we have
E(MjN |Ej = 0) = E(MjE |Ej = 1)

Theorem 6

k→∞

For variance, define the number of simultaneously empty
bins by

= E(MjE + MjN ) = R ∀j

(24)

It is not difficult to show that,


E MjN MiN i 6= j, Ej = 0 and Ei = 0 = RR̃,

where R̃ =

a−1
f 1+f 2−a−1 .

R̂ =

Using these new events, we have

k−1

1 X E
Mj + MjN
k j=0

(25)

We are interested in computing

2 
k−1
 
 1 X E
Mj + MjN   − R2 (26)
V ar(R̂) = E 
k j=0
For notational convenience we will use m to denote the
event k − Nemp = m, i.e., the expression E(.|m) means
E(.|k − Nemp = m). To simplify the analysis, we will first
compute the conditional expectation


2

k−1
X
 E
  
 1
f (m) = E 
Mj + MjN   m
(27)
k
j=0

P r(h∗i (S1 ) = h∗i (S2 )) = P r(h∗k (S1 ) = h∗k (S2 )|Ek = 0) = R By expansion and linearity of expectation, we obtain






X
X


The variance is little involved. From the collision probabilk 2 f (m) = E 
MiN MjN m + E 
MiN MjE m
ity, we have the following is unbiased estimator.
i6=j
i6=j


"

 #
k
k−1
X
X

 N 2

E
E
E
2
1X
(Mj ) + (Mj ) m
+E 
Mi Mj m + E
R̂ =
1{h∗j (S1 ) = h∗j (S2 )}.
(20)
k j=0
i=1
i6=j

Optimal Densification for Fast and Accurate Minwise Hashing

MjN = (MjN )2 and MjE = (MjE )2 as they are indicator
functions and can only take values 0 and 1. Hence,



k−1
X


E
(MjN )2 + (MjE )2 m = kR
(28)

Under any independent re-assignment, the probability that
two empty bins chooses the same non-empty bin out of m
1
non-empty bins is lower bounded by m
which is achieved
by optimal densification.

j=0

The values of the first three terms are given by the following 3 expression using simple binomial enpension and using the fact that we are dealing with indicator random variable which can only take values 0 or 1.



X

(29)
E
MiN MjN m = m(m − 1)RR̃
i6=j



"
#

X

R
(m
−
1)R
R̃
E
MiN MjE m = 2m(k − m)
+
m
m
i6=j

(30)

Let p be the probability that two simultaneously empty bins
i and j finally picks the same non-empty bin for reassignment. Then we have



h
i
X

E
MiE MjE m = (k − m)(k − m − 1) pR + (1 − p)RR̃
i6=j

(31)

because with probability (1 − p), it uses estimators from
different simultaneous non-empty bin and in that case the
MiE MjE = 1 with probability RR̃. We know that Algo1
rithm 1 which uses 2-universal hashing the value of p = m
.
This is because any pairwise assignment is perfectly random with 2-universal hashing.
Substituting for all terms with value of p and rearranging
terms gives the required expression.
When k = D, then Nemp = D − A. Substituting this value
in the variance formulas and taking the limit as D = k →
∞, we get 0 for all R.
Theorem 7
V ar(h∗ ) ≤ V ar(h+ ) ≤ V ar(h)

(32)

1
1.5
2
Proof: We have p∗ = m
≤ p+ = m+1
≤ p = m+1
. The
+
value of p and p comes from analysis in (Shrivastava &
Li, 2014c)

Theorem 8 Among all densification schemes, where the
reassignment process for bin i is independent of the reassignment process of any other bin j, Algorithm 1 achieves
the best possible variance.

