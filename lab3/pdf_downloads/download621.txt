000
001
002
003
004
005
006
007
008
009
010
011
012
013
014
015
016
017
018
019
020
021
022
023
024
025
026
027
028
029
030
031
032
033
034
035
036
037
038
039
040
041
042
043
044
045
046
047
048
049
050
051
052
053
054

Capacity Releasing Diffusion for Speed and Locality

A. CRD inner procedure
We first fill in the missing details in the CRD-inner subroutine (Algorithm 1).
Note an ineligible arc (v, u) must remain ineligible until
the next relabel of v, so we only need to check each arc out
of v once between consecutive relabels. We use current(v)
to keep track of the arcs out of v that we have checked since
the last relabel of v. We always pick an active vertex v with
the lowest label. Then for any eligible arc (v, u), we know
m(u) ‚â§ d(u), so we can push at least 1 along (v, u) (without violating m(u) ‚â§ 2d(u)), which is crucial to bound
the total work. We keep the list Q in non-decreasing order
of the vertices‚Äô labels, for efficient look-up of the lowest
labeled active vertex, and Add, Remove, Shift are the operations to maintain this order. Note these operations can
be implemented to take O(1) work. In particular, when we
add a node u to Q, it will always be the active node with
lowest label, so will be put at the beginning. We only remove the first element v from Q, and when we shift a node
v in Q, we know l(v) increases by exactly 1. To maintain
Q, we simply need to pick two linked lists, one containing
all the active nodes with non-decreasing labels, and another
linked list containing one pointer for each label value, as
long as there is some active node with that label, and the
pointer contains the position of first such active node in Q.
Maintaining this two lists together can give O(1) time Add,
Remove, Shift.
Now we proceed to prove the main theorem of CRD-inner.
Theorem 1. Given G, m(¬∑), and œÜ ‚àà (0, 1], such that
|m(¬∑)| ‚â§ vol(G), and ‚àÄv : m(v) ‚â§ 2d(v) at the start,
CRD-inner terminates with one of the following cases
(1) CRD-inner finishes the full CRD step: ‚àÄv : m(v) ‚â§
d(v).
(2) There are nodes with excess, and we can find a cut A
of conductance O(œÜ). Moreover, ‚àÄv ‚àà A : 2d(v) ‚â•
m(v) ‚â• d(v), and ‚àÄv ‚àà AÃÑ : m(v) ‚â§ d(v).
The running time is O(|m(¬∑)| log |m(¬∑)|/œÜ).
Proof. Let l(¬∑) be the labels of vertices at termination, and
let Bi = {v|l(v) = i}. We make the following observations: l(v) = h ‚áí 2d(v) ‚â• m(v) ‚â• d(v); h > l(v) ‚â•
1 ‚áí m(v) = d(v); l(v) = 0 ‚áí m(v) ‚â§ d(v).

Algorithm 1 CRD-inner(G,m(¬∑),œÜ)
.
.
.
.
.
.
.
.
.
.
.
.
.

Initialization:
. ‚àÄ{v, u} ‚àà E, m(u, v) = m(v, u) = 0.
. Q = {v|m(v) > d(v)}, h = 3 log œÜ|m(¬∑)|
. ‚àÄv, l(v) = 0, and current(v) is the first edge in
v‚Äôs list of incident edges.
While Q is not empty
. Let v be the lowest labeled vertex in Q.
. Push/Relabel(v).
. If Push/Relabel(v) pushes mass along (v, u)
. . If v becomes in-active, Remove(v, Q)
. . If u becomes active, Add(u, Q)
. Else If Push/Relabel(v) increases l(v) by 1
. . If l(v) < h, Shift(v, Q)
. . Else Remove(v, Q)

Push/Relabel(v)
. Let {v, u} be current(v).
. If arc (v, u) is eligible, then Push(v, u).
. Else
. . If {v, u} is not the last edge in v‚Äôs list of edges.
. . . Set current(v) be the next edge of v.
. . Else (i.e., {v, u} is the last edge of v)
. . . Relabel(v), and set current(v) be the first
edge of v‚Äôs list of edges.
Push(v, u)
. Assertion: rm (v, u) > 0, l(v) ‚â• l(u) + 1.
ex(v) > 0, m(u) < 2d(u).
. œà = min (ex(v), rm (v, u), 2d(u) ‚àí m(u))
. Send œà units of mass from v to u:
m(v, u) ‚Üê m(v, u) + œà, m(u, v) ‚Üê m(u, v) ‚àí œà.
m(v) ‚Üê m(v) ‚àí œà, m(u) ‚Üê m(u) + œà.
Relabel(v)
. Assertion: v is active, and ‚àÄu ‚àà V ,
rm (v, u) > 0 =‚áí l(v) ‚â§ l(u).
. l(v) ‚Üê l(v) + 1.

Capacity Releasing Diffusion for Speed and Locality

055
056
057
058
059
060
061
062
063
064
065
066
067
068
069
070
071
072
073
074
075
076
077
078
079
080
081
082
083
084
085
086
087
088
089
090
091
092
093
094
095
096
097
098
099
100
101
102
103
104
105
106
107
108
109

Since |m(¬∑)| ‚â§ vol(G), if B0 = ‚àÖ, it must be |m(¬∑)| =
vol(G), and every v has m(v) = d(v), so we get case (1).
If Bh = ‚àÖ, we also get case (1).
If Bh , B0 6= ‚àÖ, let Si = ‚à™hj=i Bj be the set of nodes with
label at least i. We have h level cuts Sh , . . . , S1 , where
vol(Sh ) ‚â• 1, and Sj ‚äÜ Si if j > i. We claim one of
these level cuts must have conductance O(œÜ). For any Si ,
we divide the edges from Si to Si into two groups: 1) edge
across one level (i.e., from node in Bi to node in Bi‚àí1 ),
and 2) edges across more than one level. Let z1 (i), z2 (i)
be the number of edges in the two groups respectively, and
def
define œÜg (i) = zg (i)/vol(Si ) for g = 1, 2.
First we show that, there must be a i‚àó between h and h/2
such that œÜ1 (i‚àó ) ‚â§ œÜ. By contradiction, if œÜ1 (i) > œÜ for all
i = h, . . . , h/2, since vol(Si‚àí1 ) ‚â• vol(Si )(1 + œÜ1 (Si )),
we get vol(Sh/2 ) ‚â• (1 + œÜ)h/2 vol(Sh ). With h =
3 log |m(¬∑)|/œÜ, we have vol(Sh/2 ) ‚â• ‚Ñ¶(|m(¬∑)|3/2 ), and
since nodes in Sh/2 are all saturated, we get a contradiction since we must have vol(Sh/2 ) ‚â§ |m(¬∑)|.
Now we consider any edge {v, u} counted in z2 (i‚àó ) (i.e.,
v ‚àà Si‚àó , u ‚àà Si‚àó , l(v) ‚àí l(u) ‚â• 2). Since i‚àó ‚â• h/2 > 1/œÜ,
cÃÇ(v, u) = 1/œÜ. l(v)‚àíl(u) > 2 suggests rm (v, u) = 0, thus
m(v, u) = 1/œÜ (i.e., 1/œÜ mass pushed out of Si‚àó along
each edge counted in z2 (i‚àó )). Each edge counted in z1 (i‚àó )
can have at most 1/œÜ mass pushed into Si‚àó , and at most
2vol(Si‚àó ) mass can start in Si‚àó , then we know
z2 (i‚àó )/œÜ ‚â§ z1 (i‚àó )/œÜ + 2vol(Si‚àó )
We will let A be Si‚àó , and we have
œÜ(A) =

z1 (i‚àó ) + z2 (i‚àó )
‚â§ 4œÜ = O(œÜ)
vol(Si‚àó )

of œà mass, we charge O(œà) to that push operation. Since
œà ‚â• 1, we charged the push enough to cover the work in
that iteration. If the call to Push/Relabel(v) doesn‚Äôt push,
we charge the O(1) work of the iteration to the next relabel
of v (or the last relabel if there is no next relabel). The
latter can happen at most d(v) times between consecutive
relabels of v, so each relabel of v is charged O(d(v)) work.
We now charge the work on pushes and relabels to the absorbed mass. Note each time we relabel v, there are d(v)
units of absorbed mass at v, so we charge the O(d(v)) work
on the relabel to the absorbed mass, and each unit gets
charged O(1). There is at most h relabels of v, so each
unit of absorbed mass is charged O(h) in total by all the
relabels.
For the
Pwork on pushes, we consider the potential function
Œõ = v ex(v)l(v). Œõ is always non-negative, and as we
only push excess mass downhill, each push of œà units of
mass decrease Œõ by at least œà, so we can charge the work
on pushes to the increment of Œõ. It only increases at relabel.
When we relabel v, Œõ is increased by ex(v). Since ex(v) ‚â§
d(v), we can charge O(1) to each unit of absorbed mass at
v to cover Œõ‚Äôs increment. In total we can charge all pushes
(via Œõ) to absorbed mass, and each unit is charged with
O(h).
If we need to compute the cut A in case (2), the running
time is O(vol(S1 )), which is O(|m(¬∑)|).

B. Local Clustering
Recall we assume B to satisfy the following conditions.
def œÜS (B)

Assumption 1. œÉ1 =

œÜ(B)

‚â• ‚Ñ¶(1)

Assumption 2. There exists œÉ2 ‚â• ‚Ñ¶(1), such that
any T ‚äÇ B with volB (T ) ‚â§ volB (B)/2 satisfies

Here we assume Si‚àó is the smaller side of the cut to compute the conductance. If this is not the case, i.e. vol(Si‚àó ) >
vol(G)/2, we just carry out the same argument as above,
but run the region growing argument from level h/4 up to
level h/2, and get a low conductance cut, and still let A
to be the side containing Sh . The additional properties of
elements in A follows from Sh ‚äÜ A ‚äÜ Sh/4 .

Now we proceed to prove the main lemma.

Now we proceed to the running time. The initialization
takes O(|m(¬∑)|). Subsequently, each iteration takes O(1)
work. We will first attribute the work in each iteration to
either a push or a relabel. Then we will charge the work on
pushes and relabels to the absorbed mass, such that each
unit of absorbed mass gets charged O(h) work. Recall the
absorbed mass at v are the first up to d(v) mass starting
at or pushed into v, and these mass never leave v, as the
algorithm only pushes excess mass. This will prove the
result, as there are at most |m(¬∑)| units of (absorbed) mass
in total.

Lemma 1. In the j-th CRD step, let Mj be the total
amount of mass in B at the start, and Lj be the amount
of mass that ever leaves B during the diffusion, then
Lj ‚â§ O( œÉ2 log1vol(B) ) ¬∑ Mj when Mj ‚â§ volB (B)/2, and
Lj ‚â§ O( œÉ11 ) ¬∑ Mj when Mj ‚â• volB (B)/2.
Proof. For simplicity, we assume once a unit of mass
leaves B, it is never routed back. Intuitively, mass coming back into B should only help the algorithm, and indeed
the results don‚Äôt change without this assumption. We denote |Mj (S)| as the amount of mass on nodes in a set S at
the start of the CRD-inner call.

In each iteration of Unit-Flow, the algorithm picks a lowest
labeled active node v. If Push/Relabel(v) ends with a push

We have two cases, corresponding to whether the diffusion
already spread a lot of mass over B. If Mj ‚â• volB (B)/2,

|E(T, B \ T )|
|E(T, V \ B)| log vol(B) log

1
œÜS (B)

‚â• œÉ2 .

Capacity Releasing Diffusion for Speed and Locality

110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164

we use the upperbound 1/œÜ that is enforced on the net mass
over any edge to limit the amount of mass that can leak out.
In particular Lj ‚â§ O(vol(B)œÜ(B)/œÜS (B)), since there are
vol(B)œÜ(B) edges from B to BÃÑ, and œÜ = Œò(œÜS (B)) in
CRD-inner. As Mj ‚â• ‚Ñ¶(vol(B)), we have Lj ‚â§ O( œÉ11 ) ¬∑
Mj .
The second case is when Mj ‚â§ volB (B)/2. In this case, a
combination of Assumption 2 and capacity releasing controls the leakage of mass. Intuitively, there are still many
nodes in B that the diffusion can spread mass to. For the
nodes in B with excess on them, when they push their excess, most of the downhill directions go to nodes inside B.
As a consequence of capacity releasing, only a small fraction of mass will leak out.
In particular, let l(¬∑) be the labels on nodes when CRDinner finishes, we consider Bi = {v ‚àà B|l(v) = i} and
the level cuts Si = {v ‚àà B|l(v) ‚â• i} for i = h, . . . , 1.
As Mj ‚â§ volB (B)/2, we know vol(Sh ) ‚â§ vol(Sh‚àí1 ) ‚â§
. . . ‚â§ vol(S1 ) ‚â§ volB (B)/2. In this case, we can use
Assumption 2 on all level cuts Sh , . . . , S1 . Moreover, for a
node v ‚àà Bi , the ‚Äù‚Äòeffective‚Äù‚Äô capacity of an arc from v to
BÃÑ is min(i, 1/œÜ). Formally, we can bound Lj by the total
(effective) outgoing capacity, which is
h
X

1
œÜ

X
1
|E(Si , BÃÑ)|
|E(Bi , BÃÑ)| ¬∑ min(i, ) =
œÜ
i=1
i=1

(1)

where h is the bound on labels used in unit flow.
We design a charging scheme to charge the above quantity
(the right hand side) to the mass in ‚àÜj (B), such that each
unit of mass is charged O(1/(œÉ2 log vol(B))). It follows
that Lj ‚â§ O( œÉ2 log1vol(B) ) ¬∑ |‚àÜj (B)|.
|E(Si ,B\Si )|
Recall that, |E(Si , BÃÑ)| ‚â§ œÉ2 log
vol(B) log(1/œÜ) from Assumption 2. We divide edges in E(Si , B \ Si ) into two
groups: : 1) edges across one level, and 2) edges across
more than one level. Let z1 (i), z2 (i) be the number of
edges in the two groups respectively.

If z1 (i)
‚â•
|E(Si , B \ Si )|/3, we charge
3/(œÉ2 log vol(B) log(1/œÜ)) to each edge in group 1.
These edges in turn transfer the charge to the absorbed
mass at their endpoints in Bi . Since each node v in level
i ‚â• 1 has d(v) absorbed mass, each unit of absorbed mass
is charged O(1/(œÉ2 log vol(B) log(1/œÜ))). Note that the
group 1 edges of different level i‚Äôs are disjoint, so each
unit of absorbed mass will only be charged once this way.
If z1 (i) ‚â§ |E(Si , B \ Si )|/3, we know z2 (i) ‚àí z1 (i) ‚â•
|E(Si , B \ Si )|/3. Group 2 edges in total send at least
(i ‚àí 1)z2 (i) mass from Si to B \ Si , and at most (i ‚àí
1)z1 (i) of these mass are pushed into Si by group 1 edges.
Thus, there are at least (i ‚àí 1)|E(Si , B \ Si )|/3 mass
that start in Si , and are absorbed by nodes at level be-

low i (possibly outside B). In particular, this suggests
|Mj (Si )| ‚â• (i ‚àí 1)|E(Si , B \ Si )|/3, and we split the
total charge |E(Si , BÃÑ)| evenly on these mass, so each
unit of mass is charged O(1/(iœÉ2 log vol(B) log(1/œÜ))).
Since we sum from i = 1/œÜ to 1 in (RHS of)
Eqn (1), we charge some mass multiple times (as
Si ‚Äôs not disjoint), but we can bound the total charge
P1/œÜ 1
by
i=1 i ¬∑ O(1/(œÉ2 log vol(B) log(1/œÜ))), which is
O(1/(œÉ2 log vol(B))). This completes the proof.

C. Empirical Set-up and Results
C.1. Datasets
We chose the graphs of John Hopkins, Rice, Simmons and
Colgate universities/colleges. The actual IDs of the graphs
in Facebook100 dataset are Johns Hopkins55, Rice31,
Simmons81 and Colgate88. These graphs are anonymized
Facebook graphs on a particular day in September 2005 for
student social networks. The graphs are unweighted and
they represent ‚Äúfriendship ties‚Äù. The data form a subset
of the Facebook100 dataset from (Traud et al., 2012). We
chose these 4 graphs out of 100 due to their large assortativity value in the first column of Table A.2 in (Traud et al.,
2012), where the data were first introduced and analyzed.
Details about the graphs are shown is Table 1.
Graph

volume

nodes

edges

John Hopkins
Rice
Simmons
Colgate

373144
369652
65968
310086

5157
4083
1510
3482

186572
184826
32984
155043

Table 1. Graphs used for experiments.

Each graph in the Facebook dataset comes along with 6 features, i.e., second major, high school, gender, dorm, major
index and year. We construct ‚Äúground truth‚Äù clusters by using the features for each node. In particular, we consider
nodes with the same value of a feature to be a cluster, e.g.,
students of year 2009. We loop over all possible clusters
and consider as ground truth the ones that have volume
larger than 1000, conductance smaller than 0.5 and gap
larger than 0.5. Filtering results in moderate scale clusters
for which the internal volume is at least twice as much as
the volume of the edges that leave the cluster. Additionally,
gap at least 0.5 means that the smallest nonzero eigenvalue
of the normalized Laplacian of the subgraph defined by the
cluster is at least twice larger than the conductance of the
cluster in the whole graph. The clusters per graph that satisfy the latter constraints are shown in Table 2. Notice that
the clusters which remain after filtering correspond to features year or dorm. This agrees with (Traud et al., 2012)

Capacity Releasing Diffusion for Speed and Locality

Sim. Rice Hop.

in which it is stated that the features with clusters with the
best assortativity value correspond to the feature of year or
dorm.

Colgate

165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219

year/dorm

volume

size

gap

cond.

217
2009
203
2009
2007
2009
2006
2007
2008
2009

10696
32454
43321
30858
14424
11845
62064
68381
62429
35369

200
886
403
607
281
277
556
588
640
638

1.48
0.67
0.58
0.73
0.57
5.35
0.57
0.69
1.19
3.49

0.26
0.19
0.46
0.33
0.47
0.1
0.48
0.41
0.29
0.11

Table 2. Clusters of chosen graphs in Table 1, see Subsection C.1
for details.

C.2. Performance criteria and parameter tuning
For real-world Facebook graphs since we calculate the
ground truth clusters in Table 2 then we measure performance by calculating precision and recall for the output
clusters of the algorithms.
We set the parameters of CRD to œÜ = 1/3 for all experiments. At each iteration we use sweep cut on the labels
returned by the CRD-inner subroutine to find a cut of small
conductance, and over all iterations of CRD we return the
cluster with the lowest conductance.
ACL has two parameters, the teleportation parameter Œ± and
a tolerance parameter . Ideally the former should be set according to the reciprocal of the mixing time of a a random
walk within the target cluster, which is equal to the smallest nonzero eigenvalue of the normalized Laplacian for the
subgraph that corresponds to the target cluster. Let us denote the eigenvalue with Œª. In our case the target cluster is a
ground truth cluster from Table 2. We use this information
to set parameter Œ±. In particular, for each node in the clusters in Table 2 we run ACL 4 times where Œ± is set based on
a range of values in [Œª/2, 2Œª] with a step of (2Œª ‚àí Œª/2)/4.
The tolerance parameter  is set to 10‚àí7 for all experiments
in order to guarantee accurate solutions for the PageRank
linear system. For each parameter setting we use sweep cut
to find a cluster of low conductance, and over all parameter
settings we return the cluster with the lowest conductance
value as an output of ACL.
For real-world experiments we show results for ACLopt.
In this version of ACL, for each parameter setting of Œ± we
use sweep cut algorithm to obtain a low conductance cluster and then we compute its precision and recall. Over all
parameter settings we keep the cluster with the best F1-

score; a combination of precision and recall. This is an
extra level of supervision for the selection of the teleportation parameter Œ±, which is not possible in practice since
it requires ground truth information. However, the performance of ACLopt demonstrates the performance of ACL in
case that we could make optimal selection of parameter Œ±
among the given range of parameters (which also includes
ground truth information) for the precision and recall criteria.
Finally, we set the reference set of FlowI to be the output
set of best conductance of ACL out of its 4 runs for each
node. By this we aim to obtain an improved cluster to ACL
in terms of conductance. Note that FlowI is a global algorithm, which means that it accesses the information from
the whole graph compared to CRD and ACL which are local algorithms.
C.3. Real-world experiments
For clusters in Table 2 we sample uniformly at random
half of their nodes. For each node we run CRD, ACL
and ACL+FlowI. We report the results using box plots,
which graphically summarizes groups of numerical data
using quartiles. In these plot the orange line is the median,
the blue box below the median is the first quartile, the blue
box above the median is the third quartile, the extended
long lines below and above the box are the maximum and
minimum values and the circles are outliers.
The results for John Hopkins university are shown in Figure
1. Notice in this figure that CRD performs better than ACL
and ACLopt, which both use ground truth information, see
parameter tuning in Subsection C.2. CRD performs similarly to ACL+FlowI, where FlowI is a global algorithm, but
CRD is a local algorithm. Overall all methods have large
medians for this graph because the clusters with dorm 217
and year 2009 are clusters with low conductance compared
to the ones in other universities/colleges which we will discuss in the remaining experiments of this subsection.
The results for Rice university are shown in Figure 2. Notice that both clusters of dorm 203 and year 2009 for Rice
university are worse in terms of conductance compared to
the clusters of John Hopkins university. Therefore the performance of the methods is decreased. For the cluster of
dorm 203 with conductance 0.46 CRD has larger median
than ACL, ACLopt and ACL+Flow in terms of precision.
The latter methods obtain larger median for recall, but this
is because ACL leaks lots of probability mass outside of
the ground truth cluster since as indicated by its large conductance value many nodes in this cluster are connected externally. For cluster of year 2009 CRD outperforms ACL,
which fails to recover the cluster because it leaks mass outside the cluster, FlowI corrects the problem and locates the
correct cluster at the expense of touching the whole graph.

Capacity Releasing Diffusion for Speed and Locality

220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274

Notice that all methods have a significant amount of variance and outliers, which is also explained by the large conductance values of the clusters.
The results for Simmons college are shown in Figure 3. Notice that Simmons college in Table 2 has two clusters, one
with poor conductance 0.47 for students of year 2007 and
one low conductance 0.1 for students of year 2009. The
former with conductance 0.47 means that the internal volume is nearly half the volume of the outgoing edges. This
has a strong implication in the performance of CRD, ACL
and ACLopt which get median precision about 0.5. This
happens because the methods push half of the flow (CRD)
and half of the probability mass (ACL) outside the ground
truth cluster, which results in median precision 0.5. ACL
achieves about 20% more (median) recall than CRD but
this is because ACL touched more nodes than CRD during
execution of the algorithm. Notice that ACL+FlowI fails
for the cluster of year 2007, this is because FlowI is a global
algorithm, hence it finds a cluster that has low conductance
but it is not the ground truth cluster. The second cluster
of year 2009 has low conductance hence all methods have
large median performance with CRD being slightly better
than ACL, ACLopt and ACL+FlowI.
The results for Colgate university are shown in Figure 4.
The interesting property of the clusters in Table 2 for Colgate university is that their conductance varies from low 0.1
to large 0.48. Therefore in Figure 4 we see a smooth transition of performance for all methods from poor to good
performance. In particular, for the cluster of year 2006
the conductance is 0.48 and CRD, ACL and ACLopt perform poorly by having median precision about 50%, recall
is slightly better for ACL but this is because we allow it
touch a bigger part of the graph. ACL+FlowI fails to locate
the cluster. For the cluster of year 2007 the conductance
is 0.41 and the performance of CRD, ACL and ACLopt is
increased with CRD having larger (median) precision and
ACL having larger (median) recall as in the previous cluster. Conductance is smaller for the cluster of year 2008,
for which we observe substantially improved performance
for CRD with large median precision and recall. On the
contrary, ACL, ACLopt and ACL+FlowI have nearly 30%
less median precision in the best case and similar median
recall, but only because a large amount of probability mass
is leaked and a big part of the graph is touched which includes the ground truth cluster. Finally, the cluster of year
2009 has low conductance 0.11 and all methods have good
performance for precision and recall.

Figure 1. Precision and recall results for John Hopkins university

Figure 2. Precision and recall results for Rice university

References
Traud, A. L., Mucha, P. J., and Porter, M. A. Social structure of facebook networks. Physica A: Statistical Mechanics and its Applications, 391(16):4165‚Äì4180, 2012.

Figure 3. Precision and recall results for Simmons college

Capacity Releasing Diffusion for Speed and Locality

275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329

Figure 4. Precision and recall results for Colgate university

