Input Convex Neural Networks: Supplementary Material

Brandon Amos Lei Xu J. Zico Kolter

A. Additional architectures

work in (2) can be written as the optimization problem

A.1. Convolutional architectures

minimize zk
y,z1 ,...,zk

Convolutions are important to many visual structured tasks.
We have left convolutions out to keep the prior ICNN notation light by using matrix-vector operations. ICNNs can
be similarly created with convolutions because the convolution is a linear operator.

(z)

(y)

subject to zi+1 ≥ Wi zi + Wi y + bi , i = 0, . . . , k − 1
zi ≥ 0, i = 1, . . . , k − 1.
(22)

This problem exactly replicates the equations of the
FICNN, with the exception that we have replaced ReLU
and the equality constraint between layers with a positivity constraint on the zi terms and an inequality. However, because we are minimizing the final zk term, and
because each inequality constraint is convex, at the solution one of these constraints must be tight, i.e., (zi )j =

 (Wi(z) zi + Wi(y) y + bi )j or (zi )j = 0, which recovers the
(z)
(x)
(y)
= gi zi ∗ Wi,j + (Sx) ∗ Wi,j + (Sy) ∗ Wi,j + bi,j ReLU non-linearity exactly. The exact same procedure can
be used to write to create an exact inference procedure for
(20)
the PICNN.

The construction of convolutional layers in ICNNs depends
on the type of input and output space. If the input and output space are similarly structured (e.g. both spatial), the
jth feature map of a convolutional PICNN layer i can be
defined by

j
zi+1

where the convolution kernels W are the same size and S
scales the input and output to be the same size as the previous feature map, and were we omit some of the Hadamard
product terms that can appear above for simplicity of presentation.
If the input space is spatial, but the output space has another
structure (e.g. the simplex), the convolution over the output
space can be replaced by a matrix-vector operation, such as



(z)
(x)
(y)
j
zi+1
= gi zi ∗ Wi,j + (Sx) ∗ Wi,j + Bi,j y + bi,j
(21)

(y)

where the product Bi,j y is a scalar.

B. Exact inference in ICNNs
Although it is not a practical approach for solving the optimization tasks, we first highlight the fact that the inference
problem for the networks presented above (where the nonlinear are either ReLU or linear units) can be posed as as
linear program. Specifically, considering the FICNN net-

Although the LP formulation is appealing in its simplicity,
in practice these optimization problems will have a number of variables equal to the total number of activations in
the entire network. Furthermore, most LP solution methods to solve such problems require that we form and invert structured matrices with blocks such as WiT Wi — the
case for most interior-point methods (Wright, 1997) or even
approximate algorithms such as the alternating direction
method of multipliers (Boyd et al., 2011) — which are large
dense matrices or have structured forms such as non-cyclic
convolutions that are expensive to invert. Even incremental
approaches like the Simplex method require that we form
inverses of subsets of columns of these matrices, which are
additionally different for structured operations like convolutions, and which overall still involve substantially more
computation than a single forward pass. Furthermore, such
solvers typically do not exploit the substantial effort that
has gone in to accelerating the forward and backward computation passes for neural networks using hardware such
as GPUs. Thus, as a whole, these do not present a viable
option for optimizing the networks.

Input Convex Neural Networks: Supplementary Material

Algorithm 1 A typical bundle method to optimize f :
Rm×n → R over Rn for K iterations with a fixed x and
initial starting point y 1 .
function B UNDLE M ETHOD(f , x, y 1 , K)
G ← 0 ∈ RK×n
h ← 0 ∈ RK
for k = 1, K do
GTk ← ∇y f (x, y k ; θ)T
. kth row of G
hk ← f (x, y k ; θ) − ∇y f (x, y k ; θ)T y k
y k+1 , tk+1 ← argminy∈Y,t {t | G1:k y+h1:k ≤
t1}
end for
return y K+1
end function

C. The bundle method for approximate
inference in ICNNs
We here review the basic bundle method (Smola et al.,
2008) that we build upon in our bundle entropy method.
The bundle method takes advantage of the fact that for a
convex objective, the first-order approximation at any point
is a global underestimator of the function; this lets us maintain a piecewise linear lower bound on the function by
adding cutting planes formed by this first order approximation, and then repeatedly optimizing this lower bound.
Specifically, the process follows the procedure shown in
Algorithm 1. Denoting the iterates of the algorithm as y k ,
at each iteration of the algorithm, we compute the first order approximation to the function
f (x, y k ; θ) + ∇y f (x, y k ; θ)T (y − y k )

(23)

and update the next iteration by solving the optimization
problem
y k+1 := argmin max {f (x, y i ; θ)+∇y f (x, y i ; θ)T (y−y i )}.
y∈Y

1≤i≤k

(24)
A bit more concretely, the optimization problem can be
written via a set of linear inequality constraints
y k+1 , tk+1 := argmin {t | Gy + h ≤ t1}

(25)

y∈Y,t

where G ∈ Rk×n has rows equal to
giT = ∇y f (x, y i ; θ)T

(26)

and h ∈ Rk has entries equal to
hi = f (x, y i ; θ) − ∇y f (x, y i ; θ)T y i .

D. Bundle Entropy Algorithm
In Algorithm 2.

(27)

Algorithm 2 Our bundle entropy method to optimize f :
Rm × [0, 1]n → R over [0, 1]n for K iterations with a fixed
x and initial starting point y 1 .
function B UNDLE E NTROPY M ETHOD(f , x, y 1 , K)
G` ← [ ]
h` ← [ ]
for k = 1, K do
A PPEND(G` , ∇y f (x, y k ; θ)T )
A PPEND(h` , f (x, y k ; θ) − ∇y f (x, y k ; θ)T y k )
ak ← L ENGTH(G` )
. The number of active
constraints.
Gk ← C ONCAT(G` )∈ Rak ×n
hk ← C ONCAT(h` )∈ Rak
if ak = 1 then
λk ← 1
else
λk ← P ROJ N EWTON L OGISTIC(Gk , hk )
end if
y k+1 ← (1 + exp(GTk λk ))−1
D ELETE(G` [i] and h` [i] where λi ≤ 0) . Prune
inactive constraints.
end for
return y K+1
end function

E. Deep Q-learning with ICNNs
In Algorithm 3.

Input Convex Neural Networks: Supplementary Material

Algorithm 3 Deep Q-learning with ICNNs. Opt-Alg
is a convex minimization algorithm such as gradient descent or the bundle entropy method. Q̃θ is the objective
the optimization algorithm solves. In gradient descent,
Q̃θ (s, a) = Q(s, a|θ) and with the bundle entropy method,
Q̃θ (s, a) = Q(s, a|θ) + H(a).
Select a discount factor γ ∈ (0, 1) and moving average
factor τ ∈ (0, 1)
Initialize the ICNN −Q(s, a|θ) with target network parameters θ0 ← θ and a replay buffer R ← ∅
for each episode e = 1, E do
Initialize a random process N for action exploration
Receive initial observation state s1
for i = 1, I do
ai ← O PT-A LG(−Qθ , si , ai,0 )+Ni . For some
initial action ai,0
Execute ai and observe ri+1 and si+1
I NSERT(R, (si , ai , si+1 , ri+1 ))
Sample a random minibatch from the replay
buffer: RM ⊆ R
+
for (sm , am , s+
m , rm ) ∈ RM do
+
+
am ← O PT-A LG(−Qθ0 ,s+
m ,am,0 ) . Uses the
0
target parameters θ
+
+ 0
ym ← rm
+ γQ(s+
m , am |θ )
end for
Update θ with a gradient step to minimize L =
2
P
1
m Q̃(sm , am |θ) − ym
|RM |
θ0 ← τ θ + (1 − τ )θ0
. Update the target
network.
end for
end for

F. Max-margin structured prediction
In the more traditional structured prediction setting, where
we do not aim to fit the energy function directly but fit
the predictions made by the system to some target outputs, there are different possibilities for learning the ICNN
parameters. One such method is based upon the maxmargin structured prediction framework (Tsochantaridis
et al., 2005; Taskar et al., 2005). Given some training example (x, y ? ), we would like to require that this example
has a joint energy that is lower than all other possible values for y. That is, we want the function f˜ to satisfy the
constraint
f˜(x, y ? ; θ) ≤ min f˜(x, y; θ)
(28)
y

Unfortunately, these conditions can be trivially fit by
choosing a constant f˜ (although the entropy term alleviates this problem slightly, we can still choose an approximately constant function), so instead the max-margin approach adds a margin-scaling term that requires this gap to
be larger for y further from y ? , as measured by some loss

function ∆(y, y ? ). Additionally adding slack variables to
allow for potential violation of these constraints, we arrive
at the typical max-margin structured prediction optimization problem
minimize
θ,ξ≥0

m
X
λ
kθk22 +
ξi
2
i=1



subject to f˜(xi , yi ; θ) ≤ min f˜(xi , y; θ) − ∆(yi , y) − ξi
y∈Y

(29)
As a simple example, for multiclass classification tasks
where y ? denotes a “one-hot” encoding of examples, we
can use a multi-variate entropy term and let ∆(y, y ? ) =
y ? T (1 − y).
Training requires solving this “lossaugmented” inference problem, which is convex for suitable choices of the margin scaling term.
The optimization problem (29) is naturally still not convex in θ, but can be solved via the subgradient method for
structured prediction (Ratliff et al., 2007). This algorithm
iteratively selects a training example xi , yi , then 1) solves
the optimization problem
y ? = argmin f (xi , y; θ) − ∆(yi , y)

(30)

y∈Y

and 2) if the margin is violated, updates the network’s parameters according to the subgradient
θ := P+ [θ − α (λθ + ∇θ f (xi , yi , θ) − ∇θ f (xi , y ? ; θ))]
(31)
(z)
where P+ denotes the projection of W1:k−1 onto the nonnegative orthant. This method can be easily adapted to use
mini-batches instead of a single example per subgradient
step, and also adapted to alternative optimization methods
like AdaGrad (Duchi et al., 2011) or ADAM (Kingma &
Ba, 2014). Further, a fast approximate solution to y ? can
be used instead of the exact solution.

G. Proof of Proposition 3
Proof (of Proposition 3). We have by the chain rule that
∂`
∂`
=
∂θ
∂ ŷ



∂ ŷ ∂G ∂ ŷ ∂h
+
∂G ∂θ
∂h ∂θ


.

(32)

The challenging terms to compute in this equation are the
∂ ŷ
∂ ŷ
∂G and ∂h terms. These can be computed (although we
will ultimately not compute them explicitly, but just compute the product of these matrices and other terms in the
Jacobian), by implicit differentiation of the KKT conditions. Specifically, the KKT conditions of the bundle entropy method (considering only the active constraints at the

Input Convex Neural Networks: Supplementary Material

H. State and action space sizes in the OpenAI
gym MuJoCo benchmarks.

solution) are given by
1 + log ŷ − log(1 − ŷ) + GT λ = 0
Gŷ + h − t1 = 0

Environment
InvertedPendulum-v1
InvertedDoublePendulum-v1
Reacher-v1
HalfCheetah-v1
Swimmer-v1
Hopper-v1
Walker2d-v1
Ant-v1
Humanoid-v1
HumanoidStandup-v1

(33)

T

1 λ = 1.
For simplicity of presentation, we consider first the Jacobian with respect to h. Taking differentials of these equations with respect to h gives

diag

1
1
+
ŷ 1 − ŷ



dy + GT dλ = 0

Gdy + dh − dt1 = 0

(34)

# State
4
11
11
17
8
11
17
111
376
376

# Action
1
1
2
6
2
3
6
8
17
17

1T dλ = 0
or in matrix form



1
diag ŷ1 + 1−ŷ


G
0

Table 4. State and action space sizes in the OpenAI gym MuJoCo
benchmarks.


 

dy
0
0

−1  dλ  =  −dh  .
dt
0
0
(35)
∂ ŷ
To compute the Jacobian ∂h
we can solve the system above
with the right hand side given by dh = I, and the resulting
dy term will be the corresponding Jacobian. However, in
our ultimate objective we always left-multiply the proper
terms in the above equation by ∂∂`ŷ . Thus, we instead define
GT
0
−1T


 
cy
diag ŷ1 +
 cλ  = 

G
ct
0


1
1−ŷ



GT
0
−1T

−1 
0
−( ∂∂`ŷ )T
 
0
−1 
0
0
(36)

We begin with a simple example to illustrate the classification performance of a two-hidden-layer FICNN and
PICNN on two-dimensional binary classification tasks
from the scikit-learn toolkit (Pedregosa et al., 2011). Figure 4 shows the classification performance on the dataset.
The FICNN’s energy function which is fully convex in
X × Y jointly is able to capture complex, but sometimes
restrictive decision boundaries. The PICNN, which is non convex over X but convex over Y overcomes these restric tions and can capture more complex decision boundaries.

and we have the the simple formula for the Jacobian product
∂` ∂ ŷ
= (cλ )T .
(37)
∂ ŷ ∂h
A similar set of operations taking differentials with respect
to G leads to the matrix equations




diag



1
ŷ

+
G
0

1
1−ŷ



GT
0
−1T

I. Synthetic classification examples


 

0
dy
−dGT λ

−1   dλ  =  −dGy 
dt
0
0
(38)

and the corresponding Jacobian products / gradients are
given by
∂` ∂ ŷ
= cy λT + ŷ(cλ )T .
(39)
∂ ŷ ∂G
Finally, using the definitions that
giT = ∇y f (x, y i ; θ)T , hi = f (x, y k ; θ)−∇y f (x, y i ; θ)T y i
(40)
we recover the formula presented in the proposition.

J. Multi-Label Classification Training Plots
In Figure 5.

K. Image Completion
The losses are in Figure 6.

Input Convex Neural Networks: Supplementary Material

Figure 4. FICNN (top) and PICNN (bottom) classification of synthetic non-convex decision boundaries. Best viewed in color.

Figure 5. Training (blue) and test (red) macro-F1 score of a feedforward network (left) and PICNN (right) on the BibTeX multi-label
classification dataset. The final test F1 scores are 0.396 and 0.415, respectively. (Higher is better.)

Figure 6. Mean Squared Error (MSE) on the train (blue, rolling over 1 epoch) and test (red) images from Olivetti faces for PICNNs
trained with the bundle entropy method (left) and back optimization (center), and back optimization with the convexity constraint
relaxed (right). The minimum test MSEs are 833.0, 872.0, and 850.9, respectively.

