Prediction and Control with Temporal Segment Models

A. Appendix
Here we give a more precise description of the architectures of the models we introduced in the paper. Both the
dynamics model and the latent action prior were trained
using Adam with the default parameters.
A.1. Dynamics Model
The following figure depicts the detailed encoder and decoder architectures for our dynamics models. The encoder
uses 1D-convolutions (across the temporal dimension) and
the ReLU activation function. The decoder is autoregressive, using dilated causal 1D-convolutions and the gated
activation function described in Section 3.1.
The layer sizes indicated below correspond to the model we
trained for the basic Reacher environment. For the obstacle and pushing environments, we used the same encoder
architecture. The decoder for those environments had 64
channels in all layers, and had an additional 1 Ã— 1 convolution with 128 channels before the final layer.

Dynamics Model
Encoder, Q(x)
Input

32 c

2 x 1 conv
stride 1

Sampled Output

16 c

2 x 1 conv
stride 2

atten,
project

Z

X+

Z
2

Z

Decoder, P(x)
Input

Output

X
32 c

U

U+

Z

2 x 1 dilated conv
rate 1

32 c
3 x 1 dilated conv
rate 2

32 c
2 x 1 dilated conv
rate 4

1 x 1 conv

X+

Prediction and Control with Temporal Segment Models

A.2. Latent Action Prior
The architecture for the latent action prior is quite similar
to that of our dynamics models as depicted on the previous
page. We used the same architecture for all experiments.

Latent Action Prior
Encoder, Q(u)
Input

12 c

2 x 1 conv
stride 1

Sampled Output

12 c

2 x 1 conv
stride 2

atten,
project

Z

Z
2

Z

Decoder, P(u)
Input

Output
32 c

U

Z

2 x 1 dilated conv
rate 1

32 c
3 x 1 dilated conv
rate 2

32 c
2 x 1 dilated conv
rate 4

1 x 1 conv

