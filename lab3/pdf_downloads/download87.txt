Efﬁcient Online Bandit Multiclass Learning

A. Adaptive Tuning of the Exploration Rate

√
In Theorem 2 we have presented a tuning of γ that guarantees a regret of the order of Õ( η1 T ). However, this setting
requires to upper bound the sum of the quadratic terms with a worst case bound. In this section, we develop an adaptive
strategy for the tuning of the exploration rate γ that guarantees an optimal bound w.r.t. to the tightest sum of the quadratic
terms.
First, we make rate
dependent of the time, i.e. γt . Our aim
is to choose γt in each time step in order to minimize the excess
��
�T k T −1 �
T
1
mistake bound E
t=1 γt + η(2−η)
t=1 γt zt At zt . The main result is that, adaptively setting γt ’s would result in a
bound within (roughly) a constant factor of that obtained by the best ﬁxed γ in hindsight. We start with a technical lemma.
�� �
�
b+ t−1
s=1 cs
, 1 . We
Lemma 4. Let c1 , . . . , cT ∈ [0, b] be a sequence of real numbers, a > 0, and deﬁne γt = min
t

have,

T �
�

γt + a

t=1

ct
γt

�

�
�
T
T
�
�
√ �
≤ (2 + 2a) T �b +
ct + a
ct .
t=1

t=1

Proof. First, note that
T
�
t=1

γt ≤

T
�
t=1

�

�
�
�
�
T �
T
T
�
�
�
�
�
√
b + s=1 cs
1
�
≤ b+
≤ 2 T �b +
cs
cs .
t
t
s=1
t=1
s=1
�t−1

Second, using the elementary chain of inequalities max(a, b) ≤ a + b, ∀a, b ≥ 0, we have that


√
T
T
�
�
ct
t
c
t

=
max  �
�t−1 , ct
γ
t
t=1
t=1
b + s=1 cs
≤

≤

T
�
√
t=1

T

�
ct
T�
ct
�t−1 +
b + s=1 cs t=1

T
√ �
c
�� t
T
t=1

t
s=1 cs

+

T
�

ct

t=1

�
�
T
T
�
�
√ �
�
≤2 T b+
cs +
ct ,
s=1

t=1

where the last inequality uses Lemma 3.5 of (Auer et al., 2002). Combining the two inequalities, we get the desired
result.
Built upon the lemma above, we show that, tailored to our setting, the adaptive tuning would result in a bound within a
constant factor of that achieved by the best ﬁxed γ in hindsight.
��
�
�
−1
T
k(1+ t−1
s=1 zs As zs )
Theorem 5. Running SOBA with the adaptive setting of γt = min
, 1 and a = X 2 , we have that
t
�

E[M ] ≤ Lη (U ) + O X

2

�U �2F

1 √
+ ( dk 2 T ln T + dk 2 ln T )
η

�

Proof Sketch. Following the same proof as Theorem 3, we get that
T
�
�
�
k T −1
aη�U �2F
1
E M̂T ≤ Lη (U ) +
z A zt ]
+
E[
2−η
η(2 − η) t=1 γt t t

.

Efﬁcient Online Bandit Multiclass Learning

Meanwhile by triangle inequality,

E[MT ] ≤ E[M̂T ] + E

�

T
�
t=1

�

1[ỹt �= ŷt ] ≤ E[M̂T ] + E

�

T
�

γt

t=1

�

.

Combining the two inequalities above, we get
�
�
T
T
�
�
k ztT A−1
aη�U �2F
1
t zt
+
γt .
+E
E [MT ] ≤ Lη (U ) +
2−η
η(2 − η) t=1
γt
t=1
We take a closer look at the last term. Lemma 4 with ct = kztT A−1
t zt ∈ [0, k], b = k, a =
T
�
t=1

1
η(2−η) ,

implies that

T
�

k
ztT A−1
t zt
η(2
−
η)γ
t
t=1
�
�
�
�
T
T
�
�
�
√
2
1
−1
�
T
k(1 +
≤ 2+
T k(1 +
zt A t zt ) +
ztT A−1
t zt ) .
η(2 − η)
η(2
−
η)
t=1
t=1

γt +

Taking
√ the expecation of both sides and using Lemma 3, we get that the last term on the right hand side is at most
12
(
dk 2 T ln T + dk 2 ln T ). This completes the proof.
η

B. Deferred Proofs
Proof of Theorem 1. Let p ≥ 2 such that p1 +
an update, i.e. makes a mistake. We have:

1
q

= 1. Denote by bt the indicator variable that multiclass Perceptron makes

�WT +1 , U �

≤ �WT +1 �F �U �F
�
2
2
= �U �F �WT � + 2bt �WT , (eyT − eŷT ) ⊗ xT � + 2b2t �xT �2
�
2
2
≤ �U �F �WT �F + 2b2t �xT �2
≤ ···

�
� T
� �
2
≤ �U �F �2
b2t �xt �2
t=1

�
� T
√ ��
≤ �U �F X 2�
b2t
t=1

�
� T
√ ��
= �U �F X 2�
bt
t=1

Efﬁcient Online Bandit Multiclass Learning

Also, we have, that
�WT +1 , U � =
=

T
�
t=1

T
�
t=1

≥
≥
≥
=

T
�
t=1

T
�
t=1

T
�
t=1

T
�
t=1

bt �U , (eyt − eŷt ) ⊗ xt �
bt [1 − (1 − �U , (eyt − eŷt ) ⊗ xt �)]
bt [1 − |1 − �U , (eyt − eŷt ) ⊗ xt �|+ ]
bt −

T
�

bt �(U , (xt , yt ))

t=1

bt − (
bt − (

T
�

1

bpt ) p (

t=1

T
�

T
�

1

�(U , (xt , yt ))q ) q

t=1

1

bt ) p (

t=1

T
�

1

�(U , (xt , yt ))q ) q .

t=1

Putting all together we have
�
� T � p1
� T
T
�
�
√ ��
1
bt ≥
bt −
bt
LMH,q (U ) q .
�U �F X 2�
t=1

Noting that

�T

t=1 bt

t=1

t=1

is equal to number of mistake MT , we get the stated bound.

Lemma 5. Suppose we are given positive real numbers L, T, H, U and function F (γ) = min(T, L+γT + UγH +
where γ ∈ [0, 1]. Then:

�

U HL
γ ),

�
√
√
∗
1. If L ≤ (U + 1) HT , then taking γ ∗ = min( H
T , 1) gives that F (γ ) ≤ L + 3(U + 1) HT .

√
√
1
1
∗
3
3
2. If L > (U + 1) HT , then taking γ ∗ = min(( HL
T 2 ) , 1) gives that F (γ ) ≤ L + 2( U + 1)(HLT ) .

Proof. We prove the two cases separately.
√
1. If T ≤ H, then γ ∗ = 1, F (γ ∗ ) ≤ T ≤ L + 3(U + 1) HT .
�
Otherwise, T > H. In this case, γ ∗ = H
T . We have that
F (γ ∗ )

=
=
≤

≤

�
U
H
U HL
L + γ∗T + ∗ +
γ
γ∗
�
√
√
√
L + HT + U HT + U L HT
√
√
L + (U + 1) HT + L + U HT
√
L + 3(U + 1) HT .

where the ﬁrst inequality is from that arithmetic mean-geometric mean inequality, the second inequality is by the
assumption on L.

Efﬁcient Online Bandit Multiclass Learning
1

2. If HL > T 2 , then γ ∗ = 1, F (γ ∗ ) ≤ T ≤ (HLT ) 3 .
1

3
Otherwise, HL ≤ T 2 . In this case, γ ∗ = ( HL
T 2 ) . We have that

∗

F (γ )

=
=
≤
≤

UH
L+γ T + ∗ +
γ
∗

1

�

U HL ∗
γ

2

2

1

L + (HLT ) 3 + U H 3 T 3 L− 3 +
√
1
1
L + ( U + U 3 + 1)(HLT ) 3
√
1
L + 2( U + 1)(HLT ) 3 .

√

1

U (HLT ) 3

2

2

1

1

1

3
where the ﬁrst inequality is from algebra and the condition on L, implying U H 3 T 3 L− 3 ≤ (HLT ) 3 U ( HT
L2 ) ≤
√
1
1
1
U 3 (HLT ) 3 , the second inequality is from that U 3 ≤ U + 1.

C. Per-Step Analysis of Online Least Squares
For completeness, we present a technical lemma in online least squares, which has appeared in (e.g., Orabona et al., 2012).
�t
T
Lemma 6. Suppose zt ’s are vectors, and αt ’s are scalars. For all t ≥ 1, deﬁne At =
s=1 zs zs , wt =
�
t−1
−1
−At−1 s=1 αs zs . Then for any vector u, we have:
1
1
1
1
2
2
2
(�wt , zt � + αt )2 (1 − ztT A−1
t zt ) − (�u , zt � + αt ) ≤ �u − wt �At−1 − �u − wt+1 �At .
2
2
2
2

Proof. Observe that wt ’s have the following recurrence:
wt+1 = A−1
t (At−1 wt − αt zt )
Since At = At−1 + zt ztT , we have

At wt+1 = At wt − (wtT zt + αt )zt

Now, by standard online mirror descent analysis (See e.g. Cesa-Bianchi & Lugosi, 2006, proof of Theorem 11.1), we have
�

wt − u , (wtT zt + αt )zt

�

≤
≤

1
1
1
�u − wt �2At − �u − wt+1 �2At + (wtT zt + αt )2 ztT A−1
t zt
2
2
2
1
1
1
1 T
T
2
�u − wt �2At−1 − �u − wt+1 �2At + (wtT zt + αt )2 ztT A−1
t zt + (u zt − wt zt )
2
2
2
2

Now, move the last term on the RHS to the LHS, we get
1
1
1
1
(wtT zt − uT zt ) · (wtT zt + uT zt + 2αt ) ≤ �u − wt �2At−1 − �u − wt+1 �2At + (wtT zt + αt )2 ztT A−1
t zt
2
2
2
2
i.e.
1
1
1
1
1
(�wt , zt � + αt )2 − (�u , zt � + αt )2 ≤ �u − wt �2At−1 − �u − wt+1 �2At + (wtT zt + αt )2 ztT A−1
t zt .
2
2
2
2
2
Now moving the last term on the RHS to the LHS, the lemma follows.

