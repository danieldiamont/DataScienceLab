Supplementary Material for RobustFill: Neural
Program Learning under Noisy I/O
A. Attention Formulas
The formula ci = Attention(hi−1 , xi , S) is as follows:

ti

=

tanh(W [hi−1 ; xi ])

dij

= sj · ti

αij

=

ci

=

edij
P d
e ik
Xk
αij sj
j

Where i is the current timestep, hi1 is the previous hidden state, xi is the current input, S = s1 , ..., sN are the vectors being
attended to, and W is a learned parameter matrix. The interpolated context vector ci is concatenated into the input and fed
into the LSTM. In the case of double attention, the output of the first attention mechanism CiA is concatenated to the input
of the second attention, i.e.:

tB
i

=

tanh(W [hi−1 ; xi ; cA
i ])

where the remaining steps are identical.

B. DSL Extended Description
Section 3.2 of the paper provides the grammar of our domain specific language, which both defines the space of possible
programs, and allows us to easily sample programs. The formal semantics of this language are defined below in Figure 1.
The program takes as input a string v and produces a string as output (result of Concat operator).
As an implementational detail, we note that after sampling a program from the grammar, we flatten calls to nesting functions
(as defined in Figure 2 of the paper) into a single token. For example, the function GetToken(t, i) would be tokenized
as a single token GetTokent,i rather than 3 separate tokens. This is possible because for nesting functions, the size of the
total parameter space is small. For all other functions, the parameter space is too large for us to flatten function calls
without dramatically increasing the vocabulary size, so we treat parameters as separate tokens.

JConcat(e1 , e2 , e3 , ...)Kv
Jn1 (n2 )Kv
Jn(f )Kv

JConstStr(c)Kv

=
=
=
=

Concat(Je1 Kv , Je2 Kv , Je3 Kv , ...)

Jn1 Kv1 , where v1 = Jn2 Kv

JnKv1 , where v1 = Jf Kv
c

JSubStr(k1 , k2 )Kv

=

v[p1 ..p2 ], where

JGetSpan(r1 , i1 , y1 , r2 , i2 , y2 )Kv

=

v[p1 ..p2 ] ,where

JGetToken(t, i)Kv

=

p1 = y1 (Start or End) of |i1 |th match of r1 in v from beginning (end if ii < 0)
p2 = y2 (Start or End) of |i2 |th match of r2 in v from beginning (end if i2 < 0)
|i|th match of t in v from beginning (end if i < 0)

p1 = k1 > 0 ? k1 : len(v) + k1
p2 = k2 > 0 ? k2 : len(v) + k2

JGetUpto(r)Kv
JGetFrom(r)Kv

JGetFirst(t, i)Kv

JGetAll(t)Kv
JToCase(s)Kv
JTrim()Kv

JReplace(δ1 , δ2 )Kv

=

v[0..i], where i is the index of end of first match of r in v from beginning

=
=

v[j..len(v)], where j is the end of last match of r in v from end
Concat(s , · · · , s ), where s denotes the j th match of t in v

=

Concat(s1 , · · · , sm ), where si denotes the ith match of t in v and m denotes the total matches

1

i

=

ToCase(s, v)

=

Trim(v)

=

Replace(v, δ1 , δ2 )

j

Figure 1. The semantics of the DSL for string transformations.

C. Synthetic Training Data Generation
Since there are only a few hundred real-world FlashFill benchmarks, we use synthetically generated training data to train
our neural models. The key idea in data generation is to uniformly sample programs from the DSL, and then for each
sampled program, generate a set of input-output examples that are consistent with it. We now describe the key steps in the
data generation process in more detail.
First, programs are sampled randomly from the DSL. We treat the DSL as a probabilistic context free grammar (PCFG)
where the probability of expanding to any child node is uniformly random. Even though the top-level concat operator
can take an arbitrary number of expressions e, in practice, we limit it to have at most k expressions, where k is randomly
sampled from 1 to 10.
Next, the input strings are sampled from the space of all random ASCII strings with lengths between 1 and 100, using
some simple heuristics that are extracted from the sampled programs preconditions. For example, if the program contained
GetToken(Word, 2) and GetFrom(Space, 4) as sub-expressions, then we would first generate 2 words and 4 spaces, then
shuffle these and add other random ASCII characters. In this case, words are defined as random ASCII strings that match
the particular regular expression of [A-Za-z]{1,10}. Finally, to generate the output strings, we execute the program on the
input strings.
However, the extracted heuristics do not always encapsulate all preconditions exactly, as there are some edge cases that
may prevent successful execution. If the program could not be executed on an input string (e.g., say one expression in
our sampled program is SubStr(GetToken(word, 2), 1, 10)), but the 2nd word isnt 10 characters long), we simply reject
the input string and re-sample until we find one that executes successfully. We find that in practice, the pre-conditions are
usually sufficient conditions for efficient generation of viable input strings.

D. Synthetic Evaluation Details
Results on synthetically generated examples are largely omitted from the paper since, in a vacuum, the synthetic dataset can
be made arbitrarily easy or difficult via different generation procedures, making summary statistics difficult to interpret.
We instead report results on an external real-world dataset to verify that the model has learned function semantics which
are at least as expressive as programs observed in real data.

Nevertheless, we include additional details about our experiments on synthetically generated programs for readers interested in the details of our approach. As described in the paper, programs were randomly generated from the DSL by first
determining a program length up to a maximum of 10 expressions, and then independently sampling each expression. We
used a simple set of heuristics to restrict potential inputs to strings which will produce non-empty outputs (e.g. any program
which references the third occurrence of a number will cause us to sample strings containing at least three numbers). We
rejected any degenerate samples e.g. those resulting in empty outputs, or outputs longer than 100 characters.
Figure 4 shows several random synthetically generated samples.
Figure 2 shows the accuracy of each model on the synthetically generated validation set. Model accuracy on the synthetic
validation set is generally consistent with accuracy on the FlashFill dataset, with stronger models on the synthetic dataset
also demonstrating stronger performance on the real-world data.

Figure 2. Generalization accuracy for different models on the synthetic validation set

E. Examples of Synthesized Programs
Figure 5 shows several randomly sampled (anonymized) examples from the FlashFill test set, along with their predicted
programs outputted by the synthesis model.
Figure 6 shows several examples which were hand-selected to demonstrate interesting limitations of the model. In the
case of the first example, the task is to reformat international telephone numbers. Here, the task is underconstrained given
the observed input-output examples, because there are many different programs which are consistent with the observed
examples. Note that to extract the first two digits, there are many other possible functions which would produce the correct
output in the observed examples, some of which would generalize and some which would not: for exampling, getting the
second and third characters, getting the first two digits, or getting the first number. In this case, the predicted program
extracts the country code by taking the first two digits, a strategy which fails to generalize to examples with different
country codes. The third example demonstrates a difficulty of using real world data. Because examples can come from a
variety of sources, they may be irregularly formatted. In this case, although the program is consistent with the observed
examples, it does not generalize when the second space in the address is removed. In the final example, the synthesis model
completely fails, and none of the 100 highest scoring programs from the model were consistent with the observed output
examples. The selected program is the closest program scored by character edit distance.

F. Induction Network Architecture
The network architecture used in the program induction setting is described in Section 6.1 of the paper. The network
structure is a modification of synthesis Attention-A, using double attention to jointly attend to I x and Oj , and an additional
LSTM to encode I x . We include a complete diagram below in Figure 3.

Figure 3. The network architecture used for program induction. A dotted line from x to y means that x attends to y.

Reference program: GetToken_Alphanum_3 | GetFrom_Colon | GetFirst_Char_4
Ud 9:25,JV3 Obb
2525,JV3 ObbUd92
zLny xmHg 8:43 A44q
843 A44qzLny
A6 g45P 10:63 Jf
1063 JfA6g4
cuL.zF.dDX,12:31
dDX31cuLz
ZiG OE bj3u 7:11
bj3u11ZiGO
Reference program: Get_Word_-1(GetSpan(Word, 1, Start, ‘(’, 5,
Start)) | GetToken_Number_-5 | GetAll_Proper | SubStr(-24, -14) |
GetToken_Alphanum_-2 | EOS
4 Kw ( )SrK (11 (3 CHA xVf )4 )8 Qagimg ) (
Qagimg4Kw Sr Vf QagimgVf )4
)(vs
)8 QaQagimg
iY) )hspA.5 ( )8,ZsLL (nZk.6 (E4w )2(Hpprsqr
Hpgjprsqr8Zs Zk Hpprsqrk.6
)2(Z
(E4w )22
Cqg) ) ( (1005 ( ( )VCE hz ) (10 Hadj )zg
hz10005Cqg Hadj Tqwpaxft
Tqwpaxft-7 5 6
Hadj )zg T5
JvY) (Ihitux ) ) ( (6 SFl (7 XLTD sfs )
lU7Jv Ihitux Frl XLTD sfs )6
)11,lU7 (6 9
NjtT(D7QV (4 (yPuY )8.sa ( ) )6 aX 4 )DXR (
DXR4Njt Pu Ztje)6 aX 4 )DX6
@6 ) Ztje
Reference program: GetToken_AllCaps_-2(GetSpan(AllCaps, 1, Start,
AllCaps, 5, Start)) | EOS
YDXJZ @ZYUD Wc-YKT GTIL BNX
W
JUGRB.MPKA.MTHV,tEczT-GZJ.MFT
MTHV
VXO.OMQDK.JC-OAR,HZGH-DJKC
JC
HCUD-WDOC,RTTRQ-KVETK-whx-DIKDI
RTTRQ
JFNB.Avj,ODZBT-XHV,KYB @,RHVVW
ODZBT
Reference program: SubStr(-20, -8) | GetToken_AllCaps_-3 | SubStr(11,
19) | GetToken_Alphanum_-5 | EOS
DvD 6X xkd6 OZQIN ZZUK,nCF aQR IOHR
IN ZZUK,nCF aCFv OZQIN
ZOZQIN
BHP-euSZ,yy,44-CRCUC,ONFZA.mgOJ.Hwm
CRCUC,ONFZA.mONFZAy,44-CRCU44
NGM-8nay,xrL.GmOc.PFLH,CMFEX-JPFA,iIcj,329

,CMFEX-JPFA,iCMFEXrL.GmOc.PPFLH

hU TQFLD Lycb NCPYJ oo FS TUM l6F

NCPSYJ oo FS FScb NCPYJ
NCPYJ
L 8Ucj dUqh CUXKQRN KDLKDL

OHHS NNDQ XKQRN KDL 8Ucj dUqh Cpk Kafj

Figure 4. Randomly sampled programs and corresponding input-output examples, drawn from training data. Multi-line examples are all
broken into lines on spaces.

Model prediction:
EOS
[CPT-101
[CPT-101
[CPT-11]
[CPT-1011]
[CPT-1011
[CPT-1012
[CPT-101]
[CPT-111]
[CPT-1011]
[CPT-101]

GetSpan(‘[’, 1, Start, Number, 1, End) | Const(]) |
[CPT-101]
[CPT-101]
[CPT-11]
[CPT-1011]
[CPT-1011]
[CPT-1012]
[CPT-101]
[CPT-111]
[CPT-1011]
[CPT-101]

[CPT-101]
[CPT-101]
[CPT-11]
[CPT-1011]
[CPT-1011]
[CPT-1012]
[CPT-101]
[CPT-111]
[CPT-1011]
[CPT-101]

Model prediction: Replace_Space_Comma(GetSpan(Proper, 1, Start, Proper,
4, End) | Const(.) | GetToken_Proper_-1 | EOS
Jacob Ethan James
Jacob,Ethan,James,Alexander.-Jacob,Ethan,James,Alexander.Alexander Michael
Michael
Michael
Elijah Daniel Aiden
Elijah,Daniel,Aiden,Matthew.-Elijah,Daniel,Aiden,Matthew.Matthew Lucas
Lucas
Lucas
Jackson Oliver
Jackson,Oliver,Jayden,Chris.-Jackson,Oliver,Jayden,Chris.Jayden Chris Kevin
Kevin
Kevin
Earth Fire Wind
Earth,Fire,Wind,Water.Sun
Earth,Fire,Wind,Water.Sun
Water Sun
Tom Mickey Minnie
Tom,Mickey,Minnie,Donald.Daffy
Tom,Mickey,Minnie,Donald.Daffy
Donald Daffy
Jacob Mickey Minnie
Jacob,Mickey,Minnie,Donald.- Jacob,Mickey,Minnie,Donald.Donald Daffy
Daffy
Daffy
Gabriel Ethan James
Gabriel,Ethan,James,AlexanderGabriel,Ethan,James,Alexander.Alexander Michael
.Michael
Michael
Rahul Daniel Aiden
Rahul,Daniel,Aiden,Matthew.- Rahul,Daniel,Aiden,Matthew.Matthew Lucas
Lucas
Lucas
Steph Oliver Jayden
Steph,Oliver,Jayden,Chris.Kevin
Steph,Oliver,Jayden,Chris.Kevin
Chris Kevin
Pluto Fire Wind
Pluto,Fire,Wind,Water.Sun
Pluto,Fire,Wind,Water.Sun
Water Sun

Model prediction:
Emma Anders
Olivia Berglun
Madison Ashworth
Ava Truillo
Isabella
Mia
Emma Stevens
Chris Charles
Liam Lewis
Abigail Jones

GetAll_Proper | EOS
Emma Anders
Olivia Berglun
Madison Ashworth
Ava Truillo
Isabella
Mia
Emma Stevens
Chris Charles
Liam Lewis
Abigail Jones

Emma Anders
Olivia Berglun
Madison Ashworth
Ava Truillo
Isabella
Mia
Emma Stevens
Chris Charles
Liam Lewis
Abigail Jones

Figure 5. Random samples from the FlashFill test set. The first two columns are InStr and OutStr respectively, and the third column
is the execution result of the predicted program. Example strings which do not fit on a single line are broken on spaces, or hyphenated
when necessary. All line-ending hyphens are inserted for readability, and are not part of the example.

Model prediction: GetToken_Proper_1 | Const(.) |
GetToken_Char_1(GetToken_Proper_-1) | Const(@) | EOS
Mason Smith
Mason.S@
Lucas Janckle
Lucas.J@
Emily Jacobnette
Emily.B@
Charlotte Ford
Charlotte.F@
Harper Underwood
Harper.U@
Emma Stevens
Emma.S@
Chris Charles
Chris.C@
Liam Lewis
Liam.L@
Olivia Berglun
Olivia.B@
Abigail Jones
Abigail.J@

Mason.S@
Lucas.J@
Emily.B@
Charlotte.F@
Harper.U@
Emma.S@
Chris.C@
Liam.L@
Olivia.B@
Abigail.J@

Figure 5. Random samples from the FlashFill test set. The first two columns are InStr and OutStr respectively, and the third column
is the execution result of the predicted program. Example strings which do not fit on a single line are broken on spaces, or hyphenated
when necessary. All line-ending hyphens are inserted for readability, and are not part of the example.

Model prediction: GetFirst_Digit_2 | Const(.) | GetToken_Number_2 |
Const(.) | GetToken_Number_3 | Const(.) | GetToken_Alpha_-1 | EOS
+32-2-704-33
32.2.704.33
32.2.704.33
+44-118-909-3574
44.118.909.3574
44.118.909.3574
+90-212-326 5264
90.212.326.5264
90.212.326.5264
+44 118 909 3843
44.118.909.3843
44.118.909.3843
+386 1 5800 839
386.1.5800.839
38.1.5800.839
+1 617 225 2121
1.617.225.2121
16.617.225.2121
+91-2-704-33
91.2.704.33
91.2.704.33
+44-101-909-3574
44.101.909.3574
44.101.909.3574
+90-212-326 2586
90.212.326.2586
90.212.326.2586
+44 118 212 3843
44.118.212.3843
44.118.212.3843

Model prediction: GetFirst_Char_1 |
GetToken_Proper_4 ) | Const(.) | EOS
Milk 4, Yoghurt 12, Juice 2 Lassi 5
Alpha 10 Beta 20 Charlie 40 60
Epsilon
Sumit 7 Rico 12 Wolfram 15 Rick 19
Us 38 China 35 Russia 27 India 1
10 Apple 2 Oranges 13 Bananas 40
Pears
10 Bpple 2 Oranges 13 Bananas 40
Pears
Milk 4, Yoghurt 12, Juice 2 Massi 5
Alpha 10 Beta 20 Charlie 40 60 Delta

Const(.)

| GetFirst_Char_1(

M.L.
A.E.

M.L.
A.E.

S.R.
U.I.
A.P.

S.R.
U.I.
1.P.

B.P.

1.P.

M.M.
A.D.

M.M.
A.D.

Parul 7 Rico 12 Wolfram 15 Rick 19
Us 38 China 35 Russia 27 America 1

P.R.
U.A.

P.R.
U.A.

Model prediction:
1, End)) | EOS
212 2nd Avenue
124 3rd Avenue
123 4th Avenue
999 5th Avenue
123 1st Avenue
223 1stAvenue
112 2nd Avenue
224 3rd Avenue
123 5th Avenue
99 5th Avenue

212-2nd-Avenue
124-3rd-Avenue
123-4th-Avenue
999-5th-Avenue
123-1st-Avenue
223-1st-Avenue
112-2nd-Avenue
224-3rd-Avenue
123-5th-Avenue
99-5th-Avenue

Replace_Space_Dash(GetSpan(AlphaNum, 1, Start, Proper,
212-2nd-Avenue
124-3rd-Avenue
123-4th-Avenue
999-5th-Avenue
123-1st-Avenue
223-1stAvenue
112-2nd-Avenue
224-3rd-Avenue
123-5th-Avenue
99-5th-Avenue

Figure 6. Selected samples of incorrect model predictions on the Flashfill test set. These include both inconsistent programs, and
consistent programs which failed to generalize.

Model prediction: GetToken_Word_1 | Const(-) | GetToken_Proper_1(GetSpan(‘;’,
-5, Start, ‘#’, 5, Start)) | GetUpto_Comma Replace_Space_Dash
| GetToken_Word_1(GetSpan(Proper, 4, End, ‘$’, 5, End)) |
GetToken_Number_-5 | GetSpan(‘#’, 5, End, ‘$’, 5, Start) | EOS
28;#DSI;#139;#ApplicationVirt-DSI-ApplicationVirtualization-BDSI-Application
ualization;#148;#BPOS;#138;#MiPOS-Microsoft PowerPoint
crosoft PowerPoint
102;#Excel;#14;#Meetings;#55;-Excel-Meetings-OneNote-Word
Excel-Meetings
#OneNote;#155;#Word
19;#SP Workflow
SP Workflow SolutSP Workflow
Solutions-Excel
Solutions;#102;#Excel;#194;- ions-Excel-Excel
#Excel Services;#46;#BI
Services-BI
37;#PowerPoint;#141;#Meetings;PowerPoint-Meetings-OneNote-Word
PowerPoint-Meetings
#55;#OneNote;#155;#Word
148;#Access;#102;#Excel;#194- Access-Excel-Excel
Access-Excel
;#Excel Services;#46;#BI
Services-BI
248;#Bccess;#102;#Excel;#194;-Bccess-Excel-Excel
Bccess-Excel
#Excel Services;#46;#BI
Services-BI
DCI-Application
28;#DCI;#139;#ApplicationVirt-DCI-ApplicationVirtualizatualization;#148;#BPOS;#138;#- ion-BPOS-Microsoft
PowerPoint
Microsoft PowerPoint
12;#Word;#141;#Meetings;#55;#OWord-Meetings-OneNote-Word
Word-Meetings
neNote;#155;#Word
AP Workflow Solutions-ExAP Workflow
99;#AP Workflow Solutions;cel-Excel Services-BI
Solutions-Excel
#102;#Excel;#194;#Excel
Services;#46;#BI
137;#PowerPoint;#141;#Meetings;PowerPoint-Meetings-OneNoPowerPoint-Meetings
#55;#OneNote;#155;#Excel
te-Excel

Figure 6. Selected samples of incorrect model predictions on the Flashfill test set. These include both inconsistent programs, and
consistent programs which failed to generalize.

