Supplemental Materials for:
Estimating individual treatment effect: generalization bounds and algorithms

Uri Shalit * 1 Fredrik D. Johansson * 2 David Sontag 2 3

A. Proofs
A.1. Definitions, assumptions, and auxiliary lemmas
We first define the necessary distributions and prove some
simple results about them. We assume a joint distribution function p(x, t, Y0 , Y1 ), such that (Y1 , Y0 ) âŠ¥
âŠ¥ t|x, and
0 < p(t = 1|x) < 1 for all x. Recall that we assume Consistency, that is we assume that we observe y = Y1 |(t = 1)
and y = Y0 |(t = 0).
Definition A1. The treatment effect for unit x is:
Ï„ (x) := E [Y1 âˆ’ Y0 |x] .
We first show that under consistency and strong ignorability, the ITE function Ï„ (x) is identifiable:

Assumption A1. The representation function Î¦ is one-toone. Without loss of generality we will assume that R is
the image of X under Î¦, and define Î¨ : R â†’ X to be the
inverse of Î¦, such that Î¨(Î¦(x)) = x for all x âˆˆ X .
Definition A3. For a representation function Î¦ : X â†’ R,
and for a distribution p defined over X , let pÎ¦ be the distribution induced by Î¦ over R. Define pt=1
Î¦ (r) := pÎ¦ (r|t =
(r)
:=
p
(r|t
=
0),
to
be
the
treatment
and control
1), pt=0
Î¦
Î¦
distributions induced over R.
For a one-to-one Î¦, the distribution pÎ¦ over R Ã— {0, 1} can
be obtained by the standard change of variables formula,
using the determinant of the Jacobian of Î¨(r). See (BenIsrael, 1999) for the case of a mapping Î¦ between spaces
of different dimensions.
Lemma A2. For all r âˆˆ R, t âˆˆ {0, 1}:

Lemma A1. We have:

pÎ¦ (t|r) = p(t|Î¨(r))
p(Yt |r) = p(Yt |Î¨(r)).

E [Y1 âˆ’ Y0 |x] =
E [Y1 |x] âˆ’ E [Y0 |x] =

(1)

E [Y1 |x, t = 1] âˆ’ E [Y0 |x, t = 0] =

(2)

E [y|x, t = 1] âˆ’ E [y|x, t = 0] .
Equality (1) is because we assume that Yt and t are independent conditioned on x. Equality (2) follows from the
consistency assumption. Finally, the last equation is composed entirely of observable quantities and can be estimated from data since we assume 0 < p(t = 1|x) < 1
for all x.
Definition A2. Let pt=1 (x) := p(x|t = 1), and
pt=0 (x) := p(x|t = 0) denote respectively the treatment
and control distributions.
Let Î¦ : X â†’ R be a representation function. We will
assume that Î¦ is differentiable.
*

Equal contribution 1 CIMS, New York University, New
York, NY 10003 2 IMES, MIT, Cambridge, MA 02142
3
CSAIL, MIT, Cambridge, MA 02139.
Correspondence
to: Uri Shalit <shalit@cs.nyu.edu>, Fredrik D. Johansson
<fredrikj@mit.edu>.
Proceedings of the 34 th International Conference on Machine
Learning, Sydney, Australia, PMLR 70, 2017. Copyright 2017
by the author(s).

Proof. Let JÎ¨ (r) be the absolute of the determinant of the
Jacobian of Î¨(r).
pÎ¦ (t|r) =

pÎ¦ (t, r) (a) p(t, Î¨(r))JÎ¨ (r)
=
=
pÎ¦ (r)
p(Î¨(r))JÎ¨ (r)

p(t, Î¨(r))
= p(t|Î¨(r)),
p(Î¨(r))
where equality (a) is by the change of variable formula.
The proof is identical for p(Yt |r).
Let L : Y Ã— Y â†’ R+ be a loss function, e.g. the absolute
loss or squared loss.
Definition A4. Let Î¦ : X â†’ R be a representation function. Let h : RÃ—{0, 1} â†’ Y be an hypothesis defined over
the representation space R. The expected loss for the unit
and treatment pair (x, t) is:
Z
`h,Î¦ (x, t) =
L(Yt , h(Î¦(x), t))p(Yt |x)dYt
Y

Definition A5. The expected factual loss and counterfactual losses of h and Î¦ are, respectively:
Z
F (h, Î¦) =
`h,Î¦ (x, t) p(x, t) dxdt
X Ã—{0,1}

Estimating individual treatment effect: generalization bounds and algorithms

Notation:
p(x, t): distribution on X Ã— {0, 1}
u = p(t = 1): the marginal probability of treatment.
pt=1 (x) = p(x|t = 1): treated distribution. pt=0 (x) = p(x|t = 0): control distribution.
Î¦: representation function mapping from X to R.
Î¨: the inverse function of Î¦, mapping from R to X .
pÎ¦ (r, t): the distribution induced by Î¦ on R Ã— {0, 1}.
t=0
pt=1
Î¦ (r), pÎ¦ (r): treated and control distributions induced by Î¦ on R.
L(Â·, Â·): loss function, from Y Ã— Y to R+ .
`h,Î¦ (x, t): the expected loss of h(Î¦(x), t) for the unit x and treatment t.
F (h, Î¦), CF (h, Î¦): expected factual and counterfactual loss of h(Î¦(x), t).
Ï„ (x) := E [Y1 âˆ’ Y0 |x], the expected treatment effect for unit x.
PEHE (f ): expected error in estimating the individual treatment effect of a function f (x, t).
IPMG (p, q): the integral probability metric distance induced by function family G between distributions p and q.
Z
CF (h, Î¦) =

`h,Î¦ (x, t) p(x, 1
X Ã—{0,1}

âˆ’ t) dxdt.

When it is clear from the context, we will sometimes use
F (f ) and CF (f ) for the expected factual and counterfactual losses of an arbitrary function f : X Ã— {0, 1} â†’ Y.
Definition A6. The expected treated and control losses
are:
Z
t=1
(h,
Î¦)
=
`h,Î¦ (x, 1) pt=1 (x) dx
F
X

t=0
F (h, Î¦) =

Z

`h,Î¦ (x, 0) pt=0 (x) dx

IPMG (Â·, Â·) defines a pseudo-metric on the space of probability functions over S, and for sufficiently large function
families, IPMG (Â·, Â·) is a proper metric (MuÌˆller, 1997). Examples of sufficiently large functions families includes the
set of bounded continuous functions, the set of 1-Lipschitz
functions, and the set of unit norm functions in a universal Reproducing Norm Hilbert Space. The latter two give
rise to the Wasserstein and Maximum Mean Discrepancy
metrics, respectively (Gretton et al., 2012; Sriperumbudur
et al., 2012). We note that for function families G such as
the three mentioned above, for which g âˆˆ G =â‡’ âˆ’g âˆˆ
G, the absolute value can be omitted from definition A7.

X

t=1
CF (h, Î¦) =

Z

`h,Î¦ (x, 1) pt=0 (x) dx

X

t=0
CF (h, Î¦) =

Z

`h,Î¦ (x, 0) pt=1 (x) dx.

X

The four losses above are simply the loss conditioned on
either the control or treated set. Let u := p(t = 1) be the
proportion of treated in the population. We then have the
immediate result:
Lemma A3.

A.2. General IPM bound
We now state and prove the most important technical
lemma of this section.
Lemma A4 (Lemma 1, main text). Let Î¦ : X â†’ R be an
t=0
invertible representation with Î¨ its inverse. Let pt=1
Î¦ , pÎ¦
be defined as in Definition A3. Let u = p(t = 1). Let
G be a family of functions g : R â†’ R, and denote by
IPMG (Â·, Â·) the integral probability metric induced by G.
Let h : RÃ—{0, 1} â†’ Y be an hypothesis. Assume there exists a constant BÎ¦ > 0, such that for t = 0, 1, the function
gÎ¦,h (r, t) := B1Î¦ Â· `h,Î¦ (Î¨(r), t) âˆˆ G. Then we have:

t=0
F (h, Î¦) = u Â· t=1
F (h, Î¦) + (1 âˆ’ u) Â· F (h, Î¦)

CF (h, Î¦) â‰¤
t=0
(1 âˆ’ u)t=1
F (h, Î¦) + uF (h, Î¦)+

t=0
BÎ¦ Â· IPMG pt=1
.
Î¦ , pÎ¦

t=0
CF (h, Î¦) = (1 âˆ’ u) Â· t=1
CF (h, Î¦) + u Â· CF (h, Î¦).

The proof is immediate, noting that p(x, t) = u Â· pt=1 (x) +
(1 âˆ’ u) Â· (Â¸x), and from the Definitions A4 and A6 of the
losses.
Definition A7. Let G be a function family consisting of
functions g : S â†’ R. For a pair of distributions p1 , p2
over S, define the Integral Probability Metric:
Z




IPMG (p1 , p2 ) = sup  g(s) (p1 (s) âˆ’ p2 (s)) ds
gâˆˆG

S

(3)

Proof.


t=0
CF (h, Î¦) âˆ’ (1 âˆ’ u) Â· t=1
F (h, Î¦) + u Â· F (h, Î¦) =


t=0
(1 âˆ’ u) Â· t=1
CF (h, Î¦) + u Â· CF (h, Î¦) âˆ’


t=0
(1 âˆ’ u) Â· t=1
F (h, Î¦) + u Â· F (h, Î¦) =


t=1
(1 âˆ’ u) Â· t=1
CF (h, Î¦) âˆ’ F (h, Î¦) +


t=0
u Â· t=0
(4)
CF (h, Î¦) âˆ’ F (h, Î¦) =

Estimating individual treatment effect: generalization bounds and algorithms

Z


(1 âˆ’ u) `h,Î¦ (x, 1) pt=0 (x) âˆ’ pt=1 (x) dx+
X
Z

u `h,Î¦ (x, 0) pt=1 (x) âˆ’ pt=0 (x) dx =
(5)
X
Z

t=1
(1 âˆ’ u) `h,Î¦ (Î¨(r), 1) pt=0
Î¦ (r) âˆ’ pÎ¦ (r) dr+
R
Z

t=0
u `h,Î¦ (Î¨(r), 0) pt=1
Î¦ (r) âˆ’ pÎ¦ (r) dr =
R
Z

1
t=1
`h,Î¦ (Î¨(r), 1) pt=0
BÎ¦ Â· (1 âˆ’ u)
Î¦ (r) âˆ’ pÎ¦ (r) dr+
R BÎ¦
Z

1
t=0
BÎ¦ Â· u
`h,Î¦ (Î¨(r), 0) pt=1
Î¦ (r) âˆ’ pÎ¦ (r) dr â‰¤
RBÎ¦
(6)

Z



t=1

BÎ¦ Â· (1 âˆ’ u) sup  g(r) pt=0
Î¦ (r) âˆ’ pÎ¦ (r) dr  +
gâˆˆG
R
Z


 
t=0
=
(7)
BÎ¦ Â· u sup  g(r) pt=1
(r)
âˆ’
p
(r)
dr
Î¦
Î¦

gâˆˆG

Let f : X Ã— {0, 1} â†’ Y by an hypothesis, such that
f (x, t) = h(Î¦(x), t) for a representation Î¦ and hypothesis
h defined over the output of Î¦.
Definition A9. The treatment effect estimate for unit x is:
Ï„Ì‚f (x) = f (x, 1) âˆ’ f (x, 0).
Definition A10. The expected Precision in Estimation of
Heterogeneous Effect (PEHE) loss of g is:
Z

2

(Ï„Ì‚f (x) âˆ’ Ï„ (x)) p(x) dx.

PEHE (f ) =
X

Definition A11. The expected variance of Yt with respect
to a distribution p(x, t):

R

t=1
BÎ¦ Â· IPMG (pt=0
Î¦ , pÎ¦ ).

(8)

Equality (4) is by Definition A6 of the treated and control
loss, equality (5) is by the change of variables formula and
Definition A3 of pt=1
and pt=0
Î¦
Î¦ , inequality (6) is by the
1
premise that BÎ¦ Â· `h,Î¦ (Î¨(r), t) âˆˆ G for t = 0, 1, and (7) is
by Definition A7 of an IPM.

ÏƒY2 t (p(x, t)) =

Z

2

(Yt âˆ’ mt (x)) p(Yt |x)p(x, t) dYt dx.
X Ã—Y

We define:
ÏƒY2 t = min{ÏƒY2 t (p(x, t)), ÏƒY2 t (p(x, 1 âˆ’ t))},

The essential point in the proof of Lemma A4 is inequality 6. Note that on the l.h.s. of the inequality, we need to
and
evaluate the expectations of `h,Î¦ (Î¨(r), 0) over pt=1
Î¦
.
Both
of
these
expectations
are
in
`h,Î¦ (Î¨(r), 1) over pt=0
Î¦
general unavailable, since they require us to evaluate treatment outcomes on the control, and control outcomes on
the treated. We therefore upper bound these unknowable
quantities by taking a supremum over a function family
which includes `h,Î¦ (Î¨(r), 0) and `h,Î¦ (Î¨(r), 1). The upper bound ignores most of the details of the outcome, and
amounts to measuring a distance between two distributions
we have samples from: the control and treated distribution.
Note that for a randomized trial (i.e. when t âŠ¥
âŠ¥ x) with we
t=0
have that IPM(pt=1
,
p
)
=
0.
Indeed,
it
is
straightforÎ¦
Î¦
ward to show that in that case we actually have an equality:
t=0
CF (h, Î¦) = (1 âˆ’ u) Â· t=1
F (h, Î¦) + u Â· F (h, Î¦).
The crucial condition in Lemma A4 is that the function
gÎ¦,h (r) := B1Î¦ `h,Î¦ (Î¨(r), t) is in G. In subsections A.3
and A.4 below we look into two specific function families
G, and evaluate what does this inclusion condition entail,
and in particular we will derive specific bounds for BÎ¦ .
Definition A8. For t = 0, 1 define:

ÏƒY2 = min{ÏƒY2 0 , ÏƒY2 1 }.
If Yt are deterministic functions of x, then ÏƒY2 = 0.
We now show that PEHE (f ) is upper bounded by 2F +
2CF âˆ’ 2ÏƒY2 where F and CF are w.r.t. to the squared
loss. An analogous result can be obtained for the absolute
loss, using mean absolute deviation.
Lemma A5. For any function f : X Ã— {0, 1} â†’ Y, and
distribution p(x, t) over X Ã— {0, 1}:
Z

2

(f (x, t) âˆ’ mt (x)) p(x, t) dxdt =
X

F (f ) âˆ’ ÏƒY2 t (p(x, t)),
Z

2

(f (x, t) âˆ’ mt (x)) p(x, 1 âˆ’ t) dxdt =
X

CF (f ) âˆ’ ÏƒY2 t (p(x, 1 âˆ’ t)),
where F (f ) and CF (f ) are w.r.t. to the squared loss.

mt (x) := E [Yt |x] .
Obviously for the treatment effect Ï„ (x) we have Ï„ (x) =
m1 (x) âˆ’ m0 (x).

Proof. For simplicity we will prove for p(x, t) and F (f ).

Estimating individual treatment effect: generalization bounds and algorithms

The proof for p(x, 1 âˆ’ t) and CF is identical.

PEHE (f ) = PEHE (h, Î¦) for f (x, t) = h(Î¦(x), t).
PEHE (f ) =
Z
2
(f (x, 1) âˆ’ f (x, 0)) âˆ’ (m1 (x) âˆ’ m0 (x)) p(x) dx =
ZX
2
(f (x, 1) âˆ’ m1 (x)) + (m0 (x) âˆ’ f (x, 0)) p(x) dx â‰¤

F (f ) =
Z
2
(f (x, t) âˆ’ Yt ) p(Yt |x)p(x, t) dYt dxdt =
X Ã—{0,1}Ã—Y
Z
X
2
(11)
(f (x, t) âˆ’ mt (x)) p(Yt |x)p(x, t) dYt dxdt+
Z 
X Ã—{0,1}Ã—Y

Z
2
2
2
(f (x, 1) âˆ’ m1 (x)) + (m0 (x) âˆ’ f (x, 0)) p(x) dx =
2
(mt (x) âˆ’ Yt ) p(Yt |x)p(x, t) dYt dxdt+
(9)
X
X Ã—{0,1}Ã—Y
(12)
Z
Z
2
(f (x, t) âˆ’ mt (x)) (mt (x) âˆ’ Yt ) p(Yt |x)p(x, t) dYt dxdt = 2
(f (x, 1) âˆ’ m1 (x)) p(x, t = 1) dx+
X Ã—{0,1}Ã—Y
X
Z
(10)
2
Z
2
(m0 (x) âˆ’ f (x, 0)) p(x, t = 0) dx+
2
X
(f (x, t) âˆ’ mt (x)) p(x, t) dxdt+
Z
X Ã—{0,1}
2
2
(f (x, 1) âˆ’ m1 (x)) p(x, t = 0) dx+
ÏƒY2 0 (p(x, t)) + ÏƒY2 1 (p(x, t)) + 0,
X
Z
2
2
(m0 (x) âˆ’ f (x, 0)) p(x, t = 1) dx =
Z X
where the equality (10) is by the Definition A11 of ÏƒY2 t (p),
2
2
(f (x, t) âˆ’ mt (x)) p(x, t) dxdt+
and because
R the integral in (9) evaluates to zero, since
X
Z
mt (x) = X Yt p(Yt |x) dx.
2
2
(f (x, t) âˆ’ mt (x)) p(x, 1 âˆ’ t) dxdt â‰¤
(13)
X

2(F âˆ’ ÏƒY2 ) + 2(CF âˆ’ ÏƒY2 ).
Theorem 1. Let Î¦ : X â†’ R be a one-to-one representat=0
be defined as
tion function, with inverse Î¨. Let pt=1
Î¦ , pÎ¦
in Definition A3. Let u = p(t = 1). Let G be a family of
functions g : R â†’ R, and denote by IPMG (Â·, Â·) the integral
probability metric induced by G. Let h : R Ã— {0, 1} â†’ Y
be an hypothesis. Let the loss L(y1 , y2 ) = (y1 âˆ’ y2 )2 . Assume there exists a constant BÎ¦ > 0, such that for t âˆˆ
{0, 1}, the functions gÎ¦,h (r, t) := B1Î¦ Â· `h,Î¦ (Î¨(r), t) âˆˆ G.
We then have:

where (11) is because (x + y)2 â‰¤ 2(x2 + y 2 ), (12) is because p(x) = p(x, t = 0) + p(x, t = 1) and (13) is by
Lemma A5 and Definition A5 of the losses F , CF and
Definition A11 of ÏƒY2 . Having established the first inequality in the Theorem statement, we now show the second. We
have by Lemma A4 that:
CF (h, Î¦) â‰¤

t=0
t=1 t=0
(1 âˆ’ u)t=1
.
F (h, Î¦) + uF (h, Î¦) + BÎ¦ Â· IPMG pÎ¦ , pÎ¦
We further have by Lemma A3 that:
t=0
F (h, Î¦) = ut=1
F (h, Î¦) + (1 âˆ’ u)F (h, Î¦).

PEHE (h, Î¦) â‰¤

2 CF (h, Î¦) + F (h, Î¦) âˆ’ 2ÏƒY2 â‰¤


t=1
t=1 t=0
2 t=0
âˆ’2ÏƒY2 ,
F (h, Î¦)+F (h, Î¦)+BÎ¦ IPMG pÎ¦ , pÎ¦

Therefore
CF (h, Î¦) + F (h, Î¦) â‰¤

t=0
t=1 t=0
t=1
.
F (h, Î¦) + F (h, Î¦) + BÎ¦ IPMG pÎ¦ , pÎ¦

where F and CF are with respect to the squared loss.

Proof. We will prove the first inequality, PEHE (f ) â‰¤
2CF (h, Î¦) + 2F (h, Î¦) âˆ’ 2ÏƒY2 . The second inequality
is then immediate by Lemma A4. Recall that we denote

The upper bound is in terms of the standard generalization error on the treated and control distributions separately.
Note that in some cases we might have very different sample sizes for treated and control, and that will show up in
the finite sample bounds of these generalization errors.
We also note that the upper bound can be easily adapted to
the case of the absolute loss PEHE |Ï„Ì‚ (x) âˆ’ Ï„ (x)|. In that

Estimating individual treatment effect: generalization bounds and algorithms

case the upper bound in the Theorem will have a factor 1
instead of the 2 stated above, and the standard deviation ÏƒY2
replaced by mean absolute deviation. The proof is straightforward where one simply applies the triangle inequality in
inequality (11).
We will now give specific upper bounds for the constant
BÎ¦ in Theorem 1, using two function families G in the
IPM: the family of 1-Lipschitz functions, and the family of
1-norm reproducing kernel Hilbert space functions. Each
one will have different assumptions about the distribution
p(x, t, Y0 , Y1 ) and about the representation Î¦ and hypothesis h.
A.3. The family of 1-Lipschitz functions
For S âŠ‚ Rd , a function f : S â†’ R has Lipschitz constant
K if for all x, y âˆˆ S, |f (x) âˆ’ f (y)| â‰¤ Kkx âˆ’ yk. If f is
differentiable, then a sufficient condition for K-Lipschitz
constant is if k âˆ‚f
âˆ‚s k â‰¤ K for all s âˆˆ S.
For simplicityâ€™s sake we assume throughout this subsection
that the true labeling functions the densities p(Yt |x) and the
loss L are differentiable. However, this assumption could
be relaxed to a mere Lipschitzness assumption.
Assumption A2. There exists a constant K > 0 such that
t |x)
for all x âˆˆ X , t âˆˆ {0, 1}, k p(Yâˆ‚x
k â‰¤ K.
Assumption A2 entails that each of the potential outcomes
change smoothly as a function of the covariates (context)
x.
Assumption A3. The loss function L is differentiable,

 and
 dL(y1 ,y2 ) 
there exists a constant KL > 0 such that  dyi  â‰¤ KL
for i = 1, 2. Additionally,R there exists a constant M such
that for all y2 âˆˆ Y, M â‰¥ Y L(y1 , y2 ) dy1 .
Assuming Y is compact, loss functions which obey Assumption A3 include the log-loss, hinge-loss, absolute loss,
and the squared loss.
When we let G in Definition A7 be the family of 1Lipschitz functions, we obtain the so-called 1-Wasserstein
distance between distributions, which we denote Wass(Â·, Â·).
It is well known that Wass(Â·, Â·) is indeed a metric between
distributions (Villani, 2008).
Definition A12. Let âˆ‚Î¦(x)
âˆ‚x be the Jacobian matrix of Î¦ at
point x, i.e. the matrix of the partial derivatives of Î¦. Let
Ïƒmax (A) and Ïƒmin (A) denote respectively the largest and
smallest singular
A.
 values
 of a matrix

 Define Ï(Î¦) =
supxâˆˆX Ïƒmax

âˆ‚Î¦(x)
âˆ‚x

/Ïƒmin

âˆ‚Î¦(x)
âˆ‚x

.

It is an immediate result that Ï(Î¦) â‰¥ 1.
Definition A13. We will call a representation function

Î¦ :
âˆ‚Î¦(x)
X â†’ R Jacobian-normalized if supxâˆˆX Ïƒmax
=
âˆ‚x
1.

Note that any non-constant representation function Î¦ can
be Jacobian-normalized by a simple scalar multiplication.
Lemma A6. Assume that Î¦ is a Jacobian-normalized representation, and let Î¨ be its inverse. For t = 0, 1, the Lipschitz constant of p(Yt |Î¨(r)) is bounded by Ï(Î¦)K, where
K is from Assumption A2, and Ï(Î¦) as in Definition A12.

Proof. Let Î¨ : R â†’ X be the inverse of Î¦, which exists
by the assumption that Î¦ is one-to-one. Let âˆ‚Î¦(x)
âˆ‚x be the
Jacobian matrix of Î¦ evaluated at x, and similarly let âˆ‚Î¨(r)
âˆ‚r
be the Jacobian matrix of Î¨ evaluated at r. Note that âˆ‚Î¨(r)
âˆ‚r Â·
âˆ‚Î¦(x)
âˆ‚x = I for r = Î¦(x), since Î¨â—¦Î¦ is the identity function
on X . Therefore for any r âˆˆ R and x = Î¨(r):

Ïƒmax

âˆ‚Î¨(r)
âˆ‚r


=
Ïƒmin

1


âˆ‚Î¦(x)
âˆ‚x

,

(14)

where Ïƒmax (A) and Ïƒmin (A) are respectively the largest
and smallest singular values of the matrix A, i.e. Ïƒmax (A)
is the spectral norm of A.
For x = Î¨(r) and t âˆˆ {0, 1}, we have by the chain rule:
âˆ‚p(Yt |Î¨(r))
âˆ‚p(Yt |Î¨(r)) âˆ‚Î¨(r)
k=k
kâ‰¤
âˆ‚r
âˆ‚Î¨(r)
âˆ‚r
âˆ‚Î¨(r) âˆ‚p(Yt |Î¨(r))
k
kk
k=
âˆ‚r
âˆ‚Î¨(r)
1
âˆ‚p(Yt |x)

k
kâ‰¤
âˆ‚Î¦(x)
âˆ‚x
Ïƒ

k

min

Ïƒmin

(15)
(16)
(17)

âˆ‚x

K


âˆ‚Î¦(x)
âˆ‚x

 â‰¤ Ï(Î¦)K,

(18)

where inequality (15) is by the matrix norm inequality,
equality (16) is by (14), inequality (17) is by assumption
A2 on the norms of the gradient of p(Yt |x) w.r.t x , and
inequality (18) is by Definition A12 of Ï(Î¦), the assumption that Î¦ is Jacobian-normalized, and noting that singular
values are necessarily non-negative.

Lemma A7. Under the conditions of Lemma A4, further
assume that for t = 0, 1, p(Yt |x) has gradients bounded
by K as in A2, that h has bounded gradient norm bK,
that the loss L has bounded gradient norm KL , and that
Î¦ is Jacobian-normalized. Then the Lipschitz constant of
`h,Î¦ (Î¨(r), t) is upper bounded by KL Â· K (M Ï(Î¦) + b)
for t = 0, 1.

Estimating individual treatment effect: generalization bounds and algorithms

Proof. Using the chain rule, we have that:
Z
âˆ‚`h,Î¦ (Î¨(r), t)
âˆ‚
k
k=k
L(Yt , h(r, t))p(Yt |r)dYt k =
âˆ‚r
âˆ‚r Y
Z
âˆ‚
k
[L(Yt , h(r, t))p(Yt |r)] dYt k =
âˆ‚r
Y
Z
âˆ‚
âˆ‚
k p(Yt |r) L(Yt , h(r, t))+L(Yt , h(r, t)) p(Yt |r)dYt k â‰¤
âˆ‚r
âˆ‚r
Z Y
âˆ‚
p(Yt |r)k L(Yt , h(r, t))k dYt +
âˆ‚r
ZY
âˆ‚
L(Yt , h(r, t)) p(Yt |r) dYt â‰¤
(19)
âˆ‚r
Y
Z
âˆ‚L(Yt , h(r, t)) âˆ‚h(r, t)
k dYt +
p(Yt |r)k
âˆ‚h(r, t)
âˆ‚r
ZY
âˆ‚
L(Yt , h(r, t)) p(Yt |r) dYt â‰¤
(20)
âˆ‚r
ZY
p(Yt |r)KL Â· b Â· K + M Â· Ï(Î¦) Â· K,
(21)
Y

where inequality 19 is due to Assumption A3 and inequality 20 is due to Lemma A6.
Lemma A8. Let u = p(t = 1) be the marginal probability
of treatment, and assume 0 < u < 1. Let Î¦ : X â†’ R be a
one-to-one, Jacobian-normalized representation function.
Let K be the Lipschitz constant of the functions p(Yt |x) on
X . Let KL be the Lipschitz constant of the loss function L,
and M be as in Assumption A3. Let h : R Ã— {0, 1} â†’ R
be an hypothesis with Lipschitz constant bK. Then:
CF (h, Î¦) â‰¤
t=0
(1 âˆ’ u)t=1
F (h, Î¦) + uF (h, Î¦)+
t=0
2 (M Ï(Î¦) + b) Â· K Â· KL Â· Wass(pt=1
Î¦ , pÎ¦ ).

(22)

Proof. We will apply Lemma A4 with G = {g :
R â†’ R s.t. f is 1-Lipschitz}. By Lemma A7, we have
that for BÎ¦ = (M Ï(Î¦) + b) Â· K Â· KL , the function
1
BÎ¦ `h,Î¦ (Î¨(r), t) âˆˆ G. Inequality (22) then holds as a special case of Lemma A4.
Theorem 2. Under the assumptions of Lemma A8, using
the squared loss for F , we have:

our control and measures an aspect of the complexity of
the true underlying functions we wish to approximate. The
terms KL and M depend on our choice of loss function and
the size of the space Y. The term b comes from our assumption that the hypothesis h has norm bK. Note that smaller
b, while reducing the bound, might force the factual loss
term F (h, Î¦) to be larger since a small b implies a less
flexible h. Finally, consider the term Ï(Î¦). The assumption that Î¦ is normalized is rather natural, as we do not
expect a certain scale from a representation. Furthermore,
below we show that in fact the Wasserstein distance is positively homogeneous with respect to the representation Î¦.
Therefore, in Lemma A8, we can indeed assume that Î¦ is
normalized. The specific choice of Jacobian-normalized
scaling yields what is in our opinion a more interpretable
result in terms of the inverse condition number Ï(Î¦). For
twice-differentiable Î¦, Ï(Î¦) is minimized if and only if Î¦
is a linear orthogonal transformation (mat).
Lemma A9. The Wasserstein distance is positive homogeneous for scalar transformations of the underlying space.
Let p, q be probability density functions defined over X .
For Î± > 0 and the mapping Î¦(x) = Î±x, let pÎ± and qÎ± be
the distributions on Î±X induced by Î¦. Then:
Wass (pÎ± , qÎ± ) = Î±Wass (p, q) .
Proof. Following (Villani, 2008; Kuang & Tabak, 2016),
we use another characterization of the Wasserstein distance. Let Mp,q be the set of mass preserving maps from
X to itself which map the distribution p to the distribution q. That is, Mp,q = {M : X â†’ X s.t. q(M (S)) =
p(S) for all measurable bounded S âŠ‚ X }. We then have
that:
Z
Wass(p, q) = inf
kM (x) âˆ’ xkp(x) dx. (23)
M âˆˆMp,q

X

It is known that the infimum in (23) is actually achievable
(Villani, 2008, Theorem 5.2). Denote by M âˆ— : X â†’ X
the map achieving the infimum for Wass(p, q) . Define
0
MÎ±âˆ— : Î±X â†’ Î±X , by MÎ±âˆ— (x0 ) = Î±M âˆ— ( xÎ± ), where
x0 = Î±x. MÎ±âˆ— maps pÎ± to qÎ± , and we have that kMÎ±âˆ— (x0 ) âˆ’
x0 k = Î±kM âˆ— (x)âˆ’xk. Therefore MÎ±âˆ— achieves the infimum
for the pair (pÎ± , qÎ± ), and we have that Wass (pÎ± , qÎ± ) =
Î±Wass (p, q).

PEHE (h, Î¦) â‰¤
t=1
2
2t=0
F (h, Î¦) + 2F (h, Î¦) âˆ’ 4ÏƒY +

A.4. Functions in the unit ball of a RKHS

Proof. Plug in the upper bound of Lemma A8 into the upper bound of Theorem 1.

Let Hx , Hr be a reproducing kernel Hilbert space, with
corresponding kernels kx (Â·, Â·), kr (Â·, Â·). We have for all
x âˆˆ X that kx (Â·, x) is its Hilbert space mapping, and similarly kr (Â·, r) for all r âˆˆ R.

We examine the constant (M Ï(Î¦) + b)Â·K Â·KL in Theorem
A8. K, the Lipschitz constant of m0 and m1 , is not under

Recall that the major condition in Lemma A4 is that
1
BÎ¦ `h,Î¦ (Î¨(r), t) âˆˆ G. The function space G we use here
is G = {g âˆˆ Hr s.t. kgkHr â‰¤ 1}.

t=0
2 (M Ï(Î¦) + b) Â· K Â· KL Â· Wass(pt=1
Î¦ , pÎ¦ ).

Estimating individual treatment effect: generalization bounds and algorithms

We will focus on the case where L is the squared loss, and
we will make the following two assumptions:

where
equality (24) is by Definition A14 of Î·, and because
R
(Y
âˆ’ mt (x)) p(Yt |x) dYt = 0 by definition of mt (x).
t
Y

Y
Y
Assumption

 YA4. There exist f0 , f1 âˆˆ Hx such that
mt (x) = ft , kx (x, Â·) Hx , i.e. the mean potential outcome functions m0 , m1 are in Hx . Further assume that
kftY kHx â‰¤ K.

Moving to R, recall that r = Î¦(x), x = Î¨(r).
By linearity of the Hilbert space,

 âˆ— Y we have
 that
mt (Î¨(r)) âˆ’ h(r, t)
=
Î“Î¦ ft , kr (r, Â·) Hr âˆ’




 h

ft , kr (r, Â·) Hr = Î“âˆ—Î¦ ftY âˆ’ fth , kr (r, Â·) Hr . By a well
known result (Steinwart & Christmann, 2008, Theorem
7.25), the product (Yt (Î¨(r))âˆ’h(r, t))Â·(Yt (Î¨(r))âˆ’h(r, t))
lies
product space Hr âŠ— Hr , and is equal
to

 âˆ—in Ythe tensor

(Î“Î¦ ft âˆ’ fth ) âŠ— (Î“âˆ—Î¦ ftY âˆ’ fth ), kr (r, Â·) âŠ— kr (r, Â·) H âŠ—H .
r
r
The norm of this function in Hr âŠ— Hr is kÎ“âˆ—Î¦ ftY âˆ’ fth k2Hr .
This is the general Hilbert space version of the fact that for
a vector w âˆˆ Rd one has that kww> kF = kwk22 , where
k Â· kF is the matrix Frobenius norm, and k Â· k22 is the
square of the standard Euclidean norm. We therefore have
a similar result for Î·Y2 t , using Assumption A5: Î·Y2 t (x) =
Î·Y2 t (Î¨(r)) = hÎ“âˆ—Î¦ ftÎ· âŠ— Î“âˆ—Î¦ ftÎ· , kr (r, Â·) âŠ— kr (r, Â·)iHr âŠ—Hr .
The norm of this function in Hr âŠ— Hr is kÎ“âˆ—Î¦ ftÎ· k2Hr .
Overall this leads us to conclude, using Equation (25) that
`h,Î¦ (Î¨(r), t) âˆˆ Hr âŠ— Hr . Now we have, using (25):

Definition
A14.
Define
Î·Yt (x)
:=
q
R
2
(Yt âˆ’ mt (x)) p(Yt |x).
Î·Yt (x) is the standard
Y
deviation of Yt |x.
Assumption A5. There exists f0Î· , f1Î· âˆˆ Hx such that
Î·Yt (x) = hftÎ· , kx (x, Â·)iHx , i.e. the conditional standard
deviation functions of Yt |x are in Hx . Further assume that
kftÎ· kHx â‰¤ M .
Assumption A6. Let Î¦ : X â†’ Y be an invertible representation function, and let Î¨ be its inverse. We assume
there
exists a boundedlinear operator
Î“Î¦ : Hr â†’ Hx such


that ftY , kx (Î¨(r), Â·) Hx = ftY , Î“Î¦ kr (r, Â·) Hx . We further assume that the Hilbert-Schmidt norm (operator norm)
kÎ“Î¦ kHS of Î“Î¦ is bounded by KÎ¦ .
The two assumptions above amount to assuming that Î¦ can
be represented as one-to-one linear map between the two
Hilbert spaces Hx and Hr .

k`h,Î¦ (Î¨(r), t)kHr âŠ—Hr =

Under Assumptions A4 
and A6 about m0 , m1 , and Î¦, we
have that mt (Î¨(r)) = Î“âˆ—Î¦ ftY , kr (r, Â·) Hr , where Î“âˆ—Î¦ is
the adjoint operator of Î“Î¦ (Grunewalder et al., 2013).

kÎ“âˆ—Î¦ ftY âˆ’ fth k2Hr + kÎ“âˆ—Î¦ ftÎ· k2Hr â‰¤

(27)

2kÎ“âˆ—Î¦ ftY k2Hr + 2kfth k2Hr + kÎ“âˆ—Î¦ ftÎ· k2Hr â‰¤

kÎ“âˆ—Î¦ k2HS 2kftY k2Hx + kftÎ· k2Hx + 2kfth k2Hr

kÎ“Î¦ k2HS 2kftY k2Hx + kftÎ· k2Hx + 2kfth k2Hr
2KÎ¦2 (K 2 + M 2 ) + 2b2 .

(28)

Lemma A10. Let h : R Ã— {0, 1} â†’ R be an hypothesis,
h
r such that h(r, t) =

andh assume that there exist ft âˆˆ H
ft , kr (r, Â·) Hr , and such that kfth kHr â‰¤ b. Under Assumption A4 about m0 , m1 , we have that `h,Î¦ (Î¨(r), t) =
R
2
(Yt âˆ’ h(r, t)) p(Yt |r)dYt is in the tensor Hilbert space
Y
Hr âŠ— Hr . Moreover, the norm of `h,Î¦ (Î¨(r), t) in Hr âŠ— Hr
is upper bounded by 4 KÎ¦2 K 2 + b2 .
R
2
Proof. We first decompose Y (Yt âˆ’ h(r, t)) p(Yt |x)dYt
into a noise and mean fitting term, using r = Î¦(x):
`h,Î¦ (Î¨(r), t) =
Z
2
(Yt âˆ’ h(r, t)) p(Yt |r) dYt =
ZY
2
(Yt âˆ’ mt (x) + mt (x) âˆ’ h(Î¦(x), t)) p(Yt |x) dYt =
ZY
2
(Yt âˆ’ mt (x)) p(Yt |x) dYt +
Y
2

(mt (x) âˆ’ h(Î¦(x), t)) +
Z
2
(Yt âˆ’ mt (x)) (mt (x) âˆ’ h(Î¦(x), t)) p(Yt |x)dYt =
Y

(24)
Î·Y2 t (x)

2

+ (mt (x) âˆ’ h(Î¦(x), t)) + 0,

(25)

k(Î“âˆ—Î¦ ftY âˆ’ fth ) âŠ— (Î“âˆ—Î¦ ftY âˆ’ fth ) + Î“âˆ—Î¦ ftÎ· âŠ— Î“âˆ—Î¦ ftÎ· kHr âŠ—Hr â‰¤
(26)

=

(29)

â‰¤

(30)

Inequality (26) is by the norms given above and the triangle
inequality. Inequality (27) is because for any Hilbert space
H, ka âˆ’ bk2H â‰¤ 2kak2H + 2kbk2H . Inequality (28) is by the
definition of the operator norm. Equality (29) is because
the norm of the adjoint operator is equal to the norm of
the original operator, where we abused the notation k Â· kHS
to mean both the norm of operators from Hx to Hr and
vice-versa. Finally, inequality (30) is by Assumptions A4,
A5 and A6, and by the Lemmaâ€™s premise on the norm of
fTh .
Lemma A11. Let u = p(t = 1) be the marginal probability of treatment, and assume 0 < u < 1. Assume the
distribution of Yt conditioned on x follows Assumptions
A5 with constant M . Let Î¦ : X â†’ R be a one-to-one
representation function which obeys Assumption A6 with
corresponding operator Î“Î¦ with operator norm KÎ¦ . Let
the functions Y0 , Y1 obey Assumption A4, with bounded
Hilbert space norm K . Let h : R Ã— {0, 1} â†’ R be an
h
hypothesis,
assume

 and
 that there exist fht âˆˆ Hr such that
h
h(r, t) = ft , kr (r, Â·) Hr , such that kft kHr â‰¤ b. Assume
that F and CF are defined with respect to L being the

Estimating individual treatment effect: generalization bounds and algorithms

squared loss. Then:
CF (h, Î¦) â‰¤
t=0
(1 âˆ’ u)t=1
F (h, Î¦) + uF (h, Î¦)+

t=0
2 KÎ¦2 (K 2 + M 2 ) + b2 Â· MMD(pt=1
Î¦ , pÎ¦ ),

(31)
where CF and F use the squared loss.
Proof. We will apply Lemma A4 with G
=
f âˆˆ Hr âŠ— Hr s.t. kf kHr âŠ—Hr â‰¤ 1.
By Lemma
A10,

we have that for BÎ¦ = 2 KÎ¦2 (K 2 + M 2 ) + b2 and L
being the squared loss, B1Î¦ `h,Î¦ (Î¨(r), t) âˆˆ G. Inequality
(31) then holds as a special case of Lemma A4.
Theorem 3. Under the assumptions of Lemma A11, using
the squared loss for F , we have:

Algorithm 1 Computing the stochastic gradient of the
Wasserstein distance
1: Input: Factual (x1 , t1 , y1 ), . . . , (xn , tn , yn ), representation network Î¦W with current weights by W
2: Randomly sample a mini-batch with m treated and m0
control units (xi1 , 0, yi1 ), . . . ,
(xim , 0, yim ), (xim+1 , 1, yim+1 ), . . . , (xi2m , 1, yi2m )
3: Calculate the m Ã— m pairwise distance matrix between
all treatment and control pairs M (Î¦W ):
Mkl (Î¦) = kÎ¦W (xik ) âˆ’ Î¦W (xim+l )k
4: Calculate the approximate optimal transport matrix T âˆ—
using Algorithm 3 of Cuturi & Doucet (2014), with
input M (Î¦W )
5: Calculate the gradient:
g1 = âˆ‡W hT âˆ— , M (Î¦W )i

as a recurrent neural network, where the states ut evolve
according to

PEHE (h, Î¦) â‰¤
t=1
2
2t=0
F (h, Î¦) + 2F (h, Î¦) âˆ’ 4ÏƒY +

t=0
4 KÎ¦2 (K 2 + M 2 ) + b2 Â· MMD(pt=1
Î¦ , pÎ¦ ).

Proof. Plug in the upper bound of Lemma A11 into the
upper bound of Theorem 1.

>
ut+1 = nt ./(nc K(1./(u>
t K) )) .

Here, K is a kernel matrix corresponding to a metric such
as the euclidean distance, Kij = eâˆ’Î»kÎ¦(xi )âˆ’Î¦(xj )k2 , and
nc , nt are the sizes of the control and treatment groups. In
this way, we can minimize our entire objective with most
of the frameworks commonly used for training neural networks, out of the box.

B. Algorithmic details
We give details about the algorithms used in our framework.

B.2. Minimizing the maximum mean discrepancy
The MMD of treatment populations in the representation
Î¦, for a kernel k(Â·, Â·) can be written as,

B.1. Minimizing the Wasserstein distance
In general, computing (and minimizing) the Wasserstein
distance involves solving a linear program, which may
be prohibitively expensive for many practical applications.
Cuturi (2013) showed that an approximation based on entropic regularization can be obtained through the SinkhornKnopp matrix scaling algorithm, at orders of magnitude
faster speed. Dubbed Sinkhorn distances, the approximation is computed using a fixed-point iteration involving repeated multiplication with a kernel matrix K. We can use
the algorithm of Cuturi (2013) in our framework. See Algorithm 1 for an overview of how to compute the gradient
g1 in Algorithm ??. When computing g1 , disregarding the
gradient âˆ‡W T âˆ— amounts to minimizing an upper bound on
the Sinkhorn transport. More advanced ideas for stochastic optimization of this distance have recently proposed by
Aude et al. (2016), and might be used in future work.
While our framework is agnostic to the parameterization of
Î¦, our experiments focus on the case where Î¦ is a neural
network. For convenience of implementation, we may represent the fixed-point iterations of the Sinkhorn algorithm

0

m
MMDk ({Î¦W (xij )}m
j=1 , {Î¦W (xik )}k=m+1 ) = (32)
m
m
X
X
1
k(Î¦W (xij ), Î¦W (xik )) (33)
m(m âˆ’ 1) j=1
k=1,k6=j

+

2
mm0

0
m m+m
X
X

k(Î¦W (xij ), Î¦W (xik )) (34)

j=1 k=m

m

X
1
+ 0
m (1 âˆ’ m0 ) j=1

0

m
X

k(Î¦W (xij ), Î¦W (xik )) (35)

k=m,k6=j

The linear maximum-mean discrepancy can be written as a
distance between means. In the notation of Algorithm ??,


 X

m0
X
1 m

1

Î¦
(x
)
âˆ’
MMD = 2 
Î¦
(x
)
W ij
W ik 
m
0
m
 j=1

k=m+1

2

Let
m

1 X
1
Î¦W (xij ) âˆ’ 0
f (W) =
m j=1
m

0
m+m
X

k=m+1

Î¦W (xik )

Estimating individual treatment effect: generalization bounds and algorithms
Table 1. Hyperparameters and ranges.

Parameter
Imbalance parameter, Î±
Num. representation layers
Num. hypothesis layers
Dim. representation layers
Dim. hypothesis layers
Batch size
Normalization
Weight decay (hypothesis)

Range
{10k/2 }6k=âˆ’10
{1, 2, 3}
{1, 2, 3}
{20, 50, 100, 200}
{20, 50, 100, 200}
{100, 200, 500, 700}
{projection, batch norm}
{10âˆ’4 , 10âˆ’3 , 10âˆ’2 }

Then the gradient of the MMD with respect to W is,
df (W) f (W)
g1 = 2
.
dW kf (W)k2

References
MathOverflow: functions with orthogonal Jacobian. https:
//mathoverflow.net/questions/228964/
functions-with-orthogonal-jacobian.
Accessed: 2016-05-05.
Aude, Genevay, Cuturi, Marco, PeyreÌ, Gabriel, and Bach, Francis.
Stochastic optimization for large-scale optimal transport. arXiv
preprint arXiv:1605.08527, 2016.
Ben-Israel, Adi. The change-of-variables formula using matrix
volume. SIAM Journal on Matrix Analysis and Applications,
21(1):300â€“312, 1999.
Cuturi, Marco. Sinkhorn distances: Lightspeed computation of
optimal transport. In Advances in Neural Information Processing Systems, pp. 2292â€“2300, 2013.
Cuturi, Marco and Doucet, Arnaud. Fast computation of Wasserstein barycenters. In Proceedings of The 31st International
Conference on Machine Learning, pp. 685â€“693, 2014.

C. Experimental details

Gretton, Arthur, Borgwardt, Karsten M., Rasch, Malte J.,
SchoÌˆlkopf, Bernhard, and Smola, Alexander. A kernel twosample test. J. Mach. Learn. Res., 13:723â€“773, March 2012.
ISSN 1532-4435.

Our implementations of CFR and TARNet are based on
Python and TensorFlow and are available at https://
github.com/clinicalml/cfrnet. Both models
were trained using stochastic gradient descent with Adam.

Grunewalder, Steffen, Arthur, Gretton, and Shawe-Taylor, John.
Smooth operators. In Proceedings of the 30th International
Conference on Machine Learning (ICML-13), pp. 1184â€“1192,
2013.

C.1. Hyperparameter selection

Kuang, Max and Tabak, Esteban. Preconditioning of optimal
transport. Preprint, 2016.

Standard methods for hyperparameter selection, such as
cross-validation, are not generally applicable for estimating the PEHE loss since only one potential outcome is
observed (unless the outcome is simulated). For realworld data, we may use the observed outcome yj(i)
of the nearest neighbor j(i) to i in the opposite treatment group, tj(i) = 1 âˆ’ ti as surrogate for the counterfactual outcome. We use this to define a nearestneighbor approximation of the PEHE loss, PEHEnn (f ) =
2
Pn
1
.
i=1 (1 âˆ’ 2ti )(yj(i) âˆ’ yi ) âˆ’ (f (xi , 1) âˆ’ f (xi , 0))
n
On IHDP, we use the objective value on the validation set
for early stopping in CFR, and PEHEnn (f ) for hyperparameter selection. On the Jobs dataset, we use the policy risk
on the validation set.
See Table 1 for a description of hyperparameters and search
ranges.
C.2. Learned representations
Figure 1 show the representations learned by our CFR algorithm.
C.3. Absolute error for increasingly imbalanced data
Figure 2 shows the results of the same experiment as Figure
2 of the main paper, but in absolute terms.

MuÌˆller, Alfred. Integral probability metrics and their generating
classes of functions. Advances in Applied Probability, pp. 429â€“
443, 1997.
Sriperumbudur, Bharath K, Fukumizu, Kenji, Gretton, Arthur,
SchoÌˆlkopf, Bernhard, Lanckriet, Gert RG, et al. On the empirical estimation of integral probability metrics. Electronic
Journal of Statistics, 6:1550â€“1599, 2012.
Steinwart, Ingo and Christmann, Andreas. Support vector machines. Springer Science & Business Media, 2008.
Villani, CeÌdric. Optimal transport: old and new, volume 338.
Springer Science & Business Media, 2008.

Estimating individual treatment effect: generalization bounds and algorithms

(a) Original data

(b) Linear MMD

(c) Wasserstein

Figure 1. t-SNE visualizations of the balanced representations of IHDP learned by our algorithms CFR, CFR MMD and CFR Wass. We
note that the nearest-neighbor like quality of the Wasserstein distance results in a strip-like representation, whereas the linear MMD
results in a ball-like shape in regions where overlap is small.

4.5

q = 0: 0

4.0

q = 0: 5

Â²PEHE

3.5

q = 1: 0

3.0
2.5
2.0
1.5
1.0
0

10 -5

10 -4

10 -3

10 -2

10 -1

10 0

10 1

10 2

Imbalance penalty; Â®
Figure 2. Out-of-sample error in estimated ITE, as a function of
IPM regularization parameter for CFR Wass, on 500 realizations
of IHDP, with high (q = 1), medium and low (artificial) imbalance between control and treated.

