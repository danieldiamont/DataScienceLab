Supplementary Material: Bayesian inference on random simple graphs
with power law degree distributions

Juho Lee 1 Creighton Heaukulani 2 Zoubin Ghahramani 2 3 Lancelot F. James 4 Seungjin Choi 1

1. Proofs
We prove Theorem 3.1 and Theorem 5.1 in the paper. First consider the following redefinition of our model with slightly
different notation; let Wn be a random variable constrained on (0, Cn ], with density
fn (dw) =

1 âˆ’Î±âˆ’1
w
(1 âˆ’ eâˆ’w )1{0<wâ‰¤Cn } dw,
Zn

(1)

where C1 , C2 , . . . , is a sequence of positive numbers satisfying
lim CnÎ± /n = 0.

lim Cn = âˆž,

nâ†’âˆž

nâ†’âˆž

(2)

Note that Zn â†’ Î“(1 âˆ’ Î±)/Î± as n â†’ âˆž, and so the sequence of densities fn (dw) converges pointwise to the density of
the BFRY distribution
Î±
f (w) =
wâˆ’Î±âˆ’1 (1 âˆ’ eâˆ’w )1{w>0} ,
(3)
Î“(1 âˆ’ Î±)
and Wn converges in distribution to a BFRY random variable. Let Wn,1 , . . . , Wn,n be n i.i.d. copies of Wn . A random
simple graph X is then defined to be a collection of Bernoulli random variables as follows:
P{Xij = 1 | ri,j } =
where Ln :=

Pn

i=1

ri,j
,
1 + ri,j

ri,j = Ui Uj ,

Wn,i
Ui = âˆš ,
Ln

(4)

Wn,i . We will write X | r âˆ¼ GRG(n, r), where r := (ri,j : i < j â‰¤ n).

We begin with a sequence of Lemmas. Define a sequence of random variables Vs,n , for every s, n â‰¥ 1, by
Vs,n :=

Wn
.
Cnsâˆ’Î±

(5)

Let Vs,n,1 , . . . , Vs,n,n be n i.i.d. copies of Vs,n , and denote the empirical mean of these copies by
n

VÌ„s,n :=

1X
Vs,n,i .
n i=1

The expectation of Vs,n is finite for all s, n < âˆž, and is computed as
Z Cn
1
E[Vs,n ] =
wsâˆ’Î±âˆ’1 (1 âˆ’ eâˆ’w )dw
Zn Cnsâˆ’Î± 0


1
1
Î³(s âˆ’ Î±, Cn )
=
âˆ’
,
Zn s âˆ’ Î±
Cnsâˆ’Î±

(6)

(7)

1
Pohang University of Science and Technology (POSTECH), Pohang, South Korea 2 University of Cambridge, Cambridge, United
Kingdom 3 Uber AI Labs, San Francisco, CA, USA 4 Hong Kong University of Science and Technology (HKUST), Clearwater Bay,
Hong Kong. Correspondence to: Juho Lee <stonecold@postech.ac.kr>.

Proceedings of the 34 th International Conference on Machine Learning, Sydney, Australia, 2017. JMLR: W&CP. Copyright 2017 by
the author(s).

Supp: Power-law simple graphs

where Î³(Â·, Â·) is the lower incomplete gamma function.
P

Let â†’ denote convergence in probability. The following lemma is a standard mean convergence result:
P

Lemma 1.1. VÌ„s,n â†’ E[Vs,n ], as n â†’ âˆž.
Proof. For all Îµ > 0, by Chebyshevâ€™s inequality and the condition in Eq. (2),
P{|VÌ„s,n âˆ’ E[Vs,n ]| â‰¥ Îµ} â‰¤

2
E[Vs,n
]
1
Var(Vs,n )
â‰¤
=
2
2
nÎµ
nÎµ
Zn Îµ2



CnÎ±
Î³(2s âˆ’ Î±, Cn )
âˆ’
n(2s âˆ’ Î±)
nCn2sâˆ’2Î±


â†’ 0,

(8)

as n â†’ âˆž, as desired.
The following lemma will be used to study various higher order moments in later results:
Lemma 1.2. For s â‰¥ 2,
Ms,n

Pn
Ws
P
:= Pni=1 n,i s â†’ 0,
( i=1 Wn,i )

as n â†’ âˆž.

(9)

Proof. We have
Ms,n =

nCnsâˆ’Î± VÌ„s,n
=
s
ns Cnsâˆ’sÎ± VÌ„1,n



CnÎ±
n

sâˆ’1

VÌ„s,n
.
s
VÌ„1,n

(10)

As n â†’ âˆž, the first factor on the right hand side clearly converges to zero (c.f. Eq. (2)), and, by Lemma 1.1, the second
term converges to a constant in probability.
P
Recall that Dn,i := j6=i Xi,j is the degree of the i-th node in the graph X | r âˆ¼ GRG(n, r), given by Eq. (4). The
following result will show up in later calculations involving the probability generating function (PGF) of the degree random
variables Dn,i :
Lemma 1.3. For every collection t1 , . . . , tn with |ti | â‰¤ 1, for i â‰¤ n,
n
hY
i
Y Ln + ti tj wi wj
D
E
ti n,i | Wn,1 = w1 , . . . , Wn,n = wn =
,
Ln + wi wj
i=1

(11)

i<jâ‰¤n

for positive w1 , . . . , wn .
Proof. The proof is given by Britton et al. (2006).
The following result studies a representation of the PGF of the degree random variables and their higher order moments:
Lemma 1.4. Fix a node k â‰¤ n. Define
Fn,k (t; wk ) :=

Y Ln,âˆ’k + wk + twk Wn,i
,
Ln,âˆ’k + wk + wk Wn,i

for |t| â‰¤ 1, and wk > 0,

(12)

i6=k

where Ln,âˆ’k :=
hold:

P

i6=k

(s)

1. Fn,k (t; wk ) is uniformly bounded, for all n â‰¥ 1;
(s)

P

(s)

Wn,i . Note that the s-th derivative Fn,k (t; wk ) exists for all s â‰¥ 0. For all s â‰¥ 0, the following

2. Fn,k (t; wk ) â†’ wks exp{(t âˆ’ 1)wk }, as n â†’ âˆž.

Supp: Power-law simple graphs

Proof. In the case s = 0, Fn,k (t; wk ) is trivially bounded by 1 since |t| â‰¤ 1. By the Taylor series expansion log(1 + x) =
x + O(x2 ), we have
P



2
Ln,âˆ’k
i6=k Wn,i
2
.
(13)
Fn,k (t; wk ) = exp (t âˆ’ 1)wk
+ O wk
Ln,âˆ’k + wk
(Ln,âˆ’k + wk )2
By Lemma 1.1,
Ln,âˆ’k
VÌ„1,n,âˆ’k
P
=
â†’ 1,
Ln,âˆ’k + wk
VÌ„1,n,âˆ’k + wk /(n âˆ’ 1)/Cn1âˆ’Î±
where VÌ„1,n,âˆ’k is the empirical mean in Eq. (6) excluding the element V1,n,k . Furthermore, by Lemma 1.2,
P


2
P
i6=k Wn,i
2
â‰¤ O(wk2 M2,n,âˆ’k ) â†’ 0,
O wk
(Ln,âˆ’k + wk )2

(14)

(15)

where Ms,n,âˆ’k is Ms,n computed without Vs,n,k . Combining, we have
P

Fn,k (t; wk ) â†’ exp{(t âˆ’ 1)wk }.

(16)

Before proceeding for s â‰¥ 1, we define
Qr,n,k (t; wk ) :=

X
i6=k

r
Wn,i
,
(Ln,âˆ’k + wk + twk Wn,i )r

(17)

for all r, n â‰¥ 1. One can easily see that Qr,n,k (t; wk ) â‰¤ 1 for all r, n â‰¥ 1. For r = 1, we have
X
i6=k

Wn,i
â‰¤ Q1,n,k (t; wk ) â‰¤ 1,
Ln,âˆ’k + wk + twk Cn

(18)

and
X
i6=k

Wn,i
1
=
Ln,âˆ’k + wk + twk Cn
1 + wk /Ln,âˆ’k + twk Cn /Ln,âˆ’k

âˆ’1
wk
CnÎ± n
P
âˆ’1
âˆ’1
= 1+
VÌ„
â†’ 1.
VÌ„
+ twk
n n âˆ’ 1 s,n,âˆ’k
(n âˆ’ 1)Cn1âˆ’Î± s,n,âˆ’k

(19)

P

Hence, by the squeeze theorem, Q1,n,k (t; wk ) â†’ 1. For r â‰¥ 2, we have
P

0 â‰¤ Qr,n,k (t; wk ) â‰¤ Mr,n,âˆ’k â†’ 0,

(20)

P

by Lemma 1.2. Hence, we have Qr,n,k (t; wk ) â†’ 0 for r â‰¥ 2.
Now we show that
(s)

(sâˆ’1)

Fn,k (t; wk ) = wk Fn,k

(t; wk )Q1,n,k (t; wk ) +

s
X

(sâˆ’r)

as,r Fn,k

(t; wk )Qr,n,k (t; wk ),

(21)

r=2

for some constants {as,r } for all s â‰¥ 1 and r â‰¥ 2. We proceed by the mathematical induction. For s = 1,
(1)

Fn,k (t; wk ) =

X
i6=k

Y Ln,âˆ’k + wk + twk Wn,j
wk Wn,i
Ln,âˆ’k + wk + wk Wn,i
Ln,âˆ’k + wk + wk Wn,j
j6=i,k

= wk Fn,k (t; wk )Q1,n,k (t; wk ).

(22)

Supp: Power-law simple graphs

Now by the inductive hypothesis,
(s+1)

Fn,k

(s)

(sâˆ’1)

(t; wk ) = wk Fn,k (t; wk )Q1,n,k (t; wk ) âˆ’ wk2 Fn,k
+

s
X

(s+1âˆ’r)

as,r (Fn,k

(t; wk )Q2,n,k (t; wk )
(sâˆ’r)

(t; wk )Qr,n,k (t; wk ) âˆ’ rwk Fn,k

Qr+1,n,k (t; wk ))

r=2

=

(s)
wk Fn,k (t; wk )Q1,n,k (t; wk )

+

s+1
X

(s+1âˆ’r)

as+1,r Fn,k

(t; wk )Qr,n,k (t; wk ),

(23)

r=2

where
as+1,2 = as,2 âˆ’ wk2 ,

as+1,r = as,r âˆ’ as,râˆ’1 (r âˆ’ 1)wk

for r â‰¥ 2,

(24)

so the inductive argument holds.
(s)

Having (21), by mathematical induction, we can easily show that Fn,k (t; wk ) is uniformly bounded for all s, n â‰¥ 1.
Moreover,
(1)

P

Fn,k (t; wk ) = wk Fn,k (t; wk )Q1,n,k (t; wk ) â†’ wk exp{(t âˆ’ 1)wk },

(25)

by (16) and (19). Combining this with (20), by mathematical induction, we can show that for all s â‰¥ 1,
(s)

P

Fn,k (t; wk ) â†’ wks exp{(t âˆ’ 1)wk }.

(26)

We will now use our collected results to analyze the asymptotic distribution of the degree random variables; the following
result characterizes this distribution:
Lemma 1.5. Fix a node k. Given {Wn,k = wk }, for some wk > 0, the degree Dn,k of node k converges in distribution to
a Poisson random variable with rate wk , as n â†’ âˆž.
Proof. The PGF of Dn,k is given by
E[tDn,k | Wn,k = wk ] = E[Fn,k (t; wk )],

for |t| â‰¤ 1.

(27)

Note that these expectations are under the Ïƒ-field generated by {Wk = wk }. For all s â‰¥ 0, we will derive the limit of
P{Dn,k = s | wk }, as n â†’ âˆž, which we note is given by the s-th order derivatives of the PGF in Eq. (27), evaluated at
(s)
the argument t = 0. It therefore suffices to show that E[Fn,k (t; wk )] â†’ wks exp{(t âˆ’ 1)wk }, as n â†’ âˆž, for all s â‰¥ 0.
(s)

(s)

P

By Lemma 1.4, we know that Fn,k (t; wk ) is uniformly bounded and that Fn,k (t; wk ) â†’ wks exp{(t âˆ’ 1)wk }, as n â†’ âˆž.
Therefore, by uniform integrability,
h
i
(s)
(s)
lim E[Fn,k (t; wk )] = E lim Fn,k (t; wk ) = wks exp{(t âˆ’ 1)wk }.
(28)
nâ†’âˆž

nâ†’âˆž

We are now ready to prove the main theorems in the paper.
Proof of Theorem 3.1. We will first verify that, for y  1, P{Dn,k = y} â†’ cy âˆ’1âˆ’Î± for every node k and for some
constant c > 0 as n â†’ âˆž. By Lemma 1.5, conditioned on {Wk = wk }, the degree Dn,k converges in distribution to a
Poisson random variable with rate wk . Then by dominated convergence,
Z âˆž
lim P{Dn,k = y} = lim
P{Dk = y|wk }pn (dwk )
nâ†’âˆž
nâ†’âˆž 0
Z âˆž y âˆ’wk
wk e
=
p(dwk )
y!
0
Î±Î“(y âˆ’ Î±)
=
(1 âˆ’ 2Î±âˆ’y ).
(29)
y!Î“(1 âˆ’ Î±)

Supp: Power-law simple graphs

By the asymptotics of the Gamma function, for y  1, we have
lim P{Dn,k = y} = cy âˆ’1âˆ’Î± ,

(30)

nâ†’âˆž

for some constant c.
Next we show that, for any finite m, the collection of random variables Dn,1 , . . . , Dn,m are asymptotically independent,
as n â†’ âˆž. We compute the (joint) probability generating function of (Dn,1 , . . . , Dn,m ), with |ti | â‰¤ 1 for i = 1, . . . , m.
By Lemma 1.3,
m
m Y
m
hY
i
hY
Ln + ti tj Wn,i Wn,j
D
E
ti n,i = E
Ln + Wn,i Wn,j
i=1
i=1 j=i+1

n
Y

Ln + ti Wn,i Wn,j i
Ln + Wn,i Wn,j
j=m+1

m Y
m
h hY
Ln,m+1:n + `n,1:m + ti tj wi Wn,j
=E E
Ln,m+1:n + `n,1:m + wi Wn,j
i=1 j=i+1

Ã—

n
Y

ii
Ln,m+1:n + `n,1:m + ti wi Wn,j
| Wn,1:m = w1:m .
Ln,m+1:n + `n,1:m + wi Wn,j
j=m+1

(31)

Given w1:m , by a similar argument as in the proof of Lemma 1.4, one can easily show that
m
Y
Ln,m+1:n + `n,1:m + ti tj wi Wn,j P
â†’ 1,
Ln,m+1:n + `n,1:m + wi Wn,j
j=i+1

as n â†’ âˆž,

(32)

and
n
Y

Ln,m+1:n + `n,1:m + ti wi Wn,j P
â†’ exp{(ti âˆ’ 1)wi },
Ln,m+1:n + `n,1:m + wi Wn,j
j=m+1

as n â†’ âˆž.

(33)

Hence, again by a similar argument as in the proof of Lemma 1.4, we have
m
m
hY
i Y
Dn,i
lim E
ti
=
E[exp{(ti âˆ’ 1)Wi }],

nâ†’âˆž

i=1

(34)

i=1

that is, the joint PGF asymptotically factorizes into the product of the PGFs for i.i.d. random variables, and the result
follows.
Proofâˆš
of Theorem 3.2. Using the fact that the expected number of nodes En :=
tn = t and obtain
h Y L + tW W i
n
n,i n,j
E[tEn ] = E
.
Ln + Wn,i Wn,j

Pn

i=1

Dn,i /2, we may take t1 = Â· Â· Â· =

(35)

i<jâ‰¤n

We evaluate the derivative of the PGF to obtain the first moment
h X
âˆ‚E[tEn ] 
Wn,i Wn,j i 1 h X Wn,i Wn,j i n
â‰¤ E
= E[Wn ].
E[En ] =
=E

âˆ‚t
Ln + Wn,i Wn,j
2
Ln
2
t=1
i<jâ‰¤n

(36)

iâ‰¤jâ‰¤n

Since
E[Wn ] =

o
1 n Cn1âˆ’Î±
âˆ’ Î³(1 âˆ’ Î±, Cn ) ,
Zn 1 âˆ’ Î±

(37)

we have
E[En ] = O(nCn1âˆ’Î± ).

(38)

Supp: Power-law simple graphs

Proof of Theorem 5.1. Recall that
P{X = x | r} =

Y
i<jâ‰¤n

n
Y x Y
ri,j
D
= Gâˆ’1 (r)
Ai,ji,j
Ui n,i ,
1 + ri,j
i=1

(39)

i<jâ‰¤n

where A := (Ai,j )i<jâ‰¤n and
G(r) :=

Y

(1 + Ai,j Ui Uj ).

(40)

i<jâ‰¤n

Since

P

x

P{X = x | r} = 1, we have
G(r) =

X Y

x

Ai,ji,j

x i<jâ‰¤n

n
Y

Dn,i

ui

.

(41)

i=1

The joint PGF of (Dn,1 , . . . , Dn,n ) is then
n
n
hY
i X
Y
D
D (x)
ti n,i | A, Wn,1:n =
E
P{X = x | r}
ti n,i
i=1

x

= Gâˆ’1 (r)

i=1

X Y
x i<jâ‰¤n

x

Ai,ji,j

n
Y

(ti Ui )Dn,i

i=1

Y 1 + Ai,j ti tj Ui Uj
=
.
1 + Ai,j Ui Uj

(42)

i<jâ‰¤n

The remainder of the proof follows analogously to the proof of Theorem 3.1 above.

References
Britton, T., Deijfen, M., and Martin-LoÌˆf, A. Generating simple random graphs with prescribed degree distribution. Journal
of Statistical Physics, 124(6):1377â€“1397, 2006.
Kingma, D. P. and Welling, M. Auto-encoding variational Bayes. In ICLR, 2014.
Knowles, D. A. Stochastic gradient variational Bayes for gamma approximating distributions.
arXiv:1509.01631, 2015.

arXiv preprint

Salimans, T. and Knowles, D. A. Fixed-form variational posterior approximation through stochastic linear regression.
Bayesian Analysis, 8(4):837â€“882, 2013.

