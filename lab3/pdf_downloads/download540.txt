Support Recovery of Hard Thresholding Pursuit

A. Technical Lemmas
The following lemma is a characterization of the co-coercivity of the objective function F (x). A similar result was obtained
in Nguyen et al. (2014, Corollary 8) but we present a refined analysis which is essential for our purpose.
Lemma 9. For a given support set Ω, assume that the continuous function F (x) is M|Ω| -RSS and is mK -RSC for some
sparsity level K. Then, for all vectors w and w′ with |supp (w − w′ ) ∪ Ω| ≤ K, we have

2
k∇Ω F (w ′ ) − ∇Ω F (w)k ≤ 2M|Ω| F (w ′ ) − F (w) − h∇F (w), w ′ − wi .
Proof. We define an auxiliary function

def

G(x) = F (x) − h∇F (w), xi .
For all vectors x and y, we have
k∇G(x) − ∇G(y)k = k∇F (x) − ∇F (y)k ≤ M|supp(x−y)| kx − yk ,
which is equivalent to
G(x) − G(y) − h∇G(y), x − yi ≤

Mr
2
kx − yk ,
2

(7)

where r = |supp (x − y)|. On the other hand, due to the RSC property of F (x), we obtain
G(x) − G(w) = F (x) − F (w) − h∇F (w), x − wi ≥

m|supp(x−w)|
2
kx − wk ≥ 0,
2

provided that |supp (x − w)| ≤ K. For the given support set Ω, we pick x = w′ − M1|Ω| ∇Ω G(w ′ ). Clearly, for such a
choice of x, we have supp (x − w) = supp (w − w′ ) ∪ Ω. Hence, by assuming that |supp (w − w′ ) ∪ Ω| is not larger
than K, we get


1
G(w) ≤ G w′ −
∇Ω G(w ′ )
M|Ω|


(7)
1
1
2
∇Ω G(w ′ ) +
k∇Ω G(w′ )k
≤ G(w ′ ) + ∇G(w ′ ), −
M|Ω|
2M|Ω|
1
2
= G(w ′ ) −
k∇Ω G(w ′ )k .
2M|Ω|
Now expanding ∇Ω G(w ′ ) and rearranging the terms give the desired result.
Lemma 10 (Lemma 1 in Wang et al. (2016)). Let u and z be two distinct vectors and let W = supp (u) ∩ supp (z). Also,
let U be the support set of the top r (in magnitude) elements in u. Then, the following holds for all r ≥ 1:
s

|W |
hu, zi ≤
kuU k · kz W k .
r
Lemma 11. Suppose that F (x) is mK -restricted strongly convex and MK -restricted smooth for some sparsity level K >
0. Then for all η > 0, all vectors x, x′ ∈ Rd and for any Hessian matrix H of F (x), we have
|hx, (I − ηH)x′ i| ≤ ρ kxk · kx′ k ,

if |supp (x) ∪ supp (x′ )| ≤ K,

and
k((I − ηH)x)S k ≤ ρ kxk ,

if |S ∪ supp (x)| ≤ K,

where

	
ρ = max |ηmK − 1| , |ηMK − 1| .

Support Recovery of Hard Thresholding Pursuit

Proof. Since H is a Hessian matrix, we always have a decomposition H = A⊤ A for some matrix A. Denote T =
supp (x) ∪ supp (y). By simple algebra, we have
|hx, (I − ηH)x′ i| = |hx, x′ i − η hAx, Ax′ i|
ζ1

= |hx, x′ i − η hAT x, AT x′ i|
D
E

′ 
=  x, (I − ηA⊤
T AT )x 




′
≤ I − ηA⊤
A
T  · kxk · kx k
T
ζ2

≤ max {|ηmK − 1| , |ηMK − 1|} · kxk · kx′ k .

Here, ζ1 follows from the fact that supp (x) ∪ supp (y) = T and ζ2 holds because the RSC and RSS properties imply that
the singular values of any Hessian matrix restricted on an K-sparse support set are lower and upper bounded by mK and
MK , respectively.
For some index set S subject to |S ∪ supp (x)| ≤ K, let x′ = ((I − ηH)x)S . We immediately obtain
2

kx′ k = hx′ , (I − ηH)xi ≤ ρ kx′ k · kxk ,
indicating
k((I − ηH)x)S k ≤ ρ kxk .
Lemma 12. Suppose that F (x) is mK -restricted strongly convex and MK -restricted smooth for some sparsity level K >
0. For all η > 0, all vectors x, x′ ∈ Rd and support set T such that |supp (x − x′ ) ∪ T | ≤ K, the following holds:
k(x − x′ − η∇F (x) + η∇F (x′ ))T k ≤ ρ kx − x′ k
where ρ is given in Lemma 11.
Proof. In fact, for any two vectors x and x′ , there always exists a quantity θ ∈ [0, 1], such that
∇F (x) − ∇F (x′ ) = ∇2 F (θx + (1 − θ)x′ ) (x − x′ ).
Let H = ∇2 F (θx + (1 − θ)x′ ). We write
k(x − x′ − η∇F (x) + η∇F (x′ ))T k = k(x − x′ − ηH(x − x′ ))T k
= k((I − ηH)(x − x′ ))T k
≤ ρ kx − x′ k ,

where the last inequality applies Lemma 11.
Lemma 13. Suppose that x is a k-sparse vector and let b = x − η∇F (x). Let T be the support set that contains the k
largest absolute values of b. Assume that the function F (x) is M2k -restricted smooth, then we have the following:
F (bT ) ≤ F (x) −

1 − ηM2k
2
kbT − xk .
2η

Proof. The RSS condition implies that
M2k
2
kbT − xk
2
1
M2k
2
2
≤ −
kbT − xk +
kbT − xk ,
2η
2

F (bT ) − F (x) ≤ h∇F (x), bT − xi +

Support Recovery of Hard Thresholding Pursuit

where the second inequality is due to the fact that
2

kbT − bk = kbT − x + η∇F (x)k
≤ kx − x + η∇F (x)k

2

2

= kη∇F (x)k2 ,

implying
2η h∇F (x), bT − xi ≤ − kbT − xk2 .

Lemma 14. Suppose that F (x) is mK -RSC. Then for any vectors x and x′ with kx − x′ k0 ≤ K, the following holds:
′

kx − x k ≤

s

2 max{F (x) − F (x′ ), 0} 2 k∇T F (x′ )k
+
mK
mK

where T = supp (x − x′ ).
Proof. The RSC property immediately implies
mK
2
kx − x′ k
2
mK
2
kx − x′ k .
≥ − k∇T F (x′ )k · kx − x′ k +
2

F (x) − F (x′ ) ≥ h∇F (x′ ), x − x′ i +

Discussing the sign of F (x) − F (x′ ) and solving the above quadratic inequality completes the proof.
Lemma 15. Assume that F (x) is mk+s -RSC and M2k -RSS. Suppose that for all t ≥ 0, xt is k-sparse and the following
holds:

F (xt+1 ) − F (x̄) ≤ µ F (xt ) − F (x̄) + τ,

where 0 < µ < 1, τ ≥ 0 and x̄ is an arbitrary s-sparse signal. Then,
 t

x − x̄ ≤

r


2M √ t 
3
( µ) x0 − x̄ + k∇k+s F (x̄)k +
m
m

s

2τ
.
m(1 − µ)

Proof. The RSS property implies that

Hence,




 M 0
x − x̄2
F (x0 ) − F (x̄) ≤ ∇F (x̄), x0 − x̄ +
2
2

1
M
M 
2
0
x − x̄ +
x0 − x̄2
k∇k+s F (x̄)k +
≤
2
2M
2
 0
2
1
2
≤ M x − x̄ +
k∇k+s F (x̄)k .
2M

2
τ
1
2
k∇k+s F (x̄)k +
.
F (xt ) − F (x̄) ≤ µt M x0 − x̄ +
2M
1−µ

Support Recovery of Hard Thresholding Pursuit

By Lemma 14, we have
s

τ
2
k∇k+s F (x̄)k2
+
+
k∇k+s F (x̄)k
2M
1−µ m
r
r

2M √ t 
1
0


≤
( µ) x − x̄ +
k∇k+s F (x̄)k
m
mM
s
2τ
2
+ k∇k+s F (x̄)k +
m
m(1 − µ)
s
r

2M √ t 
2τ
3
( µ) x0 − x̄ +
k∇k+s F (x̄)k +
.
≤
m
m
m(1 − µ)

 t

x − x̄ ≤

r

2
m

2

µt M kx0 − x̄k +

Lemma 16. Let x̄ ∈ Rd be an s-sparse vector supported on S. For a k-sparse vector x supported on Q with k ≥ s, let
b = x − η∇F (x) and let T = supp (b, k). Suppose that the function F (x) is m2k+s -RSC and M2k+s -RSS. Then we have


x̄S\T  ≤ νρ kx − x̄k + νη k∇T ∆S F (x̄)k ,
p
where ν = 1 + s/k and ρ is given by Lemma 11.
Proof. We note the fact that the support sets T \S and S\T are disjoint. Moreover, the set T \S contains |T \S| number of
top |T | elements of b. Hence, we have



1 
bT \S 2 ≥ 1 bS\T 2 .
|T \S|
|S\T |

That is,


bT \S  ≥

s


|T \S| 
bS\T  =
|S\T |

s


k − |T ∩ S| 
bS\T  ≥
s − |T ∩ S|

(8)

r


k
bS\T  .
s

Note that the above holds also for T = S. Since x̄ is supported on S, the left hand side reads as


 

bT \S  = 
(x − x̄ − η∇F (x))T \S  ,
while the right hand side reads as

Denote ν =



 

bS\T  = 
(x − x̄ − η∇F (x))S\T + x̄S\T 


 


≥ x̄S\T  − (x − x̄ − η∇F (x))S\T  .

p
1 + s/k. In this way, we arrive at
r 
 



 

x̄S\T  ≤ s 
(x − x̄ − η∇F (x))T \S  + (x − x̄ − η∇F (x))S\T 
k
≤ ν k(x − x̄ − η∇F (x))T ∆S k
≤ ν k(x − x̄ − η∇F (x) + η∇F (x̄))T ∆S k + νη k∇T ∆S F (x̄)k




≤ ν (x − x̄ − η∇F (x) + η∇F (x̄))T ∪Q∪S  + νη k∇T ∆S F (x̄)k
≤ νρ2k+s kx − x̄k + νη k∇T ∆S F (x̄)k ,

where the second inequality follows from the fact that ax + by ≤
last inequality.

p
√
a2 + b2 x2 + y 2 and we applied Lemma 12 for the

Support Recovery of Hard Thresholding Pursuit

Lemma 17. Consider the HTP algorithm with exact solutions. Assume (A1). Then



∇S t+1 \S t F (xt )2 ≥ 2mζ F (xt ) − F (x̄) ,
where

 t+1 t 
S \S 
.
ζ = t+1 t
|S \S | + |S\S t |
Proof. The lemma holds clearly for either S t+1 = S t or F (xt ) ≤ F (x̄). Hence, in the following we only prove the result
by assuming S t+1 6= S t and F (xt ) > F (x̄). Due to the RSC property, we have

 mk+s 


x̄ − xt 2 ,
F (x̄) − F (xt ) − ∇F (xt ), x̄ − xt ≥
2

which implies




 mk+s 
x̄ − xt 2 + F (xt ) − F (x̄)
∇F (xt ), −x̄ ≥
2
p

p
≥ 2mk+s x̄ − xt  F (xt ) − F (x̄).

By invoking Lemma 10 with u = ∇F (xt ) and z = −x̄ therein, we have
s

 




|S\S t |
t
+ 1 ∇S t+1 \S t F (xt ) · x̄S\S t 
∇F (x ), −x̄ ≤
t+1
t
|S \S |
s

 

|S\S t |
=
+ 1 ∇S t+1 \S t F (xt ) · (x̄ − xt )S\S t 
|S t+1 \S t |
s

 

|S\S t |
≤
+ 1 ∇S t+1 \S t F (xt ) · x̄ − xt  .
t+1
t
|S \S |

worth mentioning that the first inequality above holds because ∇F (xt ) is supported on S t and S t+1 \S t contains the
It is
S t+1 \S t  number of largest (in magnitude) elements of ∇F (xt ). Therefore, we obtain the result.

B. Proofs for Section 2
B.1. Proof for Prop. 1

Proof. Due to the RSS property, we have



 M  t+1
t+1
t
t
t
b t+1 − xt 2
F (bt+1
+
S t+1 ) − F (x ) ≤ ∇F (x ), bS t+1 − x
S
2
2
E M 
D
ζ1
 t+1

t+1
t
= ∇S t+1 \S t F (x ), bS t+1 \S t +
bS t+1 \S t 
2
2 

2 
 t

t

+ bt+1
−
x
+
x

t+1
t
t
t+1
S
∩S
S \S
S t+1 ∩S t

2
E
ζ2 D
 t+1

≤ ∇S t+1 \S t F (xt ), bt+1
S t+1 \S t + M bS t+1 \S t 

2
ζ3
= − η(1 − ηM ) ∇S t+1 \S t F (xt ) .

Above, we observe that ∇F (xt ) is supported on S t and we simply docompose the support set S t+1 ∪ S t into three
mutually disjoint sets, and hence ζ1 holds. To see why ζ2 holds, we note that for any set Ω ⊂ S t , bt+1
= xtΩ . Hence,
Ω
t+1
t+1
t+1
t
t
bS t+1 ∩S t = xS t+1 ∩S t . Moreover, since xS t \S t+1 = bS t \S t+1 and any element in bS t \S t+1 is not larger than that in




 t

 t+1

t+1
bt+1
(recall
that
S
is
obtained
by
hard
thresholding),
we
have
≤
x

b
t+1
t
t
t+1
t+1
t
S
S \S
S
\S  where we use the fact
 \St t+1   t+1 t 
t
that S \S  = S \S . Therefore, ζ2 holds. Finally, we write bt+1
S t+1 \S t = −η∇S t+1 \S t F (x ) and obtain ζ3 .

Support Recovery of Hard Thresholding Pursuit

Since xt+1 is a minimizer of F (x) over the support set S t+1 , it immediately follows that


t
t 2

F (xt+1 ) − F (xt ) ≤ F (bt+1
.
S t+1 ) − F (x ) ≤ −η(1 − ηM ) ∇S t+1 \S t F (x )
Now we invoke Lemma 17 and pick η ≤ 1/M ,

F (xt+1 ) − F (xt ) ≤ η(ηM − 1) ·
which gives

where β = 1 −


2m
F (xt ) − F (x̄) ,
1+s


F (xt+1 ) − F (x̄) ≤ β F (xt ) − F (x̄) ,

2mη(1−ηM)
.
1+s

B.2. Proof for Prop. 2
Proof. This is a direct result by combining Prop. 1 and Lemma 15.
B.3. Proof for Lemma 3
Proof. Let xt∗ = arg minsupp(x)⊂S t F (x). Since xt and xt∗ are both supported on S t , we apply Lemma 9 and obtain




∇S t F (xt )2 = ∇S t F (xt ) − ∇S t F (xt )2
∗



≤ 2M F (xt ) − F (xt∗ ) − ∇F (xt∗ ), xt − xt∗
≤ 2M ǫ.
Above, the second inequality uses the fact that ∇S t F (xt∗ ) = 0 and F (xt ) ≤ F (xt∗ ) + ǫ.
B.4. Proof for Prop. 4
Proof. We have by Lemma 16 that

 √ 

x̄ t+1  ≤ 2ρ xt − x̄ + 2 k∇k+s F (x̄)k ,
S
m

where ρ = 1 − ηm. On the other hand, Lemma 18 together with Lemma 3 shows that

Therefore,

We need to ensure

 t+1


x
− x̄ ≤ κ x̄

S t+1

√

 + 1 k∇k F (x̄)k + 1 2M ǫ.
m
m

 t+1
 √

 3κ
x
− x̄ ≤ 2κρ xt − x̄ +
k∇k+s F (x̄)k +
m

√
2M ǫ
m

√
2κ(1 − ηm) < 1.
Let η = η ′ /M with η ′ < 1. Then, the above holds provided that
1
1
κ < 1 + √ and η ′ > κ − √ .
2
2
√
√
By induction and picking proper η ′ to make 2κ(1 − ηm) < 2/4, we have

√
√


 t

x − x̄ ≤ ( 2(κ − η ′ ))t x0 − x̄ + 6κ k∇k+s F (x̄)k + 4 M ǫ .
m
m

Support Recovery of Hard Thresholding Pursuit

B.5. Proof for Prop. 5
Proof. Our proof in this part is inspired by Yuan et al. (2016). Let xt∗ = arg minsupp(x)⊂S t F (x). Then
F (xt ) − F (xt−1 ) ≤ F (xt∗ ) − F (xt−1 ) + ǫ

≤ F (btS t ) − F (xt−1 ) + ǫ

1 − ηM 
btS t − xt−1 2 + ǫ,
≤ −
2η

2
where the last inequality follows from Lemma 13. Now we bound the term btS t − xt−1  . Note that xt−1 is supported
on S t−1 . Hence,
 t


2
t−1
bS t − xt−1 2 = xt−1
t
) − xt−1 
S t ∩S t−1 − η∇S F (x

2

t−1 
t
= −xt−1
−
η∇
F
(x
)

S
S t−1 \S t
2


2


2
∇S t F (xt−1 )
= xt−1
t−1
t + η
S

\S


2
≥ η 2 ∇S t \S t−1 F (xt−1 ) .

We thus have

F (xt ) − F (xt−1 ) ≤ −


Denote ξ = ∇S t−1 F (xt−1 ). We claim that


(1 − ηM )η 
∇S t \S t−1 F (xt−1 )2 + ǫ.
2




∇S t \S t−1 F (xt−1 )2 ≥ m F (xt−1 ) − F (x̄) − 2ξ 2 ,

(9)

which, combined with Lemma 3, immediately shows
F (xt ) − F (xt−1 ) ≤ −
Using Lemma 15 completes the proof.


(1 − ηM )ηm
F (xt−1 ) − F (x̄) + 2ǫ.
2





To show (9), we consider two exhausitive cases: S t \S t−1  ≥ s and S t \S t−1  < s, and prove that (9) holds for both
cases.


Case I. S t \S t−1  ≥ s. Due to the RSC property, we have


m
x̄ − xt−1 2
2



≤ F (x̄) − F (xt−1 ) − ∇F (xt−1 ), x̄ − xt−1



m
x̄ − xt−1 2 + 1 ∇S∪S t−1 F (xt−1 )2
≤ F (x̄) − F (xt−1 ) +
2
2m

2

m
t−1
t−1
x̄ − x  + 1 ∇S\S t−1 F (xt−1 )2 +
= F (x̄) − F (x ) +
2
2m

2

m
t−1
t−1
x̄ − x  + 1 ∇S\S t−1 F (xt−1 )2 +
= F (x̄) − F (x ) +
2
2m


1 
∇S t−1 F (xt−1 )2
2m
1 2
ξ .
2m

Therefore, we get




∇S\S t−1 F (xt−1 )2 ≥ 2m F (xt−1 ) − F (x̄) − ξ 2 .




Since S t contains the k largest absolute values of bt , and S t \S t−1  ≥ s ≥ S\S t−1 , we have

2 
2
 t



bS t \S t−1  ≥ btS\S t−1  ,

Support Recovery of Hard Thresholding Pursuit

which immediately implies (9) by noting the fact that btS t \S t−1
−η∇S\S t−1 F (xt−1 ).

=

−η∇S t \S t−1 F (xt−1 ) and btS\S t−1



Case II. S t \S t−1  < s. Again, we use the RSC property to obtain

m
x̄ − xt−1 2
2



≤ F (x̄) − F (xt−1 ) − ∇F (xt−1 ), x̄ − xt−1



m
x̄ − xt−1 2 + 1 ∇S∪S t−1 F (xt−1 )2
≤ F (x̄) − F (xt−1 ) +
4
m

2
m
1 
1
t−1
t−1 2

= F (x̄) − F (x ) +
x̄ − x
+ ∇S\S t−1 F (xt−1 ) + ξ 2
4
m
m


m
1 
t−1
t−1 2
t−1 2


= F (x̄) − F (x ) +
∇S\(S t ∪S t−1 ) F (x )
x̄ − x
+
4
m

1 
∇(S t \S t−1 )∩S F (xt−1 )2 + 1 ξ 2
+
m
m
2

1 
m
t−1 2
t−1

x̄ − x
+ ∇S\(S t ∪S t−1 ) F (xt−1 )
≤ F (x̄) − F (x ) +
4
m

1 
1 2
t−1 2

+
∇S t \S t−1 F (x ) + ξ .
m
m

2
t−1


We consider the term ∇S\(S t ∪S t−1 ) F (x ) above. Actually, we have
btS\(S t ∪S t−1 ) = −η∇S\(S t ∪S t−1 ) F (xt−1 ).

=

(10)

Since S t contains the k largest absolute values of bt , we know that any component in btΩ is not larger than that in btS t
subject to Ω ∩ S t = ∅. In particular,

2

2
 t

 t

bS\(S t ∪S t−1 ) 
b(S t ∩S t−1 )\S 
≤
.
|S\(S t ∪ S t−1 )|
|(S t ∩ S t−1 )\S|




Note that S t \S t−1  < s implies (S t ∩ S t−1 )\S  ≥ k − 2s. Therefore,

2
η 2 ∇S\(S t ∪S t−1 ) F (xt−1 )
2
s 
 t−1

≤
x(S t ∩S t−1 )\S − η∇(S t ∩S t−1 )\S F (xt−1 )
k − 2s
2
2s 
2sη 2 2

 t−1
≤
ξ
x(S t ∩S t−1 )\S  +
k − 2s
k − 2s
2

2s 
(xt−1 − x̄)(S t ∩S t−1 )\S 2 + 2sη ξ 2
=
k − 2s
k − 2s
2


2s  t−1
2sη 2
2
≤
x
− x̄ +
ξ .
k − 2s
k − 2s
Plugging the above into (10), we obtain





m
2s
x̄ − xt−1 2 ≤ F (x̄) − F (xt−1 ) + m x̄ − xt−1 2 +
x̄ − xt−1 2
2
2
4
(k − 2s)η m



1
2s
1 
2
t−1 

∇S t \S t−1 F (x ) +
+ 1 ξ2.
+
m
m k − 2s

Picking k ≥ 2s +

Since η < 1/M ,

8s
η 2 m2

η 2 m2
4

gives



m
x̄ − xt−1 2 ≤ F (x̄) − F (xt−1 ) + m x̄ − xt−1 2
2
2

 2

η m
1
1 
t−1 2

ξ2 .
∇S t \S t−1 F (x ) +
+
+
m
4
m

+ 1 < 2. Therefore, by re-arranging the above inequality, we prove the claim (9).

Support Recovery of Hard Thresholding Pursuit

C. Proofs for Section 3
The following result holds for all F (x).
Lemma 18. Assume (A1) and (A2). For any k-sparse vector x and s-sparse vector x̄, we have
kx − x̄k ≤ κ kx̄T k +

1
k∇T F (x) − ∇T F (x̄)k ,
m

where T is the support set of x.
Proof.
2

k(x − x̄)T k = hx − x̄ − τ ∇F (x) + τ ∇F (x̄), (x − x̄)T i + τ h∇F (x) − ∇F (x̄), (x − x̄)T i

≤ k(x − x̄ − τ ∇F (x) + τ ∇F (x̄))T k · k(x − x̄)T k + τ k∇T F (x) − ∇T F (x̄)k · k(x − x̄)T k
≤ kx − x̄ − τ ∇T ∪S F (x) + τ ∇T ∪S F (x̄)k · k(x − x̄)T k + τ k∇T F (x) − ∇T F (x̄)k · k(x − x̄)T k
≤ ρ kx − x̄k · k(x − x̄)T k + τ k∇T F (x) − ∇T F (x̄)k · k(x − x̄)T k .

Dividing both sides by k(x − x̄)T k gives
k(x − x̄)T k ≤ ρ kx − x̄k + τ k∇T F (x) − ∇T F (x̄)k .
On the other hand,
kx − x̄k ≤ k(x − x̄)T k + k(x − x̄)T k

≤ ρ kx − x̄k + τ k∇T F (x) − ∇T F (x̄)k + kx̄T k .

Hence, we have
kx − x̄k ≤

τ
1
kx̄T k +
k∇T F (x) − ∇T F (x̄)k .
1−ρ
1−ρ

Picking τ = 1/M completes the proof.
In view of the exact (HTP3), we have
 t



x − x̄ ≤ κ x̄ t  + 1 k∇k F (x̄)k .
S
m

(11)

Now we present the crucial lemma. It is inspired by Bouchot et al. (2016) but we show a more general result.
Lemma 19. Consider the HTP algorithm. Assume (A1) and (A2). Further assume that the sequence of {xt }t≥0 satisfies
 t



x − x̄ ≤ α · β t x0 − x̄ + φ,



 t
x − x̄ ≤ γ x̄ t  + ψ,
S

for positive α, φ, γ, ψ and 0 < β < 1. Suppose that at the n-th iteration (n ≥ 0), S n contains the indices of top p (in
magnitude) elements of x̄. Then, for any integer 1 ≤ q ≤ s − p, there exists an integer r ≥ 1 determined by
√


2 |x̄p+q | > αγ · β r−1 x̄{p+1,...,s}  + θ

where

θ = αψ + φ +

1
k∇2 F (x̄)k ,
m

such that S n+r contains the indices of top p + q elements of x̄ provided that θ ≤

√
2λx̄min for some λ ∈ (0, 1).

Support Recovery of Hard Thresholding Pursuit

Proof. Without loss of generality, we presume that the elements in x̄ are in descending order by their magnitude, i.e.,
|x̄1 | ≥ |x̄2 | ≥ · · · ≥ |x̄s |. We aim at deriving a condition under which [p + q] ⊂ S n+r . To this end, it suffices to enforce




 > max bn+r  .
(12)
min bn+r
i
j
j∈[p+q]

i∈S

On one hand, for any j ∈ [p + q],

On the other hand, for all i ∈ S,

 n+r   n+r−1
 
b
=  x
− η∇F (xn+r−1 ) j 
j

 

≥ |x̄j | −  xn+r−1 − x̄ − η∇F (xn+r−1 ) j 

 

≥ |x̄p+q | −  xn+r−1 − x̄ − η∇F (xn+r−1 ) j  .
 n+r   n+r−1

b
= x
− x̄ − η∇F (xn+r−1 ) i  .
i

Hence, we know that to guarantee (12), it suffices to ensure for all j ∈ [p + q] and i ∈ S that


  

|x̄p+q | >  xn+r−1 − x̄ − η∇F (xn+r−1 ) j  +  xn+r−1 − x̄ − η∇F (xn+r−1 ) i  .
Note that the right-hand side is upper bounded as follows:

 

1 
1 
√  xn+r−1 − x̄ − η∇F (xn+r−1 ) j  + √  xn+r−1 − x̄ − η∇F (xn+r−1 ) i 
2
2




 n+r−1
n+r−1
≤  x
− x̄ − η∇F (x
) {j,i} 







≤  xn+r−1 − x̄ − η∇F (xn+r−1 ) + η∇F (x̄) {j,i}  + η ∇{j,i} F (x̄)


≤ ρ xn+r−1 − x̄ + η k∇2 F (x̄)k

≤ ρα · β r−1 kxn − x̄k + ρφ + η k∇2 F (x̄)k .
Moreover,

Put all together, we have

Therefore, when







kxn − x̄k ≤ γ kx̄S n k + ψ ≤ γ x̄[p]  + ψ = γ x̄{p+1,...,s}  + ψ.

 

1 
1 
√  xn+r−1 − x̄ − η∇F (xn+r−1 ) j  + √  xn+r−1 − x̄ − η∇F (xn+r−1 ) i 
2
2


≤ ραγ · β r−1 x̄{p+1,...,s}  + ραψ + ρφ + η k∇2 F (x̄)k


1
≤ αγ · β r−1 x̄{p+1,...,s}  + αψ + φ +
k∇2 F (x̄)k .
m
√


1
2 |x̄p+q | > αγ · β r−1 x̄{p+1,...,s}  + αψ + φ +
k∇2 F (x̄)k ,
m

we always have (12). Note that the above holds as far as αψ + φ +

1
m

k∇2 F (x̄)k is strictly smaller than

√
2 |x̄s |.

With Lemma 19, we show the following general theorem.
Theorem
20. Assume same conditions
as in Lemma 19. Then HTP successfully identifies the support of x̄ using


log(αγ/(1−λ))
log 2
+ 2 s number of iterations.
2 log(1/β) +
log(1/β)

Support Recovery of Hard Thresholding Pursuit

Proof. Without loss of generality, we presume that the elements in x̄ are in descending order by their magnitude, i.e.,
|x̄1 | ≥ |x̄2 | ≥ · · · ≥ |x̄s |. We partition the support set [s] into K folds S1 , S2 , . . . , SK , where each Si is defined as
follows:
Si = {si−1 + 1, . . . , si }, ∀ 1 ≤ i ≤ K.
Here, s0 = 0 and for all 1 ≤ i ≤ K, the quantity si is inductively given by
n
o
1 
si = max q : si−1 + 1 ≤ q ≤ s and |x̄q | > √ x̄si−1 +1  .
2

In this way, we note that for any two index sets Si and Sj , Si ∩ Sj = ∅ if i 6= j. We also know by the definition of si that

1 
|x̄si +1 | ≤ √ x̄si−1 +1  , ∀ 1 ≤ i ≤ K − 1.
2

(13)

Now we show that after a finite number of iterations, say n, the union of the Si ’s is contained in S n . To this end, we prove
that for all 0 ≤ i ≤ K,
i
[

t=0

St ⊂ S n0 +n1 +···+ni

(14)

for some ni ’s given below.
We pick n0 = 0 and it is easy to verify that S0 ⊂ S 0 . Now suppose that (14) holds for i − 1. That is, the index set of the
top si−1 elements of x̄ is contained in S n0 +···+ni−1 . Due to Lemma 19, (14) holds for i as long as ni satisfies
√


2 |x̄si | > αγ · β ni −1 x̄{si−1 +1,...,s}  + θ.

Note that







x̄{s +1,...,s} 2 = x̄ 2 + · · · + x̄ 2
SK
Si
i−1

≤ (x̄si−1 +1 )2 |Si | + · · · + (x̄sr−1 +1 )2 |SK |

≤ (x̄si−1 +1 )2 |Si | + 2−1 |Si+1 | + · · · + 2i−K |SK |

< 2(x̄si )2 |Si | + 2−1 |Si+1 | + · · · + 2i−K |SK | ,

(15)



where the second inequality follows from (13) and the last inequality follows from the definition of qi . Denote for simplicity
Ti := |Si | + 2−1 |Si+1 | + · · · + 2i−K |SK | .
As we assume θ ≤

Picking

√
2λx̄min , we get
p
√
√


αγ · β ni −1 x̄{si−1 +1,...,s}  + θ < 2αγ |x̄si | β ni −1 Ti + 2λ |x̄si | .

ni = log1/β

√
αγ Ti
+2
1−λ

Support Recovery of Hard Thresholding Pursuit

guarantees (15). It remains to calculate the total number of iterations. In fact, we have
n = n0 + n1 + . . . nK
K

=
ζ1

≤
ζ2

≤
=
ζ3

≤

X
log(αγ/(1 − λ))
1
log Ti + K ·
+ 2K
2 log(1/β) i=1
log(1/β)
! 

K
log(αγ/(1 − λ))
1 X
K
Ti +
log
+2 K
2 log(1/β)
K i=1
log(1/β)
!


K
K
log(αγ/(1 − λ))
2 X
|Si | +
log
+2 K
2 log(1/β)
K i=1
log(1/β)


K
2s
log(αγ/(1 − λ))
log
+
+2 K
2 log(1/β)
K
log(1/β)


log(αγ/(1 − λ))
log 2
+
+ 2 s.
2 log(1/β)
log(1/β)

Above, ζ1 immediately follows by observing
that the logarithmic function is concave. ζ2 uses the fact that after rearP
−j
rangement, the coefficient of |Si | is i−1
2
which is always smaller than 2. Finally, since the function r log(2s/r) is
j=0
monotonically increasing with respect to r and 1 ≤ r ≤ s, ζ3 follows.
Combining this theorem, Lemma 19 and specific results in Prop. 2, Prop. 4 and Prop. 5 gives the main theorems in Section 3.

