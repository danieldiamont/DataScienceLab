Strongly-Typed Agents are Guaranteed to Interact Safely

David Balduzzi 1

Abstract
As artificial agents proliferate, it is becoming increasingly important to ensure that their interactions with one another are well-behaved. In this
paper, we formalize a common-sense notion of
when algorithms are well-behaved: an algorithm
is safe if it does no harm. Motivated by recent
progress in deep learning, we focus on the specific case where agents update their actions according to gradient descent. The paper shows
that that gradient descent converges to a Nash
equilibrium in safe games. The main contribution is to define strongly-typed agents and show
they are guaranteed to interact safely, thereby
providing sufficient conditions to guarantee safe
interactions. A series of examples show that
strong-typing generalizes certain key features of
convexity, is closely related to blind source separation, and introduces a new perspective on classical multilinear games based on tensor decomposition.

1. Introduction

â€œFirst, do no harmâ€

Recent years have seen rapid progress on core problems
in artificial intelligence such as object and voice recognition (Hinton & et al, 2012; Krizhevsky et al., 2012),
playing video and board games (Mnih et al., 2015; Silver et al., 2016), and driving autonomous vehicles (Zhang
et al., 2016). As artificial agents proliferate, it is increasingly important to ensure their interactions with one another, with humans, and with their environment are safe.
Concretely, the number of neural networks being trained
and used is growing rapidly. There are enormous and increasing economies of scale that can likely be derived from
treating them as populations â€“ rather than as isolated algorithms. How to ensure interacting neural networks cooperate effectively? When can weights trained on one problem
1
Victoria University of Wellington, New Zealand. Correspondence to: David Balduzzi <dbalduzzi@gmail.com>.

Proceedings of the 34 th International Conference on Machine
Learning, Sydney, Australia, PMLR 70, 2017. Copyright 2017
by the author(s).

be adapted to another without adverse effects? The problems fall under mechanism design, a branch of game theory
(Nisan et al., 2007). However, neural nets differ from humans in that they optimize clear objectives using gradient
descent. The setting is thus more structured than traditional
mechanism design.
Safety. The first contribution of the paper is formalize
safety as a criterion on how agents interact. We propose
a basic notion of safety based on the common-sense principle that agents should do no harm to one another. More
formally, each agent optimizes an objective whose value
depends on the actions of the agent and the actions of the
rest of the population. A game is safe if the actions chosen
by each agent do no (infinitesimal) harm to any other agent,
where harm is measured as increased loss.
The key simplifying assumption in the paper is to take gradient descent as a computational primitive (Balduzzi,
2016). Questions about mechanism design are sharpened under the assumption that agents use gradient descent. The assumption holds broadly since the key driver
of progress in artificial intelligence is deep learning, which
uses gradient descent to optimize complicated objective
functions composed from simple differentiable modules
(LeCun et al., 2015).
A weakness of the approach is that it conceives safety more
narrowly than, for example, Amodei et al. (2016) which is
concerned with societal risks arising from artificial intelligence. We argue that a necessary foundational component
of the broader AI-safety project is to clarify exactly what
safety entails when the objectives of the agents and the algorithms they employ are precisely specified.
Strongly-typed games. The second contribution is to introduce type systems suited to multi-agent optimization
problems (that is, games). We build on the typed linear
algebra introduced in Balduzzi & Ghifary (2016). The
nomenclature is motivated by an analogy with types in the
theory of programming. Type systems are used to prevent
untrapped errors (errors that go unnoticed and cause arbitrary behavior later on) when running a program (Cardelli,
1997). A program is safe if it does not cause untrapped errors. Type systems can enforce safety by statically rejecting
all programs that are potentially unsafe.

Strongly-Typed Agents are Guaranteed to Interact Safely

The idea underlying types in programming is that â€œlike
should interact with likeâ€. Typed linear algebra, definition 1, formalizes â€œlike interacts with likeâ€ in the simplest
possible way â€“ by fixing an orthogonal basis. Section 2 introduces a wider class of games than in the literature and
defines safety. Theorem 1 shows that gradient descent converges to a Nash equilibrium in safe games. Section 3 extracts the key ingredients required for safe gradients from
two warmup examples. The ingredients are simultaneous
diagonalization, i.e. the existence of a shared latent orthogonal basis, and monotonic covariation, i.e. that the
derivatives of the objectives have the same sign in the latent coordinate system. The main result, theorem 2, is that
strongly-typed games are guaranteed to be safe.

the complementarity of the loss functions could be checked
or enforced.
The idea of investigating game-theoretic and mechanism
design questions specific to certain classes of algorithms is
introduced in Rakhlin & Sridharan (2013); Syrgkanis et al.
(2015). The papers consider how convergence in games can
be accelerated if the players use variants of mirror descent.
Terminology. If Î± â‰¥ 0 then Î± is positive; if Î± > 0 then it
is strictly positive. A (not necessarily square) matrix D is
diagonal if dij = 0 for all i 6= j and similarly for tensors.
Vectors are columns. The inner product is hv, wi = v| w.

2. Safety
Implications. Safety and strong-typing generalize key
properties of convexity. Convexity is of course the gold
standard for well-behaved gradients. We uncover latent
types and demonstrate safety of Newtonâ€™s method, natural
gradient and mirror descent; see sections 3.2, A2 and A3.
The main theme of sections 4 and 5 is disentangling latent
factors. We show that strong-typing in quadratic games is
closely related to blind source separation. Section 5 analyzes classical N -player games. The analysis yields a new
perspective on classical games based on tensor-SVD that is
closely related to independent component analysis.
Sections 6 and A6 switch to neural networks and analyze two biologically plausible variants of backpropagation
(Balduzzi et al., 2015; Lillicrap et al., 2016). We show that
the main results of the papers are to prove the respective
algorithms are safe.

2.1. Types and orthogonal projections
Let us recall some basic facts about orthogonal projections.
Let (V, hâ€¢, â€¢i) be a vector space equipped with an inner
product. An orthogonal projection is a linear transform
Ï€ : V â†’ V that is
O1. idempotent, Ï€ 2 = Ï€, and
O2. self-adjoint, hÏ€v, v0 i = hv, Ï€v0 i for any v, v0 âˆˆ V .
Lemma 1. Let P denote an (n Ã— k)-matrix with orthogonal columns p1 , . . . , pk . Then the (n Ã— n)-matrix PP| =
Pk
Pk
|
i=1 pi hpi , â€¢i =
i=1 pi pi is an (orthogonal) projection.
Lemma 2. If two orthogonal projections Ï€ and Ï„ commute
then their product is an orthogonal projection.

Scope and related work. This paper lays the foundations
of safety in gradient-based optimization. Applications are
deferred to future work.

Proof. Let q := Ï€Ï„ . If Ï€Ï„ = Ï„ Ï€ then

The literature on safety is mostly focused on problems arising in reinforcement learning, for example ensuring agents
avoid dangerous outcomes (Turchetta et al., 2016; Amodei
et al., 2016; Berkenkamp et al., 2016). Gradients are typically not available in reinforcement learning problems. We
study interactions between algorithms with clearly defined
objectives that utilize gradient-based optimization, which
gives a more technical perspective.

Checking self-adjointness is an exercise.

The idea of a population of neural networks solving multiple related tasks is developed in Fernando et al. (2017),
which uses genetic algorithms to adapt components to new
tasks. However, they repeatedly reinitialize components to
undo the damage done by the genetic algorithm. Our work
is intended, ultimately, to help design algorithms that detect
and avoid damaging updates. A recent survey paper argues
the brain optimizes a family of complementary loss functions (Marblestone et al., 2016) without considering how

q2 = Ï€Ï„ Â· Ï€Ï„ = Ï€Ï€ Â· Ï„ Ï„ = Ï€Ï„ = q.


Definition 1. A type TV = V, hâ€¢, â€¢i, {Ï€ r }R
r=1 is a Ddimensional vector space with an inner product and orthogonal projections
PR Ï€ r : V â†’ V such that Ï€ r Ï€ s = 0
for r 6= s and r=1 Ï€ r = IV is the identity. Type TV has
dimension D and rank R.
A full rank type, D = R, is equivalent to a vector space
equipped with an orthogonal basis. Lower rank types are
less rigid, and can be thought of as vector spaces equipped
with generalized orthogonal coordinates.
2.2. Safe games
Definition 2. A game consists of a type TV , feasible set
H âŠ‚ V , players [N ] := {1, . . . , N }, losses `n : H â†’ R,
and an assignment Ï : [N ] â†’ [R] of players to projections.

Strongly-Typed Agents are Guaranteed to Interact Safely

The type structure and assignments specify the coordinates
controlled by each player. On round t, player n chooses
Î¾ tn âˆˆ V and updates the joint action via
w

t+1

t

=w âˆ’

Ï€ Ï(n) (Î¾ tn )

t

where w , w

t+1

âˆˆ H.

Updates leaving the feasible set can be mapped back into
it, see section A1. The projection Ï€ Ï(n) specifies the coordinates of the joint-action vector that player n can modify.
QN
Example 1. In a block game actions w âˆˆ V = n=1 RDn
decompose as w = (w1 , . . . , wN ) where the nth player
can modify the coordinates in wn . The orthogonal projections Ï€ n (w) = (0, . . . , wn , . . . , 0) form a rank-N type
with Ï(n) = n for all n âˆˆ [N ].
Example 2. In an open game the type has rank(TV ) = 1
so the single projection is the identity and Ï(n) = 1 for all
n. Every player can modify all the coordinates.
Block games coincide with the standard definition of a
game in the literature. Open games arise below when considering Newtonâ€™s method, natural gradients, mirror descent and neural networks.
The goal of each player is to minimize its loss. Safety is the
condition that no playerâ€™s updates harm any other player.
Definition 3. It is safe for player m to choose Î¾ tm âˆˆ V if
it does no infinitesimal harm to any player



Ï€ Ï(m) (Î¾ tm ), âˆ‡ `n (wt ) â‰¥ 0 for all n âˆˆ [N ].
A game is safe if it is safe for players to use gradient descent: i.e. if choosing Î¾ tm := âˆ‡ `m (wt ) is safe for all m.
It is worth getting a degenerate case out of the way. A block
game is decomposable if player mâ€™s loss only depends on
the actions it controls. Intuitively, a decomposable game is
N independent optimization problems. More formally:
Lemma 3. A block game is decomposable if `m (w) =
`m (Ï€ m w) for all w and m. Decomposable games are safe.
Proof. Since Ï€ m is self-adjoint, we have that hÏ€ m Î¾, Î·i =
hÏ€ m Î¾, Ï€ m Î·i. Decomposability implies Ï€ m (âˆ‡ `n ) = 0
when m 6= n, so
(



kÏ€ m (âˆ‡ `m )k22 if m = n
Ï€ m (âˆ‡ `m ), Ï€ m (âˆ‡ `n ) =
0
else

(Daskalakis et al., 2009). We show gradient descent converges to a Nash equilibrium in safe convex games.
Theorem 1. Gradient descent converges to a Nash equilibrium in safe convex games with smooth losses.
PN
Proof. Introduce potential function Î¦(w) =
n=1 Î±n Â·
`n (w) where Î±n > 0 are strictly positive. Then
hÏ€ m (âˆ‡ Î¦), âˆ‡ `m i =

N
X

D
E
Î±n Ï€ m (âˆ‡ `n ), âˆ‡ `m (1)

n=1

â‰¥ Î±m Â· kÏ€ m (âˆ‡ `m )k22 â‰¥ 0
since safety implies the cross-terms are nonnegative. The
playersâ€™ updates therefore converge to either a critical point
of Î¦ or to the boundary of the feasible set. Suppose gradient descent converges to the interior of H. Eq (1) implies
that if âˆ‡ Î¦ = 0 then Ï€ m (âˆ‡ `m ) = 0 for all m. By convexity of the losses, the critical point is a minimizer of each
loss with respect to that playerâ€™s actions, implying it is a
Nash equilibrium. A similar argument holds if gradient descent converges to the boundary, see section A1.
Example 3 (convergence in a safe constrained game). Consider a two-player block game with `1 (x, y) = x + 2y and
`2 (x, y) = 2x + y where player-1 controls x and player2 controls y. Introduce feasible set H = {(x, y) âˆˆ R2 :
x2 + y 2 â‰¤ 1}. The game is convex and safe. The set of
Nash equilibria is the bottom-left quadrant of the boundary {(x, y) âˆˆ H : x, y â‰¤ 0 and x2 + y 2 = 1}. Gradient
âˆ‚
descent with positive combinations of Ï€ 1 (âˆ‡ `1 ) = âˆ‚x
and
âˆ‚
Ï€ 2 (âˆ‡ `2 ) = âˆ‚y always converges to a Nash equilibrium.
A simple game that does not converge is the following zerosum game, which is related to generative adversarial networks (Goodfellow, 2017).
Example 4 (convergence requires positivity). Consider the
two-player block game `1 (x, y) = xy and `2 (x, y) = âˆ’xy
where player-1 controls x and player-2 controls y. The
Nash equilibrium is the origin (x, y) = (0, 0). However,
gradient descent does not converge. Observe that âˆ‡ `1 =
âˆ‚
âˆ‚
âˆ‚
âˆ‚
âˆ‚
y âˆ‚x
+ x âˆ‚y
and âˆ‡ `2 = âˆ’y âˆ‚x
âˆ’ x âˆ‚y
so Ï€ 1 (âˆ‡ `1 ) = y âˆ‚x
âˆ‚
and Ï€ 2 (âˆ‡ `2 ) = âˆ’x âˆ‚y . The flow Ï€ 1 (âˆ‡ `1 ) + Ï€ 2 (âˆ‡ `2 )
rotates around the origin. No positive combination of
Ï€ 1 (âˆ‡ `1 ) and Ï€ 2 (âˆ‡ `2 ) converges to the origin.

which is always positive.

3. Strongly-Typed Games

2.3. Convergence

Strong-typing is based two key ideas: diagonalization and
positivity. Diagonalization is an important tool in applied
mathematics. The Fourier transform simultaneously diagonalizes differentiation and convolution:
 df 
F
= 2Ï€iÏ‰F(f ) and F(f âˆ— g) = F(f ) Â· F(g)
dx

A block game is convex if the feasible set H is compact
and convex and the losses `n : H â†’ R are convex in
the coordinates controlled by the respective players. Nash
equilibria are guaranteed to exist in convex block games
(Nash, 1950). However, finding them is often intractable

Strongly-Typed Agents are Guaranteed to Interact Safely

The SVD diagonalizes any matrix: Q| MP = D. Finally,
the Legendre transform f âˆ— (Î·) = maxÎ¸ {Î· | Î¸ âˆ’ f (Î¸)} diagonalizes the infimal convolution
(f g)âˆ— = f âˆ— +g âˆ— for (f g)(Î¸) = min{f (Ï‘)+g(Î¸âˆ’Ï‘)}.
Ï‘

Diagonalization finds a latent orthogonal basis that is more
mathematically amenable than the naturally occurring coordinate system. Strong-typing is based on an extension of
diagonalization to nonlinear functions. Before diving in,
we recall the basics of simultaneous diagonalization.
Symmetric matrices. Any symmetric matrix A factorizes as A = P| DP where P is orthogonal and D is diagonal. A collection A1 , . . . , AN of symmetric matrices
is simultaneously diagonalizable iff the matrices commute,
in which case Ai = P| Di P where Di is diagonal and P
determines a common latent coordinate system (or type).
Arbitrary matrices. The diagonalization of an (m Ã— n)matrix A is A = PDQ| where P and Q are orthogonal
(m Ã— m) and (n Ã— n) matrices and D is positive diagonal.
A collection of matrices is simultaneously diagonalizable
if Ai = PDi Q| for all i. A necessary condition for simultaneous diagonalizability is that
A|i Aj and Ai A|j are symmetric for all i, j.

(2)

Next, we work through two examples where diagonalization and a positivity condition imply safety.
3.1. Warmup: When are two-player games safe?
To orient the reader, we consider a minimal example which
illustrates most of the main ideas of the paper: two-player
bilinear games (von Neumann & Morgenstern, 1944). Consider a two-player block game with loss functions
`1 (v, w) = v| Aw

and

`2 (v, w) = v| Bw

and projections Ï€ 1/2 (v, w) = (v, 0) and (0, w). The
P
âˆ‚
âˆ‚
gradients are âˆ‡ `1 =
ij (wj Aij âˆ‚vi + vi Aij âˆ‚wj ) =
| |
|
| |
|
(w A , v A) and âˆ‡ `2 = (w B , v B). The game is
safe if
hÏ€ 1 (âˆ‡ `1 ), âˆ‡ `2 i = w| A| Bw â‰¥ 0
|

|

hâˆ‡ `1 , Ï€ 2 (âˆ‡ `2 )i = v BA v â‰¥ 0

and
for all v and w.

Safety requires that A| B and BA| are positive semidefinite. Any square matrix decomposes into symmetric and
antisymmetric components M = Ms + Ma = 12 (M +
M| ) + 12 (M âˆ’ M| ) where w| Ma w = 0 for all w. Thus,
a square matrix is positive semidefinite iff its symmetric
component is positive semidefinite.

We therefore restrict to when A| B and BA| are symmetric. Recalling (2), we further suppose that A and B are
simultaneously diagonalizable and obtain:
Lemma 4. A two-player game is safe if A = PDQ| and
B = PEQ| where P and Q are orthogonal matrices, D
and E are diagonal, and DE â‰¥ 0.
Proof. The assumptions imply that
hÏ€ 1 âˆ‡ `1 , âˆ‡ `2 i = w| A| Bw = w| Q(D| E)Q| w â‰¥ 0
and hâˆ‡ `1 , Ï€ 2 âˆ‡ `2 i = w| P(E| D)P| w â‰¥ 0.
3.2. Warmup: When is Newtonâ€™s method safe?
It was observed in Dauphin et al. (2014) that applying Newtonâ€™s method to neural networks is problematic because it
is attracted to saddle points and can increase the loss on
nonconvex problems. We reformulate their observation in
the language of safety.
Consider a single player open game with twice differentiable loss ` : V â†’ R and projection Ï€ = IV . Newtonâ€™s
method optimizes ` via weight updates
wt+1 = wt âˆ’ Î¾ t
where Hij (w) =

with Î¾ t = Î· t Â· Hâˆ’1 (wt ) Â· âˆ‡ `(wt ),
âˆ‚2`
âˆ‚wi âˆ‚wj (w)

is the Hessian and Î· t > 0.

Lemma 5. If ` is strictly convex then Newtonâ€™s method is
safe, i.e. hHâˆ’1 âˆ‡ `, âˆ‡ `i â‰¥ 0 for all w.
Proof. Factorize the Hessian at wt as H = PDP| . If ` is
strictly convex then D > 0 and so
hHâˆ’1 âˆ‡ `, âˆ‡ `i = hDâˆ’1 P| âˆ‡ `, P| âˆ‡ `i â‰¥ 0
as required.
Two features are noteworthy: (i) the transform Î· = P| Î¾
diagonalizes the second-order Taylor expansion of `,
1
compare `(w + Î¾) = `(w) + Î¾ | Â· âˆ‡ ` + Î¾ | HÎ¾
2
1
|
|
with `(w + PÎ·) = `(w) + Î· (P âˆ‡ `) + Î· | DÎ·,
2
and (ii) the proof hinges on the positivity of D. Sections A2
and A3 extend the approach to show the natural gradient
(Amari, 1998) and mirror descent (Raskutti & Mukherjee,
2015) are safe using the Legendre transform.
3.3. Strongly-typed games are safe
We apply the lessons from the warmups to define a factorization of nonlinear functions.

Strongly-Typed Agents are Guaranteed to Interact Safely

Definition 4. The functions {`n : V â†’ R}N
n=1 simultaneously factorize if there is a triple


pl
L
L
N
{Pl }L
l=1 , {fl : R â†’ R}l=1 , {gn : R â†’ R}n=1 ,

notation, a block game is a weighted potential game if there
exists a potential function Î¦ and scalar weights Î±n > 0
satisfying


`n (w) âˆ’ `n (w + Ï€ n v) = Î±n Â· Î¦(w) âˆ’ Î¦(w + Ï€ n v)

satisfying


`n (w) = gn f1 (P|1 w), . . . , fL (P|L w)
for all n
where Pl are (DÃ—pl )-matrices whose columns jointly form
an orthogonal basis of V and fl and gn are differentiable,
m âˆ‚gn
and the gn â€™s co-vary monotonically: âˆ‚g
âˆ‚fl âˆ‚fl â‰¥ 0.
The projections Ï„l = Pl P|l define a type structure on V .
Intuitively, the outputs zl = fl (P|l w) are latent factors
computed from the inputs w such that each zl is independent of the others â€“ independence is enforced by the projections Ï„l . Monotonic covariation of the functions gn with
respect to the factors zl plays the same role as positivity in
two-player games and Newtonâ€™s method.
Definition 5. Game (TV , {`n }N
n=1 ) is strongly-typed if the
loss functions admit a simultaneous factorization whose
N
projections {Ï„ l = Pl P|l }L
l=1 commute with {Ï€ n }n=1 .
Theorem 2. Strongly-typed games are safe.
Proof. Commutativity implies there is a basis
for
V that simultaneously diagonalizes the projections {Ï€ n }
and {Ï„ l }. Express elements of V as (v1 , . . . , vD ) in the
basis. Safety then reduces to showing
hÏ€ m (âˆ‡ `m ), âˆ‡ `n i =

{i:Ï€ m (ei )6=0}

We provide two counter-examples to show that stronglytyped games are distinct from potential games.
Example 5 (a strongly-typed game that is not a potential
game). Let `1 (x, y) = x1 y1 + 2x2 y2 and `2 (x, y) =
3x1 y1 + 4x2 y2 . The block game with projections onto
x and y is strongly-typed but is not a weighted potential
game.
Example 6 (a potential game that is not safe). Let
`1 (x, y) = xy and `2 (x, y) = xy âˆ’ 9x, with projections
onto x and y. The game is a potential game but is not safe
because
hÏ€ 1 (âˆ‡ `1 ), âˆ‡ `2 i = h(y, 0), (y âˆ’ 9, x)i = y 2 âˆ’ 9y
can be negative.

4. Quadratic Games
{ei }D
i=1

X

for all w, v âˆˆ V and n âˆˆ [N ].

âˆ‚gm âˆ‚gn
Â·
â‰¥ 0.
âˆ‚vi âˆ‚vi

k âˆ‚fl
Observe that âˆ‚f
âˆ‚vi âˆ‚vi = 0 if k 6= l since fk and fl are functions of orthogonal coordinates. It follows that
!
!
L
L
X
X
âˆ‚gn âˆ‚fl
âˆ‚gm âˆ‚gn
âˆ‚gm âˆ‚fk
Â·
Â·
=
âˆ‚vi âˆ‚vi
âˆ‚fk âˆ‚vi
âˆ‚fl âˆ‚vi
k=1
l=1


L
2
X
âˆ‚gm âˆ‚gn
âˆ‚fl
=
Â·
â‰¥0
âˆ‚fl âˆ‚fl
âˆ‚vi

l=1

since the gn â€™s co-vary monotonically.
Strong-typing is a sufficient but not necessary condition for
safety. More general definitions can be proposed according
to taste. Definition 5 is easy to check, covers the basic examples below, and incorporates the concrete intuition developed in the warmups.
3.4. Comparison with potential games
The proof of theorem 1 suggests that safe games are related
to potential games (Monderer & Shapley, 1996). In our

Given a collection of (D Ã— D)-matrices {A(n) }N
n=1 and Dvectors {b(n) } the corresponding quadratic game has loss
functions
`n (w) =

1 | (n)
w A w + w| b(n) .
2

We assume the matrices A(n) are symmetric without loss
of generality.
4.1. Open quadratic games
In an open quadratic game, each player updates the entire
joint action.
Corollary 1. An open quadratic game is safe if there is
an orthogonal (D Ã— D)-matrix P, diagonal matrices D(n)
such that D(m) D(n) â‰¥ 0, and D-vector b such that
A(n) = PD(n) P|

and

b(n) = A(n) b.

We derive corollaries 1 and 2 from theorem 2. Alternate,
direct proofs are provided in appendix A4.
PD (n)
Proof. Let fi (x) = x( x2 âˆ’ bi ) and gn (z) = i=1 di Â· zi .
Then


`n (w) = gn f1 (p|1 w), . . . , fD (p|D w) ,
where pi are the columns of P, is strongly-typed.

Strongly-Typed Agents are Guaranteed to Interact Safely

The Hessian of `n is H`n = A(n) . The conditions of corollary 1 can be reformulated as (i) the Hessians of the losses
commute H`m H`n = H`n H`m for all m and n, and (ii)
the Newton steps for the losses coincide (when the Hessians are nonsingular):
(n) âˆ’1 (n)
) A (w âˆ’ b) = w âˆ’ b.
Hâˆ’1
` (âˆ‡ `n ) = (A
| n {z }
Newton step

Example: Disentangling latent factors. An important
problem in machine learning is disentangling latent factors
(Bengio, 2013). Basic methods for tackling the problem
include PCA, canonical correlation analysis (CCA) and independent component analysis (ICA). We show how the
factorization in corollary 1 can arise â€œin natureâ€ as a variant of blind source separation.
Suppose a signal on D channels is recorded for T timepoints giving (D Ã— T )-matrix X. Assume the observations
combine L independent latent signals: X = MS where S
is an (L Ã— T )-matrix representing the latent signal and M
is a mixing matrix.
Blind source separation is concerned with recovering the
latent signals. The covariance of the signal is A = XX| .
Factorize A = PDP| and let SÌƒ = P| X. Although this
may not recover the original signal, i.e. SÌƒ 6= S in general,
it does disentangle X into uncorrelated factors:
SÌƒSÌƒ| = P| XX| P = D.
Finally, recall that finding the first principal component can
be formulated as the constrained maximization problem:
argmax w| Aw.
{w:kwk2 =1}

Now suppose there are N sets of observations
X(1) , . . . , X(N ) generated by a single orthogonal
mixing matrix acting on different sets of (potentially
rescaled) latent signals: X(n) = PS(n) . Finding the first
principle components of the signals reduces to solving the
constrained optimization problems
(
)N
argmax w| X(n) (X(n) )| w
{w:kwk2 =1}

(3)

4.2. Block Quadratic Games
The block quadratic game has losses as above; however
the action space decomposes into (w1 , . . . , wN ) with corresponding projections. Block decompose the components
of the loss as
ï£«
ï£¶
ï£«
ï£¶
(n)
(n)
(n)
A11 Â· Â· Â· A1N
b1
ï£¬ .
ï£¬ . ï£·
.. ï£·
(n)
ï£·
ï£¬
ï£·
A(n) = ï£¬
. ï£¸ and b = ï£­ .. ï£¸ .
ï£­ ..
(n)
(n)
(n)
AN 1 Â· Â· Â· AN N
bN
Corollary 2. A block quadratic game is safe if there are:
(i) (D Ã— D)-orthogonal P with Pmn = 0 for m 6= n;
(ii) (D Ã— L) matrix R with Rnâ€¢ diagonal for all n;
(iii) diagonal (L Ã— L)-matrices D(n) with D(m) D(n) â‰¥ 0;
(iv) and a D-vector b
such that A(n) = PRD(n) R| P|
b(n) = A(n) b

Quadratic games and linear regression. The blind
source separation example assumes that the linear terms
b(n) in the loss are zero. If the linear term is nonzero
then linear regression is a special case of minimizing the
quadratic loss. Safety then relates to searching for weights
that simultaneously solve linear regression problems on
multiple datasets.

for all n.

The notation Pmn and Râ€¢n refers to blocks in the rows and
columns of P and columns of R.
Proof. Let pi denote the columns of P and gn (z) =
PL (n)
Â· zl . Given l, construct Pl by concatenating the
l=1 dl
columns pi of P for which the corresponding entries of Ril
are nonzero and let rl be the vector containing the nonzero
entries of Râ€¢l . Define fl (xl ) = r|l ( x2l âˆ’ bl ) Â· (r|l xl ). Then


`n (w) = gn f1 (P|1 w), . . . , fL (P|L w) .
It is an exercise to check the game is strongly-typed.
Example: Disentangling latent factors. We continue
the discussion of blind source separation and safety. Suppose that the mixing matrix decomposes into blocks
ï£«
ï£¶
M1â€¢
ï£¬
ï£·
M = ï£­ ... ï£¸
MN â€¢

n=1

Corollary 1 implies that (3) is a safe. Note the corollary implies the optimization problems have compatible gradients,
not that they share a common solution. In general there are
many Nash equilibria, analogous to example 3.

and

The blocks generate multiple views on a single latent signal,
(Kakade & Foster, 2007; McWilliams et al., 2013; Benton
et al., 2017). The nth view is Mnâ€¢ S.
As in the example in section 4.1, now suppose there are N
sets of observed signals generated from N sets of latent signals. Each agent attempts to find the principal component
specific to its view on its set of observations. Corollary 2
implies that the problems
(
)N
argmax
{wn :kwn k2 =1}

w| X(n) (X(n) )| w
n=1

Strongly-Typed Agents are Guaranteed to Interact Safely

can be safely optimized using gradient descent if the mixing matrix has the block form
Mnâ€¢ = Pnn Â· Rnâ€¢
where Pnn is orthogonal and Rnâ€¢ is diagonal. In
other words, if the views are generated by rescaling and
changing-the-basis of the latent signals.
The open and block settings share a common theme: Safe
disentangling requires observed signals that are generated
by a single (structured) mixing process applied to (arbitrary) sets of independent latent signals. The same phenomenon arises in multi-player games, resulting in tensor
decompositions that generalize ICA.

5. Multi-Player Games and Tensor-SVD
A classic N -player strategic game
QN consists in finite actionsets An and losses `n : A = n=1 An â†’ R. Enumerate
the elements of each set as An = [Dn ], and encode the
losses as (D1 , . . . , DN )-tensors
An [Î±1 , . . . , Î±N ] := `n (Î±1 , . . . , Î±N ) where Î±n âˆˆ [Dn ].
Given a collection of N such tensors, define the corresponding multilinear game1 as
`n (w1 , . . . , wN ) = An Ã—1 w1 Ã— Â· Â· Â· Ã—N wN
:=

D1 X
,...,DN

A[Î±1 , . . . , Î±N ] Â· w1 [Î±1 ] Â· Â· Â· wN [Î±N ].

Î±1 ,...,Î±N =1

The classic example is when actions areP
drawn from the
Dn
Dn -simplex 4Dn = {wn âˆˆ RDn :
Î±=1 wn [Î±] =
1 and wn [Î±] â‰¥ 0 for all Î±}.
We now recall the orthogonal tensor decomposition or tensor SVD (Zhang & Golub, 2001; Chen & Saad, 2009). A
tensor admits a tensor-SVD if it can be written in the form
A=

L
X

1
N
dl Â· u1l âŠ— Â· Â· Â· âŠ— uN
l = D Ã—1 U Ã— Â· Â· Â· Ã—N U

l=1

where Un is a (Dn Ã— L)-matrix with orthogonal columns
and D is a diagonal (L, . . . , L)-tensor.
Corollary 3. A multilinear game is safe if it admits a simultaneous tensor-SVD
A(n) = D (n) Ã—1 U1 Ã— Â· Â· Â· Ã—N UN
where the diagonals have the same sign coordinatewise.
1
We use the n-mode product notation Ã—n , see de Lathauwer
et al. (2000).

PL (n)
Q
Proof. Let gn (z) = l=1 dl zl and fl (x) = n xn . Define Pl as the (D Ã— N )-matrix whose nth column is unl in
the block of rows corresponding to wn and zero elsewhere.
Then

`n (w) = gn f1 (P|1 w), . . . , fL (P|L w)
and the game is strongly-typed.
Not all tensors admit a tensor-SVD. However, all tensors
do admit a higher-order SVD (de Lathauwer et al., 2000).
Section A5 explains why simultaneous HOSVD does not
guarantee safety and the stronger tensor-SVD is required.
Example: Disentangling latent factors Suppose S is a
latent signal with independent non-Gaussian coordinates.
We observe X = PS +  where P is a (D Ã— L) mixing
matrix and  is Gaussian noise. By whitening the signal
as a preprocessing step, one can ensure the columns of P
are orthogonal. ICA recovers S from the cumulants of X,
see HyvaÌˆrinen et al. (2001). The main insight is that the
4th -order cumulant tensor admits a tensor-SVD:
A[i, j, k, l] = cum(xi , xj , xk , xl )
X
=
Pio Pjp Pkq Plr Â· cum(so , sp , sq , sr )
o,p,q,r

=

X

Pir Pjr Pkr Plr Â· kurt(sr )

r

since cum(so , sp , sq , sr ) = 0 unless o = p = s = r because the signals are independent. The expression can be
written A = KÃ—1 PÃ—2 PÃ—3 PÃ—4 P where diagonal tensor
K specifies the kurtosis of the latent signal. In other words,
computing the tensor-SVD recovers the mixing matrix and
allows to recover the latent signal up to basic symmetries.
Following the same prescription as the examples above, if
there are N sets of observations generated from N latent
signals by the same mixing matrix, then the resulting cumulant tensors satisfy corollary 3.

6. Biologically Plausible Backpropagation
Our ultimate goal is to apply strong-typing to safely optimize neural nets with multiple loss functions (Marblestone
et al., 2016). Doing so requires constructing variants of
backprop that allow the propagation of multiple error signals. First steps in this direction have been taken with biologically plausible models of backprop that introduce additional degrees of freedom into the algorithm.
Feedback alignment is a recent algorithm with comparable empirical performance to backprop. It is also more
biologically plausible since it loosens backpropâ€™s requirement that forward- and back- propagating weights are sym-

Strongly-Typed Agents are Guaranteed to Interact Safely

metric (Lillicrap et al., 2016). The main theoretical result
of the paper, see their supplementary information, is
Theorem. Let Î´ BP = W| e denote the error backpropagated one layer of the neural network. Under certain conditions, the error signal computed by feedback alignment,
Î´ F A = Be, satisfies
Î´ F A = Î± Â· Wâ€  e where Î± > 0
and Wâ€  is the pseudoinverse of W.
Proof. See theorem 2 of Lillicrap et al. (2016).
Corollary 4. Under the same conditions, feedback alignment is safe.
Proof. We require to check hÎ´ F A , Î´ BP i â‰¥ 0. Applying
the theorem obtains

From a different perspective, convex methods have played
an enormous role in optimization yet their relevance to
deep learning is limited. The approach to strong-typing
developed here is inspired by and extends certain features
of convexity. One of the goals of this paper is to carve
out some of the key concepts underlying convex geometry
and reassemble them into a more flexible, but still powerful framework. The proposed definition of strong-typing
should be considered a first and far from final attempt.
A large class of natural examples is generated by imposing
strong-typing on simple quadratic and multilinear games.
It turns out that, in these settings, strong-typing yields
the same matrix and tensor decompositions that arise in
blind source separation and independent component analysis, where multiple latent signals are mixed by the same
structured process. An important future direction is to disentangle nonlinear latent factors.

hÎ´ F A , Î´ BP i = Î± Â· hWâ€  e, W| ei = Î± Â· hWWâ€  e, ei.
Observe that WWâ€  is an orthogonal projection by standard properties of the pseudoinverse so
hÎ´ F A , Î´ BP i = Î± Â· hWWâ€  e, WWâ€  ei â‰¥ 0
as required.
In fact, Lillicrap et al. (2016) provide experimental and theoretical evidence that feedback alignment learns to align
the feedforward weights with the pseudoinverse of the
backconnections. In other words, they argue that feedback
alignment learns safe gradients.
Another variant of backprop is kickback, which loosens
backpropâ€™s requirement that there are distinct forward- and
backward signals (Balduzzi et al., 2015). Kickback truncates backpropâ€™s error signals so that the network learns
from just the feedforward sweep together with scalar error
signals. One of the main results of Balduzzi et al. (2015) is
that kickback is safe, see section A6.

7. Conclusion
Backprop provides a general-purpose tool to train configurations of differentiable modules that share a single objective. However, effectively training populations of neural
networks on potentially conflicting tasks, such that they automatically exploit synergies and avoid damaging incompatibilities (such as unlearning old features that are not useful on a new task) requires fundamentally new ideas.
A key piece of the puzzle is to develop type systems that
can be used to (i) guarantee when certain optimizations can
be safely performed jointly and (ii) flag potential conflicts
so that the incompatible optimization problems can be separated. The paper provides a first step in this direction.

Strong-typing and safety in neural nets. We conclude
by discussing the relevance of the framework to neural networks. Firstly, neural nets and strong-typing have many of
the same ingredients: neural nets combine linear algebra
(matrix multiplications and convolutions) with monotonic
functions (sigmoids, tanhs, rectifiers, and max-pooling
amongst others). Rectifiers and sigmoids have the additional feature that their outputs are always positive.
Secondly, there is a deeper connection between rectifiers
and strong-typing. Rectifiers are orthogonal projections
on weights: Ï(W| x) zeroes out the columns wl of W for
which wl| x â‰¤ 0. Rectifiers are more sophisticated projections than we have previously considered because they are
context-dependent. The columns that are zeroed out depend on W and x: the rectifier-projection takes W and x
as parameters, compare remarks 1 and 2 in the appendix.
Representation learning in rectifier networks can thus be
recast as learning parameterized type structures. An interesting future direction is to consider tensor-switching networks (Tsai et al., 2016), which decouple a neuronâ€™s decision to activate from the information it passes along (for a
rectifier, both depend on W| x).
Finally, it has long been known that the brain does not use
backprop (Crick, 1989). One possibility is that backprop is
the optimal deep learning algorithm which, unfortunately,
evolution failed to stumble upon. Another is that there are
evolutionary advantages to not using backpropagation. For
example, it has been argued that the brain optimizes multiple loss functions (Marblestone et al., 2016). Does jointly
optimizing or satisficing multiple objectives require learning mechanisms with more degrees of freedom than backprop (Balduzzi et al., 2015; Lillicrap et al., 2016)? Safety
and strong-typing provide the tools needed to frame and
investigate the question.

Strongly-Typed Agents are Guaranteed to Interact Safely

Acknowledgements
I am grateful to Stephen Marsland and James Benn for useful discussions.

Fernando, C, Banarse, D, Blundell, C, Zwols, Y, Ha, D, Rusu, A,
Pritzel, A, and Wierstra, D. PathNet: Evolution Channels Gradient Descent in Super Neural Networks. In arXiv:1701.08734,
2017.

References

Goodfellow, Ian J. NIPS 2016 Tutorial: Generative Adversarial
Networks. In arXiv:1701.00160, 2017.

Amari, S. Natural Gradient Works Efficiently in Learning. Neural
Comp, 10:251â€“276, 1998.
Amari, S. Information Geometry and Its Applications: Convex
Function and Dually Flat Manifold. In Nielsen, Frank (ed.),
Emerging Trends in Visual Computing, 2009.
Amodei, Dario, Olah, Chris, Steinhardt, Jacob, Christiano, Paul,
Schulman, John, and ManeÌ, Dan. Concrete Problems in AI
Safety. In arXiv:1606.06565, 2016.
Balduzzi, D, Vanchinathan, H, and Buhmann, J. Kickback cuts
Backpropâ€™s red-tape: Biologically plausible credit assignment
in neural networks. In AAAI, 2015.
Balduzzi, David. Grammars for Games: A Gradient-Based,
Game-Theoretic Framework for Optimization in Deep Learning. Frontiers in Robotics and AI, 2(39), 2016.
Balduzzi, David and Ghifary, Muhammad. Strongly-Typed Recurrent Neural Networks. In ICML, 2016.

Hinton, G and et al. Deep Neural Networks for Acoustic Modeling in Speech Recognition: The Shared Views of Four Research Groups. IEEE Signal Proc Magazine, 29:82â€“97, 2012.
HyvaÌˆrinen, Aapo, Karhunen, Juha, and Oja, Erkki. Independent
Component Analysis. John Wiley & Sons, 2001.
Kakade, Sham and Foster, Dean P. Multi-view Regression Via
Canonical Correlation Analysis. In COLT, 2007.
Krizhevsky, A, Sutskever, I, and Hinton, G E. Imagenet classification with deep convolutional neural networks. In Advances
in Neural Information Processing Systems (NIPS), 2012.
LeCun, Yann, Bengio, Yoshua, and Hinton, Geoffrey. Deep learning. Nature, 521:436â€“444, 2015.
Lillicrap, Timothy P, Cownden, Daniel, Tweed, Douglas B, and
Ackerman, Colin J. Random feedback weights support error
backpropagation for deep learning. Nature Communications, 7
(13276), 2016.

Bengio, Yoshua. Deep Learning of Representations: Looking Forward. In Dediu, Adrian-Horia, MartÄ±Ìn-Vide, Carlos,
Mitkov, Ruslan, and Truthe, Bianca (eds.), Statistical Language and Speech Processing. Springer, 2013.

Marblestone, Adam H, Wayne, Greg, and Kording, Konrad P.
Towards an Integration of Deep Learning and Neuroscience.
Front. Comput. Neurosci., 10(94), 2016.

Benton, Adrian, Khayrallah, Huda, Gujral, Biman, Reisinger,
Drew, Zhang, Sheng, and Arora, Raman. Deep Generalized
Canonical Correlation Analysis. In arXiv:1702.02519, 2017.

McWilliams, Brian, Balduzzi, David, and Buhmann, Joachim.
Correlated random features for fast semi-supervised learning.
In NIPS, 2013.

Berkenkamp, F, Moriconi, R, Schoellig, A, and Krause, A. Safe
learning of regions of attraction for uncertain, nonlinear systems with gaussian processes. In IEEE CDC, 2016.

Mnih, Volodymyr, Kavukcuoglu, Koray, Silver, David, and et al.
Human-level control through deep reinforcement learning. Nature, 518(7540):529â€“533, 02 2015.

Bubeck, SeÌbastien. Convex Optimization: Algorithms and Complexity. Foundations and Trends in Machine Learning, 8(3-4):
231â€“358, 2015.

Monderer, Dov and Shapley, Lloyd S. Potential Games. Games
and Economic Behavior, 14:124â€“143, 1996.

Cardelli, Luca. Type Systems. In Handbook of Computer Science
and Engineering. CRC Press, 1997.
Chen, Jie and Saad, Yousef. On the tensor SVD and the optimal
low rank orthogonal approximation of tensors. SIAM J. Matrix
Anal. Appl., 30(4):1709â€“1734, 2009.
Crick, Francis. The recent excitement about neural networks. Nature, 337(12):129â€“132, 1989.
Daskalakis, Constantinos, Goldberg, Paul W, and Papadimitriou,
Christos. The Complexity of Computing a Nash Equilibrium.
SIAM J. Computing, 39(1):195â€“259, 2009.
Dauphin, Yann, Pascanu, Razvan, Gulcehre, Caglar, Cho,
Kyunghyun, Ganguli, Surya, and Bengio, Yoshua. Identifying and attacking the saddle point problem in high-dimensional
non-convex optimization. In NIPS, 2014.
de Lathauwer, Lieven, de Moor, Bart, and Vandewalle, Joos.
A multilinear singular value decomposition. SIAM J. Matrix
Anal. Appl., 21(4):1253â€“1278, 2000.

Nash, John F. Equilibrium Points in n-Person Games. Proc Natl
Acad Sci U S A, 36(1):48â€“49, 1950.
Nisan, Noam, Roughgarden, Tim, Tardos, EÌva, and Vazirani, Vijay (eds.). Algorithmic Game Theory, 2007. Cambridge University Press, Cambridge.
Rakhlin, Alexander and Sridharan, Karthik. Optimization, learning, and games with predictable sequences. In NIPS, 2013.
Raskutti, G and Mukherjee, S. The Information Geometry of Mirror Descent. IEEE Trans. Inf. Theory, 61(3):1451â€“1457, 2015.
Silver, David, Huang, Aja, and et al. Mastering the game of go
with deep neural networks and tree search. Nature, 529(7587):
484â€“489, 01 2016.
Syrgkanis, Vasilis, Agarwal, Alekh, Luo, Haipeng, and Schapire,
Robert. Fast Convergence of Regularized Learning in Games.
In NIPS, 2015.
Tsai, Chuan-Yung, Saxe, Andrew, and Cox, David.
Switching Networks. In NIPS, 2016.

Tensor

Strongly-Typed Agents are Guaranteed to Interact Safely
Turchetta, Matteo, Berkenkamp, Felix, and Krause, Andreas. Safe
Exploration in Finite Markov Decision Processes with Gaussian Processes. In NIPS, 2016.
von Neumann, John and Morgenstern, Oskar. Theory of Games
and Economic Behavior. Princeton University Press, Princeton
NJ, 1944.
Zhang, T, Kahn, G, Levine, S, and Abbeel, P. Learning deep control policies for autonomous aerial vehicles with mpc-guided
policy search. In ICRA, 2016.
Zhang, Tong and Golub, Gene H. Rank-one approximation to
higher order tensors. SIAM J. Matrix Anal. Appl., 23(2):534â€“
550, 2001.

Proof. We follow Amari (1998). The problem reduces to
the constrained minimization
h
i
t
t |
argmin
`(w
)
+

âˆ‡
`(w
)
Î¾
P
{Î¾:

Gij (wt )Î¾i Î¾j =1}

which can be rewritten as
h
i
argmin âˆ‡ `(wt )| Î¾ âˆ’ Î»Î¾ | G(wt )Î¾
Î¾

with solution
Î¾ t âˆ Gâˆ’1 (wt ) âˆ‡ `(wt )

APPENDIX

as required.

A1. Proof of Theorem 1

Corollary A1. The natural gradient is safe.

For completeness we recall the notion of Nash equilibrium,
generalized to our setup:
Definition A1. The point wâˆ— âˆˆ H is a Nash equilibrium if
for all players n and for all w satisfying wâˆ— + Ï€ n (w) âˆˆ H
it holds that
`n (wâˆ— ) â‰¤ `n (wâˆ— + Ï€ n (w)).

Proof. We are required to show that
hGâˆ’1 (w) âˆ‡ `(w), âˆ‡ `(w)i â‰¥ 0 for all w.

This section completes theorem 1 when gradient descent
converges to the boundary of the feasible set. To ensure
actions stay in the feasible set we use gradient updates of
the form
wt+1 = ProjH (wt âˆ’ Ï€ Ï(n) (Î¾ tn ))

The proof is obvious. We include it to highlight the role of
latent types, diagonalization and positivity.

where

ProjH (xÌƒ) = argmin kx âˆ’ xÌƒk2 .
xâˆˆH

Proof. A point on the boundary of H is a critical point
of Î¦ if the gradient is zero or points perpendicularly
out the constraint set.
Since hÏ€ m (âˆ‡ Î¦), âˆ‡ `m i â‰¥
Î±m kÏ€ m (âˆ‡ `m )k22 â‰¥ 0 for all players m, it follows that
gradient descent by the players, with step sizes decaying as
âˆš1 , will converge to a critical point of Î¦. Critical points
T
of Î¦ are Nash equilibria of the game by convexity of the
losses as a function of their playersâ€™ actions.

A2. The natural gradient is safe
The natural gradient was introduced in Amari (1998) and
is widely used in machine learning.
Theorem. The direction of steepest descent at `(wt ) on
Riemannian manifold (Rn , G) is
Î¾ t âˆ Gâˆ’1 (wt ) Â· âˆ‡ `(wt ).
The natural gradient is the direction Gâˆ’1 (wt ) Â· âˆ‡ `(wt ).

(A1)

The metric is symmetric positive definite, and so admits
factorization
G(wt ) = P(w) Â· D(w) Â· P| (w)
where P(w) is an orthogonal matrix and D(w) strictly
Ëœ
positive diagonal for all w. After setting âˆ‡`(w)
:=
|
P (w) âˆ‡ `(w), the condition in (A1) can be rewritten as
Ëœ
Ëœ
hDâˆ’1 (w)âˆ‡`(w),
âˆ‡`(w)i
â‰¥0
which clearly holds.
Remark 1 (parametric types). The columns pi (w) of P(w)
define a parametric family of latent type systems Ï„ i (w) =
pi (w) Â· p|i (w) that is parametrized by w.

A3. Mirror descent is safe
We show that mirror descent is safe. The fact that mirror descent is well-behaved is far from new; there is an
extensive literature analyzing its convergence properties
(Bubeck, 2015). Our purpose is to highlight the type structures underlying convex duality and mirror descent.
The approach generalizes the analysis of Newtonâ€™s method.
The role played by transform that diagonalizes the Hessian
in section 3.2 is taken over by the Legendre transform here.

Strongly-Typed Agents are Guaranteed to Interact Safely

Convex duality. The exposition closely follows Amari
(2009). Consider the manifold M = RD with coordinate
system w = (w1 , . . . , wD ). Let Ïˆ : M â†’ R be a twicedifferentiable strictly convex function. It follows that the
Hessian of Ïˆ,
gij (w) = âˆ‚i âˆ‚j Ïˆ(w)

Theorem. Given loss function ` and strictly convex twice
differentiable Ïˆ, both defined on M = RD , the mirror descent step


1
wt+1 = argmin w| âˆ‡ `(wt ) + t DÏˆ (w, wt ) ,
Î·
w

is a positive definite matrix for all w which defines a Riemannian metric on the manifold M . Concretely, the distance between infinitesimally close points w and w + dw
is
X
ds2 =
gij (w)dwi dwj .

is equivalent to the natural gradient descent step

âˆ’1
Î¸ t+1 = Î¸ t âˆ’ Î· t Â· âˆ‡2 Ïˆ âˆ— (Î¸ t )
Â· âˆ‡ `(Î¸ t ).

ij

Define the dual coordinate system
Î¸ = âˆ‡ Ïˆ(w),

i.e. Î¸i =

âˆ‚Ïˆ
(w).
âˆ‚wi

in the dual coordinate system.
Proof. We sketch the proof in Raskutti & Mukherjee
(2015), which should be consulted for details. Computing
the minimizer in mirror descent by differentiating shows
that the mirror descent update is equivalent, in dual coordinates, to
Î¸ t+1 = Î¸ t âˆ’ Î· t Â· âˆ‡w `(âˆ‡ Ïˆ âˆ— (Î¸ t ))

Recall that the Legendre transform of Ïˆ,
Ïˆ âˆ— (Î¸) = max{w| Î¸ âˆ’ Ïˆ(w)},
w

Applying the chain rule obtains

âˆ’1
Â· âˆ‡Î¸ `(âˆ‡ Ïˆ âˆ— (Î¸ t ))
âˆ‡w `(âˆ‡ Ïˆ âˆ— (Î¸ t )) = âˆ‡2 Ïˆ âˆ— (Î¸ t )

satisfies the relation
Ïˆ(w) + Ïˆ âˆ— (Î¸) âˆ’ w| Î¸ = 0,
which allows to recover the original coordinates from the
dual system:
w = âˆ‡ Ïˆ âˆ— (Î¸) i.e. wi =

âˆ‚Ïˆ âˆ—
(Î¸).
âˆ‚Î¸i

so that mirror descent can be rewritten as

âˆ’1
Î¸ t+1 = Î¸ t âˆ’ Î· t Â· âˆ‡2 Ïˆ âˆ— (Î¸ t )
Â· âˆ‡Î¸ `(âˆ‡ Ïˆ âˆ— (Î¸ t ))
as required.
Corollary A2. If Ïˆ is twice-differentiable and strictly convex then mirror descent is safe.
Proof. Combine corollary A1 with the equivalence of mirror descent and the natural gradient.

Define the dual metric
g ij (Î¸) =

âˆ‚2
Ïˆ âˆ— (Î¸).
âˆ‚Î¸i âˆ‚Î¸j

Theorem. The metrics gij (w) and gij (Î¸) are inverse.
That is

A4. Direct proofs of corollaries 1 and 2
Direct proof of corollary 1.
Proof. Safety requires

dÎ¸ = G(w)dw

and dw = Gâˆ’1 (Î¸)dÎ¸.

Proof. See Amari (2009).
Remark 2 (parametric types). Convex duality can thus be
rephrased as a relationship between two parametric families of types on the tangent spaces to the manifold that is
encoded in the Riemannian metric and its inverse.
Mirror descent is safe. We show that mirror descent
is safe by applying convex duality following Raskutti &
Mukherjee (2015). Let Ïˆ be a strictly convex twice differentiable function. The Bregman divergence of Ïˆ is
DÏˆ (v, w) = Ïˆ(v) âˆ’ Ïˆ(w) âˆ’ hâˆ‡ Ïˆ(w), v âˆ’ wi.

hâˆ‡ `n , âˆ‡ `m i = (A(n) wâˆ’b(n) )| (A(m) wâˆ’b(m) ) â‰¥ 0.
Plugging in the assumptions yields
hâˆ‡ `n , âˆ‡ `m i = (w âˆ’ b)| PD(n) D(m) P| (w âˆ’ b) â‰¥ 0
which is positive by inspection.
Direct proof of corollary 2.
Proof. The gradient and projected gradient are
âˆ‡ `n = w| A(n) + b(n) and
(n)

Ï€ n (âˆ‡ `n ) = w| Aâ€¢n + b(n)
n

Strongly-Typed Agents are Guaranteed to Interact Safely

After imposing b(n) = A(n) b, safety requires that
(m)

(n)

(w âˆ’ b)| Aâ€¢m Amâ€¢ (w âˆ’ b) â‰¥ 0 for all w, m and n.
Applying the remaining conditions and setting x =
R| P| (w âˆ’ b) obtains
x| D(m) R|â€¢m Rmâ€¢ D(n) x â‰¥ 0
Since Rmâ€¢ is diagonal, it follows that D(m) R|â€¢m Rmâ€¢ D(n)
is a product of diagonal matrices. The expression is positive since D(m) D(n) â‰¥ 0 by assumption.

A5. Higher-order SVD
Any N -tensor admits a higher-order SVD (HOSVD),
whereas not every tensor admits a tensor-SVD. In this section we recall the concept of HOSVD and show why simultaneous HOSVD is not sufficient to guarantee safety. The
section relies heavily on notation taken from de Lathauwer
et al. (2000) which the reader is encouraged to consult for
details and context.
Definition A2 (matricization). The matricization of tensor A over its nth mode, denoted A(n) is an Dn Ã—
(Dn+1 Dn+2 Â· Â· Â· DN D1 D2 Â· Â· Â· Dnâˆ’1 )-matrix that contains
the element A[Î±1 , . . . , Î±N ] at the position with row number Î±n and column number
(Î±n+1 âˆ’ 1)Dn+2 Dn+3 Â· Â· Â· DN D1 Â· Â· Â· Dnâˆ’1
+(Î±n+2 âˆ’ 1)Dn+3 Dn+4 Â· Â· Â· DN D1 Â· Â· Â· Dnâˆ’1 + Â· Â· Â·
+(Î±N âˆ’ 1)D1 D2 Â· Â· Â· Dnâˆ’1 + (Î±1 âˆ’ 1)D2 D3 Â· Â· Â· Dnâˆ’1
+(Î±2 âˆ’ 1)D3 D4 Â· Â· Â· Dnâˆ’1 + Â· Â· Â· + Î±nâˆ’1

(b) ordering:
kSin =1 k â‰¥ kSin =2 k â‰¥ Â· Â· Â· â‰¥ kSin =In k â‰¥ 0
for all possible values of n.
(n)

The Frobenius-norms kSin =i k, symbolized by Ïƒi
(n)
are n-mode singular values of A and the vector Ui
th
is an i n-mode singular vector.
Proof. See de Lathauwer et al. (2000).
An important property of the HOSVD is as follows. Let
A = S Ã—1 U1 Ã— Â· Â· Â· Ã—N UN be the HOSVD of A. Then
the matricization is
A(n) = Un Î£n (Vn )|
is an SVD of A(n) , where the diagonal matrix Î£n âˆˆ
RDn Ã—Dn and the columnwise orthonormal matrix Vn âˆˆ
RDn+1 Dn+2 Â·Â·Â·DN D1 D2 Â·Â·Â·Dnâˆ’1 Ã—Dn are defined as
n
Î£n := diag(Ïƒ1n , . . . , ÏƒD
),
n

(Vn )| := SÌƒ(n) Un+1 âŠ— Â· Â· Â· UN âŠ— U1 âŠ— Â· Â· Â· Unâˆ’1

|

where SÌƒn is a normalized version of the matricization S(n)
of S, with rows rescaled to unit-length: S(n) = Î£n Â· SÌƒn .
A5.1. Discussion of safety and HOSVD
To somewhat reduce the proliferation of subscripts and superscripts, we work with two tensors denoted A and B,
which stand in for the tensors of two players A(m) and
A(n) in an N -player game.
Lemma A1. Let A[wnÌ‚ ] be the Dn -vector

Let us recall the notion of higher-order SVD (HOSVD)
from de Lathauwer et al. (2000).
Theorem. Every (I1 , . . . , IN )-tensor A can be written as
a product
A = S Ã—1 U1 Ã—2 U2 Â· Â· Â· Ã—N UN
in which

A[wnÌ‚ ] := AÃ—1 w1 Ã—Â· Â· Â·Ã—nâˆ’1 wnâˆ’1 Ã—n+1 wn+1 Ã—Â· Â· Â·Ã—N wN
where note the term wn is omitted from the expression, and
similarly for B. Then
hÏ€ n âˆ‡ `A , âˆ‡ `B i = A[wnÌ‚ ]| Â· B[wnÌ‚ ]
Proof. Direct computation.

1. Ui is a unitary (Ii Ã— Ii ) matrix
2. S is a (I1 Ã— I2 Â· Â· Â· IN )-tensor of which the subtensors
Sin =Î± , obtained by fixing the nth index to Î± have the
properties of
(a) all-orthogonality: two subtensors Sin =Î± and
Sin =Î² are orthogonal for all possible values of
n, Î± and Î² subject to Î± 6= Î²:
hSin =Î± , Sin =Î² i = 0 when Î± 6= Î²

Lemma
A2.
Let
vec(wnÌ‚ )
denote
(D1 D2 Â· Â· Â· Dnâˆ’1 Dn+1 Â· Â· Â· Dn )-vector given by

the

vec(wnÌ‚ ) = vec(w1 âŠ— Â· Â· Â· âŠ— wnâˆ’1 âŠ— wn+1 âŠ— Â· Â· Â· âŠ— wN )
and suppose that the matricization has SVD A(n) =
Un Î£n (Vn )| . Then A[wnÌ‚ ] is the Dn -vector
A[wnÌ‚ ] = Un Î£n (Vn )| vec(wnÌ‚ ).
Proof. Direct computation.

Strongly-Typed Agents are Guaranteed to Interact Safely

A6. Kickback is safe

Lemma A3.

Kickback is a complementary algorithm to feedback alignment that is motivated by the observation that neurons communicate via a single kind of signal, spikes, rather than using the two kinds of signals (the feedforward sweep and
backpropagated errors) required by backprop (Balduzzi
et al., 2015).

hÏ€ n âˆ‡ `A , âˆ‡ `B i
(n)

n |
= vec(wnÌ‚ )| VA Î£nA Î£nB (VB
) vec(wnÌ‚ ).

Proof. By the above working,
hÏ€ n âˆ‡ `A , âˆ‡ `B i
=

(n)
n |
vec(wnÌ‚ )| VA Î£nA (UnA )| UnB Î£nB (VB
)

vec(wnÌ‚ ).

Recall that
(Vn )| := SÌƒ(n) Un+1 âŠ— Â· Â· Â· UN âŠ— U1 âŠ— Â· Â· Â· Unâˆ’1

|

Kickback is a truncated version of backprop that computes
gradient-estimates using the feedforward sweep together
with global error/reward signals. The error signals take the
form of a single scalar value broadcast to the entire network, for example via neuromodulators. One of the main
results of the paper is that
Theorem. If neurons are coherent then kickback is safe.

so that
Î£n (Vn )| = S(n) Un+1 âŠ— Â· Â· Â· UN âŠ— U1 âŠ— Â· Â· Â· Unâˆ’1

|

Coherence is, essentially, a positivity condition on synaptic weights that ensures the gradient-estimates computed
by kickback have positive inner product with the gradients
computed by backprop.

which we shorten to
 |
Î£n (Vn )| = S(n) UÌƒnÌ‚
It follows that hÏ€ n âˆ‡ `A , âˆ‡ `B i equals

A7. Comparison with Strongly-Typed RNNs

vec(wnÌ‚ )| UÌƒnÌ‚A S|(n) T(n) (UnÌ‚B )| vec(wnÌ‚ ).
and the result follows.
We are finally in a position to explain why simultaneous
HOSVD is insufficient to guarantee safety. That is, we are
in a position to explain why
1

2

A = S Ã—1 U Ã—2 U Â· Â· Â· Ã—N U

Proof. See theorem 4 of Balduzzi et al. (2015).

N

B = T Ã—1 U1 Ã—2 U2 Â· Â· Â· Ã—N UN
does not guarantee hÏ€ 1 (âˆ‡ `A ), âˆ‡ `B i â‰¥ 0. Our strategy
for guaranteeing safety hinges on simultaneous diagonalization. However, HOSVD does not guarantee that the core
S is diagonal. Instead, it introduces the condition of simultaneous orthogonality on subtensors of S.
Unfortunately, there is nothing to guarantee that the cores
S and T of two different tensors are â€œsimultaneously allorthogonalâ€ across the two tensors. In other words, there is
nothing to guarantee that the product of their matricizations
S|(n) T(n)
is diagonal in general. A specific setting where this holds
is when the two tensors A and B admits a simultaneous
tensor-SVD. It is an open question whether the condition
can be guaranteed in a naturally-occurring more general
setting.

Typed linear algebra was proposed in Balduzzi & Ghifary
(2016) (STNN), which applied the framework to analyze
and simplify recurrent neural networks. The definition of
typed vector space in this paper is more general than in
STNN â€“ it replaces an orthogonal basis with orthogonal
projections.
No formal definition of strong-typing was provided in
STNN. Informally, STNN stated: â€œWe refer to architectures as strongly-typed when they both (i) preserve the type
structure of their features and (ii) separate learned parameters from state-dependenceâ€. The definition of strongtyping in the main text, definition 5 is different from strongtyping in STNN, although it draws on similar intuitions.
The settings are sufficiently disparate that no confusion
should result.

