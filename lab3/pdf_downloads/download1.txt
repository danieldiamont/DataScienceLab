Supplementary material of the article Uncovering Causality from
Multivariate Hawkes Integrated Cumulants
Massil Achab∗1 , Emmanuel Bacry1 , Stéphane Gaiffas1 , Iacopo Mastromatteo2 , and Jean-François
Muzy1,3
1

Centre de Mathématiques Appliquées, CNRS, Ecole Polytechnique, UMR 7641, 91128 Palaiseau, France
2
Capital Fund Management, 23 rue de l’Université, 75007 Paris, France
3
Laboratoire Sciences Pour l’Environnement, Université de Corse, 7 Avenue Jean Nicoli, 20250 Corte, France

1

Introduction

1.1

In a nutshell

We prove here the consistency of NPHC estimator using the framework of Generalized Method of Moments Hansen
[1982]. The main difference with the usual Generalized Method of Moments relies in the relaxation of the moment
conditions, since we have E[b
gT (θ0 )] = mT 6= 0. We adapt the proof of consistency given in Newey and McFadden
[1994].

1.2

Sketch of the proof

We can relate the integral of the Hawkes process’s kernels to the integrals of the cumulant densities, from Jovanović
et al. [2015]. Our cumulant matching method would fall into the usual GMM framework if we could estimate without bias - the integral of the covariance on R, Rand the integralRof the skewness on R2 . Unfortunately, we can’t do
that easily. We can however estimate without bias ftT Ctij dt and ftT Ktijk dt with f T a compact supported function
on [−HT , HT ] that weakly converges to 1, with HT −→ ∞. In most cases we will take ftT = 1[−HT ,HT ] (t).
T →∞
R
R
b ij,(T ) ] − C ij | = | ftT Ctij dt − C ij | can be considered a
b ij,(T ) the estimator of ftT Ctij dt, the term |E[C
Denoting C
proxy to the distance to the classical GMM. This distance has to go to zero to make the rest of GMM’s proof work:
b ij,(T ) is then asymptotically unbiased towards C ij when T goes to infinity.
the estimator C

1.3

Notations

We observe the multivariate point process (N t ) on R+ , with Z i the events of the ith component. We will often write
covariance / skewness instead of integrated covariance / skewness. In the rest of the document, we use the following
notations.
Hawkes kernels’ integrals
Theoretical mean matrix
Theoretical covariance

Gtrue =

R

R
true −1
Φt dt = ( φij
)
t dt)ij = Id − (R

L = diag(Λ1 , . . . , Λd )
C = Rtrue L(Rtrue )>

∗ massil.achab@m4x.org

1

2

K c = (K iij )ij = (Rtrue ) C > + 2[Rtrue  (C − Rtrue L)](Rtrue )>

Theoretical skewness
Filtering function
Events sets

fT ≥ 0

supp(f T ) ⊂ [−HT , HT ]

Z i,T,1 = Z i ∩ [HT , T + HT ]
bi =
Λ

Estimators of the mean

Estimator of the covariance

1
T

fsT ds

R

T
fetT = f−t

Z j,T,2 = Z j ∩ [0, T + 2HT ]
j

i
NTi +H −NH
T
T
T

b ij,(T ) =
C

FT =

e j = NT +2HT
Λ
T +2HT
P

P

τ 0 ∈Z j,T ,2

τ ∈Z i,T ,1

ej F T
fτ 0 −τ − Λ



Estimator of the skewness1
b ijk,(T ) = 1
K
T

!
X

X

τ ∈Z i,T ,1

bi
Λ
−
T + 2HT

ej F T
fτ 0 −τ − Λ


X



τ 0 ∈Z j,T ,2

ekF T 
fτ 0 −τ − Λ

τ 00 ∈Z k,T ,2




X

X

e k (F T )2 
(f T ? feT )τ 0 −τ 00 − Λ


τ 0 ∈Z j,T ,2

τ 00 ∈Z k,T ,2

GMM related notations
θ=R

and
"

θ0 = Rtrue

#
2
C − RLR>
g0 (θ) = vec
∈ R2d
2
K c − R C > − 2[R  (C − RL)]R>
#
"
b (T ) − RLR
b >
2
C
∈ R2d
gbT (θ) = vec
(T )
2
(T
)
(T
)
>
dc
b )> − 2[R  (C
b
b
K
− R (C
− RL)]R
Q0 (θ) = g0 (θ)> W g0 (θ)
b T (θ) = gbT (θ)> W
cT gbT (θ)
Q

2

Consistency

First, let’s remind a useful theorem for consistency in GMM from Newey and McFadden [1994].
Theorem 2.1. If there is a function Q0 (θ) such that (i) Q0 (θ) is uniquely maximized at θ0 ; (ii) Θ is compact;
P
b T (θ) converges uniformly in probability to Q0 (θ), then θbT = arg max Q
b T (θ) −→
θ0 .
(iii) Q0 (θ) is continuous; (iv) Q
We can now prove the consistency of our estimator.
P

cT −→ W , and
Theorem 2.2. Suppose that (Nt ) is observed on R+ , W
1. W is positive semi-definite and W g0 (θ) = 0 if and only if θ = θ0 ,
2. θ ∈ Θ, which is compact,
3. the spectral radius of the kernel norm matrix satisfies ||Φ||∗ < 1,
R
R
R
R ijk
ijk
4. ∀i, j, k ∈ [d], fuT Cuij du → Cuij du and fuT fvT Ku,v
dudv → Ku,v
dudv,
1 When

ftT = 1[−HT ,HT ] (t), we remind that (f T ? feT )t = (2HT − |t|)+ . This leads to the estimator we showed in the article.

2

P

5. (F T )2 /T −→ 0 and ||f ||∞ = O(1).
Then
P
θbT −→ θ0 .

cT = Id .
Remark 1. In practice, we use a constant sequence of weighting matrices: W
Proof. Proceed by verifying the hypotheses of Theorem 2.1 from Newey and McFadden [1994]. Condition 2.1(i)
follows by (i) and by Q0 (θ) = [W 1/2 g0 (θ)]> [W 1/2 g0 (θ)] > 0 = Q0 (θ0 ). Indeed, there exists a neighborhood N
of θ0 such that θ ∈ N \{θ0 } and g0 (θ) 6= 0 since g0 (θ) is a polynom. Condition 2.1(ii) follows by (ii). Condition
2.1(iii) is satisfied since Q0 (θ) is a polynom. Condition 2.1(iv) is harder to prove. First, since gbT (θ) is a polynom of
θ, we prove easily that E[supθ∈Θ |b
gT (θ)|] < ∞. Then, by Θ compact, g0 (θ) is bounded on Θ, and by the triangle and
Cauchy-Schwarz inequalities,


b T (θ) − Q0 (θ)
Q

 
 

cT (b
cT + W
cT> )(b
cT − W )g0 (θ)
≤ (b
gT (θ) − g0 (θ))> W
gT (θ) − g0 (θ)) + g0 (θ)> (W
gT (θ) − g0 (θ)) + g0 (θ)> (W
2 c
cT k + kg0 (θ)k2 kW
cT − W k.
≤ kb
gT (θ) − g0 (θ)k kW
gT (θ) − g0 (θ)kkW
T k + 2kg0 (θ)kkb
 P

P
b T (θ) − Q0 (θ) −→
0, we should now prove that supθ∈Θ kb
gT (θ) − g0 (θ)k −→ 0. By Θ compact,
To prove supθ∈Θ Q
(T )
P
P
P
b − Lk −→
b (T ) − Ck −→
dc
it is sufficient to prove that kL
0, kC
0, and kK
− K c k −→ 0.
P
b − Lk −→
Proof that kL
0

b
The estimator of L is unbiased so let’s focus on the variance of L.

!2 
Z T +HT
1
b i − Λi )2 ] = E 
(dNti − Λi dt) 
E[(Λ
T HT
Z T +HT Z T +HT
1
= 2
E[(dNti − Λi dt)(dNti0 − Λi dt0 )]
T HT
HT
Z T +HT Z T +HT
1
= 2
Ctii0 −t dtdt0
T HT
HT
Z T +HT
C ii
1
C ii dt =
−→ 0
≤ 2
T HT
T
P
b − Lk −→
By Markov inequality, we have just proved that kL
0.
P
b (T ) − Ck −→
Proof that kC
0

b (T ) ) 6= C. Indeed,
First, let’s remind that E(C
!
Z T +HT
Z T +2HT


1
j
ij,(T
)
i
i
j
T
b
b Λ
e F
E C
=E
dNt
dNt0 ft0 −t − Λ
T HT
0
!
Z
Z T +2HT −t
1 T +HT
j
i
i j T
=E
dNt
dNt+s fs − Λ Λ F
+ ij,T,HT F T
T HT
−t
Z
Z


1 T +HT HT
j
=
fs E dNti dNt+s
− Λi Λj ds + ij,T,HT F T
T HT
−HT
Z
= fs Csij ds + ij,T,HT F T

3

Now,


b iΛ
ej
ij,T,HT = E Λi Λj − Λ
Z T +HT Z T +2HT 

1
E dNti dNtj0 − Λi Λj dtdt0
=− 2
T HT
0
Z T +HT Z T +2HT
1
ij
0
Ct−t
=− 2
0 dtdt
T HT
0

− !+
Z
HT − |t|
1
Ctij dt
1+
=−
T
T
(T )

b
Since f satisfies F T = o(T ), we have E(C
ij,(T )
b
Let’s now focus on the variance of C
:

(T )

b
b
) −→ C. It remains
that kC
− E(C
 now to prove

ij,(T )
ij,(T ) 2
ij,(T ) 2
b
b
b
V(C
) = E (C
) − E(C
) .

(T )

P

)k −→ 0.

Now,



b ij,(T ) )2
E (C



1
= E 2
T


X

(fτ 0 −τ − F T /(T + 2HT ))(fη0 −η − F T /(T + 2HT ))

(τ,η,τ 0 ,η 0 )∈(Z i,T ,1 )2 ×(Z j,T ,2 )2

!
Z
Z
1
j
j
i
i
T
T
=E
dNt dNt0 dNs dNs0 (ft0 −t − F /(T + 2HT ))(fs0 −s − F /(T + 2HT ))
T 2 t,s∈[HT ,T +HT ] t0 ,s0
Z
Z


1
E dNti dNtj0 dNsi dNsj0 (ft0 −t − F T /(T + 2HT ))(fs0 −s − F T /(T + 2HT ))
= 2
T t,s∈[HT ,T +HT ] t0 ,s0 ∈[0,T +2HT ]
And,
b ij,(T ) )2 =
E(C

1
T2

Z
t,s∈[HT ,T +HT ]

Z
t0 ,s0 ∈[0,T +2HT ]


 

E dNti dNtj0 E dNsi dNsj0 (ft0 −t − F T /(T + 2HT ))(fs0 −s − F T /(T + 2HT ))

Then, the variance involves the integration towards the difference of moments µr,s,t,u − µr,s µt,u . Let’s write it as a
sum of cumulants, since cumulants density are integrable.
µr,s,t,u − µr,s µt,u = κr,s,t,u + κr,s,t κu [4] + κr,s κt,u [3] + κr,s κt κu [6] + κr κs κt κu − (κr,s + κr κs )(κt,u + κt κu )
= κr,s,t,u
+ κr,s,t κu + κu,r,s κt + κt,u,r κs + κs,t,u κr
+ κr,t κs,u + κr,u κs,t
+ κr,t κs κu + κr,u κs κt + κs,t κr κu + κs,t κr κu
In the rest of the proof, we denote at = 1t∈[HT ,T +HT ] , bt = 1t∈[0,T +2HT ] , ct = 1t∈[−HT ,HT ] , gt = ft −
Before starting the integration of each term, let’s remark that:
P
(?n)
1. Ψt = n≥1 Φt
≥ 0 since Φt ≥ 0.

1
T +2HT

FT

ijk
ijkl
2. The regular parts of Cuij , Su,v
(skewness density) and Ku,v,w
(fourth cumulant density) are positive as polynoms
ab
of integrals of ψ· with positive coefficients. The integrals of the singular parts are positive as well.
R
3. (a) at bt0 ft0 −t dtdt0 = T F T
R
(b) at bt0 gt0 −t dtdt0 = 0
R
(c) at bt0 |gt0 −t |dtdt0 ≤ 2T F T

4

4. ∀t ∈ R, at (b ? ge)t = 0, where ges = g−s .
R
0
0
Fourth cumulant We want here to compute κi,j,i,j
t,t0 ,s,s0 at bt0 as bs0 gt0 −t gs0 −s dtdt dsds .
2
2
We remark that |gt0 −t gs0 −s | ≤ (||f ||∞ (1 + 2HT /T )) ≤ 4||f ||∞ .
Z
Z
Z
  2||f || 2 Z
 1 Z

∞
i,j,i,j
0
0
0
κt,t0 ,s,s0 at bt0 as bs0 gt0 −t gs0 −s dtdt dsds  ≤
dtat dt bt0 dsas ds0 bs0 Ktijij
 2
0 −t,s−t,s0 −t
T
T

2 Z
Z
Z
Z
2||f ||∞
≤
dtat dt0 bt0 dsas dwKtijij
0 −t,s−t,w
T

2 Z
Z
2||f ||∞
ijij
≤
dtat Ku,v,w
dudvdw
T
4||f ||2∞ ijij
≤
K
−→ 0
T →∞
T
Third × First
First form

We have four terms, but only two different forms since the roles of (s, s0 ) and (t, t0 ) are symmetric.
Z

j
κi,j,i
t,t0 ,s Λ Gt dt

Z
Λj
0
0
κi,j,i
= 2
t,t0 ,s at bt0 as bs0 gt0 −t gs0 −s dtdt dsds
T
Z
Λj
= 2
e)s gt0 −t dtdt0 ds
κi,j,i
t,t0 ,s at bt0 as (b ? g
T
=0
since as (b ? ge)s = 0

Second form
  Λi Z
Z

 

i,j,j
i
0
0
κi,j,j
 κt,t0 ,s0 Λ Gt dt =  2
t,t0 ,s0 at bt0 as bs0 gt0 −t gs0 −s dtdt dsds 
T

 Λi Z

0 0
κi,j,j
= 2
t,t0 ,s0 at bt0 gt0 −t bs0 (a ? g)s0 dtdt ds 
T
Z
Z
Z
Λi
≤ 2 2||f ||∞ ds0 bs0 (a ? |g|)s0 dtat dt0 bt0 Stijj
0 −s0 ,t−s0
T
FT
≤ 4||f ||∞ S ijj Λi
−→ 0
T T →∞
Second × Second
First form
 2||f || Z
Z


∞
i,i j,j
ii
Ct−s
Ctjj0 −s0 at bt0 |gt0 −t |as bs0 dtdt0 dsds0
 κt,s κt0 ,s0 Gt dt ≤
T2
Z
2||f ||∞ ii jj
≤
C
C
at bt0 |gt0 −t |dtdt0
T2
FT
≤ 4||f ||∞ C ii C jj
−→ 0
T T →∞
Second form
Z

FT


i,j i,j
−→ 0
 κt,s0 κt0 ,s Gt dt ≤ 4||f ||∞ (C ij )2
T T →∞
Second × First × First
First form
Z

i j
κi,j
t,t0 Λ Λ Gt dt

Λi Λj
=
T2

Z

0
κi,j
t,t0 at bt0 gt0 −t dtdt

5

Z

as bs0 gs0 −s dsds0 = 0

Second form
Z

j j
κi,i
t,s Λ Λ Gt dt =
(T )



Λj
T

2 Z

κi,i
e)s dtdt0 ds = 0
t,s at bt0 gt0 −t as (b ? g

P

b ) −→ 0. By Markov inequality, it ensures us that kC
b
We have just proved that V(C
(T )
P
b
finally that kC
− Ck −→ 0.
dc
Proof that kK

(T )

(T )

b
− E(C

(T )

P

)k −→ 0, and

P

− K c k −→ 0

The scheme of the proof is similar to the previous one. The upper bounds of the integrals involve the same kind of
terms, plus the new term (F T )2 /T that goes to zero thanks to the assumption 5 of the theorem.

References
Lars Peter Hansen. Large sample properties of generalized method of moments estimators. Econometrica: Journal of
the Econometric Society, pages 1029–1054, 1982.
Stojan Jovanović, John Hertz, and Stefan Rotter. Cumulants of hawkes point processes. Physical Review E, 91(4):
042802, 2015.
W. K Newey and D. McFadden. Large sample estimation and hypothesis testing. Handbook of econometrics, 4:
2111–2245, 1994.

6

