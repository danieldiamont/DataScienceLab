Supplementary material of the article Uncovering Causality from
Multivariate Hawkes Integrated Cumulants
Massil Achabâˆ—1 , Emmanuel Bacry1 , SteÌphane Gaiffas1 , Iacopo Mastromatteo2 , and Jean-FrancÌ§ois
Muzy1,3
1

Centre de MatheÌmatiques AppliqueÌes, CNRS, Ecole Polytechnique, UMR 7641, 91128 Palaiseau, France
2
Capital Fund Management, 23 rue de lâ€™UniversiteÌ, 75007 Paris, France
3
Laboratoire Sciences Pour lâ€™Environnement, UniversiteÌ de Corse, 7 Avenue Jean Nicoli, 20250 Corte, France

1

Introduction

1.1

In a nutshell

We prove here the consistency of NPHC estimator using the framework of Generalized Method of Moments Hansen
[1982]. The main difference with the usual Generalized Method of Moments relies in the relaxation of the moment
conditions, since we have E[b
gT (Î¸0 )] = mT 6= 0. We adapt the proof of consistency given in Newey and McFadden
[1994].

1.2

Sketch of the proof

We can relate the integral of the Hawkes processâ€™s kernels to the integrals of the cumulant densities, from JovanovicÌ
et al. [2015]. Our cumulant matching method would fall into the usual GMM framework if we could estimate without bias - the integral of the covariance on R, Rand the integralRof the skewness on R2 . Unfortunately, we canâ€™t do
that easily. We can however estimate without bias ftT Ctij dt and ftT Ktijk dt with f T a compact supported function
on [âˆ’HT , HT ] that weakly converges to 1, with HT âˆ’â†’ âˆ. In most cases we will take ftT = 1[âˆ’HT ,HT ] (t).
T â†’âˆ
R
R
b ij,(T ) ] âˆ’ C ij | = | ftT Ctij dt âˆ’ C ij | can be considered a
b ij,(T ) the estimator of ftT Ctij dt, the term |E[C
Denoting C
proxy to the distance to the classical GMM. This distance has to go to zero to make the rest of GMMâ€™s proof work:
b ij,(T ) is then asymptotically unbiased towards C ij when T goes to infinity.
the estimator C

1.3

Notations

We observe the multivariate point process (N t ) on R+ , with Z i the events of the ith component. We will often write
covariance / skewness instead of integrated covariance / skewness. In the rest of the document, we use the following
notations.
Hawkes kernelsâ€™ integrals
Theoretical mean matrix
Theoretical covariance

Gtrue =

R

R
true âˆ’1
Î¦t dt = ( Ï†ij
)
t dt)ij = Id âˆ’ (R

L = diag(Î›1 , . . . , Î›d )
C = Rtrue L(Rtrue )>

âˆ— massil.achab@m4x.org

1

2

K c = (K iij )ij = (Rtrue ) C > + 2[Rtrue  (C âˆ’ Rtrue L)](Rtrue )>

Theoretical skewness
Filtering function
Events sets

fT â‰¥ 0

supp(f T ) âŠ‚ [âˆ’HT , HT ]

Z i,T,1 = Z i âˆ© [HT , T + HT ]
bi =
Î›

Estimators of the mean

Estimator of the covariance

1
T

fsT ds

R

T
fetT = fâˆ’t

Z j,T,2 = Z j âˆ© [0, T + 2HT ]
j

i
NTi +H âˆ’NH
T
T
T

b ij,(T ) =
C

FT =

e j = NT +2HT
Î›
T +2HT
P

P

Ï„ 0 âˆˆZ j,T ,2

Ï„ âˆˆZ i,T ,1

ej F T
fÏ„ 0 âˆ’Ï„ âˆ’ Î›



Estimator of the skewness1
b ijk,(T ) = 1
K
T

!ï£«
X

X

Ï„ âˆˆZ i,T ,1

bi
Î›
âˆ’
T + 2HT

ej F T
fÏ„ 0 âˆ’Ï„ âˆ’ Î›

ï£¶
X

ï£­

Ï„ 0 âˆˆZ j,T ,2

ekF T ï£¸
fÏ„ 0 âˆ’Ï„ âˆ’ Î›

Ï„ 00 âˆˆZ k,T ,2

ï£«

ï£¶
X

X

e k (F T )2 ï£¸
(f T ? feT )Ï„ 0 âˆ’Ï„ 00 âˆ’ Î›

ï£­
Ï„ 0 âˆˆZ j,T ,2

Ï„ 00 âˆˆZ k,T ,2

GMM related notations
Î¸=R

and
"

Î¸0 = Rtrue

#
2
C âˆ’ RLR>
g0 (Î¸) = vec
âˆˆ R2d
2
K c âˆ’ R C > âˆ’ 2[R  (C âˆ’ RL)]R>
#
"
b (T ) âˆ’ RLR
b >
2
C
âˆˆ R2d
gbT (Î¸) = vec
(T )
2
(T
)
(T
)
>
dc
b )> âˆ’ 2[R  (C
b
b
K
âˆ’ R (C
âˆ’ RL)]R
Q0 (Î¸) = g0 (Î¸)> W g0 (Î¸)
b T (Î¸) = gbT (Î¸)> W
cT gbT (Î¸)
Q

2

Consistency

First, letâ€™s remind a useful theorem for consistency in GMM from Newey and McFadden [1994].
Theorem 2.1. If there is a function Q0 (Î¸) such that (i) Q0 (Î¸) is uniquely maximized at Î¸0 ; (ii) Î˜ is compact;
P
b T (Î¸) converges uniformly in probability to Q0 (Î¸), then Î¸bT = arg max Q
b T (Î¸) âˆ’â†’
Î¸0 .
(iii) Q0 (Î¸) is continuous; (iv) Q
We can now prove the consistency of our estimator.
P

cT âˆ’â†’ W , and
Theorem 2.2. Suppose that (Nt ) is observed on R+ , W
1. W is positive semi-definite and W g0 (Î¸) = 0 if and only if Î¸ = Î¸0 ,
2. Î¸ âˆˆ Î˜, which is compact,
3. the spectral radius of the kernel norm matrix satisfies ||Î¦||âˆ— < 1,
R
R
R
R ijk
ijk
4. âˆ€i, j, k âˆˆ [d], fuT Cuij du â†’ Cuij du and fuT fvT Ku,v
dudv â†’ Ku,v
dudv,
1 When

ftT = 1[âˆ’HT ,HT ] (t), we remind that (f T ? feT )t = (2HT âˆ’ |t|)+ . This leads to the estimator we showed in the article.

2

P

5. (F T )2 /T âˆ’â†’ 0 and ||f ||âˆ = O(1).
Then
P
Î¸bT âˆ’â†’ Î¸0 .

cT = Id .
Remark 1. In practice, we use a constant sequence of weighting matrices: W
Proof. Proceed by verifying the hypotheses of Theorem 2.1 from Newey and McFadden [1994]. Condition 2.1(i)
follows by (i) and by Q0 (Î¸) = [W 1/2 g0 (Î¸)]> [W 1/2 g0 (Î¸)] > 0 = Q0 (Î¸0 ). Indeed, there exists a neighborhood N
of Î¸0 such that Î¸ âˆˆ N \{Î¸0 } and g0 (Î¸) 6= 0 since g0 (Î¸) is a polynom. Condition 2.1(ii) follows by (ii). Condition
2.1(iii) is satisfied since Q0 (Î¸) is a polynom. Condition 2.1(iv) is harder to prove. First, since gbT (Î¸) is a polynom of
Î¸, we prove easily that E[supÎ¸âˆˆÎ˜ |b
gT (Î¸)|] < âˆ. Then, by Î˜ compact, g0 (Î¸) is bounded on Î˜, and by the triangle and
Cauchy-Schwarz inequalities,


b T (Î¸) âˆ’ Q0 (Î¸)
Q

 
 

cT (b
cT + W
cT> )(b
cT âˆ’ W )g0 (Î¸)
â‰¤ (b
gT (Î¸) âˆ’ g0 (Î¸))> W
gT (Î¸) âˆ’ g0 (Î¸)) + g0 (Î¸)> (W
gT (Î¸) âˆ’ g0 (Î¸)) + g0 (Î¸)> (W
2 c
cT k + kg0 (Î¸)k2 kW
cT âˆ’ W k.
â‰¤ kb
gT (Î¸) âˆ’ g0 (Î¸)k kW
gT (Î¸) âˆ’ g0 (Î¸)kkW
T k + 2kg0 (Î¸)kkb
 P

P
b T (Î¸) âˆ’ Q0 (Î¸) âˆ’â†’
0, we should now prove that supÎ¸âˆˆÎ˜ kb
gT (Î¸) âˆ’ g0 (Î¸)k âˆ’â†’ 0. By Î˜ compact,
To prove supÎ¸âˆˆÎ˜ Q
(T )
P
P
P
b âˆ’ Lk âˆ’â†’
b (T ) âˆ’ Ck âˆ’â†’
dc
it is sufficient to prove that kL
0, kC
0, and kK
âˆ’ K c k âˆ’â†’ 0.
P
b âˆ’ Lk âˆ’â†’
Proof that kL
0

b
The estimator of L is unbiased so letâ€™s focus on the variance of L.
ï£®
!2 ï£¹
Z T +HT
1
b i âˆ’ Î›i )2 ] = E ï£°
(dNti âˆ’ Î›i dt) ï£»
E[(Î›
T HT
Z T +HT Z T +HT
1
= 2
E[(dNti âˆ’ Î›i dt)(dNti0 âˆ’ Î›i dt0 )]
T HT
HT
Z T +HT Z T +HT
1
= 2
Ctii0 âˆ’t dtdt0
T HT
HT
Z T +HT
C ii
1
C ii dt =
âˆ’â†’ 0
â‰¤ 2
T HT
T
P
b âˆ’ Lk âˆ’â†’
By Markov inequality, we have just proved that kL
0.
P
b (T ) âˆ’ Ck âˆ’â†’
Proof that kC
0

b (T ) ) 6= C. Indeed,
First, letâ€™s remind that E(C
!
Z T +HT
Z T +2HT


1
j
ij,(T
)
i
i
j
T
b
b Î›
e F
E C
=E
dNt
dNt0 ft0 âˆ’t âˆ’ Î›
T HT
0
!
Z
Z T +2HT âˆ’t
1 T +HT
j
i
i j T
=E
dNt
dNt+s fs âˆ’ Î› Î› F
+ ij,T,HT F T
T HT
âˆ’t
Z
Z


1 T +HT HT
j
=
fs E dNti dNt+s
âˆ’ Î›i Î›j ds + ij,T,HT F T
T HT
âˆ’HT
Z
= fs Csij ds + ij,T,HT F T

3

Now,


b iÎ›
ej
ij,T,HT = E Î›i Î›j âˆ’ Î›
Z T +HT Z T +2HT 

1
E dNti dNtj0 âˆ’ Î›i Î›j dtdt0
=âˆ’ 2
T HT
0
Z T +HT Z T +2HT
1
ij
0
Ctâˆ’t
=âˆ’ 2
0 dtdt
T HT
0

âˆ’ !+
Z
HT âˆ’ |t|
1
Ctij dt
1+
=âˆ’
T
T
(T )

b
Since f satisfies F T = o(T ), we have E(C
ij,(T )
b
Letâ€™s now focus on the variance of C
:

(T )

b
b
) âˆ’â†’ C. It remains
that kC
âˆ’ E(C
 now to prove

ij,(T )
ij,(T ) 2
ij,(T ) 2
b
b
b
V(C
) = E (C
) âˆ’ E(C
) .

(T )

P

)k âˆ’â†’ 0.

Now,
ï£«


b ij,(T ) )2
E (C



1
= Eï£­ 2
T

ï£¶
X

(fÏ„ 0 âˆ’Ï„ âˆ’ F T /(T + 2HT ))(fÎ·0 âˆ’Î· âˆ’ F T /(T + 2HT ))ï£¸

(Ï„,Î·,Ï„ 0 ,Î· 0 )âˆˆ(Z i,T ,1 )2 Ã—(Z j,T ,2 )2

!
Z
Z
1
j
j
i
i
T
T
=E
dNt dNt0 dNs dNs0 (ft0 âˆ’t âˆ’ F /(T + 2HT ))(fs0 âˆ’s âˆ’ F /(T + 2HT ))
T 2 t,sâˆˆ[HT ,T +HT ] t0 ,s0
Z
Z


1
E dNti dNtj0 dNsi dNsj0 (ft0 âˆ’t âˆ’ F T /(T + 2HT ))(fs0 âˆ’s âˆ’ F T /(T + 2HT ))
= 2
T t,sâˆˆ[HT ,T +HT ] t0 ,s0 âˆˆ[0,T +2HT ]
And,
b ij,(T ) )2 =
E(C

1
T2

Z
t,sâˆˆ[HT ,T +HT ]

Z
t0 ,s0 âˆˆ[0,T +2HT ]


 

E dNti dNtj0 E dNsi dNsj0 (ft0 âˆ’t âˆ’ F T /(T + 2HT ))(fs0 âˆ’s âˆ’ F T /(T + 2HT ))

Then, the variance involves the integration towards the difference of moments Âµr,s,t,u âˆ’ Âµr,s Âµt,u . Letâ€™s write it as a
sum of cumulants, since cumulants density are integrable.
Âµr,s,t,u âˆ’ Âµr,s Âµt,u = Îºr,s,t,u + Îºr,s,t Îºu [4] + Îºr,s Îºt,u [3] + Îºr,s Îºt Îºu [6] + Îºr Îºs Îºt Îºu âˆ’ (Îºr,s + Îºr Îºs )(Îºt,u + Îºt Îºu )
= Îºr,s,t,u
+ Îºr,s,t Îºu + Îºu,r,s Îºt + Îºt,u,r Îºs + Îºs,t,u Îºr
+ Îºr,t Îºs,u + Îºr,u Îºs,t
+ Îºr,t Îºs Îºu + Îºr,u Îºs Îºt + Îºs,t Îºr Îºu + Îºs,t Îºr Îºu
In the rest of the proof, we denote at = 1tâˆˆ[HT ,T +HT ] , bt = 1tâˆˆ[0,T +2HT ] , ct = 1tâˆˆ[âˆ’HT ,HT ] , gt = ft âˆ’
Before starting the integration of each term, letâ€™s remark that:
P
(?n)
1. Î¨t = nâ‰¥1 Î¦t
â‰¥ 0 since Î¦t â‰¥ 0.

1
T +2HT

FT

ijk
ijkl
2. The regular parts of Cuij , Su,v
(skewness density) and Ku,v,w
(fourth cumulant density) are positive as polynoms
ab
of integrals of ÏˆÂ· with positive coefficients. The integrals of the singular parts are positive as well.
R
3. (a) at bt0 ft0 âˆ’t dtdt0 = T F T
R
(b) at bt0 gt0 âˆ’t dtdt0 = 0
R
(c) at bt0 |gt0 âˆ’t |dtdt0 â‰¤ 2T F T

4

4. âˆ€t âˆˆ R, at (b ? ge)t = 0, where ges = gâˆ’s .
R
0
0
Fourth cumulant We want here to compute Îºi,j,i,j
t,t0 ,s,s0 at bt0 as bs0 gt0 âˆ’t gs0 âˆ’s dtdt dsds .
2
2
We remark that |gt0 âˆ’t gs0 âˆ’s | â‰¤ (||f ||âˆ (1 + 2HT /T )) â‰¤ 4||f ||âˆ .
Z
Z
Z
  2||f || 2 Z
 1 Z

âˆ
i,j,i,j
0
0
0
Îºt,t0 ,s,s0 at bt0 as bs0 gt0 âˆ’t gs0 âˆ’s dtdt dsds  â‰¤
dtat dt bt0 dsas ds0 bs0 Ktijij
 2
0 âˆ’t,sâˆ’t,s0 âˆ’t
T
T

2 Z
Z
Z
Z
2||f ||âˆ
â‰¤
dtat dt0 bt0 dsas dwKtijij
0 âˆ’t,sâˆ’t,w
T

2 Z
Z
2||f ||âˆ
ijij
â‰¤
dtat Ku,v,w
dudvdw
T
4||f ||2âˆ ijij
â‰¤
K
âˆ’â†’ 0
T â†’âˆ
T
Third Ã— First
First form

We have four terms, but only two different forms since the roles of (s, s0 ) and (t, t0 ) are symmetric.
Z

j
Îºi,j,i
t,t0 ,s Î› Gt dt

Z
Î›j
0
0
Îºi,j,i
= 2
t,t0 ,s at bt0 as bs0 gt0 âˆ’t gs0 âˆ’s dtdt dsds
T
Z
Î›j
= 2
e)s gt0 âˆ’t dtdt0 ds
Îºi,j,i
t,t0 ,s at bt0 as (b ? g
T
=0
since as (b ? ge)s = 0

Second form
  Î›i Z
Z

 

i,j,j
i
0
0
Îºi,j,j
 Îºt,t0 ,s0 Î› Gt dt =  2
t,t0 ,s0 at bt0 as bs0 gt0 âˆ’t gs0 âˆ’s dtdt dsds 
T

 Î›i Z

0 0
Îºi,j,j
= 2
t,t0 ,s0 at bt0 gt0 âˆ’t bs0 (a ? g)s0 dtdt ds 
T
Z
Z
Z
Î›i
â‰¤ 2 2||f ||âˆ ds0 bs0 (a ? |g|)s0 dtat dt0 bt0 Stijj
0 âˆ’s0 ,tâˆ’s0
T
FT
â‰¤ 4||f ||âˆ S ijj Î›i
âˆ’â†’ 0
T T â†’âˆ
Second Ã— Second
First form
 2||f || Z
Z


âˆ
i,i j,j
ii
Ctâˆ’s
Ctjj0 âˆ’s0 at bt0 |gt0 âˆ’t |as bs0 dtdt0 dsds0
 Îºt,s Îºt0 ,s0 Gt dt â‰¤
T2
Z
2||f ||âˆ ii jj
â‰¤
C
C
at bt0 |gt0 âˆ’t |dtdt0
T2
FT
â‰¤ 4||f ||âˆ C ii C jj
âˆ’â†’ 0
T T â†’âˆ
Second form
Z

FT


i,j i,j
âˆ’â†’ 0
 Îºt,s0 Îºt0 ,s Gt dt â‰¤ 4||f ||âˆ (C ij )2
T T â†’âˆ
Second Ã— First Ã— First
First form
Z

i j
Îºi,j
t,t0 Î› Î› Gt dt

Î›i Î›j
=
T2

Z

0
Îºi,j
t,t0 at bt0 gt0 âˆ’t dtdt

5

Z

as bs0 gs0 âˆ’s dsds0 = 0

Second form
Z

j j
Îºi,i
t,s Î› Î› Gt dt =
(T )



Î›j
T

2 Z

Îºi,i
e)s dtdt0 ds = 0
t,s at bt0 gt0 âˆ’t as (b ? g

P

b ) âˆ’â†’ 0. By Markov inequality, it ensures us that kC
b
We have just proved that V(C
(T )
P
b
finally that kC
âˆ’ Ck âˆ’â†’ 0.
dc
Proof that kK

(T )

(T )

b
âˆ’ E(C

(T )

P

)k âˆ’â†’ 0, and

P

âˆ’ K c k âˆ’â†’ 0

The scheme of the proof is similar to the previous one. The upper bounds of the integrals involve the same kind of
terms, plus the new term (F T )2 /T that goes to zero thanks to the assumption 5 of the theorem.

References
Lars Peter Hansen. Large sample properties of generalized method of moments estimators. Econometrica: Journal of
the Econometric Society, pages 1029â€“1054, 1982.
Stojan JovanovicÌ, John Hertz, and Stefan Rotter. Cumulants of hawkes point processes. Physical Review E, 91(4):
042802, 2015.
W. K Newey and D. McFadden. Large sample estimation and hypothesis testing. Handbook of econometrics, 4:
2111â€“2245, 1994.

6

