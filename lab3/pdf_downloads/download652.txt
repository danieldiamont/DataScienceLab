Supplementary material for A Unified View of Multi-Label Performance Measures.

A

Appendix A: Proofs

In this section, we provide detailed proofs of the theoretical results presented in the manuscript.
A.1

Proof of Theorem 4

Because F is label-wise effective, its order of prediction value on a specific instance xi is correct.
Therefore, the threshold error i can happen in either the two ways:
1. i positive labels are predicted as negative labels.
In this case, the true positive number T Pi on this instance becomes |YiÂ·+ | âˆ’ i , and the false
positive number F Pi is zero, and the false negative number F Ni becomes i .
The precision value and the recall value will be:
P reci =

T Pi
= 1,
T Pi + F Pi

Reci =

T Pi
|Y + | âˆ’ i
= iÂ· +
T Pi + F Ni
|YiÂ· |

And the F -measurei is:
2P reci Ã— Reci
2(|YiÂ·+ | âˆ’ i )
=
P reci + Reci
2|YiÂ·+ | âˆ’ i

F -measurei =

2. i negative labels are predicted as positive labels.
In this case, the true positive number T Pi on this instance is still |YiÂ·+ |, and the false positive
number F Pi = i , and the false negative number F Ni is zero.
The precision value and the recall value will be:
P reci =

T Pi
|Y + |
,
= + iÂ·
T Pi + F Pi
|YiÂ· | + i

Reci =

T Pi
=1
T Pi + F Ni

And the F -measurei is:
F -measurei =

2P reci Ã— Reci
2|YiÂ·+ |
=
P reci + Reci
2|YiÂ·+ | + i

The instance-F1 is lower bounded by the sum of minimum value of F -measurei , thus:
m
n 2(|Y + | âˆ’  )
1 X
2|YiÂ·+ | o
i
iÂ·
min
instance-F1(H) â‰¥
,
+
m i=1
2|YiÂ· | âˆ’ i 2|YiÂ·+ | + i
Under the assumption that all the instances are i.i.d drawn, micro-F1 equals instance-F1. Theorem 4
is proved.
A.2

Proof of Theorem 5

Because F is instance-wise effective, its order of prediction value on a specific label Y Â·j is correct.
Therefore, the threshold error j can happen in either the two ways:
1. j positive instances are predicted as negative instances.
In this case, the true positive number T Pj on this label becomes |YÂ·j+ | âˆ’ j , and the false
positive number F Pj is zero, and the false negative number F Nj becomes j .
The precision value and the recall value will be:
P recj =

T Pj
= 1,
T Pj + F Pj

Recj =

|YÂ·j+ | âˆ’ j
T Pj
=
T Pj + F Nj
|YÂ·j+ |

And the F -measurej is:
F -measurej =

2(|YjÂ·+ | âˆ’ j )
2P recj Ã— Recj
=
P recj + Recj
2|YjÂ·+ | âˆ’ j
1

2. j negative instanaces are predicted as positive instances.
In this case, the true positive number T Pj on this label is still |YÂ·j+ |, and the false positive
number F Pj = j , and the false negative number F Nj is zero.
The precision value and the recall value will be:
|YÂ·j+ |
T Pj
P recj =
= +
,
T Pj + F Pj
|YÂ·j | + j

Recj =

T Pj
=1
T Pj + F Nj

And the F -measurej is:
F -measurej =

2|YÂ·j+ |
2P recj Ã— Recj
=
P recj + Recj
2|YÂ·j+ | + j

The macro-F1 is lower bounded by the sum of minimum value of F -measurej , thus:
macro-F1(H) â‰¥

l
n 2(|Y + | âˆ’ j )
2|YÂ·j+ | o
1X
Â·j
min
,
l j=1
2|YÂ·j+ | âˆ’ j 2|YÂ·j+ | + j

Theorem 5 is proved.
A.3

Proof of LIMO Algorithm

Theorem A.3.1. In each iteration (step 5 to step 15) of Algorithm 1, the updated direction of the
model is an unbiased estimation of the gradient of this objective function:
arg min
W ,Î¾

s.t.

l
X
i=1

||wi ||2 + Î»1

m X
X

Î¾iuv + Î»2

i=1 (u,v)

>
uv
w>
u xi âˆ’ w v xi > 1 âˆ’ Î¾i ,
j
>
w>
j xa âˆ’ w j xb > 1 âˆ’ Î¾ab ,

l X
X

j
Î¾ab

j=1 (a,b)

Î¾iuv
j
Î¾ab

â‰¥ 0, for i = 1, Â· Â· Â· , m and (u, v) âˆˆ YiÂ·+ Ã— YiÂ·âˆ’ ,

(1)

â‰¥ 0, for j = 1, Â· Â· Â· , l and (a, b) âˆˆ YÂ·j+ Ã— YÂ·jâˆ’ .

Proof. Suppose that the function in Equation (1) is f (W ), because W can be decomposed into
[w1 , w2 , Â· Â· Â· , wl ], we consider the partial gradient of a particular wk :
âˆ‚f (W )
=2wk + Î»1 Ï†1 + Î»2 Ï†2 = 2wk
âˆ‚wk
m n
X
X
+ Î»1
[[k âˆˆ YiÂ·âˆ’ ]]xi
[[1 âˆ’ (wj âˆ’ wk )> xi > 0]]
i=1

jâˆˆYiÂ·+

âˆ’ [[k âˆˆ YiÂ·+ ]]xi

X

[[1 âˆ’ (wk âˆ’ wj )> xi > 0]]

o

(2)

jâˆˆYiÂ·âˆ’

+ Î»2

X X

(xb âˆ’ xa )[[1 âˆ’ w>
k (xa âˆ’ xb ) > 0]]

+
âˆ’
aâˆˆYÂ·k
bâˆˆYÂ·k

The second term Î»1 Ï†1 is the gradient of label-wise margin on wk , and the third term Î»2 Ï†2 is the
gradient of the instance-wise margin on wk .
Assume that (xi , yik , yij ) is picked in step 5 and 6, the direction will be computed in step 8 or 9
according to:
g label (xi , yik , yij ) =[[k âˆˆ YiÂ·âˆ’ ]]Î»1 xi [[1 âˆ’ (wk âˆ’ wj )> xi > 0]]
âˆ’ [[k âˆˆ YiÂ·+ ]]Î»1 xi [[1 âˆ’ (wj âˆ’ wk )> xi > 0]] + wk
2

Then do the expectation:

X


1
Exi Eyij [g label (xi , yik , yij )] = Exi Î»1 xi
[[1 âˆ’ (wk âˆ’ wj )> xi > 0]]
C
+
jâˆˆYiÂ·

âˆ’ Î»1 xi

1
[[1 âˆ’ (wj âˆ’ wk ) xi > 0]] + wk
D
âˆ’

X

>



jâˆˆYiÂ·

=

1
1
Î»1 Ï†1 + 0 wk
C0
D

Where C 0 and D0 are constants. Similarly, we can prove the expectation of the direction in step 11 to
15:
1
1
Exa ,xb [g inst (yk , xa , xb )] = 00 Î»2 Ï†2 + 00 wk
C
D
Because of the linearity of expectation, and absorbing the constants into Î»1 and Î»2 , the gradient
âˆ‚f (W )
âˆ‚wk can be unbiased estimated. Namely, the updated direction of the algorithm is an unbiased
estimation of the gradient of Equation (1).

3

B

Appendix B: Detailed Experimental Results

In this section, detailed experimental results are included. The results of synthetic data are in Section
B.1 and The results of benchmark data are in Section B.2
B.1

Detailed Experimental Results of Synthetic Data

In this section, the detailed experimental results of synthetic data are given.
Table B.1: Original absolute value and rescaled value of experiments on ranking measures. In the left
columns are absolute values, and in the right columns are rescaled relative values.
measure
LIMO-inst
LIMO
LIMO
ranking loss
0.027 0.00 0.015 0.99 0.015 1.00
avg. precision 0.992 0.00 0.992 0.58 0.992 1.00
one-error
0.000 1.00 0.001 0.28 0.001 0.00
1.576 0.00 1.557 0.97 1.556 1.00
coverage
macro-AUC
0.842 1.00 0.828 0.00 0.842 0.98
instance-AUC 0.973 0.00 0.985 0.99 0.985 1.00
micro-AUC
0.861 0.14 0.854 0.00 0.903 1.00

Table B.2: Original absolute value and rescaled value of experiments on classification measures. In
the left columns are absolute values, and in the right columns are rescaled relative values.
measure
LIMO-inst-t LIMO-inst-t(x) LIMO-label-t LIMO-label-t(x) LIMO-t LIMO-t(x)
Hamming loss 0.172 0.28 0.160 0.48 0.188 0.00 0.131
1.00
0.163 0.43 0.134 0.94
micro-F1
0.837 0.00 0.860 0.43 0.840 0.06 0.890
1.00
0.858 0.40 0.885 0.92
0.869 0.87 0.857 0.25 0.861 0.46 0.859
0.35
0.872 1.00 0.852 0.00
macro-F1
instance-F1 0.804 0.00 0.883 0.79 0.835 0.32 0.904
1.00
0.858 0.54 0.900 0.96
B.2

Detailed Experimental Results of Benchmark Data

The ranking results in Figure 4 in paper are computed from Table B.3. Because this table is too large,
we can only rotate it to show in the next page.

4

5

bibtex

corel5k

enron

medical

CAL500

Dataset

Algorithm
BR
ML-kNN
GFM
LIMO-inst
LIMO-label
LIMO
BR
ML-kNN
GFM
LIMO-inst
LIMO-label
LIMO
BR
ML-kNN
GFM
LIMO-inst
LIMO-label
LIMO
BR
ML-kNN
GFM
LIMO-inst
LIMO-label
LIMO
BR
ML-kNN
GFM
LIMO-inst
LIMO-label
LIMO

hamming lossâ†“
.145Â±.003(5)
.139Â±.003(3)
.200Â±.002(6)
.143Â±.004(4)
.138Â±.002(2)
.137Â±.025(1)
.011Â±.001(1)
.016Â±.001(5)
.025Â±.002(6)
.015Â±.001(4)
.014Â±.001(3)
.013Â±.001(2)
.070Â±.003(6)
.053Â±.001(3)
.069Â±.003(5)
.054Â±.001(4)
.049Â±.001(2)
.049Â±.001(1)
.014Â±.000(5)
.009Â±.000(1)
.021Â±.001(6)
.010Â±.000(2)
.011Â±.000(4)
.011Â±.000(3)
.016Â±.001(5)
.014Â±.000(2)
.037Â±.000(6)
.014Â±.000(1)
.014Â±.000(4)
.014Â±.000(3)

ranking lossâ†“
.216Â±.005(4)
.184Â±.005(3)
.522Â±.007(5)
.545Â±.015(6)
.180Â±.004(2)
.178Â±.004(1)
.073Â±.041(5)
.048Â±.008(4)
.287Â±.026(6)
.017Â±.005(1)
.032Â±.006(3)
.019Â±.006(2)
.136Â±.010(4)
.096Â±.004(3)
.554Â±.027(6)
.205Â±.008(5)
.085Â±.003(2)
.083Â±.003(1)
.280Â±.010(5)
.135Â±.002(3)
.803Â±.012(6)
.275Â±.004(4)
.112Â±.003(1)
.116Â±.003(2)
.114Â±.007(3)
.218Â±.004(5)
.707Â±.003(6)
.120Â±.003(4)
.071Â±.002(2)
.058Â±.001(1)

avg. precisionâ†‘
.470Â±.008(4)
.491Â±.007(3)
.337Â±.004(5)
.147Â±.004(6)
.499Â±.008(2)
.501Â±.008(1)
.416Â±.100(6)
.788Â±.017(4)
.692Â±.025(5)
.881Â±.018(2)
.829Â±.018(3)
.893Â±.017(1)
.539Â±.086(4)
.624Â±.014(3)
.399Â±.021(6)
.520Â±.008(5)
.672Â±.010(2)
.672Â±.010(1)
.077Â±.013(6)
.245Â±.004(2)
.100Â±.005(5)
.105Â±.004(4)
.289Â±.006(1)
.227Â±.005(3)
.528Â±.012(2)
.339Â±.006(5)
.210Â±.004(6)
.494Â±.008(4)
.527Â±.008(3)
.570Â±.004(1)

one-errorâ†“
.212Â±.025(5)
.106Â±.023(3)
.000Â±.000(1)
.971Â±.022(6)
.105Â±.023(2)
.122Â±.035(4)
.804Â±.029(6)
.266Â±.025(5)
.217Â±.025(3)
.170Â±.028(2)
.217Â±.026(4)
.147Â±.027(1)
.533Â±.263(6)
.310Â±.022(4)
.246Â±.041(2)
.344Â±.013(5)
.233Â±.017(1)
.253Â±.022(3)
.962Â±.004(6)
.736Â±.009(3)
.516Â±.030(1)
.897Â±.006(5)
.710Â±.010(2)
.791Â±.008(4)
.428Â±.014(2)
.599Â±.007(6)
.492Â±.010(5)
.469Â±.016(4)
.433Â±.013(3)
.390Â±.008(1)

coverageâ†“
143.025Â±2.319(4)
129.789Â±2.426(2)
166.481Â±0.906(6)
162.652Â±1.539(5)
129.993Â±2.491(3)
129.323Â±2.672(1)
3.697Â±1.752(5)
3.034Â±0.411(4)
6.581Â±0.714(6)
1.248Â±0.279(1)
2.237Â±0.378(3)
1.423Â±0.350(2)
16.834Â±0.669(4)
13.615Â±0.423(3)
31.645Â±0.764(6)
23.679Â±0.804(5)
12.324Â±0.444(2)
11.880Â±0.255(1)
207.643Â±3.477(5)
114.727Â±1.658(3)
320.449Â±2.173(6)
172.120Â±2.183(4)
99.629Â±2.136(2)
94.253Â±2.109(1)
32.758Â±1.929(4)
56.259Â±1.260(5)
85.281Â±0.701(6)
32.403Â±0.640(3)
20.425Â±0.422(2)
17.447Â±0.357(1)

instance-F1â†‘
.354Â±.009(5)
.321Â±.010(6)
.454Â±.006(3)
.386Â±.010(4)
.473Â±.004(2)
.475Â±.006(1)
.766Â±.022(1)
.564Â±.033(5)
.636Â±.025(4)
.444Â±.090(6)
.641Â±.030(3)
.706Â±.019(2)
.482Â±.009(3)
.409Â±.022(5)
.428Â±.022(4)
.404Â±.053(6)
.565Â±.011(1)
.562Â±.010(2)
.139Â±.005(4)
.017Â±.002(6)
.150Â±.008(3)
.058Â±.003(5)
.214Â±.004(1)
.152Â±.005(2)
.399Â±.009(1)
.160Â±.007(6)
.223Â±.008(5)
.392Â±.005(2)
.386Â±.007(4)
.390Â±.007(3)

instance-AUCâ†‘
.784Â±.005(4)
.816Â±.005(3)
.662Â±.006(5)
.455Â±.015(6)
.820Â±.004(2)
.822Â±.004(1)
.927Â±.040(5)
.953Â±.007(4)
.882Â±.013(6)
.983Â±.005(1)
.968Â±.006(3)
.981Â±.006(2)
.866Â±.010(4)
.904Â±.004(3)
.669Â±.014(6)
.796Â±.008(5)
.916Â±.003(2)
.918Â±.003(1)
.720Â±.010(5)
.865Â±.002(3)
.416Â±.012(6)
.725Â±.004(4)
.888Â±.003(1)
.884Â±.003(2)
.886Â±.007(3)
.782Â±.004(5)
.618Â±.003(6)
.880Â±.003(4)
.929Â±.002(2)
.942Â±.001(1)

macro-F1â†‘
.097Â±.006(5)
.053Â±.002(6)
.183Â±.005(3)
.302Â±.008(1)
.126Â±.003(4)
.288Â±.006(2)
.384Â±.040(3)
.190Â±.015(6)
.216Â±.018(4)
.448Â±.024(2)
.207Â±.012(5)
.464Â±.024(1)
.187Â±.015(3)
.083Â±.008(6)
.118Â±.012(5)
.310Â±.018(1)
.137Â±.005(4)
.278Â±.017(2)
.044Â±.003(4)
.009Â±.001(6)
.029Â±.002(5)
.118Â±.003(1)
.050Â±.002(3)
.117Â±.004(2)
.318Â±.016(3)
.066Â±.006(6)
.130Â±.007(5)
.323Â±.005(2)
.232Â±.004(4)
.326Â±.006(1)

macro-AUCâ†‘
.544Â±.012(2)
.523Â±.009(3)
.518Â±.013(5)
.566Â±.011(1)
.510Â±.011(6)
.523Â±.011(4)
.877Â±.038(3)
.797Â±.029(5)
.650Â±.027(6)
.901Â±.032(1)
.859Â±.035(4)
.896Â±.029(2)
.631Â±.025(5)
.633Â±.022(4)
.553Â±.015(6)
.717Â±.015(1)
.644Â±.019(3)
.663Â±.021(2)
.605Â±.004(4)
.540Â±.007(5)
.516Â±.006(6)
.706Â±.006(1)
.658Â±.006(3)
.692Â±.007(2)
.866Â±.007(4)
.661Â±.007(5)
.575Â±.003(6)
.921Â±.002(2)
.911Â±.002(3)
.924Â±.002(1)

micro-F1â†‘
.357Â±.011(5)
.318Â±.010(6)
.457Â±.006(3)
.389Â±.010(4)
.477Â±.004(2)
.479Â±.006(1)
.792Â±.020(1)
.654Â±.028(4)
.605Â±.027(5)
.439Â±.087(6)
.702Â±.020(3)
.757Â±.012(2)
.473Â±.008(3)
.461Â±.017(4)
.437Â±.016(5)
.414Â±.056(6)
.591Â±.008(2)
.596Â±.006(1)
.158Â±.006(3)
.027Â±.003(6)
.146Â±.011(4)
.057Â±.002(5)
.236Â±.004(1)
.177Â±.005(2)
.419Â±.012(3)
.211Â±.007(5)
.185Â±.007(6)
.438Â±.006(1)
.405Â±.007(4)
.435Â±.004(2)

micro-AUC â†‘
.779Â±.006(4)
.813Â±.004(3)
.661Â±.006(5)
.458Â±.014(6)
.815Â±.004(2)
.816Â±.004(1)
.910Â±.039(5)
.949Â±.008(4)
.875Â±.014(6)
.979Â±.005(1)
.960Â±.007(3)
.977Â±.006(2)
.814Â±.008(4)
.898Â±.003(1)
.654Â±.011(6)
.810Â±.006(5)
.897Â±.003(2)
.896Â±.004(3)
.706Â±.009(5)
.866Â±.002(3)
.411Â±.013(6)
.725Â±.004(4)
.882Â±.002(1)
.881Â±.003(2)
.869Â±.007(4)
.776Â±.005(5)
.626Â±.003(6)
.877Â±.003(3)
.917Â±.002(2)
.938Â±.002(1)

Table B.3: Experimental results on eleven multi-label performance measures. For each performance measure, â€œâ†“â€ indicates â€œthe smaller the betterâ€ and â€œâ†‘â€ indicates
â€œthe larger the betterâ€. The results are shown in meanÂ±std(rank). The smaller the rank, the better the performance.

