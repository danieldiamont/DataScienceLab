Supplementary material for A Unified View of Multi-Label Performance Measures.

A

Appendix A: Proofs

In this section, we provide detailed proofs of the theoretical results presented in the manuscript.
A.1

Proof of Theorem 4

Because F is label-wise effective, its order of prediction value on a specific instance xi is correct.
Therefore, the threshold error i can happen in either the two ways:
1. i positive labels are predicted as negative labels.
In this case, the true positive number T Pi on this instance becomes |Yi·+ | − i , and the false
positive number F Pi is zero, and the false negative number F Ni becomes i .
The precision value and the recall value will be:
P reci =

T Pi
= 1,
T Pi + F Pi

Reci =

T Pi
|Y + | − i
= i· +
T Pi + F Ni
|Yi· |

And the F -measurei is:
2P reci × Reci
2(|Yi·+ | − i )
=
P reci + Reci
2|Yi·+ | − i

F -measurei =

2. i negative labels are predicted as positive labels.
In this case, the true positive number T Pi on this instance is still |Yi·+ |, and the false positive
number F Pi = i , and the false negative number F Ni is zero.
The precision value and the recall value will be:
P reci =

T Pi
|Y + |
,
= + i·
T Pi + F Pi
|Yi· | + i

Reci =

T Pi
=1
T Pi + F Ni

And the F -measurei is:
F -measurei =

2P reci × Reci
2|Yi·+ |
=
P reci + Reci
2|Yi·+ | + i

The instance-F1 is lower bounded by the sum of minimum value of F -measurei , thus:
m
n 2(|Y + | −  )
1 X
2|Yi·+ | o
i
i·
min
instance-F1(H) ≥
,
+
m i=1
2|Yi· | − i 2|Yi·+ | + i
Under the assumption that all the instances are i.i.d drawn, micro-F1 equals instance-F1. Theorem 4
is proved.
A.2

Proof of Theorem 5

Because F is instance-wise effective, its order of prediction value on a specific label Y ·j is correct.
Therefore, the threshold error j can happen in either the two ways:
1. j positive instances are predicted as negative instances.
In this case, the true positive number T Pj on this label becomes |Y·j+ | − j , and the false
positive number F Pj is zero, and the false negative number F Nj becomes j .
The precision value and the recall value will be:
P recj =

T Pj
= 1,
T Pj + F Pj

Recj =

|Y·j+ | − j
T Pj
=
T Pj + F Nj
|Y·j+ |

And the F -measurej is:
F -measurej =

2(|Yj·+ | − j )
2P recj × Recj
=
P recj + Recj
2|Yj·+ | − j
1

2. j negative instanaces are predicted as positive instances.
In this case, the true positive number T Pj on this label is still |Y·j+ |, and the false positive
number F Pj = j , and the false negative number F Nj is zero.
The precision value and the recall value will be:
|Y·j+ |
T Pj
P recj =
= +
,
T Pj + F Pj
|Y·j | + j

Recj =

T Pj
=1
T Pj + F Nj

And the F -measurej is:
F -measurej =

2|Y·j+ |
2P recj × Recj
=
P recj + Recj
2|Y·j+ | + j

The macro-F1 is lower bounded by the sum of minimum value of F -measurej , thus:
macro-F1(H) ≥

l
n 2(|Y + | − j )
2|Y·j+ | o
1X
·j
min
,
l j=1
2|Y·j+ | − j 2|Y·j+ | + j

Theorem 5 is proved.
A.3

Proof of LIMO Algorithm

Theorem A.3.1. In each iteration (step 5 to step 15) of Algorithm 1, the updated direction of the
model is an unbiased estimation of the gradient of this objective function:
arg min
W ,ξ

s.t.

l
X
i=1

||wi ||2 + λ1

m X
X

ξiuv + λ2

i=1 (u,v)

>
uv
w>
u xi − w v xi > 1 − ξi ,
j
>
w>
j xa − w j xb > 1 − ξab ,

l X
X

j
ξab

j=1 (a,b)

ξiuv
j
ξab

≥ 0, for i = 1, · · · , m and (u, v) ∈ Yi·+ × Yi·− ,

(1)

≥ 0, for j = 1, · · · , l and (a, b) ∈ Y·j+ × Y·j− .

Proof. Suppose that the function in Equation (1) is f (W ), because W can be decomposed into
[w1 , w2 , · · · , wl ], we consider the partial gradient of a particular wk :
∂f (W )
=2wk + λ1 φ1 + λ2 φ2 = 2wk
∂wk
m n
X
X
+ λ1
[[k ∈ Yi·− ]]xi
[[1 − (wj − wk )> xi > 0]]
i=1

j∈Yi·+

− [[k ∈ Yi·+ ]]xi

X

[[1 − (wk − wj )> xi > 0]]

o

(2)

j∈Yi·−

+ λ2

X X

(xb − xa )[[1 − w>
k (xa − xb ) > 0]]

+
−
a∈Y·k
b∈Y·k

The second term λ1 φ1 is the gradient of label-wise margin on wk , and the third term λ2 φ2 is the
gradient of the instance-wise margin on wk .
Assume that (xi , yik , yij ) is picked in step 5 and 6, the direction will be computed in step 8 or 9
according to:
g label (xi , yik , yij ) =[[k ∈ Yi·− ]]λ1 xi [[1 − (wk − wj )> xi > 0]]
− [[k ∈ Yi·+ ]]λ1 xi [[1 − (wj − wk )> xi > 0]] + wk
2

Then do the expectation:

X


1
Exi Eyij [g label (xi , yik , yij )] = Exi λ1 xi
[[1 − (wk − wj )> xi > 0]]
C
+
j∈Yi·

− λ1 xi

1
[[1 − (wj − wk ) xi > 0]] + wk
D
−

X

>



j∈Yi·

=

1
1
λ1 φ1 + 0 wk
C0
D

Where C 0 and D0 are constants. Similarly, we can prove the expectation of the direction in step 11 to
15:
1
1
Exa ,xb [g inst (yk , xa , xb )] = 00 λ2 φ2 + 00 wk
C
D
Because of the linearity of expectation, and absorbing the constants into λ1 and λ2 , the gradient
∂f (W )
∂wk can be unbiased estimated. Namely, the updated direction of the algorithm is an unbiased
estimation of the gradient of Equation (1).

3

B

Appendix B: Detailed Experimental Results

In this section, detailed experimental results are included. The results of synthetic data are in Section
B.1 and The results of benchmark data are in Section B.2
B.1

Detailed Experimental Results of Synthetic Data

In this section, the detailed experimental results of synthetic data are given.
Table B.1: Original absolute value and rescaled value of experiments on ranking measures. In the left
columns are absolute values, and in the right columns are rescaled relative values.
measure
LIMO-inst
LIMO
LIMO
ranking loss
0.027 0.00 0.015 0.99 0.015 1.00
avg. precision 0.992 0.00 0.992 0.58 0.992 1.00
one-error
0.000 1.00 0.001 0.28 0.001 0.00
1.576 0.00 1.557 0.97 1.556 1.00
coverage
macro-AUC
0.842 1.00 0.828 0.00 0.842 0.98
instance-AUC 0.973 0.00 0.985 0.99 0.985 1.00
micro-AUC
0.861 0.14 0.854 0.00 0.903 1.00

Table B.2: Original absolute value and rescaled value of experiments on classification measures. In
the left columns are absolute values, and in the right columns are rescaled relative values.
measure
LIMO-inst-t LIMO-inst-t(x) LIMO-label-t LIMO-label-t(x) LIMO-t LIMO-t(x)
Hamming loss 0.172 0.28 0.160 0.48 0.188 0.00 0.131
1.00
0.163 0.43 0.134 0.94
micro-F1
0.837 0.00 0.860 0.43 0.840 0.06 0.890
1.00
0.858 0.40 0.885 0.92
0.869 0.87 0.857 0.25 0.861 0.46 0.859
0.35
0.872 1.00 0.852 0.00
macro-F1
instance-F1 0.804 0.00 0.883 0.79 0.835 0.32 0.904
1.00
0.858 0.54 0.900 0.96
B.2

Detailed Experimental Results of Benchmark Data

The ranking results in Figure 4 in paper are computed from Table B.3. Because this table is too large,
we can only rotate it to show in the next page.

4

5

bibtex

corel5k

enron

medical

CAL500

Dataset

Algorithm
BR
ML-kNN
GFM
LIMO-inst
LIMO-label
LIMO
BR
ML-kNN
GFM
LIMO-inst
LIMO-label
LIMO
BR
ML-kNN
GFM
LIMO-inst
LIMO-label
LIMO
BR
ML-kNN
GFM
LIMO-inst
LIMO-label
LIMO
BR
ML-kNN
GFM
LIMO-inst
LIMO-label
LIMO

hamming loss↓
.145±.003(5)
.139±.003(3)
.200±.002(6)
.143±.004(4)
.138±.002(2)
.137±.025(1)
.011±.001(1)
.016±.001(5)
.025±.002(6)
.015±.001(4)
.014±.001(3)
.013±.001(2)
.070±.003(6)
.053±.001(3)
.069±.003(5)
.054±.001(4)
.049±.001(2)
.049±.001(1)
.014±.000(5)
.009±.000(1)
.021±.001(6)
.010±.000(2)
.011±.000(4)
.011±.000(3)
.016±.001(5)
.014±.000(2)
.037±.000(6)
.014±.000(1)
.014±.000(4)
.014±.000(3)

ranking loss↓
.216±.005(4)
.184±.005(3)
.522±.007(5)
.545±.015(6)
.180±.004(2)
.178±.004(1)
.073±.041(5)
.048±.008(4)
.287±.026(6)
.017±.005(1)
.032±.006(3)
.019±.006(2)
.136±.010(4)
.096±.004(3)
.554±.027(6)
.205±.008(5)
.085±.003(2)
.083±.003(1)
.280±.010(5)
.135±.002(3)
.803±.012(6)
.275±.004(4)
.112±.003(1)
.116±.003(2)
.114±.007(3)
.218±.004(5)
.707±.003(6)
.120±.003(4)
.071±.002(2)
.058±.001(1)

avg. precision↑
.470±.008(4)
.491±.007(3)
.337±.004(5)
.147±.004(6)
.499±.008(2)
.501±.008(1)
.416±.100(6)
.788±.017(4)
.692±.025(5)
.881±.018(2)
.829±.018(3)
.893±.017(1)
.539±.086(4)
.624±.014(3)
.399±.021(6)
.520±.008(5)
.672±.010(2)
.672±.010(1)
.077±.013(6)
.245±.004(2)
.100±.005(5)
.105±.004(4)
.289±.006(1)
.227±.005(3)
.528±.012(2)
.339±.006(5)
.210±.004(6)
.494±.008(4)
.527±.008(3)
.570±.004(1)

one-error↓
.212±.025(5)
.106±.023(3)
.000±.000(1)
.971±.022(6)
.105±.023(2)
.122±.035(4)
.804±.029(6)
.266±.025(5)
.217±.025(3)
.170±.028(2)
.217±.026(4)
.147±.027(1)
.533±.263(6)
.310±.022(4)
.246±.041(2)
.344±.013(5)
.233±.017(1)
.253±.022(3)
.962±.004(6)
.736±.009(3)
.516±.030(1)
.897±.006(5)
.710±.010(2)
.791±.008(4)
.428±.014(2)
.599±.007(6)
.492±.010(5)
.469±.016(4)
.433±.013(3)
.390±.008(1)

coverage↓
143.025±2.319(4)
129.789±2.426(2)
166.481±0.906(6)
162.652±1.539(5)
129.993±2.491(3)
129.323±2.672(1)
3.697±1.752(5)
3.034±0.411(4)
6.581±0.714(6)
1.248±0.279(1)
2.237±0.378(3)
1.423±0.350(2)
16.834±0.669(4)
13.615±0.423(3)
31.645±0.764(6)
23.679±0.804(5)
12.324±0.444(2)
11.880±0.255(1)
207.643±3.477(5)
114.727±1.658(3)
320.449±2.173(6)
172.120±2.183(4)
99.629±2.136(2)
94.253±2.109(1)
32.758±1.929(4)
56.259±1.260(5)
85.281±0.701(6)
32.403±0.640(3)
20.425±0.422(2)
17.447±0.357(1)

instance-F1↑
.354±.009(5)
.321±.010(6)
.454±.006(3)
.386±.010(4)
.473±.004(2)
.475±.006(1)
.766±.022(1)
.564±.033(5)
.636±.025(4)
.444±.090(6)
.641±.030(3)
.706±.019(2)
.482±.009(3)
.409±.022(5)
.428±.022(4)
.404±.053(6)
.565±.011(1)
.562±.010(2)
.139±.005(4)
.017±.002(6)
.150±.008(3)
.058±.003(5)
.214±.004(1)
.152±.005(2)
.399±.009(1)
.160±.007(6)
.223±.008(5)
.392±.005(2)
.386±.007(4)
.390±.007(3)

instance-AUC↑
.784±.005(4)
.816±.005(3)
.662±.006(5)
.455±.015(6)
.820±.004(2)
.822±.004(1)
.927±.040(5)
.953±.007(4)
.882±.013(6)
.983±.005(1)
.968±.006(3)
.981±.006(2)
.866±.010(4)
.904±.004(3)
.669±.014(6)
.796±.008(5)
.916±.003(2)
.918±.003(1)
.720±.010(5)
.865±.002(3)
.416±.012(6)
.725±.004(4)
.888±.003(1)
.884±.003(2)
.886±.007(3)
.782±.004(5)
.618±.003(6)
.880±.003(4)
.929±.002(2)
.942±.001(1)

macro-F1↑
.097±.006(5)
.053±.002(6)
.183±.005(3)
.302±.008(1)
.126±.003(4)
.288±.006(2)
.384±.040(3)
.190±.015(6)
.216±.018(4)
.448±.024(2)
.207±.012(5)
.464±.024(1)
.187±.015(3)
.083±.008(6)
.118±.012(5)
.310±.018(1)
.137±.005(4)
.278±.017(2)
.044±.003(4)
.009±.001(6)
.029±.002(5)
.118±.003(1)
.050±.002(3)
.117±.004(2)
.318±.016(3)
.066±.006(6)
.130±.007(5)
.323±.005(2)
.232±.004(4)
.326±.006(1)

macro-AUC↑
.544±.012(2)
.523±.009(3)
.518±.013(5)
.566±.011(1)
.510±.011(6)
.523±.011(4)
.877±.038(3)
.797±.029(5)
.650±.027(6)
.901±.032(1)
.859±.035(4)
.896±.029(2)
.631±.025(5)
.633±.022(4)
.553±.015(6)
.717±.015(1)
.644±.019(3)
.663±.021(2)
.605±.004(4)
.540±.007(5)
.516±.006(6)
.706±.006(1)
.658±.006(3)
.692±.007(2)
.866±.007(4)
.661±.007(5)
.575±.003(6)
.921±.002(2)
.911±.002(3)
.924±.002(1)

micro-F1↑
.357±.011(5)
.318±.010(6)
.457±.006(3)
.389±.010(4)
.477±.004(2)
.479±.006(1)
.792±.020(1)
.654±.028(4)
.605±.027(5)
.439±.087(6)
.702±.020(3)
.757±.012(2)
.473±.008(3)
.461±.017(4)
.437±.016(5)
.414±.056(6)
.591±.008(2)
.596±.006(1)
.158±.006(3)
.027±.003(6)
.146±.011(4)
.057±.002(5)
.236±.004(1)
.177±.005(2)
.419±.012(3)
.211±.007(5)
.185±.007(6)
.438±.006(1)
.405±.007(4)
.435±.004(2)

micro-AUC ↑
.779±.006(4)
.813±.004(3)
.661±.006(5)
.458±.014(6)
.815±.004(2)
.816±.004(1)
.910±.039(5)
.949±.008(4)
.875±.014(6)
.979±.005(1)
.960±.007(3)
.977±.006(2)
.814±.008(4)
.898±.003(1)
.654±.011(6)
.810±.006(5)
.897±.003(2)
.896±.004(3)
.706±.009(5)
.866±.002(3)
.411±.013(6)
.725±.004(4)
.882±.002(1)
.881±.003(2)
.869±.007(4)
.776±.005(5)
.626±.003(6)
.877±.003(3)
.917±.002(2)
.938±.002(1)

Table B.3: Experimental results on eleven multi-label performance measures. For each performance measure, “↓” indicates “the smaller the better” and “↑” indicates
“the larger the better”. The results are shown in mean±std(rank). The smaller the rank, the better the performance.

