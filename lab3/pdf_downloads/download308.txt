StingyCD

A. Proof of Theorem 2.1
Theorem 2.1 (Safeness of StingyCD). In Algorithm 2, every skipped update would, if computed, result in δ = 0. That is,
(t−1)
if q (t−1) ≤ τi and xi
= 0, then
)
(



Ai , b − Ax(t−1) − λ
(t−1)
= 0.
max −xi
,
2
kAi k
(t−1)

Proof. Since xi

= 0, we need to prove that if q (t−1) ≤ τi , then
E
D
Ai , r(t−1) − λ ≤ 0,

(3)

where we have used the definition r(t−1) = b − Ax(t−1) .

2
We show by induction that q (t) = rr − r(t)  . The base case is that q (t−1) = 0 whenever StingyCD performs the update
rr ← r(t−1) . The inductive step is that
D
E
2
q (t) = q (t−1) − 2δ Ai , r(t−1) − rr + δ 2 kAi k
(4)

2
D
E


2
= r(t−1) − rr − 2δ Ai , r(t−1) − rr + δ 2 kAi k
(5)

2


(6)
= r(t−1) − δAi − rr

2


(7)
= r(t) − rr .
g2

Recall the definition τi = sign (gi ) kAi k2 , where gi = − hAi , rri + λ. It follows that
i

q (t−1) ≤ τi

⇒
⇒
⇒
⇒
⇒


2
gi2
 (t−1)

− rr ≤ sign (gi )
r
2
kAi k


gi
 (t−1)

− rr ≤
r
kAi k


 (t−1)

kAi k r
− rr ≤ − hAi , rri + λ




hAi , rri + kAi k r(t−1) − rr − λ ≤ 0
D
E
Ai , r(t−1) − λ ≤ 0 .

(8)
(9)
(10)
(11)
(12)

B. Proof of Theorem 2.2
Theorem 2.2 (Per iteration time complexity of StingyCD). Algorithm 2 can be implemented so that iteration t requires
(t−1)

• Less time than an identical iteration of Algorithm 1 if q (t−1) ≤ τi and xi
= 0 (the update is skipped) and rr is
not updated. Specifically, StingyCD requires O(1) time, while CD requires O(NNZ (Ai )) time.
• The same amount of time (up to an O(1) term) as a CD iteration if the update is not skipped and rr is not updated.
In particular, both algorithms require the same number of O(NNZ (Ai )) operations.
• More time than a CD iteration if rr is updated. In this case, StingyCD requires O(NNZ (A)) time.
Proof. Note that at each iteration, CD computes a dot product of length NNZ (Ai ) to compute δ. If δ 6= 0, an additional
O(NNZ (Ai )) operation is required to update r(t) .

StingyCD

Case 1: the update is skipped and rr is not updated In this case, the only computation StingyCD performs during this
iteration is (i.) deciding not to update the reference vector, (ii.) choosing a coordinate to update, and (iii.) checking whether
(t−1)
q (t−1) ≤ τi and xi
= 0. Steps (i.) and (ii.) can be easily be defined so that they require O(1) time, and checking the
conditions for (iii.) also requires constant time.
Case 2: the update is not skipped and rr is not updated In this case, the only additional operation that we have not
already considered
is the update to q (t) . This update can be performed in constant time by caching previous computations
of




2
(t−1)
hAi , rri, Ai , r
, and kAi k . The value of hAi , rri was computed when computing the threshold τi , and Ai , r(t−1)
2
and kAi k are necessary to compute δ.
Case 3: rr is updated In this case, computing τi for all i requires computing hAi , rri for all columns in A. This is a
matrix-vector multiply that requires O(NNZ (Ai )) operations.

C. Proof of Theorem 3.2
(t−1)

Theorem 3.2 (Equation for P (U (t) )). Assume xi
(
P (U (t) ) =

1−

= 0 and τi ∈ (−q (t−1) , q (t−1) ). Then Assumption 3.1 implies

1
n−1
2 I(1−τi /q (t−1) ) ( 2 ,
n−1
1
2 I(1+τi /q (t−1) ) ( 2 ,

1
2)
1
2)

if τi ≥ 0,
otherwise,

where Ix (a, b) is the regularized incomplete beta function.
Proof. Recall the illustration form Figure 2:

Because we assume r(t−1) is uniformly distributed on the boundary of S (t) , the probability that r(t−1) ∈ Ai is given by
dividing the area of Ai ∩ bd(S (t) ) by the area of bd(S (t) ). The region Ai ∩ bd(S (t) ) is a hyperspherical cap. In the case
that rr ∈
/ Ai , we know from (Li, 2011) that the area of Ai ∩ bd(S (t) ) is given by
(t)
1
1
)Isin(θ)2 ( n−1
2 area(S
2 , 2) ,

(13)

where area(S (t) ) is the surface area of S (t) and θ is the angle indicated in the diagram.
When τi ≥ 0, note that by definition of τi , we have rr ∈
/ Ai . It follows then that when τi ≥ 0, we have
P (Ut ) =

1
1
(t)
)Isin(θ)2 ( n−1
2 area(S
2 , 2)
area(S (t) )

1
= 12 I(1−cos(θ)2 ) ( n−1
2 , 2)

=

1
n−1 1
2 I(1−τi /q (t−1) ) ( 2 , 2 ) .

(14)
(15)
(16)

In the case that τi < 0, we have rr ∈ Ai , and we can use symmetry to see that
1
P (Ut ) = 1 − 12 I(1+τi /q(t−1) ) ( n−1
2 , 2) .

(17)

StingyCD

D. Details of estimating P (U (t) ) in StingyCD+
In §3.1, we defined the probability P (U (t) ). Assuming τi ∈ (−q (t−1) , q (t−1) ), we have
(
n−1 1
1
2 I(1−τi /q (t−1) ) ( 2 , 2 ) if τi ≥ 0,
(t)
P (U ) =
1
1 − 12 I(1+τi /q(t−1) ) ( n−1
2 , 2 ) otherwise,

(18)

where Ix (a, b) is the regularized incomplete beta function.
In our implementation of StingyCD+, we compute P (U (t) ) approximately using a lookup table. First, we make use of the
approximation
q

1
n−1 1
(t−1) .
I
(
,
)
≈
1
−
Φ
τ
(n
−
1)/q
(19)
(t−1)
i
)
2 (1−τi /q
2
2
Above, Φ is the standard normal CDF.
Using (19) is not strictly necessary. Using (19) leads to a simpler implementation, however, since we no longer need to
compute the regularized incomplete beta function. Instead we only need to define a lookup table for the standard normal
CDF. We expect this approximation has negligible effect on StingyCD+, since (19) is a very close approximation for
moderately large n.
√
are spaced
Using (19), our StingyCD+ implementation uses a lookup table of 128 values for 1 − Φ( x).
√ Values of x √
uniformly
between
0
and
32
inclusive,
meaning
the
table
stores
the
values
1
−
Φ(0),
1
−
Φ(
0.25),
1
−
Φ(
0.5), . . .,
√
1 − Φ( 32).
To estimate P (U (t) ) during each iteration, StingyCD+ first computes τi (n−1)/q (t−1) and then reads the closest value from
(t)
the table that
). For example, if τi (n − 1)/q (t−1) = 0.2, our approximation
of P (U (t) )
√ results in an upper bound for P (U
√
(t−1)
(t)
is 1 − Φ( 0.25) = 0.308 . . .. If τi (n − 1)/q
= −0.2, then our approximation of P (U ) is Φ( 0.5) = 0.760 . . ..

E. Proof of Theorem 3.3

Theorem 3.3 (StingyCD+ converges to a solution of (P)). In StingyCD+, assume ξ (t) ≤ NNZ x(t−1) for all t > 0.
Also, for each i ∈ [m], assume the largest number of consecutive iterations during which get next coordinate() does
not return i is bounded as t → ∞. Then
lim f (x(t) ) = f (x? ) .
t→∞

Before proving the theorem, we introduce and prove a few lemmas.
Lemma E.1. Given the assumptions of Theorem 3.3, let M be a number larger than the maximum number of consecutive
iterations get next coordinate() does not return coordinate i for all i ∈ [m] as t → ∞. Consider any iteration t > 0 of
(t−1)
StingyCD+ and any i ∈ [m] such that xi
6= 0. Then there exists an iteration t0 ≥ t during which StingyCD+ computes
an update to coordinate i. Furthermore, we have t0 ≤ t + mM .
Proof. Define C (t−1) as the set of coordinates that correspond to nonzero entries in x(t−1) :
(t−1)

C (t−1) = {i : xi

6= 0}.

(20)

(t)

Let idelayed denote the unique coordinate in C (t−1) such that the delay Di is largest:
(t)

idelayed = argmax Di .

(21)

i∈C (t−1)

This coordinate is unique because tlast
differs for all i ∈ C (t−1) —StingyCD+ updates at most one coordinate during each
i
iteration.


(t)
We must have Didelayed ≥ NNZ x(t−1) , since the NNZ x(t−1) − 1 coordinates in C (t−1) not equal to idelayed were
updated before idelayed was last updated (otherwise (21) would not hold). Thus, counting these updates, as well as the

(t)
(t−1)
update to weight idelayed during iteration tlast
.
idelayed , we must have Didelayed ≥ NNZ x

StingyCD

Now let k ≥ 0 be the smallest such k for which get next coordinate() returns idelayed during iteration t + k. Note that

(t+k)
(t)
k < M . We must have Didelayed ≥ NNZ x(t+k−1) , since (i) until an update for coordinate i is computed, Di is nonde




0
0
(t)
creasing with t for all i, (ii) we have Didelayed ≥ NNZ x(t−1) , and (iii) whenever NNZ x(t ) = NNZ x(t −1) + 1
(t0 +1)

(t0 )

for t0 ∈ {t, t + 1, . . . , t + k − 1}, we must also have Didelayed = Didelayed + 1—an update to a zero entry of x increases
the delay for all coordinates by 1.
(t+k−1)

In addition, since idelayed ∈ C (t−1) and idelayed has not been updated since before iteration t, we must have xidelayed 6= 0.

Thus, by definition of P (U (t+k) ), we must have P (U (t+k) ) = 1. Applying the assumption that ξ (t+k) ≤ NNZ x(t+k−1) ,
it follows that


(t+k)
(t+k)
P (U (t+k) )Didelayed = Didelayed ≥ NNZ x(t+k)−1 ≥ ξ (t+k) .
(22)
Thus, the condition for skipping update t + k in StingyCD+ is not satisfied. That is, during iteration t + k, StingyCD+
(t+k+1)
computes an update to coordinate idelayed . It follows that Didelayed = 1. That is, idelayed now corresponds to the weight
with smallest delay among nonzero weights.
(t−1)

Now consider any i such that xi
6= 0. This coordinate was last updated during iteration tlast
i . It follows that if
+ (m − 1)M , then i corresponds to the weight with largest delay among
coordinate i is not updated by iteration tlast
i
nonzero weights. This is because we have shown that the nonzero weight with maximum delay is updated within M
iterations, after which it becomes the nonzero weight with smallest delay. Thus, before coordinate i is updated again, at
most (m − 1) other coordinates correspond to the nonzero weight with largest delay, each of which requires at most M
iterations to update. It follows that after an additional M iterations—that is, by iteration tlast
+ mM —coordinate i must
i
be updated.
Lemma E.2. Given the assumptions of Theorem 3.3, then for some set F, StingyCD+ converges to a solution of the
problem
2
minimize
f (x) := 12 kAx − bk + λ h1, xi
x∈Rm
(P’)
s.t.
x≥0
xi = 0 ∀i ∈ F
.
Proof. First note that f (x(t) ) is nonincreasing with t. This is because whenever x(t) 6= x(t−1) , we can write
x(t) = x(t−1) + δei

(23)

for some coordinate i, where
δ=

argmin
(t−1)

δ 0 : xi

(t−1)

f (x



0

+ δ ei ) = max

+δ 0 ≥0

(t−1)
i−λ
(t−1) hAi ,b−Ax
−xi
,
kAi k2


.

(24)

Second, note that for all t, x(t) ≥ 0. From the definition of f , it follows that f (x(t) ) ≥ 0 for all t.
Thus, f (x(t) ) is a bounded monotone sequence, which implies that lim f (x(t) ) exists.
t→∞

(t)

Now let us assume that x does not converge to a solution of (P’) for some set F. Then there exists a value ν > 0 for
(t−1)
which the following holds: for all t0 > 0, there exists an iteration t > t0 such that for some i where xi
6= 0, we have

)
(




Ai , r(t−1) − λ 

(t−1)
(25)
|δ| = max −xi
,
≥ν.
2


kAi k
In other words, if StingyCD+ updated coordinate i (corresponding to a nonzero weight) during iteration t, the magnitude
of the update would be at least positive value ν.
Also, note that after any update δ to a coordinate i during iteration t of StingyCD+, we have (by Taylor expansion)

D
E
2
f (x(t) ) − f (x(t−1) ) = λ − Ai , r(t−1) δ + 12 kAi k δ 2
2

≤ − 21 kAi k δ 2 .

(26)
(27)

StingyCD
0
Now define fˆ = lim f (x(t) ). Consider an iteration t0 such that f (x(t ) ) ≤ fˆ + , where we define  > 0 later.

t→∞

(t−1)

According to (25), there exists an iteration t > t0 such that for some i for which xi

(
)




Ai , r(t−1) − λ 

(t−1)
,
max −xi
≥ν.
2


kAi k

> 0, we have
(28)

According to Lemma E.1, StingyCD+ will compute at least one update to coordinate i between iterations t and t + mM .
During each of the iterations between iteration t and t + mM , suppose that coordinate i0 is updated by an amount δ 0 . It
must be the case then that
√
2
0
δ ≤
.
(29)
kAi0 k
Otherwise the fact that fˆ = lim f (x(t) ) would be violated due to (27).
t→∞

Now let T denote the iteration during which coordinate i is next updated. From the triangle inequality and (29), it follows
that


√
 (t−1)

(30)
− r(T −1)  ≤ mM 2 .
r
This implies that



Ai , r(T −1)
2

kAi k





−

Ai , r(t−1)
2

kAi k



h
√
√ i
2
mM 2
∈ − mM
.
,
+
kAi k
kAi k

Now let δ be the update to coordinate i during iteration T . It follows that

(
)




Ai , r(T −1) − λ 

(T −1)
|δ| = max xi
,

2


kAi k

(
)



√

Ai , r(t−1) − λ  mM 2

(t−1)
,
≥ max xi
−
2


kAi k
kAi k
√
mM 2
≥ν−
.
kAi k
Now let us define s =

min

i0 : kAi0 k>0

(31)

(32)

(33)
(34)

kAi0 k.
=

1
8

 νs 2
mM

(35)

Then it follows that
|δ| > 21 ν .

(36)

From (27), it follows that
f (x(T ) ) ≤ f (x(T −1) ) −

1
2

2

kAi k δ 2 ≤ fˆ +  − 12 s2 ν 2 < fˆ ,

which violates the assumption that lim f (x(t) ) = fˆ .
t→∞

Thus, StingyCD+ must converge to a solution of (P’) for some set F.

Proof of Theorem 3.3. Suppose that StingyCD+ does not converge to a solution to (P).
Now define fˆ = lim f (x(t) ). Also define r̂ = lim r(t) and x̂ = lim x(t) .
t→∞

t→∞

t→∞

(37)

StingyCD

Lemma E.2 guarantees that the algorithm at least converges to a solution of (P’) for some set F. Using this assumption, if
StingyCD+ does not converge to (P)’s solution then there exists a ν > 0 such that for some i such that x̂i 6= 0, we have
hAi , r̂i − λ ≥ ν .

(38)

0
Consider an iteration t0 such that f (x(t −1) ) ≤ fˆ + , where we define  > 0 later. By Taylor expansion, we have for any
t ≥ t0 ,

D
E
f (x(t) ) = f (x̂) + ∇f (x̂), x(t) − x̂ +

2


≥ fˆ + 12 r̂ − r(t−1)  .
This implies that for any t ≥ t0 , we have

Define  =

i0

ν2
2.
8kA
i0 k
: kAi0 k6=0

min

1
2

2


 (t)
Ax − Ax̂

(39)
(40)


 √


r̂ − r(t−1)  ≤ 2 .

(41)

It follows then that for all t ≥ t0 ,

D
E
√
√
Ai , r(t−1) − λ ≥ hAi , r̂i − kAi k 2 − λ ≥ ν − kAi k 2 ≥ 21 ν .

(42)

Also, if we assume − hAi , rri + λ > 0, we must have
2

τi =

(− hAi , rri + λ)

≤

(43)

2

kAi k


2



− Ai , r(t−1) + λ + kAi k r(t−1) − rr
2

kAi k

≤ (q (t−1) − 12 ν)2
<q

(t−1)

(44)
(45)

.

(46)

Otherwise, we must have − hAi , rri + λ < 0, which ensures τi ≤ 0 ≤ q (t−1) . In addition, q (t−1) is bounded as t → ∞
due to (41). As a result, whenever i is returned by get next coordinate() during an iteration t > t0 , then P (U (t) ) is
(t)
bounded away from zero. As t → ∞, the delay Di increases as, at a minimum, nonzero-valued coorinates are updated.
Thus, for an eventual iteration T , we have
(t)

P (U (t) )Di ≥ ξ (t) .

(47)

At this point, an update to coordinate i is computed. From (42), it follows that
δ≥

1
2

ν
kAi k

,

2

(48)

which ensures that
f (x(T ) ) ≤ f (x(T −1) ) −
≤ f (x̂) +  −
≤ f (x̂) −

1
2

2

kAi k δ 2
2

1 ν
2 kAi k2
2

3 ν
8 kAi k2

.

(49)
(50)
(51)

This contradicts the definition of x̂. Thus, our assumption that x(t) does not converge to a solution of (P ) is incorrect.

StingyCD

F. Generalizing StingyCD to Linear SVMs
In this section, we briefly describe how to apply StingyCD to the problem
minimize
n
x∈R

s.t.

1
2

2

kMxk − h1, xi

x ∈ [0, C]n

.

(PSVM)

We note that (PSVM) is very similar to (P). If not for the constraint that x ≤ C1, in fact, (PSVM) would be an instance of
(P)—we could solve (PSVM) by defining A = M, b = 0, and λ = −1 and then running Algorithm 2.
To incorporate the new constraint, our CD update becomes
n
o
(t−1)
δSVM = min C − xi
,δ .
In this case, StingyCD’s same rule applies for guaranteeing coordinate i remains 0 during iteration t. With a minor change,
(t−1)
(t−1)
we can also check if xi
is guaranteed to remain C during iteration t. Specifically, if xi
= C and q (t−1) ≤ −τi ,
then it is guaranteed that δSVM = 0.

StingyCD

G. Additional comparisons for Lasso problems
This section contains results using additional values of λ for the experiments in §6.1. In general, we find the results to be
quite consistent, regardless of λ. Only “CD + Safe Screening” seems to be greatly affected by this parameter.
G.1. Full results for finance dataset
Number of examples: 1.6 × 104 . Number of features: 5.5 × 105 .

0.5

1.0

1.5

1.00

1.00

0.95

0.95

Support set recall

10
10−2
10−3
10−4
10−5
10−6
10−7
10−8
10−9
0.0

Support set precision

Relative suboptimality

finance, λ = 0.1λmax , kx? k0 = 375
−1

0.90
0.85
0.80
0.75
0.0

2.0

0.2

Time (min)

0.4

0.6

0.8

0.90
0.85
0.80
0.75
0.70
0.0

1.0

0.2

Time (min)

0.4

0.6

0.8

1.0

2.0

2.5

Time (min)

0

1

2

3

4

1.00

1.00

0.95

0.95

Support set recall

Support set precision

Relative suboptimality

finance, λ = 0.05λmax , kx? k0 = 1746
10−1
10−2
10−3
10−4
10−5
10−6
10−7
10−8
10−9

0.90
0.85
0.80
0.75
0.0

5

0.5

Time (min)

1.0

1.5

2.0

0.90
0.85
0.80
0.75
0.70
0.0

2.5

0.5

Time (min)

1.0

1.5

Time (min)

0

2

4

6

8

1.00

1.00

0.95

0.95

0.90
0.85
0.80
0.75

10 12 14 16

Support set recall

10
10−2
10−3
10−4
10−5
10−6
10−7
10−8
10−9

Support set precision

Relative suboptimality

finance, λ = 0.02λmax , kx? k0 = 6591
−1

0

1

2

Time (min)

3

4

5

6

7

0.90
0.85
0.80
0.75
0.70

8

0

1

2

Time (min)

3

4

5

6

7

8

Time (min)

0

10

20

30

40

50

1.00

1.00

0.95

0.95

Support set recall

Support set precision

Relative suboptimality

finance, λ = 0.01λmax , kx? k0 = 10276
10−1
10−2
10−3
10−4
10−5
10−6
10−7
10−8
10−9

0.90
0.85
0.80
0.75

0

5

Time (min)

10

15

20

25

0.90
0.85
0.80
0.75
0.70

0

Time (min)
StingyCD+

StingyCD

CD + Safe Screening

5

10

15

Time (min)
CD

20

25

StingyCD

G.2. Full results for allstate dataset
Number of examples: 2.5 × 105 . Number of features: 1.5 × 104 .

0

1.00

1.00

0.95

0.95

0.90
0.85
0.80
0.75

5 10 15 20 25 30 35 40 45

Support set recall

10
10−2
10−3
10−4
10−5
10−6
10−7
10−8
10−9

Support set precision

Relative suboptimality

allstate, λ = 0.1λmax , kx? k0 = 176
−1

0

5

10

Time (s)

15

0.90
0.85
0.80
0.75
0.70

20

0

5

10

Time (s)

15

20

Time (s)

0

10

20

30

40

1.00

1.00

0.95

0.95

0.90
0.85
0.80
0.75

50

Support set recall

10
10−2
10−3
10−4
10−5
10−6
10−7
10−8
10−9

Support set precision

Relative suboptimality

allstate, λ = 0.05λmax , kx? k0 = 1404
−1

0

5

10

Time (s)

15

20

0.90
0.85
0.80
0.75
0.70

25

0

5

10

Time (s)

15

20

25

Time (s)

0

20

40

60

1.00

1.00

0.95

0.95

0.90
0.85
0.80
0.75

80 100 120 140

Support set recall

10
10−2
10−3
10−4
10−5
10−6
10−7
10−8
10−9

Support set precision

Relative suboptimality

allstate, λ = 0.02λmax , kx? k0 = 4821
−1

0

10

20

Time (s)

30

40

50

60

0.90
0.85
0.80
0.75
0.70

70

0

10

20

Time (s)

30

40

50

60

70

Time (s)

0

50

100

150

200

250

1.00

1.00

0.95

0.95

Support set recall

10
10−2
10−3
10−4
10−5
10−6
10−7
10−8
10−9

Support set precision

Relative suboptimality

allstate, λ = 0.01λmax , kx? k0 = 6828
−1

0.90
0.85
0.80
0.75

0

20

40

Time (s)

60

80

100

120

0.90
0.85
0.80
0.75
0.70

0

Time (s)
StingyCD+

StingyCD

CD + Safe Screening

20

40

60

80

Time (s)
CD

100

120

StingyCD

H. Additional comparisons for logistic regression problems
H.1. Full results for lending club dataset
Number of examples: 1.1 × 105 . Number of features: 3.1 × 104 .

10−2
10

−3

10−4
10−5
0

2

4

6

8

10

12

1.00

1.00

0.95

0.95

0.90
0.85
0.80
0.75
0.70

14

Support set recall

Support set precision

Relative suboptimality

lending club, λ = 0.05λmax , kx? k0 = 272

0

2

4

6

Time (s)

8

10

12

0.90
0.85
0.80
0.75
0.70

14

0

2

4

6

Time (s)

8

10

12

20

25

14

Time (s)

10−2
10−3
10−4
10−5
0

5

10

15

20

25

1.00

1.00

0.95

0.95

0.90
0.85
0.80
0.75
0.70

30

Support set recall

Support set precision

Relative suboptimality

lending club, λ = 0.02λmax , kx? k0 = 878

0

5

Time (s)

10

15

20

25

0.90
0.85
0.80
0.75
0.70

30

0

5

10

Time (s)

15

30

Time (s)

10−2
10

−3

10−4
10−5

1.00

1.00

0.95

0.95

0.90
0.85
0.80
0.75
0.70

0 10 20 30 40 50 60 70 80 90

Support set recall

Support set precision

Relative suboptimality

lending club, λ = 0.01λmax , kx? k0 = 1937

0

0.85
0.80
0.75
0.70

10 20 30 40 50 60 70 80 90

Time (s)

0.90

0

10 20 30 40 50 60 70 80 90

Time (s)

Time (s)

10−2
10

−3

10−4
10

−5

0

50

100

150

200

250

Time (s)
StingyCD+ ProxNewton with Working Sets

1.00

1.00

0.95

0.95

Support set recall

Support set precision

Relative suboptimality

lending club, λ = 0.005λmax , kx? k0 = 3780

0.90
0.85
0.80
0.75
0.70

0

50

100

150

200

250

0.90
0.85
0.80
0.75
0.70

0

50

Time (s)
CD ProxNewton with Working Sets

100

150

200

250

Time (s)
StingyCD+ ProxNewton

CD ProxNewton

StingyCD

H.2. Full results for kdda dataset

kdda, λ = 0.02λmax , kx? k0 = 195

10−3
10

−4

10−5

1.00

1.00

0.95

0.95

Support set recall

10−2

Support set precision

Relative suboptimality

Number of examples: 8.4 × 106 . Number of features: 2.2 × 106 .

0.90
0.85
0.80
0.75
0.70
0.0 0.5 1.0 1.5 2.0 2.5 3.0 3.5 4.0

0.0 0.5 1.0 1.5 2.0 2.5 3.0 3.5 4.0

−4

10−5
0

1

2

3

4

1.00

0.95

0.95

0.90
0.85
0.80
0.75
0.70

5

0

1

2

4

0.85
0.80
0.75
0.70

5

0

1

2

3

4

5

Time (min)

kdda, λ = 0.005λmax , kx? k0 = 692

10−3
−4

10−5
1

2

3

4

5

6

7

1.00

1.00

0.95

0.95

0.90
0.85
0.80
0.75
0.70

8

Support set recall

Support set precision

Relative suboptimality

3

0.90

Time (min)

10−2

0

0

1

2

Time (min)

3

4

5

6

7

0.90
0.85
0.80
0.75
0.70

8

0

1

2

Time (min)

3

4

5

6

7

8

Time (min)

kdda, λ = 0.002λmax , kx? k0 = 1616

10−3
10−4
10−5
0

2

4

6

8

10

12

14

Time (min)
StingyCD+ ProxNewton with Working Sets

1.00

1.00

0.95

0.95

Support set recall

10−2

Support set precision

Relative suboptimality

Time (min)

1.00

Time (min)

10

0.75

kdda, λ = 0.01λmax , kx? k0 = 383

−2

10−3
10

0.80

0.70
0.0 0.5 1.0 1.5 2.0 2.5 3.0 3.5 4.0

Support set recall

10

0.85

Time (min)

Support set precision

Relative suboptimality

Time (min)

0.90

0.90
0.85
0.80
0.75
0.70

0

2

4

6

8

10

12

14

0.90
0.85
0.80
0.75
0.70

0

2

4

Time (min)
CD ProxNewton with Working Sets

6

8

10

12

14

Time (min)
StingyCD+ ProxNewton

CD ProxNewton

