Appendix for
“On Mixed Memberships and Symmetric Nonnegative Matrix Factorizations”

Xueyu Mao 1 Purnamrita Sarkar 2 Deepayan Chakrabarti 3

A. Identifiability
Lemma A.1. (Lemma 1.1 of (Minc, 1988)) The inverse of a nonnegative matrix matrix M is nonnegative if and only if
M is a generalized permutation matrix.
Proof of Theorem 2.1. Suppose there are two parameter settings (Θ(1) , B(1) , ρ(1) ) and (Θ(2) , B(2) , ρ(2) ) that yield the
same probability matrix:
T

T

P = ρ(1) Θ(1) B(1) Θ(1) = ρ(2) Θ(2) B(2) Θ(2) .
(1)

(2)

Pick up pure node indices set I1 of Θ(1) such that ΘI1 = I, and denote M = ΘI1 . Similarly, pick up pure node indices
(2)

(1)

set I2 of Θ(2) such that ΘI2 = I, and let W = ΘI2 .
Then
ρ(1) B(1) = ρ(2) MB(2) MT and ρ(1) WB(1) WT = ρ(2) B(2) .
Denote T = MW, then
B(1) =
(2)

1
ρ(1)

Mρ(1) WB(1) WT MT = TB(1) TT .

(1)

(1)

Note that M · 1 = ΘI1 · 1 = 1 and W · 1 = ΘI2 · 1 = 1, so T · 1 = MW · 1 = 1. We can consider T as a transition
matrix of a Markov chain, whose states are the nodes of the graph. Keep applying equation (1) to its RHS, we get
T

B(1) = Tk B(1) Tk ,
which implies B(1) = T∞ B(1) TT∞ , where T∞ = lim Tk .
k→∞

(1)

Given that B has full rank K, we must have T∞ has full rank. Now we prove that stationary point of the Markov chain,
T∞ , must be identity matrix.
The nodes of a finite-size Markov chain can be split into a finite number of communication classes, and possibly some
transient nodes.
1. If a communication class has at least two nodes and is aperiodic, then the rows corresponding to those nodes in T∞
are the stationary distribution for that class. Hence, T∞ has identical rows, so it cannot be full rank.
2. The probability of a Markov chain ending in a transient node goes to zero as the number of iterations k grows, so the
column of T∞ corresponding to any transient node is identically zero. Again, this means that T∞ cannot be full rank.
1
Department of Computer Science. 2 Department of Statistics and Data Sciences. 3 Department of Information, Risk, and Operations
Management. The University of Texas at Austin, TX, USA. Correspondence to: Xueyu Mao <xmao@cs.utexas.edu>, Purnamrita
Sarkar <purna.sarkar@austin.utexas.edu>, Deepayan Chakrabarti <deepay@utexas.edu>.

Proceedings of the 34 th International Conference on Machine Learning, Sydney, Australia, PMLR 70, 2017. Copyright 2017 by the
author(s).

On Mixed Memberships and Symmetric Nonnegative Matrix Factorizations

Hence, the only configuration in which T∞ has full rank is when it contains K communication classes, each with one
node. This implies that T∞ = I, and hence T = I. Note that if the communication classes are periodic, we can consider
Tt where t is the product of the periods of all the classes; the matrix Tt is now aperiodic for all the communication classes,
and the above argument still applies to T∞ = lim (Tt )k .
k→∞

As I = T = MW, M and W have full rank, then M−1 = W, which is the case that a nonnegative matrix M has
nonnegative inverse W, using Lemma A.1, we know that M is a generalized permutation matrix, and note that each row
of M sums to 1, the scale goes away and thus M is a permutation matrix, which implies W is also a permutation matrix.
As largest element of B(1) and B(2) are equals as 1, we should have ρ(1) = ρ(2) and thus B(1) = MB(2) MT .
Also since we have
T

(1)

T

(2)

T

ρ(1) B(1) Θ(1) = ρ(1) ΘI1 B(1) Θ(1) = ρ(2) ΘI1 B(2) Θ(2) = ρ(2) MB(2) Θ(2)
T

T

T

= ρ(2) MB(2) MT MΘ(2) = ρ(1) B(1) MΘ(2) ,
left multiply ρ(1) B(1)

−1

on both sides, we have Θ(1) = Θ(2) MT .

Thus we have shown that MMSB is identifiable up to a permutation.

B. Uniqueness of SNMF for MMSB networks
Lemma B.1 (Huang et al. (2014)). If rank(P) = K, the Symmetric NMF P = WWT is unique if and only if the nonnegative orthant is the only self-dual simplicial cone A with K extreme rays that satisfies cone(WT ) ⊆ A = A∗ , where
A∗ is the dual cone of A, defined as A∗ = {y|xT y ≥ 0, ∀x ∈ A}.
Proof of Theorem 2.2. When B is diagonal, it has a square root C = B1/2 , where C is also a positive diagonal matrix. It
is easy to see that cone(C) is the non-negative orthant RK
+ , so we have
∗

K
cone(WT ) = cone(CT ΘT ) = cone(CT ) = cone(C) = RK
+ = R+ .

The second equality follows from the fact that Θ contains all pure nodes, and other nodes are convex combinations of these
pure nodes. The fourth equality is due to the diagonal form of C.
To see that this is unique, suppose there
is another self-dual simplicial cone satisfying cone(WT ) ⊆ A = A∗ . Then we

∗
K ∗
K
have RK
⊆
A
and
A
=
A
⊆
R
=
RK
+
+
+ , which implies A = R+ .
Hence, by Lemma B.1, an identifiable MMSB model with a diagonal B is sufficient for the Symmetric NMF solution to
be unique and correct.

C. Concentration of the Laplacian
We will use X = c(1 ± ) to denote X ∈ c[1 − , 1 + ] for ease of notation from now onwards.
Lemma C.1. For Θ ∈ Rn×K , where each row θi ∼ Dirichlet(α), ∀j ∈ [K],
s
!!
n
X
αj
α0 log n
θij = n
1 ± OP
α0
αj n
i=1
with probability larger than 1 − 1/n3 .
Proof. By using Chernoff bound
 n

!
!
α
X
2 n α0j
αj 
αj

θij − n  > n
P 
≤ exp −
,

α0 
α0
3
i=1

 q
 P
q
 n
αj 
αj
n
3
so by setting  = OP 3 nαlog
,
θ
−
n
≤
3


ij
i=1
α0
α0 n log n, with probability larger than 1 − 1/n .
j /α0

On Mixed Memberships and Symmetric Nonnegative Matrix Factorizations

That is
n
X

αj
± OP
θij = n
α0
i=1

r

αj
n log n
α0



αj
=n
α0

s
1 ± OP

α0 log n
αj n

!!
.

Lemma C.2. (Theorem 5.2 of (Lei et al., 2015)) Let A be the adjacency matrix of a random graph on n nodes in which
edges occur independently. Set E[A] = P and assume that n maxi,j Pij ≤ d for d ≥ c0 log n and c0 > 0. Then, for any
r > 0 there exists a constant C = C(r, c0 ) such that:
√
P(kA − Pk ≤ C d) ≥ 1 − n−r .
Fact C.1. If M is rank k, then kMk2F ≤ kkMk2 .
Lemma C.3. (Variant of Davis-Kahan (Yu et al., 2015)). Let P, Â ∈ Rn×n be symmetric, with eigenvalues λ1 ≥ · · · ≥ λn
and λ̂1 ≥ · · · ≥ λ̂n respectively. Fix 1 ≤ r ≤ s ≤ n, and assume that min(λr−1 − λr , λs − λs+1 ) > 0, where we define
λ0 = ∞ and λn+1 = −∞. Let d = s − r + 1, and let V = (vr , vr+1 , · · · , vs ) ∈ Rn×d and V̂ = (v̂r , v̂r+1 , · · · , v̂s ) ∈
Rn×d have orthonormal columns satisfying Pvj = λj vj and Âv̂j = λ̂j v̂j for j = r, r + 1, · · · , s. Then there exists an
orthogonal matrix Ô ∈ Rd×d such that

 
 


 



23/2 min d1/2 Â − P , Â − P


F
V̂ − VÔ ≤
min(λr−1 − λr , λs − λs+1 )
F
Lemma C.4. (Lemma A.1. of (Tang et al., 2013)). Let H1 , H2 ∈ Rn×n be positive semidefinite with rank(H1 ) =
rank(H2 ) = K. Let X, Y ∈ Rn×K be of full column rank such that XXT = H1 and YYT = H2 . Let λK (H2 )) be the
smallest nonzero eigenvalue of H2 . Then there exists an orthogonal matrix R ∈ RK×K such that:
p

p
√
K kH1 − H2 k
kH1 k + kH2 k
kXR − YkF ≤
.
λK (H2 )
Lemma C.5. Recall that Â1 = V̂1 Ê1 V̂1T and P1 = P(S, S) in Algorithm 1. If ρn = Ω(log n), then




p
√




Â1 − P1  = OP ( ρn), and Â1 − P1  = OP ( Kρn)
F

with probability larger than 1 − 1/n3 .
Proof. Lemma C.2 gives the spectral bound of binary symmetric random matrices, in our model,
n
n
n
n
n
max P1 (i, j) ≤ max P(i, j) = max ρθi BθjT ≤ max ρθi IθjT ≤ ρ .
2 i,j
2 i,j
2 i,j
2 i,j
2
Note that we need to use B is diagonal probability matrix and θi , i ∈ [ n2 ] has `1 norm 1 and all nonnegative elements for
the last two inequality.
Since ρn = Ω(log n), ∃c0 ≥ 0 that ρ n2 ≥ c0 log n2 .
Let d = ρ n2 , then d ≥

n
2

maxi,j P1 (i, j) and d ≥ c0 log n2 , by Lemma C.2, ∀r ≥ 0, ∃ C > 0 that

P kA1 − P1 k ≤ C

r
ρ

n
2



n
≥ 1 − ( )−r ,
2

√
where A1 = A(S, S). So kA1 − P1 k = OP ( ρn), specially, taking r = 3 then it is with probability larger than 1−1/n3 .
Hence

 
 

√
√

 
 

Â1 − P1  ≤ Â1 − A1 + A1 − P1  ≤ Â1 − A1  + kA1 − P1 k = σ̂K+1 + OP ( ρn) = OP ( ρn),

On Mixed Memberships and Symmetric Nonnegative Matrix Factorizations

√
where σ̂K+1 is the (K + 1)-th eigenvalue of A1 and is OP ( ρn) by Weyl’s inequality.
Since Â1 and P1 have rank K, then by Fact C.1,




p
√




Â1 − P1  ≤ 2K Â1 − P1  = OP ( Kρn).
F

T

n

Lemma C.6 (Concentration of degrees). Denote βmin = mina Baa . Let P = ρΘ(1) BΘ(2) , where ρ, B, Θ(1) ∈ R 2 ×K ,
n
and Θ(2) ∈ R 2 ×K follow the restrictions of MMSB model. Let D and D be diagonal matrices representing the sample
and population node degrees. Then
p
Dii = OP (ρn/K), Dii = Ω(βmin ρn/K), and |Dii − Dii | = OP ( ρn log n/K)
with probability larger than 1 − OP (1/n3 ).
Proof. ∀i ∈ [ n2 ], we have
Dii =

n/2
X

Pij =

n/2 K
X
X

j=1

=

ρn
2K

(2)

j=1 `=1
(1)
`=1 θi` αl

PK
= ρn

(1)

ρθi` B`` θj` ≤

α0
1 + OP

K
X

(1)

ρθi`

n/2
X

(2)

θj` = ρ

j=1

`=1

K
X

(1)

θi`

n/2
X

(2)

θj`

(maxa Baa = 1 by definition)

j=1

`=1

!!
r
1
α0 log n
+ OP
2
αl n
!!
r
K log n
,
n

(from Lemma C.1)
(when αk =

α0
K , ∀k

∈ [K])

so Dii = OP (ρn/K).
Similarly,
Dii ≥

K
X

(1)

βmin ρθi`

n/2
X

(2)

θj` = βmin ρ

j=1

`=1

1
+ OP
2

α0

βmin
=
ρn 1 + OP
2K

(1)

θi`

r

K log n
n

n/2
X

(2)

θj`

j=1

`=1

(1)
`=1 θi` αl

PK
= βmin ρn

K
X

r

α0 log n
αl n

!!
(from Lemma C.1)

!!
,

(when αl =

α0
K , ∀l)

so Dii = Ω(βmin ρn/K).
Then using Chernoff bound, we have
 2

 Dii
P (|Dii − Dii | > Dii ]) ≤ exp −
,
3
 q

p
log n
so when  = OP 3 K ρn
, |Dii − Dii | ≤ Dii = OP ( ρn log n/K) with probability at least 1 − 1/n3 . Note we
have used Lemma C.1, so in total it is with probability larger than 1 − OP (1/n3 ).

Lemma C.7. Denote βmin = mina Baa . If ρn = Ω(log n), then
λK (P1 ) = Ω(βmin ρn/K),

λ1 (P1 ) = OP (ρn/K)

λK (A1 ) = Ω(βmin ρn/K),

λ1 (A1 ) = OP (ρn/K)

and

2

3

with probability larger than 1 − OP (K /n ).

On Mixed Memberships and Symmetric Nonnegative Matrix Factorizations

Proof. For conciseness, we will omit the subscript 1 (see Lemma C.5) in the following proof without loss of generality.
The K-th eigenvalue of P is
λK (P) = λK (ρΘBΘT ) = λK (ρΘB1/2 B1/2 ΘT ) = λK (ρB1/2 ΘT ΘB1/2 ).
Here we consider θi as a random variable. Denote
n/2

M̂ =
then M̂ab =

1
n/2

√

βa βb

Pn/2
i=1

1
1 X
ρB1/2 ΘT ΘB1/2 =
ρB1/2 θiT θi B1/2 ,
n/2
n/2 i=1

ρθia θib .

Consider θi ∼ Dirichlet(α), then
E[θia · θib ] =
so E[M̂ab ] =

√

(
Cov[θia , θib ] + E[θia ] · E[θib ] =
2

Var[θia ] + E [θia ] =

αa αb
α0 (α0 +1) ,

αa (αa +1)
α0 (α0 +1) ,

if a 6= b
if a = b

βa βb ρE[θia · θib ] ≤ ρ. And
E[M̂] = ρ(diag(Bα) + B1/2 ααT B1/2 )/(α0 (α0 + 1)).

Using Chernoff bound, we have



2 n E[M̂ab ]


P M̂ab − E[M̂ab ] > E[M̂ab ] ≤ exp − 2
3
so when  = OP

q

18 log n
ρn

!

2 ρn
≤ exp −
6



,


 


, M̂ab − E[M̂ab ] ≤ E[M̂ab ] with probability larger than 1 − 1/n3 . Thus
q

 


 

M̂ − E[M̂] ≤ M̂ − E[M̂] ≤ K 2 2 E2 [M̂ab ] ≤ Kρ.
F

Note that
λK (E[M̂]) = ρλK (diag(Bα) + B1/2 ααT B1/2 )/(α0 (α0 + 1))


≥ ρ λK (diag(Bα)) + λK (B1/2 ααT B1/2 ) /(α0 (α0 + 1))


= ρ min βa αa + 0 /(α0 (α0 + 1))
a

mina βa αa
=ρ
α0 (α0 + 1)
βmin ρ
,
=
K(α0 + 1)

(when αa =

α0
K , ∀a)

the first inequality is by definition of the smallest eigenvalue and property of min function; the second equality is by the
smallest eigenvalue of a K × K rank-1 matrix (K > 1) is 0.
By Weyl’s inequality,

 


 

λK (M̂) − λK (E[M̂]) ≤ M̂ − E[M̂] = OP

r
K

ρ log n
n

!
,

so
n
n
λK (P) = λK (M̂) ≥
2
2

βmin ρ
− OP
K(α0 + 1)

r
K

ρ log n
n

!!

On Mixed Memberships and Symmetric Nonnegative Matrix Factorizations

with probability larger than 1 − K 2 /n3 , and thus λK (P) = Ω(βmin ρn/K).
With similar argument we can get


α0
kβk1 /(K(α0 + 1))
λ1 (E[M̂]) ≤ ρ 1 +
K
≤ ρ (1 + α0 ) /(K(α0 + 1))
ρ
= ,
K
then λ1 (P) = OP (ρn/K).
From Weyl’s inequality, we have
√
|λi (A) − λi (P)| ≤ kA − Pk = OP ( ρn) ,
so
√
λK (A) ≥ λK (P) − OP ( ρn) =⇒ λK (A) = Ω(βmin ρn/K)
√
λ1 (A) ≤ λK (P) + OP ( ρn) =⇒ λ1 (A) = OP (ρn/K) .

Lemma C.8. If ρn = Ω(log n), ∃ orthogonal matrix Ô1 ∈ RK×K ,




K 3/2


V̂1 − V1 Ô1  = OP
√
βmin ρn
F
with probability larger than 1 − OP (K 2 /n3 ).
Proof. From Lemma C.7 we know that
λK (P1 ) = Ω(βmin ρn/K)
with probability larger than 1 − OP (K 2 /n3 ). Because P1 has rank K, its K + 1 eigenvalue is 0, and the gap between
the K-th and (K + 1)-th eigenvalue of P1 is δ = Ω(βmin ρn/K). Using variant of Davis-Kahan’s theorem (Lemma C.3),
setting r = 1, s = K, then d = K is the interval corresponding to the first K principle eigenvalues of P1 , we have
∃ Ô1 ∈ RK×K ,
 
 
√ 

 



23/2 min
K Â1 − P1  , Â1 − P1 


F
,
V̂1 − V1 Ô1  ≤
δ
F
using Lemma C.5,
 3/2 √





2
Kρn
K 3/2


V̂
−
V
Ô
=
O
=
O
 1
√
1 1
P
P
βmin ρn/K
βmin ρn
F
with probability larger than 1 − OP (K 2 /n3 ).

Lemma C.9. If ρn = Ω(log n), then the orthogonal matrix Ô1 ∈ RK×K of Lemma C.8 satisfies


p


Ê1 − ÔT1 E1 Ô1  = OP ( Kρn/βmin )
F

with probability larger than 1 − OP (K 2 /n3 ).

On Mixed Memberships and Symmetric Nonnegative Matrix Factorizations

Proof. We have




p




V̂1 Ê1 V̂1T − V1 E1 V1T  = Â1 − P1  = OP ( Kρn)
F

F

3

with probability larger than 1 − 1/n by Lemma C.5, and




K 3/2


V̂1 − V1 Ô1  = OP
√
βmin ρn
F
with probability larger than 1 − OP (K 2 /n3 ) by Lemma C.8. Also,



 

V̂1 Ê1 V̂1T − V1 E1 V1T = V̂1 Ê1 − ÔT1 E1 Ô1 V̂1T + V̂1 ÔT1 E1 Ô1 V̂1T − V1T + V̂1 ÔT1 − V1 E1 V1T .
So

 







Ê1 − ÔT1 E1 Ô1  = V̂1 Ê1 − ÔT1 E1 Ô1 V̂1T 
F
F













T
T
T
T
≤ V̂1 Ê1 V̂1 − V1 E1 V1  + V̂1 Ô1 E1 Ô1 V̂1 − V1T  +  V̂1 ÔT1 − V1 E1 V1T 
F
F
F


p

T
≤OP ( Kρn) + 2 kE1 k V̂1 − V1 Ô1 
F


p
K 3/2
ρn
=OP ( Kρn) + OP
·
√
K βmin ρn
p

=OP
Kρn/βmin ,
with probability larger than 1 − OP (K 2 /n3 ).
Lemma C.10. If ρn = Ω(log n), then ∃ an orthogonal matrix R1 ∈ RK×K , together with the orthogonal matrix Ô ∈
RK×K of Lemma C.8 satisfies





1/2
1/2 
2
R1 E1 Ô1 − Ê1  = OP K 3/2 /βmin
F

with probability larger than 1 − OP (K 2 /n3 ).
Proof. From Lemma C.9 we have




p





Kρn/βmin .
Ô1 Ê1 ÔT1 − E1  = Ê1 − ÔT1 E1 Ô1  = OP
F

2

F

3

with probability larger than 1 − OP (K /n ).
By Lemma C.4, there exists an orthogonal matrix R1 ∈ Rd×d such that:

 r
 p
√ 




T
T
K Ô1 Ê1 Ô1 − E1 
Ô1 Ê1 Ô1  + kE1 k



1/2
1/2 
Ô1 Ê1 R1 − E1  ≤
λK (E)
F
√

p ρn 
p ρn 
√
K · OP
Kρn/βmin OP
K + OP
K
≤
Ω(βmin ρn/K)


2
≤ OP K 3/2 /βmin
.

(from Lemma C.7)

Note that







 1/2


1/2
1/2 
1/2
1/2
1/2 
R1 E1 Ô1 − Ê1  = E1 − RT1 Ê1 ÔT1  = Ô1 Ê1 R1 − E1  ,
F

F

so





1/2
1/2 
2
.
R1 E1 Ô1 − Ê1  = OP K 3/2 /βmin
F

F

On Mixed Memberships and Symmetric Nonnegative Matrix Factorizations

Proof of Lemma 4.1. Note that if α = u1, u > 0, then
D21 (i, i) =

X

X

ρθia Baa θja =

a∈[K],j∈S

ρθia Baa

X
j∈S

a∈[K]

θja

ρn X
θia Baa
=
2K

r
1 ± OP

a∈[K]

K log n
n

!!
.

(by Lemma C.1)
Because
"
#
2

P
2
√
2
ρ a∈[K] θia
Baa
ρ eTi Θ2 B1/2 F
1
1

−1/2
T
1/2 
p
p
,
∈ ρn P
 ρ · ei D21 Θ2 B  =
D21 (i, i)
F
a∈[K] θia Baa 1 + OP ( K log n/n) 1 − OP ( K log n/n)
2K
P
2
i
h
p
p
2K
a∈[K] θia Baa
=
1 − OP ( K log n/n), 1 + OP ( K log n/n) ,
·P
n
a∈[K] θia Baa
also note that
P
2
2K
2K
2K
a∈[K] θia Baa
·P
· max θia ≤
,
≤
a
n
n
n
θ
B
ia
aa
a∈[K]
where the first inequality is an equality when ∀k ∈ [K], θik = maxa θia or 0. The second inequality becomes an equality
when maxa θia = 1 (i.e. i is a pure node). This implies that the LHS of the above equation equals 2K/n if and only if i
corresponds to a pure node. Then we have
√
2


p
2K


−1/2
· max θia 1 + OP ( K log n/n) ,
 ρ · eTi D21 Θ2 B1/2  ≤
a
n
F
and


P
2
2
√
2
 2K P
p
2K
a∈[K] θia Baa 
a∈[K] θia Baa

−1/2
T
1/2 
·P
·P
· OP ( K log n/n)
 ρ · ei D21 Θ2 B  −
=

n
n
F
a∈[K] θia Baa 
a∈[K] θia Baa


2K p
= OP
· K log n/n
n
with probability larger than 1 − O(1/n3 ).

2
√

−1/2
So  ρ · eTi D21 Θ2 B1/2  concentrates around
F

2K
n

for pure nodes. Note that we implicitly assume that the impure

nodes have maxa θia bounded away from one, and hence have norm bounded away from 2K/n.

Proof of Theorem 4.2. Denote Θ1 = Θ(S, :) and Θ2 = Θ(S̄, :). Denote A12 = A(S, S̄) and A21 = A(S̄, S), D12
−1/2
−1/2
−1/2
and D21 are the (row) degree matrix of A12 and A21 . GeoNMF projects D21 A21 onto V̂1 Ê1 , and D12 A12 onto
−1/2
V̂2 Ê2 .
Now, V1 E1 V1T = P1 = ρΘ1 BΘT1 , with both E1 and B diagonal. This imples that there exists an orthogonal matrix Q1
√
1/2
such that V1 E1 Q1 = ρ · Θ1 B1/2 (by Lemma A.1 of (Tang et al., 2013)).
Also, as shown in Lemmas C.8 and C.10, there exists orthogonal matrices Ô1 and and R1 such that




K 3/2


,
V̂1 − V1 Ô1  = OP
√
βmin ρn
F
with probability larger than 1 − O(K 2 /n3 ).

and






1/2
1/2 
2
R1 E1 Ô1 − Ê1  = OP K 3/2 /βmin
F

On Mixed Memberships and Symmetric Nonnegative Matrix Factorizations

Then we have:


√

 T
−1/2
− ρ · eTi Θ2 B1/2 QT1 RT1 
ei P21 V1 Ô1 Ê1
F


√

−1/2
T
T
T
1/2 T T 
= ρ · ei Θ2 BΘ1 V1 Ô1 Ê1
− ρ · ei Θ2 B Q1 R1 
F




√


−1/2
1/2 T
T
1/2
T
B Θ1 V1 Ô1 Ê1
− ρ · ei Θ2 B1/2 QT1 RT1 
= ρ · ei Θ2 B

F

T

√ 
1/2
−1/2
T
1/2
T
1/2
T
T
V1 E1 Q1 V1 Ô1 Ê1
= ρ·
− ei Θ2 B Q1 R1 
ei Θ2 B

F




√  T
1/2
−1/2
1/2 T T
T
1/2 T T 
− ei Θ2 B Q1 R1 
= ρ · ei Θ2 B Q1 R1 R1 E1 Ô1 Ê1
F
√




1/2
1/2
−1/2 
T
1/2 T T
=  ρ · ei Θ2 B Q1 R1 R1 E1 Ô1 − Ê1
Ê1 
F


 
√

1/2
1/2   −1/2 
T
1/2 T T  
≤  ρ · ei Θ2 B Q1 R1  R1 E1 Ô1 − Ê1  Ê1 
F
s
!
√



K

T
1/2 T T 
3/2
2
≤  ρ · ei Θ2 B Q1 R1  · OP K /βmin · OP
βmin ρn
F

(by P21 = ρΘ2 BΘT1 )

(by Lemma A.1 of (Tang et al., 2013))

(by Lemmas 4.1, C.6, C.7 and C.10)



√

√




−1/2
=⇒ eTi P21 V1 Ô1 Ê1
− ρ · eTi Θ2 B1/2 QT1 RT1  =  ρ · eTi Θ2 B1/2 QT1 RT1  · OP
F

F

K2
5/2 √

!
.

(2)

βmin ρn

Now that


√

 T −1/2
−1/2
−1/2
− ρ · eTi D21 Θ2 B1/2 QT1 RT1 
ei D21 A21 V̂1 Ê1
F

 p

p
 √


−1/2
≤ eTi A21 V̂1 Ê1
1 + OP
K log n/nρ − ρ · eTi Θ2 B1/2 QT1 RT1  / D21 (i, i)

(by Lemma C.6)

F


p
  h


i
√
 T

−1/2
1 + OP
K log n/nρ · ei (A21 − P21 ) V̂1 + P21 V̂1 − V1 Ô1 + P21 V1 Ô1 Ê1
− ρ · eTi Θ2 B1/2 QT1 RT1 
F
p
≤
D21 (i, i)

 p
 √
p


+ OP
K log n/nρ ·  ρ · eTi Θ2 B1/2 QT1 RT1  / D21 (i, i)
F






p
 n
 T

−1/2 
−1/2 
≤ 1 + OP
K log n/nρ · ei (A21 − P21 ) V̂1 Ê1  + eTi P21 V̂1 − V1 Ô1 Ê1 
F

 o p F
 p

√
 T
−1/2
T
1/2 T T 
2
+ ei P21 V1 Ô1 Ê1
− ρ · ei Θ2 B Q1 R1  / D21 (i, i) + OP K log n/n ρ
F


≤ 1 + OP



 (

p
1 p
K log n/nρ
· OP
Klog n · OP

(by Lemmas 4.1 and C.6)
s

K

!

(by Azuma’s and Lemma C.7)
βmin
βmin ρn
s
!)
r 


p
ρn
K 3/2
K
+OP
· OP
· OP
/ βmin ρn/K
(by Lemmas C.6, C.8, and Eq. (2))
√
K
βmin ρn
βmin ρn
!
r
 p

2K
K2
2ρ
+
· OP
+
O
K
log
n/n
P
5/2 √
n
βmin ρn
!
√
K 5/2 log n
=OP
.
5/2
βmin ρn

2


In the last step we use the fact that eTi (A21 − P21 ) V̂1  is a sum of K projections of eTi (A21 − P21 ) on a fixed
F
unit
come from the different partition of the graph). Now Azuma’s inequality gives
 vector (since the eigenvectors
√
 T

ei (A21 − P21 ) V̂1  = OP ( K log n) with probability larger than 1 − O(1/n3 ).
F

On Mixed Memberships and Symmetric Nonnegative Matrix Factorizations

Now as

2
√
2
ρ eTi Θ2 B1/2 F
ρ · eTi Θ2 BΘT2 ei

−1/2
T
1/2 
=
 ρ · ei D21 Θ2 B  =
D21 (i, i)
D21 (i, i)
F


 
P2 (i, i)
ρ
K
=
=Ω
= OP
,
D21 (i, i)
ρn/K
n
let O = QT1 RT1 , then ∀i,


√

 T −1/2
−1/2
−1/2
− ρ · eTi D21 Θ2 B1/2 O 
ei D21 A21 V̂1 Ê1
F


= OP

√
−1/2
 ρ · eTi D21 Θ2 B1/2 

r !
√
K 5/2 log n
n
·
5/2
K
βmin ρn
!
√
K 2 log n
5/2 √
βmin ρ n

F

= OP
with probability larger than 1 − n · O(K 2 /n3 )=1 − O(K 2 /n2 ).

D. Correctness of Pure node clusters
p
Proof of Lemma 4.3. Recall that max
around 2K/n and this is achieved at the pure nodes. For ease
pi kXi k concentrates p
of analysis let us introduce Ŷ := n/2K
 = n/2KX. Recall that from Theorem 4.2 we have entry-wise
 X̂ and Y
consistency on kŶi − Yi Ok ≤ 0 = OP
Let norm = OP

q

K log n
n



√
K 2 log n
5/2 √
βmin ρ n

with probability larger than 1 − OP (K 2 /n2 ).

= OP (0 ) be the error of the norm of pure nodes in Lemma 4.1. Then ∀i ∈ F,

p
kX̂i k ≥ (1 − 0 ) max kX̂j k ≥ (1 − 0 )(1 − 0 ) max kXj k ≥ (1 − 0 )(1 − 0 )(1 − norm ) 2K/n.
j

j

Hence we have a series of inequalities,
(1 − 0 )(1 − 0 )(1 − norm ) ≤ kŶi k ≤ kŶi − Yi Ok + kYi k ≤ 0 + kYi k.
Hence
kYi k2 ≥ (1 − 0 − 20 − norm )2 ≥ 1 − 2(0 + 20 + norm )
And from the proof of Lemma 4.1,
2
a∈[K] θia Baa

P
0

2

1 − 2(0 + 2 + norm ) ≤ kYi k ≤ P
=⇒ max θia ≥ 1 − 2(0 +
a

≤ max θia (1 + norm )

a∈[K] θia Baa
20 + 1.5norm )

a

= 1 − OP (0 + 0 )

for  = 2(0 + 20 + 1.5norm ) = OP (0 + 0 ), with probability larger than 1 − OP (K 2 /n2 ).
Note that kXi k2 of those nearly pure nodes with maxa θia ≥ 1 −  also concentrate around 2K
n . These nearly pure nodes
can also be used along with the pure nodes to recover the MMSB model asymptotically correctly.
Lemma D.1. Let F be the set of nodes with kX̂i k ≥ (1 − 0 ) maxj kX̂j k. Then when 0 = OP (0 ) and  = OP (0 + 0 )
from Lemma 4.3,
min D2 (i, i) =
i∈F

ρn
(βmin ± OP ()) ,
2K

with probability larger than 1 − OP (K 2 /n2 ).

and

max D2 (i, i) =
i∈F

ρn
(1 ± OP ())
2K

On Mixed Memberships and Symmetric Nonnegative Matrix Factorizations

Proof. From Lemma 4.3 we know that ∀i ∈ F, ∃ai that θiai ≥ 1 − , where  = OP (0 + 0 ) = OP (0 ). Then
D2 (i, i) =

n/2
X

Pij =

j=1

=ρ

K
X

n/2 K
X
X

(2)

(2)

ρθi` B`` θj` = ρ

j=1 `=1
(2)

θi` B``

`=1

K
X

(2)

θi` B``

`=1

r

n
2K

1±OP

K log n
n

n/2
X

(2)

θj`

j=1

!!
(from Lemma C.1)

!!
r
K log n
ρn
((1 − OP ())Bai ai + OP ()) 1 ± OP
=
2K
n
ρn
=
(Bai ai ± OP ()) .
2K
h
q

q
i
K log n
K log n
,
1
+
O
, so
Using the proof in Lemma C.6, we have D2 (i, i) ∈ D2 (i, i) 1 − OP
P
ρn
ρn
D2 (i, i) =

ρn
(Bai ai ± OP ()) .
2K

Then
ρn
(βmin ± OP ()) ,
2K
ρn
max D2 (i, i) =
(1 ± OP ())
i∈F
2K
min D2 (i, i) =
i∈F

with probability larger than 1 − OP (K 2 /n2 ).
Proof of Theorem 4.4. To prove this theorem, it is equivalent to prove that the upper bound of Euclidean distances within
each community’s (nearly) pure nodes is far more smaller than the lower bound of Euclidean distances between different
communities’ (nearly) pure nodes.
0
Recall that from
 Lemma4.3, for i 6= j ∈ F, ∃ a, b ∈ [K], such that θia ≥ 1 −  and θjb ≥ 1 − . Note that  = OP (0 +  )

for 0 = OP

√
K 2 log n
5/2 √
βmin ρ n

and 0 = OP (0 ).

Using a similar argument as in the proof of Lemma 4.1, we have:
1. if a 6= b,
"

kYi −

2
Yj k2

≥

1/2

1/2

θia Baa
θja Baa
pP
− pP
k θik Bkk
k θjk Bkk

!2

1/2

+

1/2

θib B
θjb B
pP bb
− pP bb
k θik Bkk
k θjk Bkk

!2 #

r
·

1 − OP

!!
r
2

2 #
1−

1−

K log n
≥ Baa √
−√
+ Bbb √
−√
· 1 − OP
n
βmax
βmin
βmax
βmin
"
!!
r

2 #
1−

K log n
≥ 2βmin √
−√
· 1 − OP
n
βmax
βmin


s
"
! #2
!!
r
 β

βmax
K log n
min
≥ 2
1− 1+

· 1 − OP
 βmax

βmin
n
s
(
"
!
#)
!!
r
βmin
βmax
K log n
2
= 2
1−2 1+
 + OP ( )
· 1 − OP
βmax
βmin
n
s
!!
βmin
βmax
=2
1 − OP 
.
βmax
βmin
"



K log n
n

!!2

On Mixed Memberships and Symmetric Nonnegative Matrix Factorizations

So,
s
kXi − Xj k2 ≥

βmin
2
βmax

r

s

2K
n

1 − OP



βmax
βmin

!!
,

and then,












X̂i − X̂j  ≥ kXi − Xj k2 − X̂i − Xi  − X̂j − Xj 
2
2
2
s
s
!!
r
βmin 2K
βmax
≥ 2
1 − OP 
− 2 kXi k · 0
βmax
n
βmin
s
s
!!
r
r
βmax
2K
βmin 2K
≥ 2
1 − OP 
−2
· (1 + OP ()) · 0
βmax
n
βmin
n
r
r !
Kβmin
K
=2
− OP 
.
(βmax = 1 by definition)
n
n
2. if a = b, first of all we have
(1 − )βa ≤

X

θik Bkk ≤ βa + 

k

X

βk ,

k6=a

then
1/2

kYi −

2
Yj k2

=

X
l

1/2

θjl B
θil B
pP ll
− pP ll
θ
B
k ik kk
k θjk Bkk

!2

r
·

1 + OP

K log n
n


!!2


2
1/2
1/2
X βmax 
Baa
(1 − )Baa

 +
−q
≤ p
2  · (1 + OP ())
P
βmin
(1 − )βa
βa +  k6=a βk
k6=a
(
)
P

2
β


β
k
max
k6
=
a
=
1 + + OP (2 ) − (1 − ) 1 −
+ OP (2 )
+ (K − 1)
2 · (1 + OP ())
2
2
βa
βmin
(
P

2

)
3
βmax 2
k6=a βmax
2
+
≤
 + OP ( ) + OP K

· (1 + OP ())
2
2βmin
βmin


βmax 2
 .
= OP K
βmin
So,
r
kXi − Xj k2 ≤

2K
OP
n

s

βmax
 K
βmin

!

and then,












X̂i − X̂j  ≤ kXi − Xj k2 + X̂i − Xi  + X̂j − Xj 
2
2
2
s
!
r
2K
βmax
≤
OP  K
+ 2 kXi k · 0
n
βmin
s
!
r
r
2K
βmax
2K
≤
OP  K
+2
· (1 + OP ()) · 0
n
βmin
n
s
!
K2
= OP 
.
(βmax = 1 by definition)
nβmin

On Mixed Memberships and Symmetric Nonnegative Matrix Factorizations

q

Now we can see 12 Kβnmin can be used as a threshold to separate different clusters. However, in the algorithm we do not
know βmin in advance, so we need to approximate it with some computable statistics. From Lemma D.1, we know that
ρn
D2 (i, i) = 2K
(Bai ai ± OP (0 )) when θiai ≥ 1 − . So mini∈F D2 (i, i) and maxi∈F D2 (i, i) can be used to estimate
βmin .
s
s
s
!
r
K mini∈F D2 (i, i)
K ρn (βmin ± OP ()) /(2K)
1 Kβmin
K
τ=
=
=
± OP 
.
4n maxi∈F D2 (i, i)
4n ρn (1 ± OP ()) /(2K)
2
n
nβmin
Clearly,
r
2

Kβmin
± OP
n

r


K
n

s

!
> 2τ  OP



K2
nβmin

!
,

which means PartitionPureNodes(X̂(F, :), τ ) can exactly give us K clusters of different (nearly) pure nodes and return
one (nearly) pure node from each of the K clusters with probability larger than 1 − OP (K 2 /n2 ).

E. Consistency of inferred parameters
p
p
Proof of Theorem 4.5. Let Ŷ := n/2K X̂ and Y = n/2KX. Let  = OP (0 + 0 ) = O (0 ) from Lemma 4.3, where
we show that kYi k2 ≥ 1 −  for i ∈ SP . Furthermore for ease of exposition let us assume that the pure nodes are arranged
so that Θ̂2p = Θ̂2 (Sp , :) is close to an identity matrix, i.e., the columns are arranged with a particular permutation.
p
P
Thus kYp k2F = i kYp (i, :)k2 ≥ K(1 − ) and so kYp kF ≥ K(1 − ).
√
We have also shown that kYp (i, :)k2 ≤ 1 + , so kYp kF ≤ K (1 + ).
We will use
kŶp−1 − (Yp O)

−1

−1

kF ≤ k (Yp O)

(Yp O − Ŷp )Ŷp−1 kF ≤ kYp−1 kF kYp O − Ŷp kF kŶp−1 k.

(3)

First we will prove a bound on kŶp−1 k. Let σ̂i be the ith singular value of Ŷp ,
kŶp−1 k =

1
.
σ̂K

(4)

We can bound σ̂K by bounding σK . In what follows we use M1p to denote the rows of M1 indexed by Sp when
√ M1
is n/2 × K and √by the square submatrix
M
(S
,
S
)
is
when
M
is
n/2
×
n/2.
Note
that
kΘ
−
Ik
=
K,
1 p
p
1
2p
F
√
−1
kB1/2 kF = OP ( K), kΘ2p kF = OP ( K) and kD21p
kF = OP (K 3/2 /βmin ρn),
σi2 = λi (Yp YpT ) =

ρn
−1/2
−1/2
λi (D21p Θ2p BΘT2p D21p )
2K

ρn
−1
λi (B1/2 ΘT2p D21p
Θ2p B1/2 )
2K 


ρn
−1
−1
−1
=
λi B1/2 D21p
+ (Θ2p − I)T D21p
Θ2p + D21p
(Θ2p − I) B1/2 .
2K

=

−1 1/2
Note that the matrix B1/2 D21p
B
is a diagonal matrix with the (i, i)th diagonal element being βi /D21p (i, i).

With similar arguments in the proof of Lemma D.1, we can get
D21p (i, i) =

nρ
(βi ± OP ()) ,
2K

so
−1 1/2
λK (B1/2 D21p
B )=

2K
(1 ± OP (/βmin )) .
ρn

On Mixed Memberships and Symmetric Nonnegative Matrix Factorizations

By Weyl’s inequality and note that operator norm is less than or equal to Frobenius norm, it immediately gives us:


ρn  1/2 −1 1/2  ρn 

 2

−1
−1
λi B D21p B
· B1/2 (Θ2p − I)T D21p
Θ2p B1/2 + B1/2 D21p
(Θ2p − I)B1/2 
σi −
≤
2K
2K 


 −1 
ρn  1/2 

1/2 
 · 2 kΘ2p k · 
≤
· B  · kΘ2p − IkF · D21p

B
F
F
2K
F
F


√
√
ρn √
K 3/2 √
=OP
· K · K ·
· K· K
2K
βmin ρn
!
√
K 9/2 log n
=OP
7/2 √
βmin ρ n
!
√
K 9/2 log n
2
=⇒ σK =1 ± OP
.
7/2 √
βmin ρ n
Now, Weyl’s inequality for singular values gives us:
√
|σ̂i − σi | ≤ kŶp − Yp Ok ≤ kŶp − Yp OkF = OP ( K)
!!1/2
!!
√
√
√
K 9/2 log n
K 2 log n
σ̂K = 1 ± OP
1 ± OP
K · 5/2 √
= 1 ± OP
7/2 √
βmin ρ n
βmin ρ n

!
√
K 9/2 log n
.
7/2 √
βmin ρ n

Plugging this into Equation (4) we get:
kŶp−1 k = 1 ± OP

!
√
K 9/2 log n
.
7/2 √
βmin ρ n

Finally putting everything together with Equation (3) we get:
−1

kX̂−1
p − (Xp O)
kX−1
p kF

kF

−1

=

kŶp−1 − (Yp O)

kF

kYp−1 kF

≤ kYp O −

Ŷp kF kŶp−1 k

= OP

!
√
K 5/2 log n
5/2 √
βmin ρ n

(5)

with probability larger than 1 − OP (K 2 /n2 ).
−1/2

1/2

(Sp , Sp ). First note that if one plugs in the population
Proof of Theorem 4.6. Recall that Θ̂2 = Θ̂(S̄) = D12 X̂X̂−1
p D21
counterparts of the the terms in Θ̂2 , then for some permutation matrix Π that Θ2p := Θ2 (Sp , :) · Π is close to an identity
matrix, and


 1
−1/2
−1/2
1/2
−1/2
1/2 √
−1 1/2
−1
1/2
−1/2
ρ
·
D
Θ
B
·
B
ΠΘ
D
D21 XX−1
D
=
D
√
2
p
21p
21
21
2p
21p D21p = Θ2 ΠΘ2p ,
ρ
so
−1/2

1/2

Θ2 Π = D21 XX−1
p D21p Θ2p .
We have the following decomposition








 1/2
 1/2
−1/2 
1/2
−1 −1/2 
Θ̂2 − Θ2 Π ≤ (D21 − D21 )X̂X̂−1
p D21p  + D21 (X̂ − XO)X̂p D21p 
F
F
F




 1/2
 1/2
−1/2 
−1/2
−1/2 
−1
−1
+ D21 XO(X̂−1
−
(X
O)
)D
+
XX
(D
D21
p
p
p
21p 
21p − D21p )
F
F


 1/2

−1 −1/2
+ D21 XXp D21p (I − Θ2p ) .
F

p

p

p
From the proof of Lemma C.6 we have D21 (i, i) = D21 (i, i)(1 ± OP ( K log n/nρ)) and hence

 

p
 1/2
 1/2 
1/2 
D21 − D21  = D21  OP ( K log n/nρ),

On Mixed Memberships and Symmetric Nonnegative Matrix Factorizations

and

 

p
 −1/2 
 −1/2
−1/2 
D21p − D21p  ≤ D21p  OP ( K log n/nρ).
p
p
And kX̂−1
n/(2K)kŶp−1 k = OP ( n/K), as we have shown in the proof of Theorem 4.5. Furthermore, by
p k =
√
Fact C.1, kX̂−1
p kF = OP ( n).
√
From the proof of Theorem 4.2 we can get kX̂ − XOkF = OP ( K0 ). Theorem 4.5 gives
!
√
K 5/2 log n
−1
−1
−1
kX̂p − (Xp O) kF = kXp kF · OP
5/2 √
βmin ρ n
!
!
r 
√
√

√
n
K 5/2 log n
K 5/2 log n
= OP
K·
· OP
= OP
.
5/2 √
5/2
K
β ρ n
β ρ
min

min

√
around its population entry-wisely, and the max norm of any row of the
Also kX̂kF =pOP ( K), since it concentrates
√
population is 2K/n, so kXkF = OP ( K). And
p
p
√
1/2
1/2 √
−1/2
kD21 Xk = kD21 ρ · D21 Θ2 B1/2 k = k ρ · Θ2 B1/2 k = kPk = OP ( ρn/K).
Hence,



  


 1/2
 1/2
1/2
−1/2 
1/2     −1   −1/2 
(D21 − D21 )X̂X̂−1
p D21p  ≤ D21 − D21  X̂ X̂p  D21p 
F
F




p
√ 
p
p
p
p
ρn/K OP
K log n/nρ · OP
K · OP
n/K · OP ( K/βmin ρn) = OP
K log n/βmin ρ ,
= OP




 


 1/2
 1/2  
  −1   −1/2 
−1/2 
D21 (X̂ − XO)X̂−1
p D21p  ≤ D21  X̂ − XO  X̂p  D21p 
F
F

r
 2√

p


√

p
p
n 0
K log n
0
= OP
ρn/K · OP
K · OP
n/K · OP ( K/βmin ρn) = OP
 = OP
,
3 ρ
βmin
βmin




 

 1/2
 1/2  
−1/2 
−1
−1   −1/2 
)D21p  ≤ D21 X X̂−1
D21 X(X̂−1
 D21p 
p − (Xp O)
p − (Xp O)
F
F
!
√
 5/2 √


p
5/2
p
K
log n
K
log n
ρn/K · OP
· OP ( K/βmin ρn) = OP
= OP
,
3 ρ
5/2
βmin
βmin ρ





  −1/2
 1/2
 1/2  
−1/2
−1/2 
−1/2 
 −1  
D21 XX−1
D21p − D21p 
p (D21p − D21p ) ≤ D21 X Xp
F
F



p
p
p
p
p
√
ρn/K · OP ( K · n/K) · OP ( K/βmin ρn)OP
K log n/nρ = OP
K log n/βmin ρ ,
= OP




  −1/2 

 1/2

 1/2  
−1/2
 −1  
D21p  kI − Θ2p kF
D21 XX−1
p D21p (I − Θ2p ) ≤ D21 X Xp
F
F
s
!
 5/2 √

p

p
p
√
√ 0
Kn 0
K
log n
= OP
ρn/K · OP ( K · n/K) · OP ( K/βmin ρn) · K = OP
 = OP
.
3 ρ
βmin
βmin
So
 5/2 √



K
log n


.
Θ̂2 − Θ2 Π = OP
3 ρ
βmin
F
Since kΘ2 k2F = Ω(n/K), we finally have:




Θ̂2 − Θ2 Π

F

kΘ2 kF
with probability larger than 1 − O(K 2 /n2 ).


≤ OP

√

K 3 log n
√
3 ρ n
βmin

On Mixed Memberships and Symmetric Nonnegative Matrix Factorizations

2



1/2
Proof of Theorem 4.7. Recall that ρ̂β̂a = eTa D21 (Sp , Sp )X̂p  , and for some permutation matrix Π that Θ2p :=
F

Θ2 (Sp , :) · Π is close to an identity matrix, if one plugs in the population counterparts of the the terms in Θ̂2 ,
√


√


√

 T 1/2




ea D21 (Sp , Sp )Xp  =  ρ · eTa Θ2p ΠT B1/2  =  ρ · eTa (Θ2p − I) ΠT B1/2 + ρ · eTa ΠT B1/2 
F
F
F
√
√




T
T 1/2 
T
T 1/2 
≤  ρ · ea (Θ2p − I) Π B  +  ρ · ea Π B 
F
F
p
√
= ρ0 + ρβa0 ,
where a0 ∈ [K] satisfies Πa0 a = 1.
Using the bounds mentioned in the proof of Theorem 4.6, we have:


 

 T 1/2
 
1/2
1/2
1/2
1/2
ei (D21 X̂ − D21 XO) = eTi (D21 − D21 )X̂ + eTi D21 (X̂ − XO)
p
 p


p

 

≤
D21 (i, i) − D21 (i, i) eTi X̂ +  D21 (i, i)eTi (X̂ − XO)


p
 
  
p
 p




≤
D21 (i, i) − D21 (i, i) eTi X̂ − XO  + eTi X + D21 (i, i) eTi (X̂ − XO)
s
!
!"
r !#
p
r 
r 
nρ
K log n
K 5 log n
K
nρ
= OP
+
O
OP
OP
+
O
· OP
P
P
5/2
K
nρ
n
K
βmin ρn
!
K 5/2 log n
= OP
.
5/2 √
βmin ρn

p

K 5 log n

!

5/2

βmin ρn

As a result,
q

p


 ρ̂β̂a − ρβa0  ≤ OP



K 5/2 log n
5/2 √
βmin ρn

!
+

√

0

ρ = OP

K 5/2 log n
5/2 √
βmin ρn

!
,

and note that ρβa0 = Ω(ρ), we have
"
ρ̂β̂a ∈ ρβa0 1 − OP

K 5/2 log n
5/2 √
βmin ρ n

!
, 1 + OP

K 5/2 log n
5/2 √
βmin ρ n

!#

with probability larger than 1 − O(K 2 /n2 ).

References
Huang, Kejun, Sidiropoulos, Nicholas, and Swami, Ananthram. Non-negative matrix factorization revisited: Uniqueness
and algorithm for symmetric decomposition. Signal Processing, IEEE Transactions on, 62(1):211–224, 2014.
Lei, Jing, Rinaldo, Alessandro, et al. Consistency of spectral clustering in stochastic block models. The Annals of Statistics,
43(1):215–237, 2015.
Minc, Henryk. Nonnegative matrices. 1988.
Tang, Minh, Sussman, Daniel L, Priebe, Carey E, et al. Universally consistent vertex classification for latent positions
graphs. The Annals of Statistics, 41(3):1406–1430, 2013.
Yu, Yi, Wang, Tengyao, Samworth, Richard J, et al. A useful variant of the davis–kahan theorem for statisticians.
Biometrika, 102(2):315–323, 2015.

