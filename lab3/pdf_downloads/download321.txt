Long Version of Proof of Theorem 3
Supplement to ICML submission â€œLearning in POMDPs with Monte Carlo Tree Searchâ€
While RS-BA-POMCP is potentially more efficient, it is not directly whether it still converges to an -optimal
value function. Here we show the main steps in proving that it is sound. These main steps are similar to the proof
in POMCP. We point out however, that the technicalities of proving the components are far more involved.

Notation
We will use the following notation.
Action-observation histories.
â€¢ hd is an action-observation history at depth d of a simulation,
â€¢ hd = (a0 , z1 , . . . , adâˆ’1 , zd ).
â€˜Fullâ€™ histories. In addition to actions and observations, full histories also include the states.
â€¢ H0 the (unknown) full history (of real experience) at the root of the simulation: i.e., if there have been k
steps of â€˜realâ€™ experience H0 = (sâˆ’k , aâˆ’k , sâˆ’k+1 , zâˆ’kâˆ’1 , . . . , aâˆ’1 , s0 , z0 )
â€¢ Hd is a full history (of simulated experience) at depth d in the lookahead tree: Hd = (H0 , a0 , s1 , z1 , a1 , s2 , z2 , . . . , adâˆ’1 , sd , zd )
(Hdâˆ’1 , adâˆ’1 , sd , zd ) = hs0:d , hd i.
(i)
â€¢ Hd the full history at depth d corresponding to simulation i.
â€¢ In our proof, we will also need to indicate if a particular full history Hd is consistent with a full history at the
root of simulation:
(
1 if Hd is consistent with the full history at the root H0 ,
Cons(H0 , Hd ) =
0 otherwise.
Dynamics Function. We fold transition and observations function into one:
â€¢ D denotes the dynamics model
s0 z
t zt
â€¢ Dsstâˆ’1
(s , z ) = D(st , zt |stâˆ’1 , atâˆ’1 ) = Pr(st , zt |stâˆ’1 , atâˆ’1 )
atâˆ’1 = Dsa = Dstâˆ’1
D,atâˆ’11 1 t t
E
s z
s|S| z |Z|
â€¢ Dsa denotes the vector: Dsa
, . . . , Dsa
Counts
0
â€¢ Ï‡ssaz denotes how often hs0 , zi occurred after hs, ai
â€¢ Ï‡sa is

 the vector of counts
 for hs, ai.
â€¢ Ï‡ = Ï‡s1 a1 , . . . , Ï‡s|S| a|A| is the total collection of all such count vectors.
â€¢ Ï‡(Hd ) denotes the vector of counts at simulated full history Hd .
â€¢ If Ï‡0 is the count vector at the root of simulation, we have that Ï‡(Hd ) = Ï‡0 + âˆ†(Hd ), with âˆ†(Hd ) the vector
of counts of all (s, a, s0 , z) quadruples occurring in Hd .
Dirichlet distributions
â€¢ let x = hx1 . . . xK i âˆˆ âˆ†K and Î± = hÎ±1 . . . Î±K i be a count vector
QK
i âˆ’1
â€¢ Dir(x|Î±) = Pr(x;
Î±) = B(Î±) i=1 xÎ±
i
P
Î“( i Î±i )
â€¢ with B(Î±) = Q Î“(Î±
the Dirichlet normalization constant, with Î“ the gamma function.
i)
i
â€¢ So, in translated in terms of dynamics function and counts, we have:
 0 Ï‡ssa0 z
Q
sz
â€“ for a particular s, a: Dir(Dsa |Ï‡sa ) = Pr(Dsa ; Ï‡sa ) = B(Ï‡sa ) hs0 ,ziâˆˆSÃ—Z Dsa
1

â€“ we will also abuse notation and write Dir(D|Ï‡) =

Q

hs,ai

Dir(Dsa |Ï‡sa ).

Var.
â€¢ xÌ‡ denotes a root sampled quantity x.
â€¢ I{condition} is the indicator function which is 1 iff condition is true and 0 otherwise.

Definitions
Definition 1. The expected full-history expected transition BA-POMDP rollout distribution is the distribution
over full histories of a BA-POMDP, when performing Monte-Carlo simulations according to a policy Ï€. It is given
by
P Ï€ (Hd+1 ) = DÏ‡(Hd ) (sd+1 , zd+1 |as , sd )Ï€(ad |hd )P Ï€ (Hd )
(1)
with P Ï€ (H0 ) = b0 (hs0 , Ï‡0 i) the belief â€˜nowâ€™ (at the root of the online planning).

Definition 2. The full-history root-sampling (RS) BA-POMDP rollout distribution is the distribution over full
histories of a BA-POMDP, when performing Monte-Carlo simulations according to a policy Ï€ in combination
with root sampling of the dynamics model D. This distribution, for a particular stage d, is given by
Ï€
PÌƒK
(Hd ) ,

Kd
1 X
o
In
(i) ,
Kd i=1 Hd =Hd

where
â€¢ K is the number of simulations that comprise the empirical distribution,
â€¢ Kd is the number of simulations that reach depth d (not all simulations might be equally long),
(i)
â€¢ Hd is the history specified by the i-th particle at stage d.
Remark: throughout this proof we assume that there is only 1 initial count vector at the root. Or put better:
we assume that there is one unique H0 at which all simulations start. However, for â€˜realâ€™ steps t > 0 we could be
. In this case, root sampling from the
in different Htreal all corresponding to the same observed real history hreal
t
belief can be thought of root sampling the initial full history H0 âˆ¼ b(Htreal ). As such, our proof shows convergence
in probability of
p
Ï€
âˆ€H0 âˆ€Hd PÌƒK
(Hd |H0 ) â†’ P Ï€ (Hd |H0 ).
d
for each such sampled H0 . It is clear that that directly implies that
h
i p
Ï€
Ï€
âˆ€Hd PÌƒK
(H
)
=
E
PÌƒ
(H
|H
)
â†’ EH0 [P Ï€ (Hd |H0 )] = P Ï€ (Hd ).
d
H
d
0
K
0
d
d
In the below, we omit the explicit conditioning on H0 .

Proof of Main Theorem
The proof depends on a lemma that follows below.
Theorem 3. The full-history RS-BA-POMDP rollout distribution (Def. 2) converges in probability to full-history
BA-POMDP rollout distribution (Def. 1):
âˆ€Hd

p

Ï€
PÌƒK
(Hd ) â†’ P Ï€ (Hd ).
d

(2)

Proof. For ease of notation we prove this for stage d + 1. Note that a history Hd+1 = (Hd , ad , sd+1 , zd+1 ), only
differs from Hd in that it has one extra transition for the (sd , ad , sd+1 , zd+1 ) quadruple, implying that Ï‡(Hd+1 ) only
Ï€
differs from Ï‡(Hd ) in the counts Ï‡sd ad for sd ad . Therefore, the expression for PÌƒK
(Hd ) derived in Lemma 4 below
d
(cf. equation (20)) can be written in recursive form as

2

PÌƒ Ï€ (Hd+1 )

=

Cons(H0 , Hd )

d
Y

Ï€(at |ht )

t=0

=

=

=

dâˆ’1
Y

Y
hs,ai

B(Ï‡sa (H0 ))
B(Ï‡sa (Hd+1 ))

Y B(Ï‡sa (H0 )) B(Ï‡sa (Hd ))
B(Ï‡sa (Hd )) B(Ï‡sa (Hd+1 ))
t=0
hs,ai
ï£¹ï£®
ï£¹
ï£®
dâˆ’1
Y B(Ï‡sa (Hd ))
Y
Y B(Ï‡sa (H0 ))
ï£»ï£°
ï£»
Cons(H0 , Hd )
Ï€(at |ht )Ï€(ad |hd ) ï£°
B(Ï‡sa (Hd ))
B(Ï‡sa (Hd+1 ))
t=0
hs,ai
hs,ai
ï£®
ï£¹
dâˆ’1
Y
Y B(Ï‡sa (H0 ))
ï£°Cons(H0 , Hd )
ï£» Ï€(ad |hd ) B(Ï‡sd ad (Hd ))
Ï€(at |ht )
B(Ï‡
(H
))
B(Ï‡sd ad (Hd+1 ))
sa
d
t=0

Cons(H0 , Hd )

Ï€(at |ht )Ï€(ad |hd )

hs,ai

=

PÌƒ Ï€ (Hd )Ï€(ad |hd )

B(Ï‡sd ad (Hd ))
B(Ï‡sd ad (Hd+1 ))

with base case PÌƒ Ï€ (H0 ) = 1, and
B(Ï‡sd ad (H0 )) B(Ï‡sd ad (Hd ))
B(Ï‡sd ad (H0 ))/B(Ï‡sd ad (Hd+1 ))
B(Ï‡sd ad (Hd ))
=
Â·
=
B(Ï‡sd ad (Hd+1 ))
B(Ï‡sd ad (Hd+1 )) B(Ï‡sd ad (H0 ))
B(Ï‡sd ad (H0 ))/B(Ï‡sd ad (Hd ))

(3)

the result of dividing out the contribution of the old counts for sd ad and multiplying in the new contribution, and
similar for the observations probabilities. Now, we investigate these terms more closely.
Again remember that the sole difference between Hd+1 = (HdP
, ad , sd+1 , zd+1 ) andHd is that it has one extra
0
transition for the (sd , ad , sd+1 , zd+1 ) quadruple. Let us write T = (s0 ,z) Ï‡ssdzad (Hd ) for the total of the counts for
s
zd+1
sd , ad and N = Ï‡sd+1
(Hd ) for the number of counts for that such a transition was to (sd+1P
zd+1 ). Because Hd+1
d ad
0
only has 1 extra transition, we also know that for this history, the total counts is one higher: (s0 ,z) Ï‡ssdzad (Hd+1 ) =
s
zd+1
T + 1 and since that transition was to (sd+1 zd+1 ) the counts Ï‡sdd+1
(Hd+1 ) = N + 1. Now let us expand the term
ad
from (3):
Q
0
Î“(T )/ s0 z Î“(Ï‡ssdzad (Hd ))
B(Ï‡sd ad (Hd ))
Q
=
B(Ï‡sd ad (Hd+1 ))
Î“(T + 1)/ s0 z Î“(Ï‡ss0dzad (Hd+1 ))
Q
s0 z
Î“(T )
s0 z Î“(Ï‡sd ad (Hd+1 ))
Q
=
s0
Î“(T + 1)
s0 z Î“(Ï‡sd ad (Hd ))
Q
0
sd+1 zd+1
(Hd+1 )) s0 z6=(sd+1 zd+1 ) Î“(Ï‡ssdzad (Hd+1 ))
Î“(T ) Î“(Ï‡sd ad
Q
=
zd+1
Î“(T + 1) Î“(Ï‡ssdd+1
(Hd )) s0 z6=(sd+1 zd+1 ) Î“(Ï‡ss0dzad (Hd ))
ad
s

=

z

d+1
Î“(T ) Î“(N + 1)
Î“(T ) Î“(Ï‡sdd+1
(Hd+1 ))
ad
=
sd+1 zd+1
Î“(T + 1) Î“(Ï‡sd ad
Î“(T + 1) Î“(N )
(Hd ))

Now, the gamma function has the property that Î“(x + 1) = xÎ“(x) [DeGroot, 2004], which means that we get
=

Î“(T ) N Î“(N )
N
= .
T Î“(T ) Î“(N )
T

Therefore we get

s

z

d+1
B(Ï‡sd ad (Hd ))
Ï‡sd+1
(Hd )
a
= P d d s0 z
B(Ï‡sd ad (Hd+1 ))
Ï‡
0
(s ,z) sd ad (Hd )

and thus

s

Ï‡sd+1
a
PÌƒ Ï€ (Hd+1 ) = PÌƒ Ï€ (Hd )Ï€(ad |hd ) P d d

zd+1

(Hd )
.
s0 z (H )
Ï‡
d
(s0 ,z) sd ad

(4)

the r.h.s. of this equation is identical to (1) except for the difference in between PÌƒ Ï€ (Hd ) and P Ï€ (Hd ). This can be
resolved by forward induction with base step: PÌƒ Ï€ (H0 ) = b0 (hs0 , Ï‡0 , Ïˆ0 i) = P Ï€ (H0 ), and the induction step (show
PÌƒ Ï€ (Hd+1 ) = P Ï€ (Hd+1 ) given PÌƒ Ï€ (Hd ) = P Ï€ (Hd )) directly following from (1) and (4). Therefore we can conclude
that âˆ€d PÌƒ Ï€ (Hd ) = P Ï€ (Hd ).
3

Since Lemma 4 already established that âˆ€Hd
âˆ€Hd

p

Ï€
PÌƒK
(Hd ) â†’ PÌƒ Ï€ (Hd ), we directly have
d
p

Ï€
PÌƒK
(Hd ) â†’ P Ï€ (Hd ),
d

thus proving the result.
The proof depends on the following lemma:
Lemma 4. The full-history RS-BA-POMDP rollout distribution converges in probability to the following quantity:
ï£¹
" d
#ï£®
Y
Y
B(Ï‡sa (H0 )) ï£»
p
Ï€
âˆ€Hd PÌƒK
(Hd ) â†’ b0 (s0 )
Ï€(atâˆ’1 |htâˆ’0 ) ï£°
(5)
d
B(Ï‡sa (Hd )
t=1
hs,ai

with B(Î±) =

Î“(Î±1 +...Â·+Î±k )
Î“(Î±1 )Â·...Â·Î“(Î±k )

the normalization term of a Dirichlet distribution with parametric vector Î±.

Proof. Via the weak law of large numbers, we have that the empirical mean of a random variable converges in
probability to its expectation.


Kd
1 X
p
InH =H (i) o â†’ E InH =H (i) o
d
d
Kd i=1
d
d

âˆ€Hd

This expectation can be rewritten as follows

 X


(i)
n
o
E I H =H (i) =
PÌƒ Ï€ Hd InH
d

d

(i)

(i)
d =Hd

o

= PÌƒ Ï€ (Hd )

(6)

Hd

where PÌƒ Ï€ (Hd ) denotes the (true, non-empirical) probability that the RS-BA-POMDP rollout generates full history
Hd . This is an expectation over the root sampled model DÌ‡:
Ë†


PÌƒ Ï€ Hd |DÌ‡ Dir(DÌ‡|Ï‡Ì‡)dDÌ‡
(7)
PÌƒ Ï€ (Hd ) =
"
#
Ë†
d
Y
=
Cons(H0 , Hd )
DÌ‡(st zt |stâˆ’1 , atâˆ’1 )Ï€(atâˆ’1 |htâˆ’1 ) Dir(DÌ‡|Ï‡Ì‡)dDÌ‡
(8)
t=1

"
= Cons(H0 , Hd )

d
Y

Ï€(atâˆ’1 |htâˆ’1 )

# Ë† " d
Y

t=1

#
DÌ‡(st zt |stâˆ’1 , atâˆ’1 ) Dir(DÌ‡|Ï‡Ì‡)dDÌ‡

!
(9)

t=1

Where Cons(H0 , Hd ) is a term that indicates whether (takes value 1 if) Hd is consistent with the full history at the
root H0 .1
1 An earlier version of this proof [anonymous] contained a term b (s ) instead of Cons(H , H ). This was incorrect since it failed to
0 0
0
d
recognize that this proof assumes H0 to be fixed. See also the remark on page 2.

4

Now we can exploit the fact that only the Dirichlet for the transitions specified by Hd matter.
#
Ë† "Y
d
DÌ‡(st zt |stâˆ’1 , atâˆ’1 ) Dir(DÌ‡|Ï‡0 )dDÌ‡

(10)

t=1

={split up the integral over one big vector into integrals over smaller vectors}
ï£¹
#ï£®
Ë†
Ë† "Y
d
Y
t ,zt
ï£°
...
DÌ‡sstâˆ’1
Dir(DÌ‡sa |Ï‡sa (H0 ))ï£» dDÌ‡s1 a1 . . . dDÌ‡s|S| a|A|
,atâˆ’1
t=1

(11)

hs,ai
0

z
={reorder the transition probabilities: âˆ†sas
(Hd )is the number of occurences of (s, a, s0 , z)in Hd }
Ï‡
ï£®
ï£¹ï£®
ï£¹
0z
Ë†
Ë† Y Y 
âˆ†sas
Y
(Hd )
0
Ï‡
sz
ï£»ï£°
... ï£°
DÌ‡sa
Dir(DÌ‡sa |Ï‡sa (H0 ))ï£» dDÌ‡s1 a1 . . . dDÌ‡s|S| a|A|
hs,ai hs0 ,zi

Ë†

Ë†

=

...

ï£®
Y Y 
ï£°
hs,ai

Ë†

Ë†

=

ï£®

...

ï£°
Ë†

=

ï£®

Y 

Ë†

=

...

ï£»ï£°

s0 z
DÌ‡sa

âˆ†Ï‡sas0 z (Hd )

ï£®

ï£­B(Ï‡Ì‡sa ) ï£°

Y 

ï£°

0

sz
DÌ‡sa

Y 

B(Ï‡Ì‡sa )

0

sz
DÌ‡sa

0z
Ï‡sas
âˆ’1
0

ï£¹
ï£» dDÌ‡s1 a1 . . . dDÌ‡s|S| a|A|

(13)

hs0 ,zi

ï£¹ï£¶ï£¹
0z
Y  0 Ï‡sas
âˆ’1
0
s
z
ï£»ï£¸ï£» dDÌ‡s1 a1 . . . dDÌ‡s|S| a|A|
ï£» ï£°B(Ï‡Ì‡sa )
DÌ‡sa
ï£¹ï£®

0z
âˆ†sas
(Hd )
Ï‡

(14)

ï£¹ï£®

ï£¹ï£¶ï£¹
0z
Y  0 Ï‡sas
âˆ’1
0
sz
ï£»ï£°
ï£»ï£¸ï£» dDÌ‡s1 a1 . . . dDÌ‡s|S| a|A|
DÌ‡sa

hs0 ,zi

(15)

hs0 ,zi

ï£®
Y

B(Ï‡Ì‡sa )

Y 

hs0 ,zi

hs,ai

Ë†

Y

hs0 ,zi

ï£«

ï£°

ï£¹ï£®
hs,ai

ï£­ï£°

Y

...

sz
DÌ‡sa

0z
âˆ†sas
(Hd )
Ï‡

ï£«ï£®

hs,ai

Ë†

0

hs0 ,zi

Y

(12)

hs,ai

0

sz
DÌ‡sa

0z
0z
Ï‡sas
âˆ’1+âˆ†sas
(Hd )
0
Ï‡

ï£¹
ï£» dDÌ‡s1 a1 . . . dDÌ‡s|S| a|A|

(16)

hs0 ,zi

hs,ai

Now we reverse the order of integration and multiplication, which is possible since the different s, a pairs over which
we integrate are disjoint.2 We obtain:
Y

=

B(Ï‡sa (H0 ))

Ë† Y 

0z
0z
Ï‡sas
+âˆ†sas
(Hd )âˆ’1
0
Ï‡
DÌ‡sa (s0 , z)
dDÌ‡sa

(17)

hs0 ,zi

hs,ai

={since we integrate over the entire vector DÌ‡sa , the integral equals 1/B(Ï‡sa (H0 ) + âˆ†sa
Ï‡ (Hd ))}
Y
1
B(Ï‡sa (H0 ))
B(Ï‡sa (H0 ) + âˆ†sa
Ï‡ (Hd ))

(18)

hs,ai

Y B(Ï‡sa (H0 ))
B(Ï‡sa (Hd ))

=

(19)

hs,ai

Therefore

#ï£®

ï£¹
Y B(Ï‡sa (H0 ))
ï£»,
PÌƒ Ï€ (Hd ) = Cons(H0 , Hd )
Ï€(at |ht ) ï£°
B(Ï‡sa (Hd ))
t=0
"dâˆ’1
Y

(20)

hs,ai

proving (5).
2 E.g,

consider two sets A1 =
X

2
X Y

a1 âˆˆA1 a2 âˆˆA2 i=1

n

ai =

a1 , a1

o

X

X

(1)

(2)

and A2 =

n
o
(1) (2) (3)
a2 , a2 , a2 . Equation (16) is of the same form as
(1) (1)

a1 a2 = a1 a2

(1) (2)

+ a1 a2

(1) (3)

+ a1 a2

(2) (1)

+ a1 a2

(2) (2)

+ a1 a2

(2) (3)

+ a1 a2

a1 âˆˆA1 a2 âˆˆA2




 


(1)
(2)
(3)
(2)
(1)
(2)
(3)
(1)
(2)
(1)
(2)
(3)
a2 + a2 + a2
+ a1
a2 + a2 + a2
= a1 + a1
a2 + a2 + a2
ï£¹ï£®
ï£¹
2
X
X
Y
X
=ï£°
a1 ï£» ï£°
a2 ï£» =
ai
(1)

= a1
ï£®

a1 âˆˆA1

a2 âˆˆA2

i=1 ai âˆˆAi

5

References
Morris H. DeGroot. Optimal Statistical Decisions. Wiley-Interscience, April 2004.

6

